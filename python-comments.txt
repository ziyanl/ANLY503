Version 3.6.0 of praw is outdated. Version 4.0.0 was released 1 day ago.
Hiring x3 Python Software Developers + (Visa Sponsorship) at Scurri

https://www.djangojobs.net/jobs/632/x3-python-software-developers-visa-sponsorship-scurri/
Any simple python coding job.

I work for an Atlanta based company called Amplify Technologies.  We're looking to fill three positions at the moment.


[Python/Django Developer](http://www.amplifynation.com/assets/pdf/Software_Engineer-Amplify.pdf)

[Site Reliability Engineer (SRE)](http://www.amplifynation.com/assets/pdf/Site_Reliability_Engineer-Amplify.pdf)    

[Technical Project Manager](http://www.amplifynation.com/assets/pdf/Technical_Project_Manager-Amplify.pdf)


I can honestly say that this company is one of the best companies that I have worked for. We're small (12 people currently), we have a fantastic startup culture, many great benefits detailed [here](http://www.amplifynation.com/), competitive compensation, a CEO with a history of success, and tons of freedom in the work place. 

Should you apply via the email in the PDFs, please reference this reddit post.

Please PM me with any questions.

Thanks!

Senior Python developer avaiable for remote work from GÃ¶teborg, Sweden (CET). Also capable web-frontend developer. [Portfolio](http://jacob414.plexical.com/portfolio-en.html), [GitHub](https://github.com/JacobOscarson). [Location](https://www.google.se/maps/place/Gothenburg/@57.7016454,11.6135144,10z/data=!3m1!4b1!4m5!3m4!1s0x464f8e67966c073f:0x4019078290e7c40!8m2!3d57.70887!4d11.97456?hl=en)
looking for remote part time python/django job.
Looking for remote job. Part or full-time.
Senior level: Django, Asyncio, PostgreSQL, MongoDB.
Ready for test job up to 8 hours. Hourly rate is 30-70$ depends on the project and work volume. PM.
Why the hell can't I find a job? I've been working with the same company as a freelancer making very little compared to most developers for the past year, but I haven't even been to an in-person interview in almost a year now. I feel like I'm good at what I do, but even jobs where I'm like "HOLY CRAP! THIS IS A PERFECT MATCH!" I get a form letter response saying "Thanks, but we're going with someone who's experience and skills are a better match." Like wtf? Is it because I didn't finish college? I only went for a year or two and didn't do very well, so I said screw it and went to one of those developer bootcamps instead. I also educated myself via online courses such as Treehouse. I'm located in Portland, OR.
I have a Python tool which scrapes a website, and conceptually I need the same type of tool but for another website. The HTML looks exposed, so I'd like the job to login and download a series of files. PM me.
looking for an intermediate python job, "sponsored visa" or "remotely". i have 3 years of experience and atm i am doing some side project with Golang, take a look at my linkedin profile:
https://www.linkedin.com/in/eslammostafa
We are hiring for a DevOps Engineer and Platform Engineer in Santa Fe, NM at OpenEye Scientific Software. Santa Fe is a city rich with art, music & food culture - as well as fantastic outdoor recreation (skiing, hiking, cycling). OpenEye is a small company with a fun and unique culture. There are numerous perks; here are a few examples: employees have their own private offices, free lunch, home Internet access, gym reimbursement, an on-premise doctor. 

Both positions are Python centric. We also use Django, Ansible, and AWS. http://www.eyesopen.com/careers

**Update: Still looking!**

I'm looking for a Python-oriented summer 2017 SWE internship, though I'm willing and able to learn any new language or technology you throw at me! Currently an undergraduate sophomore CS student at Penn State University. You can view my resume, GitHub and LinkedIn from my personal Github Page here: http://joshuarli.github.io/

If you're interested in hiring, we should definitely talk! Shoot me an email or PM! :)
Anyone mid-level Pythonista's here looking for a job in Singapore. 

I work for a HFT and we're looking for trading ops guys, relocation included if you don't live in Singapore currently (lots of Aussies in the office). It's like a tech firm so things are pretty chill.
Graduating in December. Searching for a software engineer position(in USA).
I am planning to start working around February 2017 in the Washington D.C. area. Does anybody know a good way to search for Python jobs by location?
ETS (educational testing service) is hiring two engineers (and probably a third one in a month or so, but it's not official yet) for the automated scoring group (read: NLP and speech processing):

[NLP/Speech](http://ets.pereless.com/careers/index.cfm?fuseaction=83080.viewjobdetail&CID=83080&JID=232678&type=&cfcend) (Princeton, NJ or San Francisco)

[Dialog, Multimodal, and Speech](http://ets.pereless.com/careers/index.cfm?fuseaction=83080.viewjobdetail&CID=83080&JID=232411&type=&cfcend) (San Francisco or Princeton, NJ)

Both positions are for the same general research group, but will have different focuses. While the job isn't really a "Python" job, it's mostly Python-related. It's one of the main languages used. The other being Java. Almost all text processing and machine learning/stats analysis-type work is done with Python, though.
Why not introduce option to add flair of `hiring` or `for hire` instead of single post for all job posts?
I'm working as a network engineer, I would like to find a job in network automation or SDN. I have intermediate knowledge of Python (3 years of experience with it) 
Looking for an entry/intermediate level remote job. I do not have any formal job experience in programming, but have been focusing all of my spare time trying to grow as a developer. I feel I am now ready to try to enter the field. 

I promise to show strong determination to learn any new skills, and my rates will be very reasonable as I am looking to gain any experience I can. 
Senior Web Developer (Python / Django) at Association of American Medical Colleges (AAMC)

See more at: 

https://www.djangojobs.net/jobs/630/senior-web-developer-python-django-association-of-american-medical-colleges-aamc/
Looking for an entry level job in the Philly area.
I am a programmer looking for remote job/projects. I am into Web Programming and Data Scraping. Check my site at http://adnansiddiqi.me

Thanks
I'm a senior data engineer at Clover Health: https://www.cloverhealth.com/en/about-us/careers

We're a new health insurance company operating in the Medicare Advantage (age 65+ or disabled) space and trying to operate as a technology company instead of a bureacracy. A lot of our work involves dealing with bureacratic data systems (like the federal government) and reconciling data against other data; there's also a ton of work around internal operational tools to optimize care management.

We're hiring application engineers, data engineers, and data scientists. Our stack is Python, PostgreSQL, and Javascript. We're doing a bunch of stuff with Apache Airflow and complex data pipelines.

All engineering positions are based in San Francisco, CA (with no remote). Right now, we're primarily hiring for mid and senior level positions but we might consider early level candidates.

PM me if you have questions or want to chat about Clover.
Looking for data analysis internship in California. 
I study ML, and other data courses in a LA college . 
Know MySQL, HTML,js,python. 
No related experience.
I'm searching for a junior C/C++/Python Embedded Software Developer position in Germany. I got a master in Embedded Systems in France (Paris) and had the opportunity to work in Japan and Germany for more than 3 years on low/high level projects (besides C/C++ and Python, I have an extensive experience with Golang). I have a preference for systems based on Linux.
Thank you.
My DevOps team is looking to add another engineer to our in-house team in San Francisco (downtown near Muni and BART with commuter benefits). We build automated deployment tools using Fabric + Cloudformation + AWS + Docker and more. 

I originally switched over from backend software engineer to come work for this company because they are doing some awesome work. 
Need an entry level job in India starting from January.
Hi All, 

I'm looking to connect with Python/Software Engineers for a contract position. 

Based in Coventry, UK for a largely known automotive company, they are looking for a strong Python professional who is competent with Hadoop, Machine Learning and Data Manipulation. 3-month rolling contract based on-site. 

Please contact me if this could be of interest to you and I can provide further information: rachael.smith@suitablecandidates.com. 

Thank you.
Senior from a private Midwest University that is graduating in May 2017. Looking for full-time work, willing to relocate. [Github] (https://github.com/solkaz) 
Graduating in December, need a job near Detroit
I am looking for freelance gigs related to machine learning, data analysis, web scraping, programming, and web development. I have used R and Python for data analysis and machine learning projects

I also have experience working on complex projects in C++

I have also worked on personal projects using Flask and Django to create web applications

PM for my portfolio
Loooking for Remote JOB
Writing a HTTP/2 server for my web framework.
Solving the cryptopals probelm sets, almost done with the second set
Writing some tools for Autodesk Maya
Calculating fuel addition and chemistry management schemes for nuclear molten salt reactors :D
I'm porting dropbox's zxcvbn library to python. There is a port already but it's not being maintained and is 4 years behind.
A Flask-driven Automated Parking System. It's open source so I am trying to get some good documentation in it.
Working on a propagation model of Gaussian beams. With added least square fit algorithm of experimental data. That's a first for me since I used to do all that in MatLab, but for this one I decided it was time to dig in numpy/scipy.

Spent like 2h trying to install scipy via pip, but finally gave up and installed Anaconda.
Writing a table tennis tournament management software. It also calculates the ratings of the players. GUI written with kivy running on Raspberry pi.
Some spectro-temporal speech analysis with a close look at phase-derivatives and phase-derivation methods. Also, I just recently switched back from Anaconda to plain old pip and virtualenv, and after some massaging of fish and Emacs, it works wonderfully. Oh, and looking forward to Matplotlib 2.0 and Python 3.6.
Stars Without Number RPG galaxy sector generator and map image creator.
I wrote myself a script last night/today that allows me to PM my Reddit bot account links to NHK Easy News articles, have it pull out the text and furigana, properly assemble everything into a pdf (which is harder than it sounds thanks to the furigana), and have that file immediately sent to my printer and deleted. I even set up a few optional arguments in the messages so I can change text size, or choose not to print and save it instead.

It's basically a manifestation of my studying anxiety, but I've used it a lot since I finished it today. Every time I hear my printer start up, I get super giddy because all I did was send a PM on Reddit a few minutes ago, and now I'm printing things.
I'm jumping into Python this week to help me with some daily task via SMS. Current hurdle is sifting through the options (API or not). Thus far, have a couple major firms looking attractive.

This is my voyage into 3.3+ after holding out on 2.7 for enterprise automation and validation.
Brainfuck interpreter !
Making a troll bot for IRC. 
I'm working on a discord bot that monitors prices of things on Amazon, I'm going to try to make it so it can monitor every item on wish lists, as well as monitoring individual items.
Digging through old projects, looking at stuff I wrote years ago, and trying to figure out WTF was I thinking.
I'm working on a program which should make it easier to fly a quadrotor whose position is known.

Right now I'm moving to a new computer, and because it requires a lot of manual setup I'm learning Docker to automate the whole thing. Might just use Ansible to install Docker and make everything really easy after a fresh install.
I'm teaching myself Python 3. Working at the moment on some data parsing/validation and hoping to extend that to updating it via web scraping.
I'm trying to wrap my head around how API's work using Reddit's API. I still haven't thought of a good/fun bot to make with it though. :/

Suggestions are welcome.
Working and finishing school projects and finals... But then playing with tensorflow on windows with gpu support. Hype! I've been dying to implement DQN to play atari games a la DeepMind paper.

I really want to have a solid foundation of experience by the time the Starcraft 2 AI playground is released. 
Lyrics are impressive but that speech synthesis is straight out of 1987
You are better off posting this to r/learnpython and asking how you can improve or what you can optimize. Everyone here just wants to criticize and not give back any solid feedback. Keep up the hard work!
Looks like a neural network wrote that code as well.  No organization whatsoever...
LOL that's impressive! Good job, you gave me a huge inspiration! Please keep improving :)
click bait title writing is on point at least 
This is a really neat idea because if you were to catalogue all the lyrics you could create a new rap in the style of Eminem or in the style of 2 Chainz (wow Google I said 2 Chainz and you know how to spell it, Now spell duck)
You should document the algorithm. How is it defining rhyme and meter? What is the neural net trained on? Is it picking existing lines or generating new ones?
Meh
This is sweet. Is there a way to run it without CUDA?
Moving towards Season 2 Episode 1 of Black Mirror I see! 

Hahaha thanks for this. Pretty awesome!
[deleted]
Trump, please.
You also need to install TwitterAPI. I didn't see a `requirements.txt` but if you could add one it would be much appreciated. 
This is long-awaited news for those of us constrained to the Windows ecosystem for reasons beyond our control.
Great news! The best OpenSource Erp!
Application platform. Nice. GPL3. No thanks.
> package and distribute my altered version of the open-source project to my other packages

It's best if you can avoid having a fork of cobrapy but rather your own package that sub-classes cobrapy classes and adds/changes functionality to those. That way, you won't have to adjust your fork every time the upstream changes (you also don't cause head-ache for the cobrapy project in case your fork would become very popular (: ). With your new package, consider making it a proper python package if you haven't already and let continuous integration service like [travis](https://docs.travis-ci.com/user/languages/python/) build/test and distribute the package for you (assuming your package is pure python, this is really quite straight-forward, just include a .travis.yml file and turn on automatic builds on push).

> package my extension, which depends on my altered open-source project, to my Flask project.

do the same as for your other package, and adjust your [setup.py](http://python-packaging.readthedocs.io/en/latest/dependencies.html) to make python include the dependency on install.

> upon updating something in the extension or open-source project code, be able to re-build my projects which depend on them (doesn't have to be fully-automatic, just sensible)

travis will take care of this for you. For the web-service you may consider bundling it as a [docker image](https://docs.docker.com/engine/tutorials/usingdocker/) hosted on docker cloud, travis can then also take care of updating that image (and auto-deploy it if you want). 

And, if you want, you are of course welcome to submit suggested changes to cobrapy, we might also be able to suggest alternative ways to accomplish what you want!

On the virtualenvs, I use one for each setup I intend to support, so one for each of py27, 34 and 35 but use the same for different packages. You may consider looking into using [tox](https://tox.readthedocs.io/en/latest/) for testing.


Just getting my ass into python myself, so take what I say with a grain of salt, but what I'd say is if you're providing your own package id look into what it takes to get it on PyPi. That would solve serving the package to the masses since that makes it easy to just pip install it. For virtualenv, I'd say keeping separate environments for both would be good, even though at first it may seem unneeded. You might have extra dependencies in your flask project that are extraneous for your package, so keeping them separate would help avoid weird dependencies. 
>package and distribute my altered version of cobrapy to my other packages

I assume you have a modified clone of `cobrapy`?  In that directory, run `pip install -e .`; this installs cobrapy as a sneaky reference to the current directory.  Everything works as normal, but your changes are instantly seen by anything else which imports cobrapy and any commandline or other tools.

If you mean 'distribute to other users', you should almost certainly get your changes merged upstream instead.  Can you work with the maintainers to make this faster?  Can you work around them to use the current version with reduced functionality?

>package my extension, which depends on my altered cobrapy, to my Flask project.

The best way to do this is an optional extension in `setup.py`, so you end up with `pip install mymodule[web_interface]` to install the whole thing.  See [here](https://packaging.python.org/installing/#installing-setuptools-extras) and [here](https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-extras-optional-features-with-their-own-dependencies) for details.

So I would wait for the changes to cobrapy, then `pip install yourextension[web_interface]` and run the flask server.

>upon updating something in the extension or open-source project code, be able to re-build my projects which depend on them (doesn't have to be fully-automatic, just sensible)

I'm not sure what you mean here.  `pip install -e .` might help, though you might need to do it with each virtualenv active!  I tend to use one environment for several projects, if they have common dependencies, precisely to minimise this kind of bookkeeping. 
You could consider [monkey patching](http://stackoverflow.com/questions/19545982/monkey-patching-a-class-in-another-module-in-python) with the [mock](https://pypi.python.org/pypi/mock) package in order to make your modifications. That way you don't have to fork cobrapy, and your modification can be available to everything you need it to be.

Come to think of it, I ended up patching Biopython for a similar reason, and it's going to be a while before the next version hits PyPI... This might not be a bad solution for that.
/r/learnpython
Interesting framework! Looks very useful! In the past, I developed such a framework for .NET, but I'll definitely try it out since I focus more on Python development than anything else these days.
Teaching beginners that bytes and strings are the same is an invalid cognitive shortcut and just outright bad education.
> 90% of programmers donât need to think about Unicode

Until they run their script/app/project in the real world and hit UnicodeDecodeError. 

Probably should be "90% of programmers don't think about Unicode, but probably should". 
I work for one of those enterprise shops, and because it was my call to make, I put in a plan for 2.7 -> 3.5 migration. I'm still debugging shit months later, and everything left is all tied to the string/unicode -> bytes/string conversion. In Python's defense, a substantial part of it is Django's fault. This whole "all uploads are bytes, fuck you" thing is a source of endless pain when dealing with libraries like configparser that expect files as input. Still, there comes a point when you realize that the pain is also a result of Python 3 abandoning Python 2's typing principles. Methods like .startswith() really should be agnostic to byte/string parameters. They both quack, they're both ducks.
I would like to see Shaws idea of exactly how it would work to run py2 in py3. If I concat a bytes and str in python2 code in a python3 vm, what should happen?

Do they work if the file "is" python2 but fail if the file "is" python3? And if so, how the hell do you tell?
A less entertaining, but probably more solid rebuttal than eevee's, however much I enjoyed that.
Rebutting Zed's article promises to become an enduring Pythonista pasttime.  
A coding language only improves when it is used. 

In this light, the Python ecosystem and community is being actively and deliberately harmed by those who promote continued adherence to Python2 and advocate against using Python3.
I've been lurking recently becausw I'm just starting to learn. I want to use Python for data analysis and visualization, maybe modelling and simulation. Does this affect me? Should I worry about learning 2.7?
It's refreshing to see some civility, finally. And the author actually addressed the points in Zed's Shaw's article while avoiding jumping on the whole Turing-completeness thing.

One thing, though, I would have liked to have seen addressed is whether Python 2 or Python 3 is better for beginners, which is actually where Zed Shaw was coming from. 

Also, sure it's difficult to recommend an EOL language, but to a beginner who just got their first programming job where Python 2 is the language used in the company, telling the beginner "You shouldn't use Python 2 because X, Y, and Z" isn't helpful -- and doesn't serve the beginner (who probably doesn't have a choice). And there is heaps of legacy Python 2 code, believe it or not, as well as companies that use them. I'm in one. 
> 90% of programmers don't ~~need to~~ think about Unicode.

FTFY.

I try never to care about Unicode... most things I do with python are little tools to ease some private task of my own.  And yet... Unicode has bitten me more times than I can remember.  If it had just been in python from the beginning a lot of those bites would not have happened.  So now, even though I don't care about Unicode... I care about Unicode.

Incidentally the biggest nightmare I have is with python's own `struct` module -- which itself doesn't seem to know the difference between bytes and strings (but perhaps it's me, or perhaps I'm using some older version of python 3).
Promising to keep 2.7 as a stable target makes it highly attractive. Coding costs are mostly maintenance. If you went to python3 you get to recompile your extensions every year and you have to keep doing it as each 3.(N-1) is declared dead. Six year old .pyd/.so extensions for 2.7 still work now. 
The killer feature of 2.7 is long term binary compatibility. 
Crossposting my comment in the site:

The Python 2 -> Python 3 transition was made in a terrible way, it almost killed the languageâ¦

The only change that made it backward incompatible was to make strings unicode by default. They should have added a transitional string (something like strbytes) and then 2to3 would just add parenthesis for print, // for /, and make every string âstrbytesâ.

Anyhow, I think Python 3 is a better language (it is where all Python progress happened in the last decade after all), and itâs finally flourishing. By 2020 debian and red hat will ship Python 3 by default, facebook already uses Python 3 by default, Google is transitioning to Python 3 (web2py is finally being ported to Python 3) â in the end everyone will be on Python 3+ (and by everyone I mean 85% of active Python devs).

About formatting strings, I do not think there is âtoo many waysâ of doing it.

The new way should be the default, and itâs just a shortcut for â.formatâ. Sometimes you cannot use fâstrings, maybe you want to use a prepared string that codifies the format, and then you should use the unsugared â.formatâ. The percent way should be used when you want to treat bytes and strings more or less equally (it would be perfect for the âstrbyte compatibility stringâ, but alas â that does not exist).



My _only_ case against Python 3 is that RHEL/CentOS isn't using it by default yet.
Most nerds are very tolerant and accepting, but see someone outspoken with a strong opinion and they might think "Hey, be tolerant like I am loudmouth!"

So, I can see why he draws a little fire.

That said, I think zed shaw has a couple good points.

python is wonderful.  but python 3 is chaotic.

There is lots of wonderful stuff written in python, but a lot of it breaks on python 3, either directly or indirectly.

I am reminded of an old [Joel on Software article](http://www.joelonsoftware.com/articles/fog0000000069.html) that is full of opinion, but also full of wisdom.

Basically he says throwing stuff out and starting over is bad.

And I think the python 2 -> 3 broke this rule.

"I don't like this, I'm not going to run it."

Who said that?  Both Zed Shaw  AND  python 3.
I wish there was more of a case FOR Python 3.
Why does everyone only think about strings and the few applications Python is already in?

The whole "divide is an integer" part of python 2 is a complete non-starter for any scientific work.
Anyone here available to be a code mentor?
Not making v2 and v3 compatible was not an amazing decision. We python programmers lost due to this. We could all be using new version of the language we so loved instead of dreading to make that switch. The main problem is that python3 does not have enough features to make us want to switch. I use a lot of unicode, I was hoping python3 would have as much support as Java. Whenever I need to handle unicode I just use Java, not worth the hassle.
If only python would support something line " # -*- version: 2.4 2.9 -*- " and then make python install the version needed automatically. 
He forgot to mention that not all new programmers are taught in English so his 10% is meaningless,  especially for people who are taught in languages that use unicode. And it is a pain in the ads to work with unicode. It is that and the amount of libraries available that make python 2 the best choice for beginners. (BTW,  my first programming language was python )
[deleted]
/r/learnpython is the right place to post such questions. Please read the sidebar. And consider posting some code so that people can help you out!
Belongs on /r/django (although it is hardly news anymore)
I'd say the number one skill is the ability to write medium.com blog posts, or generate other content spam  trying to capitalise on the 'everything is data science' fad.
Stop spamming Reddit
Data['DepartureBoard'][Departure'] seems to be a list, not a dict. So just iterate over each of its items:

departure_exist = False
For departure in Data['DepartureBoard'][Departure']:
    If departure['name'] == desired_name:
        departure_exist = True
You don't need a for loop: using any() and a generator expression:

    departure_exist = any(d.get('name') == desired_name for d in Data['DepartureBoard']['Departure'].values())

Remove .values() if it was actually a list instead of a dict.


A list will use all the memory it requires; a generator will use only the memory necessary for one element (well, more or less, but basically this).

Sure, if you're dealing with 10 or so elements, that difference doesn't make much... erm... difference. But when you're dealing with 100,000 elements (or even more), that makes a huge difference (not to mention, most algorithms would require creating the list of 100,000 elements and the process it instead of "build one, process one, repeat").
/r/learnpython
There is a rule of thumb when using generators and this is what other languages call "lazy evaluation". When you have large set of results where you don't know if you will need all of them. This also makes yield a great tool to write callbacks or recursive functions. yield is not easy to master and you need to study a few real life scenarios in order to fully understand it.

I pasted the same thing on another similar post.
https://github.com/crazyguitar/pysheeet/blob/master/docs/notes/python-generator.rst
I came here somehow convinced it was a question about lambda instead of yield. Now I'm disappointed...
    def big_list_of_numbers():
        ''' Returns a list of a billion numbers.  Uses a lot of memory to do it '''
        i=1
        my_list=[]
        while True:
            my_list.append(i)
            i+=1
            if i >= 1000000000:
                return my_list

    def generator_of_numbers():
        ''' Returns a billion numbers.  Uses a tiny amount of memory to do it. '''
        i=1
        while True:
            yield i
            i+=1
            if i >= 1000000000:
                return
    
    # Run the below at your own risk, they will use a lot of system resources.
    for i in big_list_of_numbers():
        # do nothing, just demonstrate list vs. yield
        pass
        # This will probably throw a MemoryError after consuming a couple GB of memory

    for i in generator_of_numbers():
        pass
        # This will tie up the CPU for a minute or so but not use much memory
http://www.dabeaz.com/generators/
As throwaway143259 said, please post such questions to /r/learnpython. Please read the instructions in the sidebar.
"Yield" can to used to greatly simply your code.  See for example Ned Batchelder's excellent [How to loop like a native](https://www.youtube.com/watch?v=EnSu9hHGq5o)
Everytime this domain is linked, my amazement is renewed that there is such a site with so much information and yet no search.

I am so petty that I refuse to visit that domain based entirely on the lack of this feature.
How doest it works?

I checked the Django downloads count from here https://bigquery.cloud.google.com/dataset/the-psf:pypi


    SELECT count(*)
    FROM
      TABLE_DATE_RANGE(
        [the-psf:pypi.downloads],
        TIMESTAMP("20161101"),
        TIMESTAMP("20161130")
      )
    WHERE file.project='django'
     and details.installer.name='pip'
     and file.filename='Django-1.10.3-py2.py3-none-any.whl'


It gives me 313370, while your service shows only 50788
    return [(True if v > boundary else False) for v in values]

... 

    return [v > boundary for v in values] 
Coupon Save 100% . 
This course is a one-stop-shop for everything youâll need to know to get started with Python, along with a few incentives
The app is very simple and has limited features:

- User signup (with invite code)
- Messaging and secret/sneaky messaging (with email notifications)
- Gallery
- Admin features - Drawing names, Sending mass emails

Check screenshots [here](http://avi.im/della/#screenshots).
That's pretty funny, [I recently finished working on a Python-powered Reddit bot for sending anonymous messages to people in a Secret Santa exchange](https://github.com/WolfgangAxel/ClosetSantaMessagingBot). It's just that time of year I guess.
The unpacking operators are much more versatile than this post describes * can unpack any iterable and ** can unpack any mapping that implements `.keys()` and `.__getitem__()`.
I would say it can be long, but pretty easy.
Depends how experienced you are with Python and Flask and how much features you can pull down from PyPi (authentication, sqlalchemy etc).
Did you code it or just use a template from http://www.question2answer.org/ ? Hard is a relative term
I'd recommend django (maybe). I haven't gotten to into sqlalchemy so maybe I'm off base, but djangos ORM seems much more powerful. Sadly I haven't found a simple way to decouple it and use it in other projects.
Hey, Reddit! So previously when I've given out free codes for a period, afterwards people will message me since they missed out. I would give out free codes to people who messaged me, but this time around I told myself that this is how I make my living now (I left my software dev job two years ago to write full time) and I should be taking it seriously.

So, I won't give out codes once Monday ends. However, you can use this code to knock off 80% from the normal price down to $10: https://www.udemy.com/automate/?couponCode=FOR_LIKE_TEN_BUCKS

Good luck! Keep coding, keep learning! 
/u/AlSweigart

A while ago when this book came out (and later the course, which you also provided for free) I worked through the whole thing, and it really gave me a solid foundation in Python. I was comfortable with basic syntax and I had toyed with some simple scripts before, but not enough. Since then I've gotten a software engineer job where I code in Python, and I'm in the Georgia Tech online MS CS program (finishing my first semester), where I also mostly code in Python. And it's your book that gave me the all-important push toward self confidence in the language. 

I just want to say: Thanks!
Thanks for all your work u/AlSweigart, love your content!
Currently I'm working with the book (I'm totally into it). I wouldn't even dream of possibility to take an additional video course. Big thanks!
its not free only for today, right? once i've made the account and have the course i can do it any time in future ?
Thanks! Signed up.
Thanks /u/AlSweigart. Love your books! Can't wait to go through the video course.
As someone who has worked through the book and videos, I just want to say thank you. I hope you know that this course and book really set me on a new direction in life!
You should tweet about this so I can retweet you.
I can't recommend this course high enough.  I have to say Al is one hell of a good writer. Automate the Boring Stuff is a website I tell all my friends interested in learning python about.  I know 3 people who have gotten started and stuck with it thanks to how Al explains things.  If you have the time do it!

Also, thanks again Al, your work is appreciated.

edit:  run together sentences and various sundry changes that I don't care if you know about

fuck yeah! Thank you!
"Experienced software engineers who are already familiar with Python and the modules the course covers can skip this course."
Does anyone know how long it takes to get a refund? I just purchased this course a few days ago.
Awesome! Signing up ASAP!
Thanks! :)
Signed up thanks 
Thanks a lot!
Thank you!
Well poop. I just paid for it last week.
Thanks for the give OP!
Just got to NC for almost a month of work. This is going to fill hotel time.
thanks a looot ! 
xoxo 
Thanks a lot!
Wowee Zowee Nifty Keen, Thanks!

Thanks a lot. I was actually looking at automating some tasks. While I'm already a decent programmer it's always helpful to pick up some extra knowledge.
Love this content!
Signed up, thanks a lot OP! 
Thank you!
Thanks! Just signed up and used the code
how do I download it?! (will i still ahve acess tomorrow?!)
Awesome! I love free stuff. I bought a couple NodeJS/React courses on Udemy over their black friday sale, and was very happy with all the content. Seems like most of the instructors on that sight have put together great courses. Thank you very much, will be digging into it over the holidays :)
I bought this book not long ago. I struggle with studying at home but I'm determined to read the book cover to cover. I can recommend this book if you were always interested in Python but never got around to learning it. 
This is great. Thanks for the heads up! 
Thanks!
What kinda keyboard is that? Sounds like blues. 
Got it! Thank you reddit! 
Thank you!
Thanks this is great. 
I really appreciate it! Just started reading the book and this will make a great companion. You sir, are the man!
How long it takes to finish this?
Thanks 
I'm planning to buy the book with 13 $ fees. Did the book price and its shipping fees are worth it? 
Thank you so much! It's been on my back burner for a while. Maybe I'll open it now!
FYI, this coupon has now expired.
Coupon expired :(
This is the only Udemy course that I have finished from start to finish. Thank you so much for your work!
Aww man... Missed it by a few hours.
Just want to say thanks for the awesome content you produce! Automate the boring stuff is a perfect approach to learning a new language, while highlighting the areas where python excels at the same time.
Damn, missed it. 
Thank you sir. I just signed up for your "Automate the Boring Stuff with Python" 

Side note: While I was at it, I picked up another Udemy course I've been curious about, "Black Algo Trading: Build Your Trading Robot"

I found a similar Udemy coupon
http://onlinecoursespro.com/black-algo-trading-build-your-trading-robot-coupon/
Its already free....
Free? I am on the Udemy site right now and the course costs $280 (normally $750).
Step 1) Get a throwaway mail

Step 2) Register

Step 3) Find a script on github that will download the course for you

Step 4) Enter your email and password

Step 5) Wait about 30mins (times may vary)

Step 6) Never actually watch the cource cuz aint nobody got time for dat shit
You are recursing to fix invalid input. Please don't, python doesn't support recursion well (there is a max stack size, each function call adds to that)

https://gist.github.com/SilverWingedSeraph/e17468d747c7053c18e9964e3f91cece#file-pronouns-py-L47-L51 this suffers from copy-pasting, best solution would be to reduce the branching there

You are centering your code all around the existence of a class, so you might as well have pronoun creation as part of the class

    Pronouns('he')
    Pronouns('she')
    Pronouns('they')
    Pronouns(a, b, c)
    Pronouns(a, b, c, e, f)

https://gist.github.com/SilverWingedSeraph/e17468d747c7053c18e9964e3f91cece#file-pronouns-py-L76

else and elif after returning branches, unneeded.

- - -

Since this is bordering on the realm of localization, having something that would work well with gettext would probably be a more practical angle
You don't really need those plus signs in the last statement. A group of strings separated by newlines surrounded by parentheses will be joined implicitly:

    >>> ('Hello '
    ... 'World!')
    'Hello World!'
you should support non-binary pronouns before you offend someone!
Uhhh, that kind of thing is generally not allowed in games. If it's a decent game they'll have methods in place to prevent you from doing this.
You're making your life a lot harder by wanting the keyboard and mouse controls to operate in the background. I suppose you could run the bot with a headless browser like PhantomJS.

I think this might be a bridge too far if you are a beginner. Assuming you could capture and parse the gamestate from Wireshark (not a guarantee), at a glance, the game still looks pretty complicated, you might want to step back and look at similar projects people have undertaken with simpler games. 

This is a paper (written for an undergraduate course assignment) from Stanford about using reinforcement learning to program a Mario AI bot - it's probably as accessible a paper as you will find for that particular problem domain.
http://cs229.stanford.edu/proj2012/LiaoYiYang-RLtoPlayMario.pdf

If you search Google Scholar for "Mario AI Competition" you'll find lots of other papers. There used to be a Python client for the competition, but since it's lapsed, you might need to go dumpster diving in Google to find a copy.

If this is a bit much (and it probably is), you should start with a simple game like Pong and work your way up. 
At that point you might as well first try decompiling and reverse engineering the jar file. Unless it's very basic communications in a non custom message type it will get difficult fast.
Can you tell us the specific packages you're trying to install and their versions?
Switch to conda now and never look back. 
I don't really see how this should be presented as a comparison. They are just simply 2 different tools, not much in common.
This is comparing apples to oranges.  You may as well compare Django to Jinja2.

BS4 is a library for parsing HTML/XML.  It has minimal/limited functionality for anything outside of that.  You give it HTML, it gives you the stuff out.  It's similar to the Scrapy team's `parsel` library.

Scrapy is an entire framework for crawling and parsing websites.  Unlike BS4, it will handle authentication, concurrency, headers, redirects/retries, site filtering (no duplicates requests, no unwanted sites/domains), and throttling.  It's  also extensible with Extensions/Middlewares, and implements functionality to keep large projects sane and organized (Item loaders, Item pipelines, Logging). 

As for the article itself, it's full of misleading information:

> Scrapy handles the cookies for you out of the box but LinkedIn [... has cookies] which will tell the server validating the request's cookies that something is not OK   
[...]  
With BeautifulSoup and requests you can customize this behavior. Naturally this involves more coding but you have everything in the tip of your fingers to take care about all the cookies you want to send.

You also have this functionality with Scrapy via a middleware, which would be as easy or easier to implement then `requests` cookie jar manipulation.

>Most websites do not use "tricky" cookies like we have seen previously but count incoming requests from IP addresses in a given time-frame [...] because Scrapy does multiple requests at a time you can easily encounter this problem.

>If this happens try to [...] change the DOWNLOAD_DELAY parameter again in the settings.py to a bigger value [...] this makes your scraping slower but you don't [...] get blocked which in the end makes your scraping faster.

> With BeautifulSoup there is no such problem by default because such applications run in one thread and block until the response is there from the server and the parsing is done. 

This isn't a feature! Using blocking operations for fetching data **is one of the worst things you can do for crawling**.  With crawling, there is a very long period of time you're waiting on responses to requests with you could be parsing and outputting data, queueing up other requests.  This would be, by far, the biggest bottleneck of the project.

With Scrapy you have complete control over delays and concurrency, and there's no reason to say this is a downside.
In general the article is light on code examples, and reflects a significant degree of misunderstanding of even basic functionality of BeautifulSoup. There are only the most basic BeautifulSoup examples. And they have problems. And seemingly no Scrapy examples at all.

I just don't get what he is talking about here:

>**Just the one or the other?**

>If you ask yourself: "Which one shall I use? I like how BeautifulSoup treats parsing but I love the ways Scrapy leverages my work with less code." In this case my answer is: use both. Because Scrapy is a website scraper it uses content extractors. And because BeautifulSoup is a content extractor you can include it in your project to do the scraping with this library instead of built-in solutions:

    import scrapy
    from bs4 import BeautifulSoup
    def parse(self, response):
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.title

>"**As you can see** you can mix both approaches together so you do not have to learn a new syntax if you just want to switch over to Scrapy


I don't see. He imports Scrapy, and then parses a title tag using BeautifulSoup alone. No Scrapy involved. Also, the presence of the "self" argument is incorrect. There is no class definition. The indentation does not even imply the existence of a class.

Also, what is this in the section titled **"Throttling"**?

>With BeautifulSoup there is no such problem [of getting blocked by the server due to concurrent requests] by default because such applications run in one thread and block until the response is there from the server and the parsing is done. Naturally sometimes this can cause troubles if you have a fast internet connection and computer and you can gather and process information really fast and you get blocked. To avoid this you have to take care manually: you can add some sleep into your code for example between getting the website contents and extracting the information:

    def scrape(url):
        soup = BeautifulSoup(urlopen(url), 'html.parser')
        sleep(3)
        for article in soup.find_all('div', class_='ckt-article'):

>In the example above we wait 3 seconds before we extract the contents. I know this can be slow but sometimes it is faster than a "working for 5 minutes -- getting banned for 24 hours -- working for 5 minutes -- getting banned ..." almost endless loop.

So. The sleep is pointless, and does nothing. The extraction takes place after the data has been downloaded already. You grabbed the data at whatever rate you could on a single threaded process from a single internet connection (unlikely to result in some kind of server error unless you structure your request to ask for a huge number of items and the server limits the response time or something)... and then you just wait before you start to organize it on your disk. Parsing takes place locally, not on the server.

Those are, by the way, the only two code examples. Also, what is with the cut-off for loop at the end? Why not just finish the example?

I don't mean to belittle the author, but he or she should examine what it is that they were trying to achieve, and ask themselves if they are willing to put in the effort to really learn the material. These examples strike me as having been copied from somewhere without comprehension.
Hey man,

You'll possibly want to x-post to r/networking as there's more of us who use python there for automating network tasks. 

Having worked with the major vendor in my state who uses Allworx everywhere, I'm not sure if they can even be SSH'd to or have a very well-documented API (the field techs doing the installs just kind of winged it to make it work). 

I'd look into how Netmiko works with the cisco/juniper/etc equipment and go from there. I know people use python's expect toolset to make their appliances work, and Kirk Byers probably used something like that for his Netmiko library. 

Paramiko may be generic enough to help with what you need.

Basically, I'd approach it like this (I do this with Avaya configs):

* Find out how the device stores the configuration

* Use python to take inputs from a database/csv/raw text and make a 'baseline' or even completed configuration file.

* Toss it up on the PBX, reboot and bam!

A quick google search gave me absolutely nothing in the way of tools for automating or syncronizing Allworx deployments.
You might benefit from working within an existing framework for automation like Ansible or Salt. They are both built in Python, and both the tools themselves and the communities around them have expertise about doing X on dozens of servers, for many different values of X. Look at how they handle network devices such as switches, routers, or load balancers, and see if you can imitate that.

It may seem like a big cognitive load to learn how a big project built on Python does things, rather than just building on Python yourself, but the stability and maintainability you stand to gain are worth it, imo.
/u/jsisto ,

As the downvote seems to imply (not from me), this isn't really the right subreddit for this kind of post. /r/learnpython would be a much better bet.

That said, congratulations on writing your first script. Python is a great skill to learn. After looking at your script, I had a couple of ideas on how to simplify it and improve the structure.

https://gist.github.com/anonymous/3251ae77ee75c066e37ff38e182065c9

Although I didn't use it in the above script (for simplicity), you might want to look into [`requests`](http://docs.python-requests.org/en/master/) instead of `urllib` (it's just a nicer way of making html requests).

---
EDIT:

Just to show an example of using `requests`, only the top of the gist needs to be changed (remove imports of `json` and `urllib` and slightly modify `get_bitcoin_price`):

    from __future__ import print_function
    from datetime import datetime, timedelta
    from requests import get
    
    
    def get_bitcoin_price(endpoint):
        req = get('http://api.coindesk.com/v1/bpi/{}'.format(endpoint))
        return req.json()

At first, I didn't like the '(s)' here:

    matchResult = match.search(s)

But then I thought it was cool cause it  kinda codes it more.

Overall, good job. Not bad for a first project, but, then again, I am not a Python Dev yet.
Yeah I could have definitely used a better name for that string to make my script more readable. Thank you for the input
Hi .. I am starting to learn python and just came across your post . Can you provide pointers to the resources you used to study python ? TIA
> Originally inspired from

You wrote like 3 meaningful short functions on top of the original code. 

Uploading someone's private images to a file sharing site only to be compatible with ONE of many deep learning apis is also concerning.


edit: oh it's you who inspired you. sorry for the first paragraph then. i thought it's someone else.
This really belongs on /r/learnpython.

The usual way for doing this is to write an infinite loop that you break out of when an acceptable value is found, such as:

    while True:
        temp = float(raw_input('Enter a value: '))
        if 0 <= temp <= 100:
            break
        print('Try again')

There are no statements underneath the while: statement to re-prompt the user for additional input to re-assign a new value to temp.
There's an art to writing regular expressions that are fast.  For example, that `.*?` at the beginning isn't doing anything useful and is just eating up time.  And you can combine them into one regex if you can make a few concessions:

    tmp_links = [m.group(2) for m in re.finditer(r'(?:URL|window\.location)\s*=\s*([\'"])([^\'"]+)\1', rstring)]

This will match either quoting style, and will reject mixed quotes (e.g. `URL='foo"` won't match) but it won't catch embedded quotes, such as `URL='foo"bar'`.  If these are URLs, chances are that embedded quotes would be urlencoded anyway, so that's probably not an issue.  But even if it is, you can at least reduce this to two passes from four, which will halve the time it takes from what you have currently.


Please keep in mind that html can not be properly parsed with regex. It's fine for a hack, but don't do this anywhere where the results can compromise security.
I think compiling the regex before using it is a little faster.
i.e.


    rx = re.compile('myregex')
    re.findall(rx, rstring)


Are you parsing a whole html file or just javascript?

Parsing html with regex is generally a bad idea.

If you're parsing a whole html file, it's almost definitely better to parse it with something like lxml and only run your regex on the actual javascript code.

Is your string javascript? If  so, you might want to give a javascript parser a shot, for example https://github.com/rspivak/slimit. 
You should post this in /r/learnpython
You'll need to show where you are calling `ApplicationForm` as well.
"... If wait is False then this method will return immediately and the resources associated with the executor will be freed when all pending futures are done executing. Regardless of the value of wait, the entire Python program will not exit until all pending futures are done executing." 
Also, you can try cancel() method of a Future object, or just raise an exception with exception() method of the same object.
Your question is bad written...

VBA is easier to use with excel, but Python is a great language for writing automating applications/scripts.

For excel you have [XlsxWriter](https://xlsxwriter.readthedocs.io/) and [Xlwings](https://www.xlwings.org/). Your undo remark is wrong, using Python or AHK does not make you "lose the undo option" - it will depend on how you write the code and the features the library support.

AHK is easier for writing game bots, but Python has several gui automation libraries - like PyAutoGui. A cool tutorial on making a flash game bot is [this one](http://inventwithpython.com/blog/2014/12/17/programming-a-bot-to-play-the-sushi-go-round-flash-game/)

Profissional game bots are usually written in C++, or C#, for better low-level integration with Windows, and easier injections. In that case, you can use Cython that integrates directly with C.
Chapter 12 of https://automatetheboringstuff.com/ is about working with Excel using Python.
**Re: VBA**  
VBA is really restricted in what it can be used for.  It's almost strictly for MS Office Apps.  With that said, it's one of the best things you can use if the interaction you want is almost entirely *inside* the application, and can bring a lot of power.

**Re:AHK**  
AHK automates mouse and keystrokes.  It is first and foremost a macro program.  Yes, it can do a lot more then that, but that's where it's primary focus and inspiration comes from.  

It's a great productivity tool, but it may be lacking for games.  A lot of games purposefully stop hooks and interaction with them, and a lot of extra work goes into writing the most basic functionality inside of games.  It might be easier for your game if it does work, because you just "think" in terms of how you'd need to interact (instead of trying to "think like a programmer").

**Re: Python**  
Powerful and versatile.  Just read this subreddit for a while to see what it can do.
https://imgur.com/a/JB7Fv
Have you ever done something on your computer, and thought to yourself, 'Wow, that was harder than it should have been'?  That's what scripting languages like Python were originally designed for, and is typically a great way to get started.  

One of my first projects was using Python to rename a bunch of files on my hard drive.  There were programs out there that did it, but none that did exactly what I wanted, and it was driving me crazy.  So I took one of the programs which had been coded in Python and changed it so that it worked for me.

Python can do so much more than that, though; it's a phenomenal tool for STEM research & data visualization, it's a web development platform, it's all kinds of things!

But you've got to find something that's interesting to you, for whatever reason, and start using Python.  Just like with a spoken language, if you're not using it regularly you will soon forget it.
Hojing, can you elaborate on what "*this*" is?
Well what are you interested in? Machine learning? Web development? Automated processes? Whatever you want, there's frameworks for it and tutorials for how to use them.
Have a browse, see if there are any projects you're interested in.

https://github.com/trending/python

When you find one that's interesting, read it carefully and help them out by writing some unit tests, and/or pydocs.
start with small and useful scripts for you own use.
This [book] (https://automatetheboringstuff.com/) may be useful 
This isn't a guide for beginners, and it isn't a a learning resource at all, as it's not actually teaching anything.  It's more of an introductory showcase with a couple tasks.

I would advise anyone looking to start with Scrapy to skip this and go to the [Scrapy docs](https://doc.scrapy.org/en/latest/).  It's a longer read, but it will actually equip you do write a functional spider/scraper.

Your project is missing key points every beginner should know, including (but not limited to):

- Scrapy core components/functionality, including information on what the settings file (`settings.py`), Items, Pipelines, Middlewares, etc. (***this should all be the first thing new people learn so they understand how Scrapy is doing what it does***).
- No information is provided on concepts and methods that are crucial to Scrapy, such as callbacks, selectors, itemloaders, requests, responses, etc.  
- No information is provided on the command line arguments.  Furthermore, those you do provide won't even work (you suggest they run a spider named 'hm', which doesn't exist, before you've even talked about the code it would run if it did).  None of the commands are explained, and new people will have no idea what's going on.

Worse then neglecting all of that, ***your project teaches people the wrong way to do things***.  Of note:  

- The variable `entry` isn't used, you implemented it by overriding `start_requests`, which you never explained. Why do this at all?  Just hard code the `start_urls` to the URL you want.
- You don't use the default callback of `parse` for starting pages, instead opting for `parse_entry_page`, and again, callbacks aren't explained at all.  Anything trying this with their own spider will fail.
- You instruct people that `TaskID` is both common and important, but fail to indicate it's not used in any Spider except your own (and you fail to explain how)
- You talk briefly about the `scrapy.Item` class, and try and explain that all data should be dumped as a dictionary into a `scrapy.Field` called `data`.  This is absolutely ridiculous, and not how items should be explained to a beginner. 
- You use global selectors and load what would be lengthy lists of items/data on a real page.  All because you fail to use items properly, or itemloaders.
- Lies about writing tests, saying there's no good way, when there are in fact -- [Spider Contracts](https://doc.scrapy.org/en/latest/topics/contracts.html?highlight=contracts)
- You recommend bad logging practices (log a single event, broken up onto multiple lines; ans dumping the entire HTML source to a log file under the info level; etc.) 

Add to this all of typos ("becuase", "scrawl", "hsave", "taskls", "souce", etc.) and poor English* and you have a document that's hard to get through and understand, and worse for you if you do. 

^(*_I appreciate that you're not a  native English speaker, but that doesn't detract from the difficulty in reading through the documentation_)
DID YOU JUST WEAKLY TYPE MY GENDER?
You're using an if-else when you should use an if-elif-else abort/retry/fail. Don't assume that if someone isn't female that they're male. I mean that in the logical sense, not in the gender-is-a-social-construct sense. 

Depending your country/context though, you might want to add non-binary options, though. 
So much for input validation.
I'm just curious about your code now.. :)
A `while True break` loop could help you here.

    # You may want to sanitize the input from the user to make it one case. 
    # Or use something like str.lower while doing comparisons.
    while True:
        choice = raw_input('What is your gender? ')
        if choice == 'm' or choice == 'M':
            # do something!
            gender = 'm'
            break
        elif choice == 'f' or choice == 'F':
            # do something else!
            gender = 'f'
            break
         else:
            pass
    
â¦ I wish I had a high-resolution display.
M/F/Apache Helicopter?
If you want some help writing your text-based game, I'd be glad to help. I've got [some experience](https://www.bitmonga.me/web-client).
Sorry to ask a kind of off-topic question but what IDE are you using? This looks like InteliJ or Android Studio but for Python?
What IDE is that?
Here's the UK Government's advice on asking users for gender: https://www.gov.uk/service-manual/user-centred-design/resources/patterns/gender-and-sex.html
If you really want to force a gender on a game player, in order to support a plot twist, do it like Infocom did it in *Leather Goddess of Phoebe*. Otherwise drop the question entirely, unless you need the statistics for advertisers.

How to make this easier: take gender as a string, not a boolean. Solves all your problems and makes your game not trans-exclusionary. Nowadays if I see something like that I drop the game like a hot block of tar.
Very interesting! The article seems to end rather abruptly though, with a heading? 
Looks like a fascinating article, but I had to come back to reddit to comment before continuing past the first code block: The code blocks aren't monospaced!
This is fabulous, looking into it right now. If I understood it's human readable constraints. 
Any thoughts about the performance of the library? Let's say I want to embed it in a pyspark application, will it be efficient "enough"?
I don't really see this simplifying this much at all.  Assuming we stick to the same data structures, we could easily write:

    >>> parent_child = {"Homer": ("Bart", "Lisa", "Maggie"), "Marge": ("Bart", "Lisa", "Maggie"), "Abe": ("Homer",) }
    >>> barts_parents = [x for x in parent_child if 'Bart' in parent_child[x]]
    >>> barts_grandparents = [x for x in parent_child for y in barts_parents if y in parent_child[x]]

Throwing together a quick generator would make creating each list even shorter. Furthermore, looking at your later big example, the same functionality is reproduced with Python's simple logic:

    def validate_order(order):

        def fetch_espresso_machine():
            valid_drinks = {'drip': ('sm', 'md', 'lg', 'xl'), 
                            'latte': ('sm', 'md', 'lg', 'xl'),
                            'americano': ('sm', 'md', 'lg', 'xl'),
                            'cappucino': ('sm', 'md', 'lg'),
                            'espresso': ('sm', 'md')}
            drinks_with_milk = ['drip', 'latte', 'cappucino']

            drink = order.get('drink')
            if not drink:
                raise ValidationError("Missing required drink")

            drink_type = drink.get('drink_type')
            drink_size = drink.get('size')
            drink_extras = drink.setdefault('extras', {})

            # Our rules
            if any((drink_type not in valid_drinks, 
                    drink_size not in valid_drinks.get(drink_type),
                    drink_type not in drinks_with_milk if "milk_type" in drink_extras else False)):
                raise ValidationError("Drink size too large for drink type or milk included in non milk drink")
            return True

        def fetch_pastry_counter(order):
            pass

        valid_destinations = ['espresso_machine', 'pastry_counter']
        if order.get('order_destination') not in valid_destinations:
            raise ValidationError("Valid destination not present")
        else:
            return locals()["fetch_" + order['order_destination']]()

It's shorter, runs quicker, populates less objects, and doesn't require learning a framework.  More importantly than all of that, it is significantly more readable than: 

    valid = run(1, x, must_contain_section(order['order_destination'], x),
                membero(x, set(order.keys())))

for anyone familiar with Python.
The grand parents relationship could be easily solved by using json and for parent p1, p2 in Bart['parent'] get p1['parent'] and same for p2. The syntax reminds me of SQL and R somewhat.
this is the worst thing I have ever seen
It's not totally ridiculous, but there are some significant challenges the author seems to be overlooking:

1. Security! If you're downloading code, at an absolute minimum it should be over HTTPS. And how secure is that domain where you host it?
2. Caching: If you want your application to be usable without an internet connection, you need to store the code somewhere locally, and decide when to use that versus downloading the latest code.
3. Users still need to install at least Python and your launcher script to run the application, so it doesn't solve the distribution question.
I'm by no means an expert, and I'm not sure, but it seems like there will be at most 2000*1999 = 3998000 unique combinations of primes, thus only that many unique cyphers? That's not really a lot...
The way to preprocess raw text is to first split on whitespace, strip punctuation and invalid characters, lowercase the tokens, then remove stop words.

Any reason tf-idf was not used for term weights?

Nltk is strictly a teaching tool. It is easy and simple because it is for learning purposes. It should not be used in production.
A very welcome feature! I've worked a few times with repli.it to write Python code and it's great. A full-fledged debugger will make it even better. Right now, you can't watch locals or evaluate expressions with the debugger, so I find that there's no real use to it. I guess that this is more like a proof-of-concept. However, this is a very good start!
This subreddit is NOT stackoverflow.com.

This subreddit is NOT /r/learnpython.

If you have an error you MUST try and solve it yourself; dealing with exceptions is a big part of programming, and learning to do it yourself is vital.
here is a picture of the error I get when I try pip install requests[security]. http://imgur.com/XtGOVS7
If you're good at what you do I don't care what degree you have.

If you're bad at what you do, I also don't care what degree you have.

The software world really is pretty much a meritocracy.  And one with a low barrier to entry at that.  Go and read [Python for Data Analysis](http://shop.oreilly.com/product/0636920023784.do), and you'll already be better equipped than a lot of stats experts I've met.
id say being able to mung data with python/R will get you some pretty cool jobs. get good @ excel and learn how to use pythons packages to manipulate excel stuff. 
You could maybe get an entry level job in a place that uses SAS, but in terms of adding another string to your bow, R would make more sense for you at this stage. There will be places that make use of SAS and R, but I don't recall ever seeing a job advert calling for Python and SAS (that didn't also require R). 

That's largely because SAS and R tend to be used by people who are statisticians, who minor in code, versus Python which is often used by coders who know a little stats. You are going to have more luck getting a job with the stats heavy folks, if that is your background. 

But by all means, learn Python - it's way fun.
The source code doesn't appear to be hosted somewhere like github so I can't super easily link you to lines. However, if you download the source from here:

https://pypi.python.org/pypi/google

And then look at line 301 of `google/__init__.py` there is the following:

    # Sleep between requests.
    time.sleep(pause)

I stepped through a debugger and my default value was set to 2 seconds. The pause is a parameter you can apparently specify in the search function, but there is the following warning in the docs:

    @type  pause: float
    @param pause: Lapse to wait between HTTP requests.
        A lapse too long will make the search slow, but a lapse too short may 
        cause Google to block your IP. Your mileage may vary!

This is just a network/rate-limiting issue. You could release the gil or use asyncio, but that's all overkill and not really the issue here.

https://breakingcode.wordpress.com/2010/06/29/google-search-python/
Use either python threads or multiprocessing or async. 

Each time you query Google, you're taking a speed hit. Threads would let your code run while Google is waiting to respond, or multiprocessing would let you run multiple sessions of python at once. Async runs similar to threads but is easier to use. 

I would try async first if you're on python 3.5
Good video, keep em coming 
Hi, I'm the dev advocate for PyCharm...super video and good comments here as well.
You can CTRL + click on a function and go to its definition. CTRL-clicking on a function definition will bring up a list of places its used that you can then click on to go to. 

EDIT: Another thing I like is that you can make custom TODO's in the settings:

> File > Settings > Editor > TODO

You can add regexes for TODO highlighting and make custom filters. I do this to work with TODOs, modeling assumptions, code to go back to, etc.
The right click menu has some cool stuff too that I really like.

* Compare with Clipboard 
* Local History
* Column selection mode
* Execute line in Console

or highlight some code, then:

* Execute selection in Console

Some other features I like:

* Record Macros under the Edit menu. (Although keyboard macros my usual go-to)

* Click the hyperlinks in the Traceback to bring up the source code. It takes you right to the line last called.

>File > Settings > Editor > General > Smart Keys > Surround Selection on typing quote or brace

* Now you can double click/highlight and surround selection with quotes, braces, parenthesis, etc. by typing one button. You're welcome.

* Right click file tabs and split vertically/horizontally to have multiple files displayed concurrently.

* Create a template by writing some code, clicking Tools > Save file as template. Use a template by creating a new file, but instead of selecting Python File, select one of your presaved templates.

* Click External Libraries which is at the bottom of the Project Menu on the left. You can quickly access all your installed libraries.

Thanks for this. Quite new to PyCharm and fairly new to really putting some effort into learning to program. I got the feeling that PyCharm was good but clearly there are even more amazing features. Thanks for this. Subscribed to the YouTube channel. Looking forward to more.
"Finish this project", That TODO comment.
PyCharm feature that I used most are:


- Go to class: `Ctrl + n` / `Cmnd + n`
it helps if I had projects with bunch apps. I only remember class name but too lazy to find out the file on project panel.

- Search everywhere: `Double shift`
it helps if I had bunch of helper function and I don't remember the definition location. I just need to type function name and pycharm will search for me.

Very helpful to save 5-10 seconds to find manually.
Is the database view in the Community Edition? I can't seem to find it anywhere...
Bookmarks tip could be better with "[Task & Contexts](https://www.jetbrains.com/help/pycharm/2016.2/managing-tasks-and-context.html)"
Hey there. I use python for many accounting tasks including transparency reporting and streamlining the payables process. I also use it to help answer some of my emails. I use python to distribute invoices across the office, so coworkers can legitimate bills. 
work in finance. use python, vba, excel, vbs.....derp
I'm considering using python for this kind of work, but I don't know where to start.

What were your first implementations?
I'm a CPA who is a forensic accountant. I use python for data analysis, visualization, and doing boring stuff that would take too long in excel.
The discovery that a minimal `setup.py` file is actually pretty easy.

When pip-installing my own packages became trivial, that was really nice: suddenly I could have my project in any directory, `pip install` it, and use it in a project in any other directory. That made splitting functionality into its own package so much easier.

Here's your directory:

    <root>
    <root>/setup.py
    <root>/darling/__init__.py  # contains: from .core import public_hello
    <root>/darling/core.py  # contains public_hello

Here's your `setup.py`. Usually `name` and `packages` would both be 'darling', but I've made them different to show their different functions.

    from setuptools import setup

    setup(
        name='darling_pip_thing',
        version='1',
        packages=['darling']
    )

Here's how you install it:

    pip install .
    # ...
    # Successfully installed darling_pip_thing

`pip install -e .` is also nice: that points directly at your source code instead of installing a snapshot.

Here's how you use it:

    >>> import darling
    >>> darling.public_hello()
    Hello, public!

As well as (or instead of) a `packages` argument pointing at a directory, you can also have a `modules` argument pointing at a `.py` file. Useful if your package is just a single-file module.

EDIT: [/u/florencka pointed
out](https://www.reddit.com/r/Python/comments/5f6ev8/what_one_thing_took_your_python_to_the_next_level/daj1q6c/) that the `packages` argument does not work when pointed at a file (`x.py`) instead of a directory (`x/`, `x/__init__.py`). Took that occasion to make this entire comment more batteries-included, and also add [/u/coelhudo's `pip -e` tip](https://www.reddit.com/r/Python/comments/5f6ev8/what_one_thing_took_your_python_to_the_next_level/dai52np/).

Mastering generators
Understanding how iteration really works in Python opens up many possibilities for elegant, high performance code. Use iPython. Learn that **for** does tuple unpacking; play with **zip**, **enumerate**, **all**, **any**; take a look at the **itertools** module. Study generator functions. Focus on plain generators, not coroutines (that's also interesting, but another subject). So, focus on **next(g)**, forget about **g.send()** (that's for abusing generators as coroutines). List, set & dict comprehensions are nice syntax sugar; generator expressions are more important!
Unit tests! Pytest in particular! Gives you a whole new perspective on your code and dammit, it's so satisfying to get all those green OKs! 
For me, all the work of David Beazley, in particular http://www.dabeaz.com/coroutines/
Getting an in-built understanding of:

    zip
    lamba
    filter
    yield

And:

* generators
* list / dictionary comprehensions

Finally:

* ipython 
* managing virtual environments

Oh. And realising *everything* is an object.
Not using classes until I needed them.
For me, it was list comprehensions. It got me thinking more in the terms of loops/list processing, refactoring so I can create the loops more easily, etc. That lead into generators, and so on....
I've been using Python for a long time (I'm an early perl apostate), so I'm not always up on the newest stuff.

For me, really digging into context managers has resulted in the biggest changes to how I program, as well as the biggest benefit. 
Definitely agree with several of the items mentioned already (PyCharm, generators, closures...), so here's something else that changed how I write Python:

Decorators.

Being able to slap @retry(3) or @timeout(secs=60) on top of a function definition really simplifies the codebase.
Code reviews.

Try to work on a project with other people. Or some open source GitHub project.
Pandas Dataframes. 
I found using pdb liberally for larger projects has helped immensely.

    import pdb 

    pdb.set_trace()

Will pause the shell at the point that you input the above. Lets you meddle with variables, see what values are set to at that point in the code. I've found it especially useful for debugging django template tags that just aren't working the way I want them to.

edit: fixed for /u/KimPeek :)
Learning a programming language with a different paradigm. Specifically I learned Haskell. It introduced a lot of new approaches to solving problems, many of which I could apply in Python. Now it also made me dislike Python and I now try to do all my projects in Haskell, so take this advice at your own risk. 
PyCharm editor
Reading high quality code from big libraries, seeing best practices and coding that way.
you are probably already beyond this, but the python module of the week series really helped me figure out the standard library and other useful libraries for python:

https://pymotw.com/2/

Flask. 

I allready learned about Classes. With Flask I could use them for functional code. My programs got far complexer but the documentation and style improved quickly. Since using Flask I see myself as a real programmer. 
code quality tools. flake8, mypy, radon, to name a few. the code inspections pycharm can do are also extremely useful.
Understanding metaclasses. They aren't useful frequently, but sometimes they just fit a need so well that they're a beautiful solution. I think I've written about 3 or 4 that are actually used in production code, but they simplified my code by an order of magnitude once introduced. In particular, I find them great when writing what amount to small frameworks. Whenever I have to write code that acts as the structure for others to build their applications on they seem to crop up.
Looking at a few specific parts of the cpython source code to get a feel for what's really going on:

* **The grammar** https://hg.python.org/cpython/file/tip/Grammar/Grammar

* **The builtin types of objects** 
https://hg.python.org/cpython/file/tip/Objects

* **The virtual machine loop that "runs" python opcodes** https://hg.python.org/cpython/file/876bee0bd0ba/Python/ceval.c#l1220
Great question Turk! 

For me it wasn't tools, tutorials, modules. It was when I started making stuff that I use every day. That's a big thing. You get a surge of satisfaction when you log in, reminders and feedback as you use it, a slowly growing desire to make it better. And new ideas for further projects.

I've got four things on my desktop that I wrote myself: a menu button, a shutdown application, a sort of info bar/panel, and the newest item, a todo list application. The latter just today replaced the same job as four conky scripts. And it looks a lot better. I have a couple more things to make and then the presentation of my entire desktop will be stuff I made. 

Behind the scenes I have about 100 minor scripts ready to go, mostly just little things like unit conversion, such as Celsius to Fahrenheit and back, but also some more important things like scripts to manipulate the todo lists, one that sets a random wallpaper on log in, curators when I get sick of one, one that that backs up my current open browser tabs and favourites list. And so on.

When you start owning the functionality of your computer, you start setting achievable, meaningful goals. Techniques and tricks which were interesting and cool become *useful* and satisfying.
I'm working my way through project euler

https://projecteuler.net/archives

Forces me to think carefully about how I approach a problem. Makes me much more facile with array manipulation and stuff like list comprehension.
After I made my first setup.py
Learning Haskell.
Learning functional programming.

It's amazing how much you can transfer from ML-based languages (F# in this case) to Python.
Metaprogramming.

In general if you're solving a problem with metaprogramming you're probably doing it wrong. It's a lot of cleverness that can be detrimental to readability and there are many better ways to handle whatever you're trying to do. But there are a few cases...

Understanding that there is nothing special about the class creation pattern (for example):

    class Foo(bar):
        def __init__(self, y):
            self.y = y
        def my_method(x):
            return self.y + x

Could be written like:

    type('foo', (bar,), {y=y, my_method=lambda x: x+y})

Like. Ok. That's terrible and your probably shouldn't do that. But... there are some cases. Let's say you're trying to write a unittest around something that inherits Python's Unittest.TestCase. But you can't have a unittest.TestCase inherited by your unittests because the unittest runner will (correctly) identify it as a unittest and try to run it. If you understand metaclasses you could make a new object that is exactly like the original only it stubs out that problematic unittest.TestCase inheritance.

I find myself pulling out metaclasses any time I need to stub out something complicated for testcases. I also find myself much faster at working with blackbox / undocumented python code - I have all the tools I need to inspect it now. But even beyond that understanding how things work under the surface gave me some new tools for solving complicated problems. Once you understand this you can start making dynamic code that changes based on how, why, and where it's called. Sometimes, with complicated problems or legacy code, you need a little bit of magic to make things work.
Dataframes make data io, formatting, visualization and cleaning ridiculously easy. If anything it's a bit of a crutch for me.
Protocols.

A protocol is basically a set of special methods (`__getitem__`, etc). If your class implements all the methods of the given protocol, then it's said to implement the protocol. For example, there's a bunch of special methods that your class can implement to be a *mapping*. This way, not only objects of your class are compatible with operators such as `[key]`, but you know that if you ever encounter a function whose argument must be a "mapping", objects of your class can be safely passed to this function. A marriage between C++ operator overloading, and Java interfaces, basically.
I always try to keep methods / functions to 5 lines or less. That doesn't mean cram code into difficult-to-follow one-liners, but split it up into smaller units and remember to use comprehensions. I find this practice makes me think more critically about my code as I write it, and it ends up much more readable (and sexy!) as a result 
Not Python specific, but I've found function closures to be extremely useful.  I often find myself wanting to save some sort of state between function calls, but feel like defining a class is too much.
 Mastering use of raw interactions with cProfile, and pdb. And learning proper application of map/filter, lambda
For me it was pyramid and sqlalchemy.  Incredibly powerful combination that allows me to build very complex and flexible web applications. 
cProfile and timeit gave me great insight into what the interpreter is actually doing. 
For me it was Dive Into Python, an online book.
Ipython notebooks. God I love those. Easy to chunk up and execute your code. Try lots of different things out. Figure out basic algorithms. 

I've even started making some online books with them.
Requests library and jinja2
Taking a functional programming course that was not directly related to Python. Mastering more general concepts allows one to easily understand how things work (in contrast to learning how to use them without knowing the details). For example to understand how Python decorators work, one has to understand the concept of functions beeing first class objects and function closures. These are all well known terms in the functional world. 

Learning the differences between different type systems, scopes, etc. also changed the way I write code.
Test driven development pushed me to learn a lot of the other patterns, tricks, and tools that have been mentioned here, and it is still pushing me to think more deeply before I start writing any code.  
For me it was having a friend who knew Python way better than I did review a project I was working on. My background before that had been all C/C++ so I still had a lot of artifacts from that and it was making some simple things in python unnecessarily complicated. It was enlightening.
Getting a job where python was the primary language used really took my python to the next level. 
Always log everything.  It will be only your only chance to debug some logical error you can't reproduce.
Writing bots changed everything, because that's when my programming went from theory to practice. Try writing Reddit bots to start, but then move on to Twitter and other platforms -- you would be surprise to see what it does for you
SimulateMe! NicolasGuacamole
Clean and simple concurrency. 
http://stackoverflow.com/documentation/python/542/parallel-computation/5700/using-parent-and-children-scripts-to-execute-code-in-parallel
Learning scheme and working through the examples in SICP
Realising that most traditional OOP techniques aren't good patterns in Python. For example:

1) Not everything has to be a class - unless something needs to hold state it should probably be a module with plain function(s).

2) Embrace duck-typing and use it to your advantage. Avoid names that have programming words in them. A non-programmer should be able to understand what most of your classes represent. In Python there's almost never a need for things like `FooFactory`, `BarAdapter` or `BazInterface`.
I wrote a debugger using [sys.settrace](https://docs.python.org/2/library/sys.html#sys.settrace), and a Object mapper, which required understanding metaclasses.  You learn a lot about the internals of the language and a lot of the nuance.
i love type hinting. it when used with an IDE that supports it, it makes life a lot easier and has saved me from many a runtime error.

e.g.

    def f(s: str, f: float, o: SomeClass) -> dict:

that, and keyword-only args, especially for bools:

    def g(name: str, *, truncate=False, annotate=True, bend=False) -> List[str]
Learning classes, not python but Jesus it made my rather large round about ways of getting something done a whole lot more simpler!
Using http://www.tornadoweb.org/ in one of projects, for me it was a first experience to work with eventloop in web. 
Collections module
Generators
And Classes (barely used them)
Pygame, Tkinter, Matplotlib, BeautifulSoup and Flask are great tools to create nice Python applications.
This is pretty general but creating my own custom IDE color scheme helped me a lot I think.
A long long time ago: leaning that python variables and members are actually just entries in some dictionary - and from there to metaprogramming. Warp speed.
Learning a shitload of other languages. Can gladly recommend, it helped not only my Python ;-)
my mom said that Python was neat and that made me want to python.
It's interesting that JKM decided to present parameterised functions rather than fixtures.

In my experience, pytest fixtures are both more interesting and more useful/convenient, parameterised tests are neat but otherwise easy to replicate.

Fixtures are pytest's answer to setup/teardown concerns filling in for multiple issues, some caused by pytest but most being intrinsic issues of xUnit-style setup and teardown:

* method-based setup and teardown are difficult to compose, IME small setup/teardown "mixins" lead to complex inheritance graphs and don't work that well, so I've tended to resort to bigger less reusable or reused ones, commonly no reuse at all of the methods and some setup functions on the side (which would hopefully work)
* providing set up resources to the tests is annoying as you have to set them on the test instance, that also makes what resources or set up steps each test needs very unclear
* xUnit-style means setup and teardown *of a given resource* are far apart *and* mixed with other stuff (other setups and teardowns, non-resource setup code, â¦) *and* you have to be very careful to teardown in reverse order from the setup lest you teardown a dependency before its dependent and the teardown blows up (or worse)
* partial setup/teardown (a subset of the setup blowing up after some of it has been executed) really doesn't work in xUnit style, unittest [had to grow an addCleanup method](https://docs.python.org/3/library/unittest.html#unittest.TestCase.addCleanup), mixing addCleanup and xUnit-style tearDown doesn't necessarily work correctly (by default cleanups are all called *after* teardown)
* using methods, scopes (a group of tests bracketed by a single setup/teardown pair) are pretty inconvenient, older unittest only had test-scope, newer unittest has class and module requiring different hook names
* because the canonical test "bundle" in pytest is a function you can't have setup/teardown methods

Instead pytest uses "fixture functions", which are simply decorated with `@pytest.fixture`, and are *pretty good*:

* Fixtures are dependency-injected, if a test (or an other fixture) wants to use a fixture they just request it by name e.g.

        def test_sendmail(smtp):
            â¦

  requests the `smtp` fixture, and that's it. Fixtures work the same way, they can just request an other fixture by name to explicitly depend on it or use it. Because it's convenient and explicit, pytest plugins (and external libraries via a bundled pytest plugin) can easily provide fixtures e.g. Django could provide a set of pytest fixtures as testing support without having to have its entire testing framework, [that's essentially what pytest-dj.
* fixtures can either return an object directly (with a normal `return`) or perform setup/teardown similar to `contextmanager`-decorated functions: set up, `yield` (with an optional value) and teardown e.g.

        @pytest.fixture
        def smtp():
            s = setup_server()
            yield s
            s.close()

  this makes for simple and obvious code, with very little distance between the setup and teardown of the resource, and it's compatible with contextmanagers:

        @pytest.fixture
        def smtp():
            with contextlib.closing(setup_server()) as s:
                yield s

  these steps are automatically and correctly ordered between dependencies (such that all dependents of a fixture A are torn down before A is).
* if a fixture setup fails, all previously set up fixtures will be properly torn down in reverse order, fixtures encourage small self-contained single-concern setup/teardown functions: one fixture manages one resource, or sets up one configuration point, or creates one type of objects

Now these are the simple and obviously convenient use cases, but fixtures also (optionally) provide way more power than that:

* pytest fixtures have a concept of *scope* as a fixture attribute (`pytest.fixture(scope=â¦)`, this defines how long the fixture remains alive before being torn down. There are 3 unittest-like scopes ("function" ~ setUp, "class" ~ setupClass, "module" ~ setupModule) and then there's "session" which scopes the feature to the entire test session, very cool for stuff like starting a test server or semi-static configuration
* pytest fixtures are lazy, pytest allows filtering tests (using tags or regex or whatever) and fixtures which are never requested are not instantiated
* fixtures can also be marked as `autouse` in which case the fixture will automatically be used for all functions matching the fixture's *definition scope* (e.g. an autouse fixture in a module will be applied to all tests of that module but only them, whereas a project-wide or plugin autouse fixture will be applied to all tests of the project)
* fixtures can be parameterised, and will in turn automatically parameterise their dependents e.g. given

        @fixture(params=['a', 'b'])
        def demo(request):
            â¦

        def test_foo(demo):
            â¦

  `test_foo` will be called twice, once with `demo('a')` and once with `demo('b')`.
I'm just getting into pytest myself and I've been combining it with [Hypothesis](http://hypothesis.works). which I enjoy a lot. Anyone else using Hypothesis? Why or, perhaps more interestingly, why not?
I really enjoy the package unittest in the standard lib.

It could be a little more verbose but I really enjoy the modularity of the TestCase class with setUp(Class) tearDown(Class) well managed through the exeception.

Also appreciate the whole set of method assert* ...

In fact this package is for me a very strong asset for Python regarding the other languages.
You didn't search that hard then, https://github.com/python-hyper/hyper-h2. Been using that in production close to a year now (client side).
You shouldn't be using a Python HTTP server to serve up your pages. Look into deploying with WSGI and a real web server like nginx.
Most websites outside of the huge ones that can afford the push (and need it) are perfectly fine for the time being using http 1.1. The other comment in this thread points to a suitable library for http 2 client and server side interaction, and I believe that there is a flask plug in for http/2. That being said, http/1.1 is still very suitable for request/response types of web applications, which most apps are. Long polling and very responsive or large scaling applications benefit from http/2, but will result in a very small performance increase for a heck of a lot of work for smaller apps. This is all relating to current technologies, fwiw
Look into `subprocess.check_output`. Also, /r/learnpython is a better place for questions.
There are various midi libraries, but I am not deeply familiar with them. You should be able to figure out some way to output midi data at a given frequency.

What are you trying to do specifically, if you don't mind my asking? The question would imply that you are wanting to produce pitches which are outside the 12-tone scale, which is quite interesting to me. 
Check out pyo. Simple to use yet very efficient.
Hello,

Please read the sidebar:
If you are about to ask a question, please consider r/learnpython. Homework-style questions will be removed, and you'll be encouraged to post there instead.

And when you move over to learnpython, please describe in more detail and post the code you have written so far.

Also, pycharm is a good IDE.
Jesus. Why can't you folks read the side bar?
I'd love it if you helped out with [my project](http://git.p2p.today), but I'd understand if it's a little too much.
sure:

- [syp](https://gitlab.com/vindarel/syp) is a command line tool to save packages you install (with pip, apt,â¦) into requirements files, and also sync the lists with the system, so we can also edit the files manually
- https://github.com/asciimoo/searx: meta-search engine, many bugs and feature requests
- https://github.com/duniter/silkaj a command-line client for a free alternative money implementing a basic income
- https://gitlab.com/vindarel/bookshops is a books scraping library, has feature requests and needs python3 porting (I'm the author)

enjoy yourself !
I could always use some help with my Rest package for Django: https://github.com/FFX01/django-restup
    def genFace():
       face = "ears", "forehead", "eyes", "cheeks", "nose", "expressions"
       return "".join(choose(dicts[1].contents, x) + "\n" for x in face)

"Reducing" should never be a goal in itself. You should strive for two things - clarity (in terms of reading) and efficiency (in terms of performance).  Sometimes those happen to coincide with reducing code, but that should never be the goal. 
Downvote for posting a picture instead of text.

Do you edit your code with Photoshop?
What is `dicts`?
SciPy has non-trivial native library dependencies for BLAS, LAPACK and probably a bunch more. It's possible to build a wheel that internalizes these dependencies, but that wheel will almost certainly break should your Python application directly or otherwise link against any other native code that uses these libraries, which is a likely outcome in a scientific setting.

As for what "break" looks like, all kinds of fun can happen when two ABI-incompatible versions of the same library get loaded, especially if its internal structures somehow get shared across function calls into the distinct versions. Another possibility is duplicate symbol errors from the runtime linker during import, etc.


The "use Conda" answer is a decent one, it handles all these native issues for you, including ensuring the same third party libraries are linked correctly everywhere
I don't know the reasons, but really, use conda (http://conda.pydata.org/docs/) for this -- if you're interested in using the scientific stack of Python, it'll make your life much easier.
I'll sometimes use an index in a loop...
Mission analysis and trajectory optimization software development at NASA.  Usually the theory stuff that i do with pencil and paper comes with calculus,  then you routinely rearrange the resulting equation depending on what you know and what you want to know.   Therefore I use algebra more than anything else by far.   Next is probably linear algebra then calculus.   After that is things that are not frequently used,  like graph theory and geometry. 
Tax/accounting: + - / *

:)
PhD student in image processing. The standard is MATLAB but I much prefer python so I use that. The math is mostly linear algebra, images are essentially matrices, with some calculus for optimisation, machine learning and Fourier transforms. 
Physicist: lots of geometry for system design, numerical integration of complex functions and Fourier transforms for optics, linear algebra for solving everything that comes up. Rudimentary calculus and differential equations to model things and for error propagation. Spreadsheet math for budgets and schedules. 
I use quadratures, gaussian processes, neural networks, PDEs, ODEs. My PhD (which is relevant to my job) was on polynomial chaos expansions which are a generalized Fourier series.

I am a computer scientist/engineer/applied mathematician at a national lab working in the verification & validation and uncertain quantification department.
BS Physics, MS Electrical/Computer Engineering. Senior Software Engineer as a job. I use PEMDAS if I'm lucky. Mostly just plumbing and translating data between webpages, microservices and databases. 

Weekly in my spare time, I'll brush up on my mathematical analysis education. Scared if I don't use it, I'll lose it. 
Basic algebra ... Systems programmer.
I mostly use linear algebra, bit of calculas and group theory. Also a decent amount of Bayesian work. Im a grad student studying experimental quantum computing/information. 
PhD in optics, working in a field that's heavy in nonlinear optimization. Essentially build an optical model to create an image, parameterize it, and perform optimization to find the correct values of parameters.

As a result, we use optimization (obviously), but also linear algebra, fourier transforms, and a boatload of calculus. The calculus is the biggest and most important part - for finding search directions for the optimization algorithm to traverse, it needs the gradients of your error metric with respect to the parameters. You can do this with finite differences calculations, but that can take a long time when building images. If you write your forward model's steps in reverse using algorithmic differentiation, you gain a ton of speed in the optimization.

We use a LOT of Scipy and Numpy to do our work, in other words.
Job: Lead developer in [GIS](https://en.wikipedia.org/wiki/Geographic_information_system) company.

Tons of calculus coming from physics (e.g [atmoshperic correction](https://en.wikipedia.org/wiki/Atmospheric_correction)). Statistics (particularly interpolation methods using it, like [kriging](https://en.wikipedia.org/wiki/Kriging)). Linear algebra (coordinate translations). [Quaternions](https://en.wikipedia.org/wiki/Quaternion) (satellite movement calculation).
Discrete maths to prove algorithms correct and to figure out optimal solutions to problems, keeping in mind the lower bounds of the problem in hand.
CS Researcher at University of Eastern Finland here: all sorts, but due to my field of expertise, specially statistics, algebra and calculus.
Mostly machine learning, some signal processing. I consult on ML/AI/NLP problems in London, I also co-chair PyDataLondon (Europe's largest Python data science meetup). My blog shows the sort of things I'm interested in, a chunk of this year has involved proof of concept medical/IoT data analysis.
I guess mathematical optimization has the closest relation to my job. Kinda some graph theory and linear algebra I guess. I am a research fellow in computational intelligence.
Mathematician, I use a lot of number theory (and probablistics) and a fair bit of analysis in my studies in analytic number theory.
Right now I'm a math teacher, so I use whatever math they need me to teach. Currently, I've got sessions going for geometry and algebra 2.
Calculus of variations, ODEs, Linear Algebra, Numerical methods. PhD student in Aerospace Engg. 

My lab used to be all MATLAB. We switched to Python a little over a year ago and never looked back!
EE here doing design/verification work as a digital designer in the semiconductor businsss. I do a lot of boolean algebra and bitwise calculations daily. Occasionally I do basic probability and statistics.  On average the math I use as a tool isn't very difficult, but I need to know advanced math to understand what I'm working on. I personally like using ipython notebook (jupyter) to create an interactive notebook for my calculations. 
I do computer system performance analysis and capacity planning.  Mostly 4th grade math with a smattering of stats, just to keep it from being totally mind numbing.
Sometimes I can add and multiply without screwing it up. I'm a full stack web developer at a big 4.

I always wonder why people stress math so heavily for all developers. I understand there are plenty of jobs where advanced math (calculus, linear algebra) is a requirement. But, there are definitely jobs, high paying ones even, where basic algebra and statistics  (just the college prereq's or intro courses) are all you need.
You're probably going to get a biased sample here because people who are proud of their math usage will be more likely to respond.

I'm an astronomy PhD student, and the most advanced math I've used in the last year is algebra. I use calculus about once a year on finals. Literally none of the math classes I took in undergrad are relevant to my work. I use words like `gradient` when explaining algorithms to people, but only because that's a more concise way to explain what's going on at a high level. I could make do just fine without any calculus.
I do predictive modeling in general insurance, I use the usual machine learning hodgepodge of linear algebra and calculus, but with a big emphasis on probability (e.g. Poisson, Gamma, Tweedie distributions).
In the future, questions like this belong on /r/learnpython. This subreddit is intended for news about the language and associated software.

`scipy.optimize.curve_fit` Is a perfectly fine tool for what you want to do. I think you haven't realized that because the name of the function and its arguments were chosen to assist the brain in grasping a particular use case.

The function asks for a minimum of three things:

* A callable thing that takes at least two arguments and returns a 1-d array of floats (this is usually a function, but it may be possible to stick something else in here)

* An input to the function that stays the same and will always be passed as the first argument

* A 1-d array of floats with the same length as the function's output that it will try to match

That's it, those are the only restrictions.

Do you see how you can do this? I don't want to give it away if you see where I'm going.
`sys.setdefaultencoding('utf8')` - please don't do this. The function gets removed for a reason.


Good job. Just played around with it and added a requirements.txt, moved the database to Postgres and changed Safari to Chrome using webbrowser.
Still not working as expected but I'll try again tomorrow :)
Learn about the argparse module and list comprehensions, it will make your code much better.

    idList = []
    for i in range(len(tempList)):
	    idList.append(tempList[i][0])

Could be just

    idList = [list[0] for list in tempList]

Also no camelCase in variable names pls.
[deleted]
In my experience, the most reliable way to do this is by using Python to control MS Word using whichever [PyWin32](https://sourceforge.net/projects/pywin32/files/pywin32/Build%20220/) version is appropriate for your interpreter.

I don't remember the exact process for how to use it, but if I remember right, you import win32com.client, and then can call the function win32com.client.gencache.EnsureDispatch("Word.Application"), which returns an Application object corresponding to the Word object model: https://msdn.microsoft.com/en-us/library/office/ff838565.aspx

It's not very fun to use, but sometimes it's necessary.
I've used python-docx for generating Word docs. It works as advertised but don't expect a ton of features and functionalities. It only does the basics. As far as extracting, I think the more you know about XML the better off you are. I don't believe Microsoft Office XML specs are freely available so it's going to be a challenge figuring things out.
VBA for all it annoyances is sometimes the superior choice, especially cases like this. 

Dealing with ms office files can be a real pain, easier to convert the files first if possible, xlsx > csv and docx > txt

You can still call the macro from python if it's being integrated into something bigger.

 To run a VBA macro on startup:

    Private Sub Workbook_Open()
Pretty well used feature, but when first I discovered python's list and dictionary comprehensions years ago, I was absolutely blown away. I still am blown away. I feel like a neanderthal in most other languages when I have to write loops that can otherwise be expressed as comprehensions.
Maybe it's not a feature, but when I realized I could add functions to a list and then call them by reference and have an instant "menu" I was pretty excited. 
Overriding operators, with (for example) _____**add**_____(self, other) and then just adding objects by using the + operator. 

Coming from Java, this was pretty astonishing. 
I only recently discovered that you can unpack lists as arguments in a function.

e.g

    my_list = [3, 2]
    
    def f(a, b):
        return a * b

    f(*my_list)

For quick-and-dirty shell scripts where I want to throw on some command line arguments I do this:

    import argparse

    args = argparse.ArgumentParser()
    args.add_argument("foo")
    globals().update(**args.parse_args().__dict__)
    print(foo)

Of course, if there is the slightest possibility it is code someone else would use, then I don't do it like that, I would just keep a reference to the namespace object and access foo as ns.foo.
Not strictly python, but I recently learned that you can run shell commands in IPython by just prepending a bang like this

    In [1]: ! echo Hello World
    Hello World

It works in notebooks as well which can be neat. For example, I like to add a

    ! git log -1

to all my notebooks to document the state of the project when the notebook was run.
Generators! If you have a heavy function that return a list of stuff, you can make it faster by just"yield" each element of the list instead of returning all elements at once, making the code more dynamic
> python -m SimpleHTTPServer 8000

Like who thinks of this of stuff? Oh yeah, programmers.
My life changed when I discovered list comprehensions.
    In [1]: 10/2
    Out[1]: 5.0

    In [2]: 10//2
    Out[2]: 5
Late to the party, but I discovered some sweet implementation details of Python by accident. Notes [here](https://norvoshipriest.wordpress.com/2016/06/06/pythons-number-caching-and-code-parsing/) (TL;DR below). I might be wrong on some things because like I said, I discovered them by accident.
The `key` argument to `min` and `max` is pretty useful. You can pass it a function that accepts any item from the passed list as argument, and returns something that can be compared, like a number or a list/tuple. For example, you can find the name of the place closest to a coordinate in a dict of place names and coordinates: 

    import math

    def key_func(pt, places):
        def key(place):
            pt2 = places[place]
            return math.hypot(pt[0] - pt2[0], pt[1] - pt2[1])
        return key

    places = dict(zip("abcd", [(0, 0), (5, 5), (2, 7), (6, 1)]))

    coord = (5, 0)
    print("Place closest to {} is {}".format(
        coord, min(places, key=key_func(coord, places))))

In other scenarios you can make use of the fact that `(0, 0) < (0, 1) < (1, 0) < (1, 1) < ...` by having your key function return a tuple of sortable values in order of importance, so, sort by the first element of the tuple first, and if equal, sort by the second item, etc. Often times it's the other way around... you're sorting by some single value key, but then discover an exception to the rule you use and need this to override the default sorting order. Simple! Just return a 2-tuple instead, with your single value as the second element and an override value as the first.

If you need the n smallest values for n larger than 1, use `heapq.nsmallest` with the same key func, as this is more efficient than repeated use of `min`, or using `sorted(...)[:n]`. But as n grows, at some point `nsmallest` no longer has an advantage and you should just pass your list to `sorted` (which also takes a key argument) to get the whole list.

Sometimes you need to group a list by some key, e.g. group a list of people by their home address or a list of hostnames by their top-level domain. You can then first sort by a key which looks up the address or returns the tld or whatever, and then pass the resulting list to `itertools.groupby` with the same key!

**TL;DR: Key functions rock!**

**EDIT:** Improved example key func, thanks /u/Franciscouzo! Also, fleshed out the text a bit and added more possibilities and examples.

Everything in the [`collections`](https://docs.python.org/2/library/collections.html) library.
`python3 -m http.server`

Great trick when you need to move files to another between computers on the same LAN, works instantly.
The 'transpose trick':
transpose = list(zip(*matrix))
Python skin may be stretched and formed as the sound board of some string musical instruments, such as the erhu spike-fiddle, sanxian and the sanshin lutes.
The "help" command.

import os 
help(os.getcwd)

I would always just print out the __doc__ to get the docs for it until I realized there was a help command. 
Pandas DataFrame.to_sql() and read_sql_table(). I use Python and Pandas to do a lot of small ETL jobs. Not memory efficient, but fairly trivial to do a lot of work. 

The REPL.
In 3.6 there's an `f` print function. I'm not even sure what it's called. 

    name = 'Bob'
    f"My name is {name}"


Edit: They're called formatted string literals [Source](https://docs.python.org/3.6/whatsnew/3.6.html#whatsnew36-pep498)
list comprehensions <3

Didn't know about them in my early days of python, and when I did it changed my life!
`dir ()` can often be useful. Pickle is also great. I use those a lot.
`pdb` is magical.

`dir` too.
Making `8 == 9`, making `1 == 72`, and all around torturing the interpreter. (python 3 only)

    >>> import ctypes
    >>> ctypes.cast(id(8), ctypes.POINTER(ctypes.c_int))[6] = 9
    >>> 8 + 1
    10
    >>> 8
    9

and 


    >>> ctypes.cast(id(1), ctypes.POINTER(ctypes.c_int))[6] = 52
    >>> 1
    [1]    69350 segmentation fault  python3


And making `0 == 1` results in quite the shenanigans:


    >>> ctypes.cast(id(0), ctypes.POINTER(ctypes.c_int))[6] = 1
      File "<stdin>", line 1
        SyntaxError: invalid syntaxctypes.cast(id(0), ctypes.POINTER(ctypes.c_int))[6] = 1
                   ^
    SyntaxError: invalid syntax
%paste when using IPython REPL.
That you can turn it into a fully statically typed language using mypy and it works perfectly. The typing syntax is integrated into Python 3, but you can still use it with Python 2.7 using comment type annotations. 
    class Foo:  # in some third-party lib
        â¦
    
    class Bar(Foo):  # our code
        def our_new_method(self, â¦): â¦
    
    obj = some_thid_party_lib.get_foo()  # can't change the way we get this object, butâ¦
    obj.__class__ = Bar  # we can still make it into our better version
    type(obj)  # â Bar
    obj.our_new_method()  # works!
As a first time Python user, dictionaries and slices were useful for a project I was asked to do at work.  

It seems like there is a library for just about everything.  It reminds me of [this](https://xkcd.com/353/).
You can assign slices to variables 
I like that it is not more verbose than it needs to be, and not more terse than it should be :)
    import itertools

Lots of goodies there.

The divmod library function. Divmod returns a tuple representing the dividend and remainder of  an integer division operation.  For example:

   >>> divmod( 7,2)
   (3, 1)
    
What divmod does is similar to what the hardware divide instruction does.   And it uses a distinctively Python feature where a function returns multiple values in a tuple. (Ruby has a similar function that produces an array). So those make it kind of cool.

 
For large numbers, DivMod is actually faster.  For small numbers, because Python is high level and because divmod() is a library call it generally doesn't optimize divmod enough to make it as fast as doing both the integer divide (//) and modulo divide(%) operation 

This StackOverflow shows how to time operations using timeit and how to optimize a library function call by using a local variable.  It compares divmod calls with the operation calls. 

http://stackoverflow.com/questions/30079879/is-divmod-faster-than-using-the-and-operators



And learning about that was cool. 

Dynamically setting variables(for throwaway code):

    thismodule = sys.modules[__name__]
    for i in range(5):
        setattr(thismodule, "foo%d"  % i, i)

    >>> foo1
    1
    >>> foo2
    2

If you have a bunch of HTML and CSS files around some times just double-clicking the index.html will not give you a good exprience due to the CSS not being correctly linked.

Just cd to the root folder and go

`python -m SimpleHTTPServer`
What are the specific things you are looking for? There is probably another library you can use. 
> Republican Surgeon`s Warning : Reddit makes you dumb, and has been measured as 8x more effectual than soy products at giving you a small wiener.


this is some grade A spam site.

Take this with about half a grain of salt.
who is supposed to care? reporting as spam.
**Update**

Managed to increase accuracy by almost 70% when I added darker pixels around the letters.

The problem is with 1 and 7 and tesseract seems to mess this up quite a bit.
From past experience Tesseract works better on bigger images (so upscale the image by e.g. 5*). You can also try variant images where you do different thresholding after blurring. This is a very manual discovery process but if you know the answers for a sample, you could auto-tune the process. 

Since you have segmented individual letters you _could_ also look at machine learning. There's a large literature on recognising single digits using machine learning (from naive bayes through to deep belief networks), but I suspect you'll get quite a long way just with tesseract.

Hope that helps, Ian.
tensorflow
Install numpy
Are you using Python standalone or the console provided in ArcMap (or Desktop, Pro, etc--I left off at 10.1/10.2)?

As suggested by u/elbiot, make sure all dependencies are loaded. Be sure that your installation is pointing to the correct directories.
In my experience, more often than not, "prototypes" become production code pretty often (for me, >95% of the time as a conservative estimate).

The only real factor of "whether you rewrite your code with a different language" comes from one of a few possible avenues:

1. CTO (or similar) decides all they care about is performance, so you have to do it in whatever is most performant.
2. CTO (or similar) decides they prefer language/ecosystem X over Y, so you do it in X
3. You measure and understand where the performance is impacted, evaluate if it is something related to code and whether or not it's something fixable - and start from determining if Python can do what you need or if you need a change. In many cases, the bottleneck isn't the code - it's waiting on something else (DB, external service, etc).

So to your initial statement, yes - python is excellent for quick MVPs and prototypes. I would extend that to quick deploy-to-production applications. Python optimizes for developer time (which is not cheap, generally) and refusing to guess in the face of ambiguity (see [Zen of Python](https://www.python.org/dev/peps/pep-0020/#id3)).

It's not the answer to every problem, but it can generally solve every problem. There are a few cases where you'd be better served by dropping into C or using a different language, that does definitely happen - but in my experience to date that is the exception (not the rule).
You're right, Python is excellent to build MVPs and prototypes.

Now, I'm just curious... What leads you to believe that you should eventually switch to another language?
Link should be http://coconut-lang.org/ (no ssl)

I have no experience with Coconut :)
Who uses coconut? I've never heard of it
When I tried it debugging was straightforward because it is integrated with ipython/jupiter. Still want to use it moreâ¦
a bit of rambling thoughts from trying it out on some small projects (personal things)

You need to have a seperate build dir, if you mix coco and py files (since x.coco becomes x.py, you'll have an unfun time .gitignoring one and not the other)


Error messages are a bit junky, since you have coco compiling to a massive pile of custom classes, functions, decorators, etc, and your equivalent py code, so something simple, could quite easily go through several layers of indirection, meaning a quite useless traceback.

I wish mochi's approach was taken, where you can use a mochi module loader to compile and run .coco files on import, instead of the weird compile step (and then just have a `__main__.py/.coco` to manage that)

I do know that it is possible to run without compiling, though I havn't looked closely at it. there may be a module loader, but I havn't looked to closely at that either admittedly.

the language is quite nice, I do want to do more of it.
Install [Anaconda](https://anaconda.org) to get all the data analytics packages you need to start, then run [Spyder](https://github.com/spyder-ide/spyder) from there.  That should get you started.

I started with RStudio and this was my preferred Python equivalent.  I had too many problems using Rodeo where changes I made were not saved back to the file.  Spyder v2 was slow, but v3 seems vastly improved.
How about http://rodeo.yhat.com/?
It may be worth trying PyDev along with its interactive console: http://www.pydev.org/manual_adv_interactive_console.html

You can use an editor to type the code and use F2 to send things line by line to a console afterwards or Ctrl+Alt+Enter to run the file in the console and make all symbols available for your current file (and then work interactively).

Also, you can have a debugger view connected to the console (http://www.pydev.org/manual_adv_interactive_console.html#full-debug-support-in-interactive-console).

This way, you can have all the IDE features you expect  -- such as go to definition: F3, browse through all symbols available: Ctrl+Shift+T, find references: Ctrl+Shift+G, etc, while still having an interactive console integration... 

If you go that route, make sure you take a look at http://www.pydev.org/manual_101_root.html to configure things properly.

Can't hurt trying ;)
I think /u/swingking8 was spot on when s/he said to find a project that captures your interest. You'll be *using* the language and not just following a tutorial.

But, once you have a feel for the syntax, I can't recommend strongly enough that you look up presentations and writing by [Raymond Hettinger](https://twitter.com/raymondh) and [David Beazley](http://www.dabeaz.com/). 

If you learn best by reading before doing, Mark Lutz's [Learning Python](https://www.amazon.com/Learning-Python-5th-Mark-Lutz/dp/1449355730) seems intimidating because of its size. But it's so big because it is both comprehensive and accessible for beginners. So depending on what you already know, you can skip large parts. But if you really *understand* everything in that book, you are well on your way to being an intermediate level Python dev.
Hi, I'm the author of "Automate". The best next steps for any language are getting familiar with the standard library and doing projects. I recommend Doug Hellmann's Python Moduel of the Week blog https://pymotw.com/3/ and the "Python Cookbook" book.

For projects, you can work on your own or try tackling the problems on http://exercism.io/ (I like it better than Project Euler)
>What else would I need?

A project that captures your interest. I've made so many weird different automation programs with Python that it's really helped me explore different facets of Python, and it's made the process really enjoyable.

Py3 is definitely the right choice. I have some legacy Py2 code that I maintain, but for any new projects, it's all Py3 from here on. After learning language and OO basics, pick up a web framework like Flask - you will find yourself using it again and again. (Oh, coming from Java background? Take care not to replicate Java thinking to your Python - see this post: http://dirtsimple.org/2004/12/python-is-not-java.html)
Just write stuff yo.  You can read all the books in the world, but if you never write anything you're never gonna progress.
I think Automate would be all you need to start.
[Fluent Python](http://shop.oreilly.com/product/0636920032519.do) is a great book to learn python3, a lot advansed topics explained very nice. It is very different from other Python books.
You can use cron to do this. 
http://launchd.info/

http://launched.zerowidth.com/
crontab -e
Just a heads up, I've been tinkering around with gRPC and decided to create a specific subreddit for it, some points on that:

1. It's not Python specific but has Python bindings and Python seems to be a popular language used with it.

2. I've use rPyC, Pyro, xmlRPC and other RPC frameworks/approaches with Python. . . gRPC just "feels right" to me, especially in that it's cross-platform and cross-language.

3. My main motivation for creating this subreddit is that gRPC is complicated enough but seriously lacking in good documentation and more specifically concrete examples.  Actually, it reminds me of asyncio in that regard, although there are more asyncio examples online now.

That's it, check it out, let me know what you think.
> There's a CPython semi-oficial repository in Github that can be a good start. But eventually, I opted for the more official way and downloaded the source code from the Python's foundation downloads page so that I could comfortably explore it with my text editor.

There's [a link to the source code of each module at the top of the documentation](https://docs.python.org/3/library/functools.html).  The source is [officially hosted on hg.python.org](https://hg.python.org/cpython/file/tip), not github.

> `role[randint(0,len(role)-1)]`

You might want to give `random.choice` a spin.
instead of `print('text', variable, 'text')`, you should look into either an actual templating language (like Jinja2 as others have suggested), or pythons built in format strings, like `print('text {} text'.format(variable))`

on the surface that doesn't look much better, of course, but you can expand it as so:  `print('text {0} text {1} {0}'.format(variable, other_variable)`

so you can more easily alter the basic template without worrying about having to re-order the arguments to the `format()` call.

Take that a step further and define the template on one line, and call `format()` on another.


    story_template = '''
    A 20-something {0} (played by that one actor who is in every movie) decides to {1} in {2}.  There she meets {3} and falls madly in love. 
    However, she is currently engaged to {4}. Fortunately for the plot, her current fiance is revealed to do something mean (such as 
    close an orphanage or something), and with the help of {5} she is able to break up with him for her 3 day love with no moral qualms.
    At the end of the movie, it's a christmas miracle when {6}. The movie ends with the lovers sitting around a christmas tree singing 
    a cheesy fake christmas carol (so Hallmark doesn't have to pay for royalties) and {7}.'''

    print(story_template.format(
        ran_from_role(female_role_table), 
        ran_from_role(decision_1_table), 
        ran_from_role(setting_table), 
        ran_from_role(male2_table), 
        ran_from_role(male_1_table),
        ran_from_role(helper_table), 
        ran_from_role(miracle_table), 
        ran_from_role(ending_table)))


Already more readable and easier to maintain IMO.  Then there's one more layer of improvement:

    story_template = '''
    A 20-something {fem_lead} (played by that one actor who is in every movie) decides to {decision_1} in {setting}.  There she meets {new_male} and falls madly in love. 
    However, she is currently engaged to {old_male}. Fortunately for the plot, her current fiance is revealed to do something mean (such as 
    close an orphanage or something), and with the help of {helper} she is able to break up with him for her 3 day love with no moral qualms.
    At the end of the movie, it's a christmas miracle when {miracle}. The movie ends with the lovers sitting around a christmas tree singing 
    a cheesy fake christmas carol (so Hallmark doesn't have to pay for royalties) and {ending}.'''

    print(story_template.format(
        fem_lead = ran_from_role(female_role_table), 
        decision_1 = ran_from_role(decision_1_table), 
        setting = ran_from_role(setting_table), 
        new_male = ran_from_role(male_2_table), 
        old_male = ran_from_role(male_1_table),
        helper = ran_from_role(helper_table), 
        miracle = ran_from_role(miracle_table), 
        ending = ran_from_role(ending_table)))

Now you can alter the template without any worry about the order of the arguments, and you get the benefit of fields having meaningful names that are a lot easier to keep track of than a bunch of indices. 
This would be a great project for you to try out a templating engine like Jinja. That lets you easily edit the text without having to mix it up with code. 
Going to fire off a couple of these to my sigother and see if she'd be interested in watching them. 
Fun project! :) If you wanted to build on it, you could try allowing the user to enter some new options (like MadLibs). 
Eesh, this hits home. I think you need an "Average 'Christmas' per minute <random int>", too, since it seems like Hallmark requires movies mention the C-word at least twice a minute. I swear you'd think the director is afraid viewers will forget it's a Christmas movie unless literally every moment is padded with it.

Have you noticed how every single movie's "soundtrack" (if you can call it that) is exactly the same? It's like they bought the license for a handful of "reaction" tracks (surprise, climax, sadness, major plot point, etc) and never use anything else.
I did a similar project a few years ago for generating B-movie titles.  I was never entirely satisfied with the results, which is why it's still version 0, but it was a fun project nonetheless:

http://www.zycha.com/BMovie.py

The source code can be found here:  https://github.com/ConceptJunkie/BMovie

> It seems that perfection is attained not when there is nothing more to add, but when there is nothing more to remove.

*Antoine de Saint ExupÃ©ry*

Every code you add to the standard library is code you have to maintain; at some point, you risk spending more time maintaining existing code (bugfixes etc.) than adding new functionality to the language.

Also, where do you draw the line? If there's a function to choose by weighted values, how about choosing from gaussian or poisson distributions? How about adding some randomness tests to the library as well?

Furthermore, since it's the *standard* library, you can't really make many changes to the API, so if some bad decisions were made, you're pretty much stuck with them for quite some time (see Python 3 which was designed as a one-time thing to fix some bad decisions that couldn't be changed without removing backwards compability, and how long it takes for people to use it). It's much better to limit the scope of the library and let third party libraries handle the special cases.
They already included a ton of features in the stdlib random module that a lot of standard libraries don't bother with.

It's already pretty full featured. I've had to do weighted choice myself but it's actually really easy to do so I don't see a problem. Look into any markov chain library and it'll have to implement some version of it.

If you want an inefficient but super simple way of doing a weighted choice using positive integers, try this:

    import random
    weighted = 20*['alpha'] + 5*['beta'] + 1*['gamma'] + 12*['delta']
    print(random.choice(weighted))

Bam, weighted choice. If you need the real thing with floating points, it's pretty easy to do (again, markov chain implementations).
1. In Python 2, use `raw_input` instead of `input`.

2. All-caps titles are not a good idea.

3. Post questions in /r/learnpython.
Fucking noobs
Compared to web, how hard/frustrating was it? And how would you compare the results in terms of potentialities? 

PS for making style a little less tk-ish for every widget you can use a **prefs that is a dict with your prefered stuff like bg colors and al. Cf this gist for an example https://gist.github.com/jul/e9132abe8b5aeea573917191591fb90b
 (search for **pref)
PPS I am the troll who wrote http://beauty-of-imagination.blogspot.fr/2016/01/tcltk-vs-web-we-should-abandon-web.html so I am curious to see if I was the only one pleased with going back to tk


You need Javascript for that. 
What you're asking for has nothing to do with Flask.  You probably want either [Selenium](http://www.seleniumhq.org/) for automating a web browser on the PC your Python code is executing on or client-side JS for opening tabs on clients that visit your Flask site.  Client-side JS has restrictions on how it can interact with other tabs for annoyance/security reasons.
Depends what you're after really. You can make a link which opens in a new tab by using :

    <a href="google.com" target="blank">...</a>

But as for controlling what happens there, that would be a job for selenium, unless you're talking about doing something on the client side, which I doubt is possible, and I expect there are good reasons why...
Yes, there is an "included battery" that does exactly that.

You can see it in action if you write `import antigravity` (awesome easter egg!).

You can't close it. The **only** thing you can do with it is to make it go to another link.

https://docs.python.org/3.6/library/webbrowser.html
If I understand correctly, I need to have this [script in the path with the PDFs](https://github.com/michael-123/PYDFMerger/blob/master/pydfmerger.py#L63) I want to merge?

That doesn't seem too slick, I should be able to pass a `target directory`.

Also, it looks like filename conventions are required to do the merge. Do I have to rename any file I want to something the tool will understand? That seems unwieldy.

Lastly, it's nice that you included test PDFs, but those are probably better suited in a `tests` directory.
Doesn't sound like you need deep neural nets, just basic ml algorithms. Use sci kit learn. 
I found it pretty fast easy to use the linear regression models in scikit-learn.
I've found  Lasagne on Ubuntu to be the easiest to set up and use. 
I am using TensorFlow myself, due to the versatility that the library offers and partially due to the fact that it's popularity gives me access to tons of resources online. You might not be intrested in the versatility aspect of the language, yet the online tutorials should get you covered as far as learning the library is concerned.
I found Keras to be super simple and fun. But your problem rather sounds like linear regression. For that, scikit-learn would be a good package.
I haven't used any. But I'd use TensorFlow. The interface seems very simple and there's plenty official tutorials (with their respective data sets) up on YouTube.
If you are running Linux I think Tensorflow will give you the most depth. 
I don't use either, just syntastic.
I use python-mode and pydiction.

I think it's still usable and I'm pretty happy with it.

I would recommend it.

The defaults are a bit too much for me. I disabled some stuff like rope for example.

didn't even know it was no longer maintained, hopefully somebody will pick it up in the future.
tl;dr: I would say try python-mode, pick what you like and setup your own config. Don't buy into the full thing as it will slow vim down considerably.

---

python-mode is an opinionated set of plugins related to python while jedi-vim just exposes the jedi library to vim (aka autocomplete).

pyhon-mode is perhaps the easiest way to get started when you don't realy know what you are looking for, but its lack of granularity (and maintenance) makes it VERY SLOW on big-enough/real-life projects and after a while you will most likelly move to a more custom/granular configuration.
I used to used python-mode for a long time. It was pretty nice, but I kept running into performance issues, especially when working on large projects - had to keep tweaking the settings - I think I had to disable rope and some other stuff to prevent freezes. Think I also had to disable some folding feature for perf issues, and use vim-fast-fold instead.

For completion, I used to use YouCompleteMe, which worked nicely - though you had to keep recompiling libs when an update was rolled out.

I think there are also issues where you can't have python-mode and jedi-vim side-by-side - not sure if issues are resolved. (ie. if you wanted most of python mode features, but wanted to use jedi-vim for completion, etc).

For linting and all, syntastic works well. I think I disabled python-mode's linting and enabled linting in syntastic.

At some point I think I just disabled python-mode altogether. All I missed were the convenient motions to select/change/delete methods and classes - cim, dam, viC, daC etc etc.

I'm currently redoing my vim setup. I'm using neovim now, using neomake for supa-fast async linting. 

For completion, I'm using deoplete along with deoplete-jedi. I had to install jedi-vim as well to be able to have the 'go-to-definition' feature (disabled completion in jedi-vim - since that is handled by deoplete-jedi).
I used python-mode, but it's not updated from january 2016, the issues are not resolved and in the github site you can read that the author don't have time to resolve the issues. Was a too-much plugin with many settings that can be implemented with other plugins and settings. The autocomplete used rope and was cumbersome with virtualenvs. So i search for additional options, and instead of jedi-vim, I choosed YouCompleteMe, that use jedi for python autocompletion. i complement with Supertab to add Ultisnips too. And some time i leave python-mode and implemented some settings for python filetype, autoindent, smarttabs and tabstops settings.

Some weeks ago i begin to use NeoVim and for this I changed YouCompleteMe and Ultisnips with Deoplete, Deoeplete-jedi, NeoSnippets and Neomake. my actual settings are published here:

https://gitlab.com/snippets/25691

Why not both? I use Jedi for autocomplete and then turn off pretty much every feature in python-mode except rope refactoring tools
jedi-vim and VimCompletesMe for autocompletion.

[ropevim](https://github.com/python-rope/ropevim) for refactoring.

A [flake8 compiler plugin](https://github.com/drgarcia1986/python-compilers.vim) for building.

Gutentags and Universal Ctags for building tags
This better be focusing on python 3 and not the outdated python 2.

The longer we keep python 2 alive the slower the python community evolve because of the divide.

Its time to move on folks!



Nope. It's just supports python 2.
Whatever 

Just for giggles i hope they'll break python 4 and have the gil removed.
Pyston is touted as a high performance JIT for Python but it seems like pypy out performs Pyston.  I am curious about whether Pyston ultimately has more legroom to run than Pypy.  It seems like if you want a JIT, you should choose Pypy over Pyston.  What am I missing?
Dropbox's Investment into a new Python Implementation is really great. It really pushes the whole python ecosystem forward. We needed a company like them to finally do that!

TL;DR:

"Both Python and R have great packages to maintain some kind of parity with the other, regardless of the problem you're trying to solve (...) But if you're looking for a flexible, extensible, multi-purpose programming language that also excels in both machine learning and data analysis, Python is the clear choice.
Not to mention major differences in the culture of documentation.

In Python, you're likely to find a website with images or an interactive notebook.

In R, you'll get a 90+ page PDF without graphic examples.

I do data visualization and use both R and Python regularly, with a strong preference for the latter. The number of R packages for graphics that are one hundred pages without a single example of said graphics is ridiculous. It's like documentation is maintained by an academic who hasn't been told those PDFs don't count during tenure review.
The thing that bothers me the most is R's coding style. I guess it's more of a personal preference but I just cannot get over it.
Shiny is still the quickest way to get really nice dashboards up and running. Also, R has quite a bit more flexibility in dealing with missing data than sci kit learn.

One place where I am now finding a lot of good use for Python though is with redshift. You cannscale Python udfs to a lot of data.
Python for sure. It blends into application stacks much easier than R.
Python is also my choice for data analysis!
R's strength includes ggplot2 and stats modeling.

Python's port of ggplot2 is promising.  IMO, people ought to use ggplot2 rather than seaborn, etc.

Python's statmodels need to have better documentation and many more things to approach R's statistical modeling.
I love Python but disagree. The tidyverse and Shiny have put R way ahead as a data language
I think it's kind of a silly question, sort of like "Python versus R for networking". Both do it. Tons of languages do it. I know guys who've done ML and data analysis with python, scala, R, lua (cuda torch). They all have great libraries. 

It's not what language you use, it's how you solve the problem. The hard part is definitely not working with the language, or what "looks the cleanest". 
IMO, Python is way better tha R if you plan to do data minig for a long time.
Let me try..

|    |   Python |  R  |
|---|----------|----|
| basic ML | scikit-learn | 1,000,000 packagesÂ¹ |
| deep ML | 1,000,000 packagesÂ¹Â² and mxnetÂ³ | mxnetÂ³ |
| Bayesian inference | pymc | 1,000,000 packagesÂ¹ |
| basic plotting | matplotlib | built-in |
| nicer plotting | matplotlib + seaborn | ggplot2 |

Â¹ and 1,000,000 different APIs

Â² good luck getting everything installed and running on GPU if you're on Windows

Â³ also available for Python, R, Scala, Julia, and of course C++; probably the easiest DeepML library to install and get running
Mixed effects logistic regression is the biggest missing piece in Python for me, so I do almost everything in Python,but most of my regressions and related plotting in R. Not the worst status quo.
As someone who uses both for Data Science things, I think the discussion should be less "Python vs R" and more "how can I leverage both of these to my best advantage?".

Unequivocally, Python has advantages like being faster, being able to neatly fit into applications/web/pre-existing tech stacks a lot easier and it's got a huge variety of great libraries and they're often put together a lot more rigorously.

However, I've found that R's advantage, due to its academic background, is that there are more implantation of new and 'cutting edge' stuff. Also, to my knowledge, there aren't any good libraries for things like association rule mining in Python (and the SKLearn team refuse to implement it) whereas there is with R. I also find that getting regression models off the ground is a lot easier and faster with R due to its insanely straightforward plotting and how many modelling packages will usually provide a full set of diagnostic graphs etc.

I usually harvest my data in Python, try and do initial exploration and cleaning in R, replicate the cleaning/preprocessing that worked/helped in Python, try some models in R and Python depending on what I want to do. Refine models, figure out the python implementation of the final set of preprocessing, cleaning, modelling and plotting and roll that out in one neat script/pipeline.
I do analysis at work all the time. We set up API servers for streaming data analysis. The thought of doing that in R makes me shudder. R might have the better ecosystem when it comes to actual stats, but the rest of Pythons ecosystem is far better (networking, etc.) and makes common programming tasks (set up an API, give users quota, etc.) so much easier. 
If you're an experienced Python (or really any standard system or scripting language) developer, you're almost always going to prefer Python over R - it's much closer to what you are used to. 

However, if you are from a STEM field that doesn't teach programming and instead uses R, or SPSS, or some other stats based language - you are probably not going to bother putting in the time to learn Python unless someone pays you to learn it - and even then, you'll probably still prefer R. 

R is a specialist language, and as such, it tends to get the cutting edge stuff from academia faster than Python (often an R package for a new algorithm will be released alongside the paper to encourage use), but the Python data community has become extremely good at porting the most important contributions from the R community to Python - that's why we have libraries like pandas. 

The article is a good overview of the strengths and weaknesses of both, but I think this is the key quote from the conclusion: "There are so many distributions, modules, IDEs, and algorithms for each that you really can't go wrong with either." In other words, follow your bliss. 

Personally, I know and use both with the decision resting on what I'm actually trying to achieve. A web based dashboard? Python. Quick data cleaning and exploratory analysis? R. 

R wasn't created to replace or replicate what Python already does. Stats and graphs. Created by biology students I think? That's why counting starts from one and not zero.
I learned about pandas maybe a year after learning R (2012) and preferred it until pandas became insanely overused and over relied on to do data analysis. Plus pandas is super slow.
Yes. You might want to investigate [Boost.Python](http://www.boost.org/doc/libs/1_62_0/libs/python/doc/html/index.html).  I've worked on large commercial systems which integrate Python and C++ code bases using Boost.Python. It has a steep learning curve, but is very powerful.
Yes. Look into `ctypes` in the standard library or [cffi](http://cffi.readthedocs.io/en/latest/).
I would consider [wrapping it in cython](http://cython.readthedocs.io/en/latest/src/userguide/wrapping_CPlusPlus.html).
Avoid swig like the plague
I have a sort of skeleton repository doing this sort of thing here directly using the C/C++ api. I personally find it easier to use that directly than to use Boost Python/pybind11/swig/ctypes (though you should definitely check that out too since maybe that's your thing). It's written for python 2.7 (only ever tested it on Ubuntu and debian) and it's not well documented, but it might be helpful (at least I personally like to have code as guides):

https://github.com/ApproximateIdentity/module

Basically the way you use that is the following:

1. Clone repo to `module/` folder (well anywhere, but I'll refer to the folder location like that).
2. Go into `module/cpp` and run `make`. This will compile a C++ shared library.
3. Next set paths: `export LD_LIBRARY_PATH=module/cpp`, `export LIBRARY_PATH=module/cpp`, and `export CPATH=module/cpp/include` (actually make sure to set these to the _full_ paths and not relative...).
4. Go into `module` and create a virtual environment `virtualenv venv` and then execute `source venv/bin/activate`.
5. Finall run `make` inside the `module` folder.

After this has all been done go to another folder and execute the following python commands: `import module; module.print_strings(["hello"])`.

After this is all done, look at the C++ code itself and the wrapper code in python. It hopefully will make some sense. In your case, you would basically need to write the C++ wrapper code to fit your library. By the way, you might want to look at the repo's history, because I did try to make it reasonably clean. Hopefully this helps...
The best option is to return the values from your functions, and pass them as arguments to subsequent functions that need them. Relying on global state is a terrible, terrible idea. Also, questions go in /r/learnpython - this subreddit is for news and discussion.
If you are familiar with classes and creating instances of classes, x y and z would be like instance attributes, and a new instance is "created" every time you run the function.
Just don't use functions?
Oh man, are you in for some fun!

First off, it is generally better for your edification to post to r/learnpython.  Other people usually point it out before me, but I consider it to be good etiquette.  Repetition is key.

Moving on.  Without knowing precisely why you are trying to put your code together that way, I'm not going to comment on it, save that it seems like something that would have to have a very good reason to exist if it did.

You wanna have fun with scopes?  Check this nonsense out.

    def main():
        x = 1
        y = 5
        z = 8
        def function_2():
            a = x * 10
            b = y * 10
            c = z * 10
            def function_3():
                print(a)
                print(b)
                print(c)
            function_3()
        function_2()
    main()

That should give you the output you're looking for.  Figuring out why would probably be a good exercise!
Variables in side functions are only local to that function. you need to pass them through of make them global.

a mixture of the two would be :

    X = 0
    Y = 0
    Z = 0
    
    def function_1():
        global X
        global Y
        global Z
        X = 1
        Y = 5
        Z = 8
    
    def function_2():
        a = X * 10
        b = Y * 10
        c = Z * 10
        return a, b, c
    
    def function_3(a, b, c):
        print(a)
        print(b)
        print(c)
    
    def main():
        function_1()
        a, b, c = function_2()
        function_3(a, b, c)

    main()
    import urllib.request as request
    from bs4 import BeautifulSoup
    import string, re, pprint, unicodedata
    import csv, os, datetime
    
    class SecFilings():
        def __init__(self,stock_symbol,start_row=1, end_row=10,sort=('date_filed','ascending'), url_root="http://secfilings.nasdaq.com/"):
            self.url_root = url_root
            self._get = self.parser(stock_symbol,start_row,end_row,sort)
            self.export = self.export()
    
        def __getitem__(self,filing_id):
            return self._get[filing_id]
        
        def __str__(self):
            return str(self.pretty_print(self._get))
        
        def __repr__(self):
            return str(self._get)
        
        def pretty_print(self, x):
            pp = pprint.PrettyPrinter(indent=4)
            return pp.pprint(x)
        
        def build_query(self, stock_symbol, start_row, end_row, sort=('date_filed', 'descending')):
            #Process the inputted arguments used for our query url
            asc_desc = {'ascending':'A', 'descending':'D'}
            sort_ids = {'form_type':'104', 'date_filed':'101', 'period':'105'}
            sort_by = sort_ids[str(sort[0])]
            sort_direction = asc_desc[str(sort[1])]
    
            #build minimal query to get get total number of records
            url_template = str("{ur}filingsCompany.asp?SortBy={sb}&{sd}=D&StartRow={sr}&EndRow={er}&selected={ss}&SchValue=0000320193")
            url = url_template.format(ss=stock_symbol, ur=self.url_root, sr=1, er=1, sb=sort_by, sd=sort_direction)
            pre_results = request.urlopen(url)
    
            #Display the url for our query just so we can make sure everything is on track.
            print('Accessing url: ' + url + '...')
            print('Stock symbol: ' + stock_symbol)
            
            #Download the results for the first stage of the query
            print('Searching...')
    
            #Make soup, and parse outter table
            soup = BeautifulSoup(pre_results.read(), from_encoding="iso-8859-1")
            meta_table = soup.find_all("table",attrs={"class":"body1"})[2] #This outter level of the table contains the "Records X - Y of Z" statement, which is useful data to our parser function.
    
            meta_row = meta_table.find_all("tr")
            #print(meta_row)
            
            for record in meta_row:
                meta_statement = record.find("td", attrs={"align":"center"}).text
                count = re.search(r"(\bRecords )(\d+)( - )(\d+)( of )(\d+)", str(meta_statement)).group(6) #Parse "Records X - Y of Z"
                self.count = int(count)
                print(str(count) + " records found.")
    
            query = url_template.format(ss=stock_symbol, ur=self.url_root, sr=start_row, er=self.count, sb=sort_by, sd=sort_direction)
            self.query = query
            return query
    
        def parser(self,stock_symbol,start_row,end_row,sort):
            url = self.build_query(stock_symbol,start_row,end_row,sort)
            print('Downloading...')
            results = request.urlopen(url)
            soup = BeautifulSoup(results.read(), from_encoding="iso-8859-1")
    
            print('Parsing...')
            #Find the table
            table = soup.find_all("table",attrs={"class":"body1"})[3] #Tables appear to be nested for formatting purposes on this page. [3] selects the 3rd level of nested table, which contains our data.
    
            #Returns a list of rows in our main table
            rows = table.find_all("tr")
    
            #rows[0] contains some directions that aren't useful to us. row[1] contains headings. All other rows[2:] contain the actual data you want to parse.
            data_rows = BeautifulSoup(str(rows[2:])).find_all('tr')
            heading_row = BeautifulSoup(str(rows[1])).find_all('td')
               
            #Add two list comprehensions together to create list of headers. Two are needed due to different formatting on headers.
            headings = [heading.find('b').text for heading in heading_row if heading.find('b') and not heading.find('a')] + [heading.find('a').text for heading in heading_row if heading.find('a')]
            headings.append('Owner/Filer')  #additional heading
            headings.append('Filing Id')    #another additional heading!
            self.headings = headings
    
            row_list = list()
            self.list = row_list
    
            row_dict = dict()
            self.dict = row_dict
    
            #Open a for loop that will take us down to the individual-record level.
            for record in data_rows:
                row = dict()
    
                #Start parsing the html tags and adding them to row{} dict. 
                company_name = record.find('b')
                if company_name:
                    company_name = unicodedata.normalize("NFKD", company_name.text).strip()
                    row[headings[0]] = str(company_name)   #Should be 'Company Name'
    
                    form_type = record.find('a')
                    if form_type:
                        form_type = unicodedata.normalize("NFKD", form_type.text).strip()
                        row[headings[2]] = str(form_type)   #Should be 'Form Type'
    
                    period = record.find('td', attrs={"class":"secperiod"})
                    if period:
                        period = unicodedata.normalize("NFKD", period.text).strip()
                        row[headings[4]] = str(period)
    
                    filed = record.find('td', attrs={"class":"secreceived"})
                    if filed:
                        filed = unicodedata.normalize("NFKD", filed.text).strip()
                        row[headings[3]] = str(filed)
    
                    #Parse the filer name. Tricker 
                    filer = record.find('font', attrs={"class":"smallText"})
                    if filer:
                        filer = unicodedata.normalize("NFKD", filer.text)
                        if 'Reporting' in filer:
                            filer = filer.replace('Reporting Owner: ','')
                        elif 'Filed' in filer:
                            filer = filer.replace('Filed As: ','')
                        elif 'Filer' in filer:
                            filer = filer.replace('Filer: ','')
                        
                        row['Owner/Filer'] =  re.sub(r'[\t\n\r]', '', filer)
    
    
                    #Parse the list of urls from the href tags.
                    url_list = [link.get('href') for link in record.find_all('a', href=True)]
                    url_dict = dict()
                    #remove duplciates by using set() as an intermediary type
                    url_list = list(set(url_list))
    
                    #append root directory for any urls that were parsed as a relative path
                    for n,url in enumerate(url_list):                
                        if self.url_root not in url:
                            url_list[n] = str(self.url_root) + str(url)
    
                    #build dictionary of urls based on file type
                    if url_list:
                        for url in url_list:
                            if 'html' in url:
                                url_dict['html'] = url
                            if 'pdf' in url:
                                url_dict['pdf'] = url
                            if 'xls' in url:
                                url_dict['xls'] = url
                            if 'orig' in url:
                                url_dict['original'] = url
                            if 'rtf' in url:
                                url_dict['rtf'] = url
        
                        row[headings[1]] = url_dict
        
                    #Parse the filing_id from the first url available using regex. Not available in any other location.
                    filing_id = re.search(r"(FilingID=)(\d+)", url_list[0]).group(2)
                    row['Filing Id'] = filing_id
        
                    #Add our newly created row to our list-of-dicts, aka row_list[]
                    row_list.append(row)
        
            for row in row_list:
                row_dict[row['Filing Id']] = row
            print('Parsing completed.')
    
            if self.export == True:
                export(self.list)
    
            return row_dict
    
        def export(self,directory="~"):
            now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            filename=str('\SEC_Filings({now}).csv').format(now=now)
            location = str(directory + filename)
            print(location)
    
            with open(str(filename), 'w') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=self.headings)
    
                writer.writeheader()
                for record in self.list:
                    writer.writerow(record)



/r/dailyprogrammer

I believe this is it
Disclosure: I'm one of the authors of The Python Apprentice.

I was disappointed to see the furore around LPTHW and Zed Shaw's attack on Python 3.  I've been developing with Python since Python 1.5.2 (around 2000) and programming exclusively in Python 3 for five years now, since Python 3.2.  Python 2 seems like a distant memory.  My only recent contact with Python 2.7 is occasionally tweaking my own open source code so it so it is backwards compatible with Python 2.7.

Python 3 is the only viable future.
Great to see a constructive comeback! Thumbs up. 
Looking at the table of contents it looks like it's rather basic for me....and since I cant see a sample of the writing style im holding off. I am curious to know when and what your sequels will cover. Python Journeyman, Python Master
Is Python 2 done now?
So, you pitch the book as teaching best practices, but your preview shows you decided to use methods where properties are the best practice.

Is there a reason for this?

I'd reject any code that I'm reviewing if it did what you do with your Flight class.
I have been a professional software engineer for 15 years, the last 3 of which I've spent using Python. The 12 before that were using a variety of other languages. Python is unique in this toxic fanboi shit. Bury your heads, folks: you'll be irrelevant soon.
* .split???

  * Ideally I'd like to use json parsing. Unfortunately the packets picked up by pyshark/tshark don't contain the complete json string, only fragments. Searching for text data and grepping for text known to be nearby to the roomId is the next best thing

* But why not just use regex, it would be so much cleaner

  * I agree, but hey, this works. You wouldn't get any more reliability out of using regex, it would return the same data, and the bottleneck is on the network anyway.

* memory pointers instead of unreliable packet sniffing?

  * Jackbox doesn't store the current room id at a static pointer. That was the first thing I tried, definitely would have been easier than this solution
Hm... 502 is not "Connection Refused", but "Bad Gateway" -- well, at least in HTTP land, and that usually happens when the load balancer/proxy to the real server loses connection to said server. The whole 5xx errors represent [server errors](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes#5xx_Server_Error), which you have no control over (it's *their* side breaking, not yours).
I don't mean to self-promote, so please mods delete if so,  but I have a free API as I found the yahoo finance one unreliable.

http://api.tiingo.com and check out the docs for daily prices. I secured licensing rights so you may redistribute as you will.

Just a heads up- you have to make an account so I can put bandwidth limits (pretty sane - just to prevent DDOS). Also- I may at some point have to start charging since 25k tickers, but it would be reasonable at $7/month. I figure people will pay it for a reliable expansive API

Edit: I forgot to mention I have copy/paste Python snippets 
[transfer a file from one computer to another without the need of knowing either hostname](https://github.com/nils-werner/zget)
I created a business name brainstorming website: http://nameamigo.com

The idea is you type in some words, or sentences that relate to your idea and the website will generate business names for you. I have found it quite helpful when just looking to brainstorm ideas, or to find an open URL that sounds good.
I've got a Python script that sits in my system tray on my work machine that gives me a context menu full of helpful stuff for my job. 

Pulling the most recent code version, kicking off a build, database backups / restores - super handy, and trims time off menial tasks that I do dozens of times a day

**EDIT:** So a few people have asked to see the code for this to perhaps use it or something like it themselves.  
The source of the actual menu itself can be seen [here](http://pastebin.com/kjpqn72m). When this starts up, it looks for a path in a config file to find a directory from which to load plugins. Each [plugin script](http://pastebin.com/6UTbLKs0) is assumed to have a `RegisterMenu` function to be called to add it to the core context menu, which you can then define the event for.

The main file is a `.pyw` file rather than a `.py`, allowing it to be run continually in the background and not needing to keep a cmd window open for it by launching it using `pythonw`.

Hopefully some of you may find some use for this, it certainly trims minutes off here and there in my day, generally making things easier.
Trying to get a job at a University that rarely has openings so rather than checking their site over and over I have a Python script that emails me everytime they post a new IT job.

Another recent script was helping my wife combine images, she had a picture of a full dress and then a close up of the pattern on the fabric, about 150 of them, it was slow going with Photoshop to put the images side by side then watermark it.  Python + Pillow made short work of it though.  
Not a developer. I work as a financial analyst. 

I wrote a script to extract data from an unwieldy xml periodically published by a regulator and write the interesting parts in a excel sheet, that I can manage with my usual tools.
Back in my third year of university I wrote a program that would scan a word doc and do my stats homework for me. The format was always the same on the doc, so I'd just have to tell it what the question wanted once it had all the numbers. Saved me a bunch of time, and since I wrote it myself I didn't think it counted as cheating.
Wrote a [python script](https://github.com/SathyaBhat/spotify-dl) which you can use to download songs from your Spotify playlist. Published it [on PyPi](https://pypi.python.org/pypi/spotify-dl) as well
* A bunch of web-scrapers.
* A video converter with hardsubbing function to watch any video on any device (it also saves all fonts found within MKVs to my font collection; one TV series had more than a hundred!).
* A scan splitter which detects the border between spread pages of a book.
* A web-comic splitter which cuts 4000x500 pixel files into something I could read on my tablet (naturally with a scene detection).
* A program which adds 'fingerprints' to image file names, so similar images would stay together when sorted alphabetically.
* A program converting image folder to PDF which can be opened on my e-book.
* A bilingua maker which combines two language version of the same book into a 2-column PDF, so I could practice other languages.
* A program which converts an English book into cyrillic phonetic transcription, so I could practice this insane pronunciation while reading.
Since Python is embedded into video surveillance system I use in my work I wrote a bunch of scripts to manage cameras, export info and organise stuff.
The company I work for just switched from Lotus Notes to Outlook, but neglected to provide a client for Linux users (my whole team) and turned off all pop/imap functionality. This forced us to use a crappy web client and miss a ton of notifications of email, calendar events, etc. I wrote a script that logs in and periodically scrapes the web client for various notifications then routes them as DBUS notifications so we get a little tray popup in gnome/kde.

It's not a perfect setup, but works well enough while we try to petition the overlords for sanctioned Linux support :)
My band had dozens of hours of raw camera footage and the task of making sense of it to form a coherent promo video was so daunting that it kept anyone from doing it.

Instead I just wrote a script to randomly draw video snippets and combine them under our studio recordings.

See finished product [here](https://youtu.be/nFW0vHi_me0) and [here](https://youtu.be/h8jv3yzYnZo)
I'm a mapmaker. One thing I do a lot is take information from one layer of information (say, neighborhood boundaries) and put it in another (say, fire hydrants.) Usually the two layers don't have a convenient common field to connect them, so I have to do a join to a new layer based on their spatial relationship, and then copy the field back to the original source file.

I finally got tired of doing this and wrote a script that does the spatial join automatically, then pulls the data into a dictionary that it uses to populate the target field in the original source data. Saves me a few minutes at a time, but as often as I do this stuff, it adds up.
a script to parse the latest weekly ad for the grocery store across the street to see if there are any current deals on hot cheetos
I've posted this before, but here it is again:

[This script](https://github.com/joshnewlan/say_what) listens to meetings I'm supposed to be paying attention to and pings me on hipchat when my name is mentioned.

It sends me a transcript of what was said in the minute before my name was mentioned and some time after.

It also plays an audio file out loud 15 seconds after my name was mentioned which is a recording of me saying, "Sorry, I didn't realize my mic was on mute there."
* [automatically gather a bunch of statistics on GitHub pull requests](https://github.com/xiongchiamiov/github-pr-stats)
* [find a new domain to register for an email address to read over the phone](https://github.com/xiongchiamiov/phone-suitable-domain-name)
* [make it easier to manage spf records](https://github.com/xiongchiamiov/hydrate-spf)
* [requeue all the jobs in a ci system when we had issues](https://github.com/xiongchiamiov/requeue-cimpler-jobs)
* [assign a bunch of labels to GitHub pulls](https://github.com/xiongchiamiov/github-labels-from-tsv)

More but my phone is about to die.
Back in highschool when I took AP US History, the teacher had us do 300+ flash cards. So I fed a spreadsheet of them to a script that would search it and use Google's definition box that appears near the top of the page.
https://github.com/kdesimone/popeye

a tool for developing and testing quantitative models of human brain function as measured with fMRI.
I work at a startup and before i got there all their analysis routines were people-intensive.  Move this file out of this folder, run this program, move the file back into the folder, run this other program, upload the data to the network then import it into excel, etc.  all for one data set.  

fuck. that.  i wrote a script that takes care of all the piddly shit so you can just run it and walk away and in 5 minutes *ding!* results.
I wrote a hacky script to randomize my wallpaper!

    #!/usr/bin/env python3

    import os
    import random
    from subprocess import call

    EXTENSIONS = ("jpg", "jpeg", "png")
    BASEDIR = os.environ["HOME"] + "/Pictures"
    WALLPAPER = BASEDIR + "/wallpaper"
    WALLPAPERS = BASEDIR + "/wallpapers"

    def main():
        file_list = [f for f in os.listdir(WALLPAPERS) if f.endswith(EXTENSIONS)]
        new_wp = random.randint(0, len(file_list) - 1)
        try:
            os.unlink(WALLPAPER)
        except FileNotFoundError:
            pass

        os.symlink("%s/%s" % (WALLPAPERS, file_list[new_wp]), WALLPAPER)
        call(["feh", "--bg-scale", WALLPAPER])

    if __name__ == "__main__":
        main()
I get text message notifications when a new edition of my favorite manga is out. No more checking every hour on those days for me.
Read a few hundred text-based comp. Chem. output files, find the last number for energy, and put all of them into a CSV file. 
Also a script to generate all the possible permutations for molecule inputs.
It's something I just finished - a script that I use to write my powerlifting workout logs to a SQLite database. I used to write everything down by hand in little journals. After I put all of my old workouts in the database (2.5 years worth..it's going to take a little while), all future workouts will just be entered through the terminal.  I can then perform analysis on my training with pandas and other libs.
I created a python application (and full installer too on Windows) that allows for a user to right-click on any ".py" file they created and compile it to a single EXE file (either that app will run in the console or non-console mode)...It's PyInstaller all in one shot
https://github.com/nicolewhite/simplebank

I built an API for my bank. It allows me to create my monthly goals with a script. They've been saying recurring goals are "coming soon" for about 2 years now so I built this.
Wrote a script that applies to daily web contests.
I created an application that copied the [Synopsys Verdi nWave](https://www.semiwiki.com/forum/attachments/content/attachments/10917d1399182004-verdi2-jpg) interface for debugging embedded power management firmware on Intel CPUs in simulation. My manager believed the tool was a waste of time so I did my development primarily while commuting in to work on light rail and some during my nights and weekends. I polished it as well as I could over two years of development in 45 minute sprints on Portland's MAX. I never received any recognition for having created it. When I left Intel, preservation of the source code was considered to be of paramount importance. FML.

I recently spoke with one of my former colleagues and asked about my app. He thought it unusual that I thought the tool was for meant for debugging when it was really designed for helping firmware architects (he was a firmware architect and used it). I can't even get recognition for it after leaving. FML.
Wrote a program that would press the windows key twice every 5 minutes so that my computer wouldn't log me out when idle. Our company policy logs you off when idle, but sometimes I need to be able to see the screen but not be at the computer for more than 10 minutes... drives me nuts. So I fixed it. Don't tell IT...
Created a script that searches a folder for .c assignments from students, automatically compiles them, saves the compilation output and displays a menu that allows me to explore which assignments compiled with and w/o warnings/errors, read the compilation output and execute any of the generated executables from the same terminal. In the end it deletes all of the generated files so I can have a nice Git repo without clutter.
Is that un-reservable game checked in to my local library? No? Fine, I'll check again in an hour...
A python script that pretty prints json. It aligns colons and does line breaks only when appropriate. Used as a command you can pipe json into it and it will write pretty printed json to stdout.

[pretty_json.py](https://gist.github.com/mbarkhau/c9eb067454ba16cdc03818e8f2ec26b4)

Sample Output

    [
        {"menu": {
            "id"   : "file",
            "popup": {"menuitem": [
                {"onclick": "CreateNewDoc()", "value": "New"},
                {"onclick": "OpenDoc()", "value": "Open"},
                {"onclick": "CloseDoc()", "value": "Close"}
            ]},
            "value": "File"
        }},
        {"widget": {
            "debug" : "on",
            "image" : {
                "alignment": "center",
                "hOffset"  : 250,
                "name"     : "sun1",
                "src"      : "Images/Sun.png",
                "vOffset"  : 250
            },
            "text"  : {
                "alignment": "center",
                "data"     : "Click Here",
                "hOffset"  : 250,
                "name"     : "text1",
                "onMouseUp": "sun1.opacity = (sun1.opacity / 100) * 90;",
                "size"     : 36,
                "style"    : "bold",
                "vOffset"  : 100
            },
            "window": {
                "height": 500,
                "name"  : "main_window",
                "title" : "Sample Konfabulator Widget",
                "width" : 500
            }
        }}
    ]
    
Nothing special to show in a repository but I created a script to process PDF. Each week a goverment institution sent 50-70 sheets of names in PDF that required one-two people working ALL the week transcribing names and SS numbers in our database.

Furthermore if somebody made a mistake let's say, three weeks ago, all work done should be redone starting from that week on.

My script converted PDFs to text using pdftotext Linux utility and all that work could be done in a few seconds just by using a few regular expressions. Luckily management decided not to fire anybody and use these two colleagues for useful tasks
Support Toolset/Portal to handle heterogeneous System data analysis. Its a command line toolset with a UI Adapter. It handles command line calls and convert it into generic structures. This result can forward by mail client, stdout or as result after calling by webui over network.

I like this toolset because i can only create a new command line tool and have automatically a web ui mapping too. The web ui control form are generated from argparse object which was converted into JSON. If i need i can append an other view based on templates fÃ¼r each command. 

Code less do more ;).
an arduino kitted with various things to let me control my house from an android app. The python is in the django server, letting me connect from anywhere, set schedules for lights, etc. The django server sends commands over a Bluetooth connection.

Basic functionality and app are functional. I'm just waiting on parts.
I like to save all my text messages. I've saved the majority of them since 2007. They're in a mixture of SQLite (iPhone) and XML (Android) files. I wrote a small Python script that's takes all the XML backups, create a SQLite db of them as well as decode the raw base 64 images. 

It's fun too see and cringe at the stuff I used to say.
I do video on the side so I knocked together an FFMPEG script (with ffmpy, awesome lib!) to process my raw videos.

My recorded video files with 3 audio streams go in and it spits out an image sequence (much easier to edit image sequences than compressed video) and separate stereo .wav files for each audio stream as well as a compressed copy of the original video with 2 of the 3 audio streams mixed into a single stream for easy distribution and backup.

This makes processing the 1TB backlog much easier so I can concentrate on the cutting and finishing process!

Doing this without FFMPEG/Python would have me sat at a workstation doing these three tasks one after the other - time I could be spent doing something more productive. I love Python for jobs like this!
Years ago I wrote a little script that would translate SRT subtitles using Google Translate API. I really wanted to watch an anime which I could only find with Spanish subs. It worked out pretty well and it was a great feeling to finally solve an actual problem of mine using Python.
I do a lot of technical blogging and need to quickly take screenshots (via OSX `screencapture`) and produce the HTML `<img>` tags (or Markdown), which I copy-paste into my blog:

So I wrote a little script named `screenpy` which I run from the command line: https://gist.github.com/dannguyen/bfb45408d43986eefdf83b59bc9e8629

Sample usage:  

       $ screenpy images/myimage.jpg

Produces this Markdown and HTML code, which I copy-paste:

       ![image hello.jpg](images/myimage.jpg)
       <img src="images/myimage.jpg" alt="hello.jpg">

Or, if I'm in a rush, I just pipe it straight into `pbcopy`:
     
       $ screenpy images/myimage.jpg | pbcopy

    
Or, if I'm not blogging using a static site generator (in which all the content is just files in a folder that I upload) and need a remote URL, I include the `boto3` library that's configured to push to a S3 bucket:

         $ screenpy --s3 my-remote-image.jpg


Makes producing lengthy, illustrated technical posts a **lot** easier, e.g. http://2015.padjo.org/tutorials/mapping/077-ok-schools-quakes/



When I was in high school, I hated math, even though I was good at it. I also hated homework, so I made a calculator that would handle any geometry calculation. It worked for any 2d or 3D object, and would ask you for the dimensions that you had, then would give you surface area, volume, perimeter, and would do side angle side for you.

After than, I never spent more than 10 minutes on my math homework.
The website ticketswap.nl acts as an intermediary for people looking to sell or buy 2nd hand tickets for festivals. Here in the Netherlands it's quite big.

The hassle however is that for popular festivals the tickets are hard to get due to people spamming the pages for new tickets. This can be very annoying if you really want a ticket.

I wrote a program that logs into Facebook, then into Ticketswap and keeps scanning the page of the festival looking for new tickets and if they meet my price demands it automatically reserves the ticket on the account. It then sends me or whoever wants ticket an SMS text with the account and ticket info so they can login and purchase the ticket. 

Me and a lot of my friends use it regularly, less time hitting the F5 button means more time to party. Yay.


To remove docker Images from hosts after not being used for one Week. 
I used to write lots of memos for ongoing/pending work-related claims. Wrote a script to automate the creation of those memos, using data populated from CSVs (as plain text-databases). Cuts down writing time for each memo from 5 mins to about 5 secs each. (Creation time takes less than a second; it's the manual checking which takes up the balance of the seconds.)
A plug-in based telegram bot with multiple plug-ins that help me with day to day stuff, e.g.

* A printer plug-in which prints any document you send to it on the office printer with CUPS. (Yes I have some form of authentication ;) ) 
* A reminder plug-in for simple things that aren't worth putting in my calendar, such as coffee in an hour with a colleague, remember to reply to some email before I leave etc and it'll send me a message when it's time to remind me.

* Weather status and forecast plug-in

* A bus reminder plug-in that scrapes the timetable page from the bus company's website and sends me the times in a message and reminds me when I need to start packing up to get the next bus. Useful since the buses are infrequent, at quite random times and the time I leave the office varies quite a bit.

* A plug-in to show me patches and news items from steam games I use

* An event plug-in that's made for the group chat I have with friends. Allows people to create events, such as for online gaming. One can reserve a place, ready-up etc with callback buttons attached to the message. 

* A plug-in that allows me to keep track of going to the gym. I "check in" at the gym by sending it my location when I'm there. It shames me if I haven't been in a while.

The bot is made in a way that making new plug-ins is super easy, and they interface with telegram side of things using a mixin that registers commands and callbacks to be dispatched to the right functions etc. So if I think of a new simple feature that would be useful I can just make a simple class that uses the plugin mixin and bung it in the plug-ins folder and it'll be loaded up automatically.
Wrote a script that reads my spotify saves and creates a spotify playlist of bands I might like that are coming to my town (using songkick). Now I can just fire up the playlist and hear bands-I-like-or-might-like with real concert potential based on songkick. I like it. Well I used to. It doesn't work anymore. I should fix it.

I half finished a next step that reads my google calendar and does the playlist based not on my home town but rather wherever I'll be (I travel a lot). I think all together this could be awesome. But even the simpler version is really nice.
Well. It's been a hobby of mine for a while. Saved me lots of money!

https://www.stealengine.com

All python and C
I've got one that makes my wallpaper the most up voted image on /r/EarthPorn
Managing forwarded zones in Unbound without restarting with a python script that is triggered by puppet. Unbound drops the whole DNS cache when restarting / reloading.
I wrote a few:  
* For my  work to do simple tasks on Active Directory (nope, powershell was not available because we had Windows Server 2003), to add users, read from a csv file and copy department's name of the users to add in the AD field, security group, etc.  
* To edit the metadata from my mp3 files, Artist, Album,etc.  
* To copy files over ftp to my xbox creating directories and subdirectories. 
I'm interacting with my home pc mostly without keyboard. Just for run videos, music and so on. Some of internet services unavailable for location reason (Russia). For example Spotify. Time to time I should open VPN connection for run such services. I wrote a script for grub free VPN account and open VPN connection from my router via telnet interface.
Backup all the things daily like websites, local files or emails to a local NAS and remote storage.

Download new videos from my favorite youtubers.

Download new vods from my favorite twitch streamers.

Display the current local weather and forecast in my terminal with colors and all.

All kinds of utility scripts, basically if I do something twice by hand I automate it.
https://github.com/Python-scripter/PySpace

A Python script that looks for duplicate files on my computer and remove them.
After Youtube removed subscription lists I made a script that fetches new videos from specific youtube channels. And automatically adds them to my "Watch Later" playlist (4 times a day). And when I'm done I can press the "Remove watched" button, clearing the list for the next batch of videos.

It is not the most efficient code, but the user experience is pretty awesome. It uses youtube's "email me" notification and fetches the video links from my mail. It makes it very easy to subscribe/unsubscribe to people from inside youtube. At the moment mails are still in my inbox, but it haven't bothered me enough to create a rule to move them out of the way.

EDIT: I have been thinking about making a chrome extension and eliminate the mail system altogether. Then it might be more feasible to provide as a service for other people. But haven't had the time.
Wrote something to delete all posts from a subreddit I moderate.
[fnord.safename](https://pypi.python.org/pypi/fnord.safename/0.5)
I want to practice data science with something I'm passionate about, so I developed a [python package to interact with ESPN fantasy football](https://github.com/rbarton65/espnff). I'm able to grab data and form a dataframe to practice on. If I want to practice on something I can't access easily, I just develop the python package even more.
A script to open up an AWS console using only your API keys, as well as set up the roles required for it to work.

https://github.com/eikenb/aws-console
I have a script that runs every 5 minutes during the baseball season and manages my fantasy lineup to ensure my entire roster is active every day.
A pomodoro timer for OSX!

https://github.com/gcr/pocketwatch

There are many like it. But this one is mine. :-)
I was just thinking of posting something like this yesterday because I just had the biggest Ah Ha moment in my life. I made a script that would automate massive amount of repetitive work in photoshop. Might not seem impressive when you are just editing 10 or 20 layers but when you replace that workload with 100 layers 200 layers or even 500 layers, it such a life saver! What's more amazing is that the script was written in javascript and not in python. I used what I learned in python to apply the general knowledge to what I was doing in PS, I was also able to read the majority of the boring ass doc and understood what they were talking about. I had no perspective before how absolutely AMAZING this is, I had 5 lines of code, hours time saved in the future, reusable script, and its fucking awesome.
Wrote my own CLI around the Salesforce API so I can easily view cases, customer numbers, support contracts, order item lists, etc.

The webapp is pretty fully featured, but it's too slow when you need something fast.
Built a scraper to farm rewards points for using a particular search engine in a particular browser.
A podcast downloader, badly in need of maintenance.  I use it multiple times a day (or rather, cron uses it multiple times a day.)
o A full-boat macro language implementation

o A documentation generator that uses the above

o A 100% compatible preprocessor allowing new methods for built in classes, for instance strings:
    `'mystring'.myNewFunction()`

o wrapper for sqlite3 to make DB ops considerably easier

o qmail wrapper that transparently handles MIME and text email

o pre- and post-increment for python

o class to handle console text colors

o class to handle console graphing

o CGI library to make building server side CGI much easier

...this is all Python, not Python3. Most of it has been made publicly available. Lots of other stuff, typically applications like point of sale, inventory management, various data manipulation engines, etc.

- [Syp](https://gitlab.com/vindarel/syp): easily keep track of the packages I install with pip, apt or anything else. AÂ command writes the packages to install in requirement files and at the same time it checks what's new in them. That way I can edit my system's requirements file manually, or with a command. (all nice, but the greatest would be [gnu guix ](http://alpha.gnu.org/gnu/guix/) !)
I had made a script to scrape my various banking institutions and update a spreadsheet with account balances but due to me not knowing shit about security and caring less and less about weekly fluctuations I dropped it
I wrote a [script to automate whitelisted dot file version control](https://github.com/tstringer/dotfiles/blob/master/automate.py) including a desktop notification when there are changes to dot files I version control.
I've made a [config file manager](https://github.com/solkaz/cfm).

It's a WIP but I like it. I hate having to remember where all my config files are so I made this. 
A script to download U.K. Index fund prices from a broker's site. Google/Yahoo doesn't list all U.K. Funds prices. 
I wrote a stupid little script that will go into multiple repos, and compare their requirements.txt files looking for potentially bad pinning choices and version disagreements in common libraries, it exports it to github/gitlab flavored markdown. 
Sorry for double post, but I also wrote a stupid little script that scrapes a fanfiction from ff.net to a markdown file with relatively preserved formatting, I get into totally disconnected situations a lot and want something to read. 
[Cloning Linux hard drives incrementally to any drive, including smaller ones](https://github.com/DonyorM/weresync)
Wrote a very basic script to figure out where I was based on my IP address that created time cards for time tracking.
Https://getappenlight.com is my creation because I hated all other tools out there. 
[This super simple script](https://github.com/chughtaimh/Excel2Jira) that takes an excel table and converts it into a jira-formatted table and copies it to your clipboard. I added a simple UI to it, and I use it nearly every day at this point.
It  just collates data from a horribly annoying web admin interface with date ranges in drop downs, using beautiful soup and pycurl and turns a horribly annoying interface into a spreadsheet friendly format.  It saves me hours of mouse clicking nonsense.
[Proofread Wikipedia](https://github.com/priyankamandikal/arowf) (my GSoC student Priyanka Mandikal finished it.)
At least one aspect of it: I usually check for movie ratings before watching/acquiring, so I created a Flask web-app that scans Rotten Tomatoes and IMDB for newly listed movies and gives an average rating of the two (actually three) scores. My first ever app.

I'm just now getting into Bitcoin and I kinda want to write a trading bot.
I automate a lot of stuff at work with Python.  For myself, I wrote a bunch of scripts that monitor radio station playlists and send me an email when my band gets a play.
For my MSc thesis I wrote a few classes that wrap various sql injection tools and allow them to all be automated (so you can test a site using a ton of different tools all in one go)

I then wrote an SQL injection detector tool from scratch and automated that too

I just finished automating frontend website testing ( for aites built using a framework I wrote and maintain in php) using the selenium python wrappers (automated a ton of common use-cases and now run these in our CI tool on every commit to master along with our phpunit tests [which I wrote too])

also wrote a ton of automated project creation, duplication, deploy, backup, etc scripts in bash and then rewrote them in python :|


I built a dashboard for our lab environment at work, every hour it polls the whole IP address range and then using fping, nmap and queries to the API on our appliances determines which are currently licensed and what version of our software is running on it. Makes finding a system to test against much faster than our current hip chat bot method
Wrote a script to hash all accessible files on a network share, and work out what / how much was duplicated. Took a while to run - but revealed over 50% was copied. Was interesting, but not enough to worry about optimising things!
I was sick of manually copying files from a network drive over to a local drive. Just this last week, I wrote a script to copy files from the network drive that have been modified since the last copy to the local drive, using `shutil`.
I love to read pen and paper RPG rulesets. Whenever I find a web page for a free p&p it takes about an hour of my time to search for all its sub pages and download all PDFs on there. So I wrote a script that handles this for me. Traverse an URL, follow links, download every PDF you find.
* Download the newest entrants **songs** every week in the BillBoard Hot 100 [LINK]( https://github.com/guptachetan1997/crawling-projects/tree/master/bill_board_top50_download)
* Wrote script to set the bing image as wallpaper [LINK](https://github.com/guptachetan1997/crawling-projects/blob/master/bing_image_download.py)
* Get latest cricket scores [LINK](https://github.com/guptachetan1997/crawling-projects/tree/master/Cricbuzz)
* Episode tracker and recommender [LINK](https://github.com/guptachetan1997/Episodes)
Has anyone created a script to work inside outlook desktop? I'd like to scrap through my inbox and assign priority like 1-10 based on keywords, sender and if I'm in the To box. Unfortunately the outlook rules really hasn't made life too much easier. 
I still have to fill out an excel timesheet at work, sign it, and send it to my boss. Now it's one click: pull in dates, add jpg of signature, generate PDF, email to boss's admin. Only thing I haven't done is schedule a job to run it, but that's next. 
 As a Debian unstable user I sometimes need to downgrade packages, if they are not in the other branches I have to manually search for the package at the Debian snapshot repo.I wrote a python program that gets  the info I need from its api from the my termunal and appends the right entry in my .list file 
This is super basic, but one day I thought to myself, "It would be really handy to have a very simple key-value store that works from the command line," so I created a little script that just reads and writes to a file containing a dictionary. I then combined it with a small shell function to let me set a working directory for different project and cd into them easily.
[POS](https://github.com/aiforai/GSI)
I wrote a one time script for my work to fill out a PDF form for machines that we were requesting approval to be destroyed. The form has to be filled out based upon the funding project and could only have a max of 4 machines listed. I took the excel tables we had it the machines for disposal and the other one for the funding into and imported it into SQLite. With 2 queries and a couple for loops it would generate FDF files which would be the data to fill out the forms with. Using PDFTK to combine it with the actual PDF. Reduced the workload from filling out about 100 machines to barely anything. My boss asked me to put it in the internal wiki but it needs a lot of work because importing is a pretty manual process to a random person looking to use the script.
Converting text based lyrics and chords to chopro and then to html for my songbook.

Wrote a double entry accounting system 30 years ago mostly in AWK. Been converting (slowly) to Python.

Various file conversion programs. Like digging XIF info from media files, table formats (html, tsv, etc.), building web pages from tabular data. Bioinformatics files.

So no big whoop.
A Python meta orchestrator over an OpenStack platform !
> microsoft access database files

sigh why ?
I have so many of them. Highlights include tools for every other project I work on, a notifier for when sold-out Kickstarter rewards go back online, and an IRC bot that posts today's lunch in our channel every day. I've made countless things, and definitely have failed to mention some of the coolest, but those come to mind right now and aren't too complicated. 

Right now, though, I'm working on something that's really gonna make life easier for me. I call it *Animorning* - it's an alarm clock that runs on your Raspberry Pi, and every morning it wakes you up with the next episode of an anime you're watching. It's almost done - I'm putting a lot of work into its web front-end! It'll be very nice to be woken up comfortably by a nice TV show, instead of abruptly and constantly snoozing by music or beeping.

Just the word if you'd like more info on something or a download or anything like that.
This is my most recent. I use python extensively for my job, and find it my go-to language for creating useful little programs to facilitate my day to day. In my spare time, I live code visuals at algoraves using a program called Fluxus - basically coding reactive visuals on the fly to music that is coded on the fly. A key part of this is that your screen, code and all, is projected. 

Fluxus is scheme based, and takes vectors for colour values, each value presenting an r g b channel between 0 and 1. For example, red would be (vector 1 0 0).  

I'm also big on colour and like to collect palettes of perfect hues, often converting hex to rgb or picking colours on photoshop. Of course, these are all represented as 0-255, and during a live set I need to either have a list prepared, or be able to convert them quickly without causing uproar with my projection whilst being able to react to the music. Time is essential here. 

So pretty simply, I used TKinter to return rgb values as Fluxus friendly vectors, show swatches to ensure I have a good colour match, output multiple colours as a list. 

Really simple, but so useful for my niche need! 


I have a lot of these because my work was very manual before I got there.

1) auto fill in my timecard. I have a site that I can hit which logs my time, then every Monday it uses selenium to take those entries and enters them into our work site (which is an old java site)

2) every hour go out and vnc into every one of our scoreboards (on a manufacturing floor) and take a screenshot and save the image so it can be viewed on a web page (all at once to see for issues)....and make backups of all the last 24hrs of images.

3) I have a site where I can add torrent links. My home server goes out and checks the site every 5 minutes and if there's a new link it adds it to my local utorrent app and begins the download process. This is great when I want to download something but I'm at work and don't want to do it at work obviously. I just add the torrent link and my home server does it.


push left ctrl to left-click 20 times a second, left shift to right click, move the cursor or push esc to halt

    import win32api
    import win32con
    from time import sleep
    
    def click(coord, right=False):
        x,y = coord
        win32api.SetCursorPos(coord)
        if right:
            win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN, x, y)
            win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP, x, y)
        else:
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, x, y)
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, x, y)
        sleep(.05)
    
    if __name__ == '__main__':
    
        old = win32api.GetCursorPos()
        looping = False
        delay = None
    
        import sys
        if len(sys.argv[1:]) > 0:
            delay = float(sys.argv[1])
    
        while 1:
            if win32api.GetAsyncKeyState(win32con.VK_LCONTROL) != 0:
                looping = True
                right=False
                print 'starting loop'
            if win32api.GetAsyncKeyState(win32con.VK_LSHIFT) != 0:
                looping = True
                right=True
                print 'starting right click loop'
    
    
            if looping:
                click(win32api.GetCursorPos(), right)
    
            if win32api.GetAsyncKeyState(win32con.VK_ESCAPE) != 0:
                print 'Closing Program'
                exit()
    
            if win32api.GetCursorPos() != old:
                print 'Moved cursor, stopping click'
                looping = False
    
            old = win32api.GetCursorPos()
            if delay:
                sleep(delay)
I recently wrote a program that has the user input their monthly utility bills and divides it by the amount of individuals splitting the costs.

I know I could have done something similar in excell that probably would have been easier, but I get a kick out of learning how to do it from scratch.

I'm currently trying to expand the program into a rent & bills calculator for shared living spaces. Progress has been slow though, since I have minimal understanding of what I'm doing. Learning a lot in the meantime through trial and error
Motion detection script (with OpenCV) that records videos and puts them in Dropbox. Also initiates soul destroying cursing from the speakers. 
1. Created a program that reads a word document of multiple choice questions exam. The program creates a new document with multiple exams. Each exam has all the questions shuffled, and the answer in each question shuffled as well. 

2. Created a program that generates random encounter for my DnD cmapaign based on a data base of creatures and treasure. The idea was to have a pool of creatures that slowly reduces and let the players try roam around. 
I made a little utility to download and organize photos from my devices to my desktop.

It pulls all of the photos from a staging area, copies them to the correct folder by month (YYYY_MM), ignores duplicates, time-stamps the file name, and delets the staged photos when complete.
I made a script that transfers an iTunes Playlist to a Creative MP3 player that I owned. Buying an iPod would have been cheaper if my time is worth anything but programming is more fun.
Just today I found myself refreshing a website trying to snag a black friday deal, and it occurred to me that this was something that should be automated. So I spent 5 minutes to write a quick script that checks the page for the name of the product I'm looking for every 60 seconds, and if it finds a match it shoots me an email.

Small, but very pleasing because it's the first script I've written that wasn't work related and actually made my life easier.
Had a homework assignment in Computer Typography, had to manually set up word division points (for words divided at the end of the line), had a 150 word text that I just couldn't go through doing the same thing over and over, run each pair of letters through an algorithm manually.

What I did was, write word by word one after the other and it just threw out the result (word parts with a hyphen inbetween)
Splits the string into a list, runs each letter pair through a for loop, checking every 1st+2nd, 2nd+3rd, 3rd+4th etc. Letters. Then depending on what letters of the pair are vowels or consonants, it adds a hyphen before, between or doesnt add a hyphen depending on the arrangement of vowels and consonants in the letter pair.

I've started doing python 7 weeks ago at my university, this is my first useful program really. 

TO DO: Make it do the whole text all at once.
 
I used to work for a company and I would automate all the websites we had to do repetitive tasks on.  It involved automation and web scraping.  I built [a really small framework](https://github.com/Wykleph/Slack) for running the automations, scraping data, connecting to databases, reading config files using a basic templating engine(so users can define variables, lists and dicts in a file to fetch in the code), and running multi-threaded automations(and more).  Everything is really modular so you can install the framework and only use the pieces you need.  If you aren't automating a website, you can still pull in the config parser or use the database migrations and whatnot.  

There is even an adapter to get `Requests` to act like `selenium`'s `WebDriver` so you can use `Requests` along with `BeautifulSoup` and `lxml` to traverse a websites DOM and scrape data using `selenium`'s syntax i.e. 

    element = requests_driver.find_element_by_tag_name('body').find_element_by_id('username')
    print element.text

You just can't interact with a webpage like you could with selenium if you are using the requests adapter.  This also requires a couple more modules to use(`Requests`, `BeautifulSoup4`, and `lxml`).

You can run 'Jobs'(special case files that contain code for doing a specific `thing`).  They sound useless, but if I have a script that needs to do something at a specific time every day, or code that isn't related to the main automation, it's easier for me to just create a "Job" that can be executed with a simple `run_job('Seed.Users')`, or `run_job('Queue.Clear')` where `Seed` is a folder in the `Jobs` directory and `Users` is a python script containing a `start_job` function.  These scripts are usually 1-off scripts that can be used to set up the environment for my program to run(seeding a database or something like that), or they can be scripts that need to be run, but are not controlled by the main program.  It's mostly an organizational thing to keep that code away from the other bits of code that are needed by the main program.

Then there is also the project creator which creates all the files/folders needed for the framework to actually work.  You can basically just do:

    import Slack.make_project
    make_project('~/Documents/Python/SomeNewProject')

and it will create all the files you need.  Oh, and it should work with python 2.7 and python 3, although I'm not 100% sure if all the dependencies for *everything* are python 3 compatible yet, but I'm pretty positive they are.

So the "program" I made to make my life easier is really just a collection of methods, functions and classes that make building web automations(or just software in general) a little bit quicker and to the point.  It uses some reflection to do a few of the things it does and it was a really good opportunity for me to learn about object oriented design.  I'm not claiming the design is perfect or anything, but it suits my needs and it's simple to maintain.
I made this so i didn't have to clear my browser history...
[Image_Gen](https://github.com/Comm4nd0/Image_gen )

it basically searching a subreddits for all image types, mp4 and webm's and displays them either in the gui or in a web browser.
I wrote a script to download the subtitles for any movie that lands in my video folder automatically. Not the biggest achievement, but it's a time saver.
I wrote a script that makes managing the SQLite entries used by another, bigger Python project a lot easier. I can chose to go into user management or global management from a bash script which opens up the relevant Python script. From there, input is turned into SQLite queries that make the changes I want. Much easier than going into the database and writing them manually.
I'm sort of a n00b still so I haven't done anything super cool, but the first time I felt compelled to make something that had nothing to do with my work was a little alarm.

It would play a bit of music to wake me up, read headlines, and then give me the weather and tell me what to wear.  That last part was the crux because I am one of those people who hates making decisions.  I figured I'd outsource it to a program that would take the humidity, temp and precipitation probabilities at different times during the day and map that on to what I know I like to wear.  

Unfortunately, I never got the timed task to run properly.
[A tool to automate taking packet captures on multiple remote machines and allow for immediate local viewing.](https://github.com/evanfoster/remotecap)
Isn't the goal to write a program which makes your life much much harder? :)

I made a python script which generates a random number between 1 and 999. You have to write the number in spanish. If you fail you get asked again. I put this in my bashrc. OK I can quit it by pressing ctrl+c if I am in a hurry but it helps a lot getting better with the numbers.
More scripts than programs but [git grep multiple repos at once](https://www.alexkras.com/git-grep-multiline-repos-at-once/) and similar [generate weekly reports from my Git commit history](https://www.alexkras.com/generate-weekly-reports-from-your-git-commits/)
I work QA for a development platform, and part of the testing process is setting up around 30 test applications.  ... on about 5 different operating systems, and including N+1 clustering....

I wrote a python script that not only sets them up, but can be used to setup pretty much any test app.  

I went further and then automated the entire process, starting from spinning up a virgin VM, downloading and installing the latest build.  Configuring it and setting up external resources as needed for a given test set, setting up the tests, running the tests, validating the tests and then reporting the results.  It's all parameterized with script hooks, to be as open-ended as possible.  It's about about 13k likes of code.  (well, about 300k if you count everything, but 13k that I wrote) 

It was my first program, ever.  Prior to that I had only ever made smallish scripts in bash, php, javascript and our proprietary languages.  But no python.  I have no programming background or education, either - and it took me about 3 months to complete.  Mostly in my spare time, as I still had to keep up on manual testing and professional service type issues.   

Somehow this didn't earn me any clout in the company.  Seemingly the opposite, even.  No one really gave a shit, even seemed to be even a little shitty about how long it took me.   But at least we're getting a bit more regression coverage.  ...
It was sometime ago, I created a simple facebook in the terminal cli tool.
to show me only data [ posts ] that I wanted to see [ posts from specific pages or profiles ].
it helped me to only checkout facebook once or twice a day max, and not scroll down to infinity wasting my time.
it doesn't work now due to changes in facebook's graph api.  
[Shuffles your Spotify library as I find Spotify's shuffle algorithm repeats too many songs](https://github.com/DiljotSG/spotify-shuffler).

1. Given a playlist, it will empty that playlist.
* Gather all the tracks in your library.
* Shuffle them
* Add them back to the playlist.
Wrote a script to automate bot testing for halite.io. 
Two things 

A list of python articles i often refer to
https://github.com/Leo-G/DevopsWiki#python-guides-and-scripts

A script to scaffold database driven web apps and api's
https://github.com/Leo-G/Flask-Scaffold
Wrote an entire package to clean, summarize, and organize research data from my lab. I've gotten to send it out to all our collaborators too .  Takes raw training data and provides summaries and visualizations 
I frequently need to convert file sizes from B, to GiB, or TiB to GiB, etc. I used to visit [Matisse's Bit Calculator](http://www.matisse.net/bitcalc/) in my web browser to calculate/print a conversion table for this purpose. After a while, I got tired of launching a new browser tab (taking focus away from my workspace), dealing with network slowness and such.

I wanted something local that I could run from the command line, so I wrote a little utility called [pybitcalc](https://github.com/miliarch/pybitcalc) that functions pretty similarly. It was a fun project, and comes in handy all the time =)

Not nearly as interesting as many other projects in this thread, but I figured I'd share!

Here's some example output:
    
    Unit Type               Value
      b - Bits              76538632408
      B - Bytes             9567329051
    Kib - Kibibits          74744758.211
    KiB - Kibibytes         9343094.776
    Mib - Mebibits          72992.928
    MiB - Mebibytes         9124.116
    Gib - Gibibits          71.282
    GiB - Gibibytes         8.91
    Tib - Tebibits          0.069611480656022
    TiB - Tebibytes         0.008701435082003
    Pib - Pebibits          0.000067979961578
    PiB - Pebibytes         0.000008497495197
I wrote a script that automatically generate transcript from Viber
I made an application for sharing clipboard contents on gdrive/(own|next)cloud/gist/imgur. Snapshot of portion of screen can be taken and shared as well. You get URL or two (like view and delete) for sharing with your friends. You can log in with your account or upload files anonymously on services supporting this.

https://github.com/rokups/paste2box/
Just yesterday, a small python program ~50 lines which downloads the images from a scribd pdf (mostly sheet music that's why it's fine that it only gets images) and puts them in a pdf.  
Every month I lay out what I want to accomplish and have a set format for my daily tasks for the work week. So I wrote MarkdownClerk which basically generates all of that for me with a little input from the CLI. We use TFS for our stories so I largely track my work in my markdown and transfer it when it's done because TFS is painful to use. 

I also have a script that creates our skeleton repos and I'm working on making it able to generate visual studio projects for all of our .Net developers. I've used cog and cookiecutter and both are good but the former has syntax I don't like and the latter has whitespace and formatting issues. 
Represent and analyze data with [pandas](http://pandas.pydata.org/)-dataframe-based networks: [DeepGraph](https://github.com/deepgraph/deepgraph)

I use it as a research physicist working on complex systems. So far I have used the package for neurophysiological and climate data. It's very handy if you want to compute and analyze relations between objects of some system.
I built a selenium webdriver bot to automate mobile bank account creations. We set up clients to have access to mobile check depositing using an app that they need a user name and password for. Instead of giving the task to someone to perform manually, I built the webdriver bot to accept a csv with all the vital data, open a web browser, navigate to the bank site, and perform all the data entry and clicks,and preserves the temp password produced for the account. Once complete, it takes all the temp passwords and exports those to another csv. It all happens very fast. I'm sure there are even faster ways of doing it, but this is how I've automated it so far.
RemindMe! 2 days
[deleted]
python programs
Shall we get a high score table going? 

I lasted 47 seconds
why is this specific to python. (not going to down vote yet because I only lasted 3 seconds, and maybe I'm missing something)
I was expecting Raymond Hettinger talking about Pythonic vs non Pythonic. 

I was deeply disappointed...
I am going to attempt reviewing the video, since I know that the video producer Siraj does produce some interesting content sometimes, but also to see if there's benefit in watching this. I'm going in with the prejudice that it's not going to be a great video, since from what I remember of Siraj's videos in the past he did not seem to be a theoretical type of person, just more practical. This post might also the benefit of OP and/or future posters, to help glean why this content could be interesting - if enough people agree with me.

* A video discussing one of the most famous problems in computer science and mathematics starts with a shout out to another YouTuber performing magic. Normally shoutouts are fine, but this particular shoutout is a problem for the following reasons. Personally when I watch a video on YouTube with interesting content, and the content producer recommends another channel, I'm presuming that the other channel is a personal recommendation based on the fact that I liked the content in the video I'm currently watching. I'm not saying that you should never plug another channel unless it is related content, but the lack of self awareness here is off putting. At the very least he should have said something like - "This is a shoutout for a channel about magic videos, the person that makes them is a good friend and I wanted to give them a shoutout every though you as a viewer are really here for the math". Also, why is he climbing up the roof of a building?

* Examples of P/NP problems that he provides at 0.19 are all attempt to use footage from videos that he made, instead of actual real world problems that make this topic interesting. 

* At 0.32, polynomial is misspelled. I mean come on! This is literally the P in `P vs NP`! 

* 0.45 has an image about a biker farting because of beans (I don't even know) that is a joke in pure taste. There's no reference to this in the audio. Presumably, he added it while editing to match him saying "fast". Watching a few more seconds, it appears that the rest of the video will be littered with this sort of stuff. I'm going to try not mention it since I'll attempt to tune it out. But if the video producer reads this, I would just like to say that low effort low brow low quality jokes constantly throughout the video have no place in educational content. There is something to be said about making content funny so that it's memorable, but this clearly was an afterthought in this production. When you happen to accidentally pay attention to them, these particular jokes are annoying, and unfortunately forgetful since they are random jokes as opposed to jokes that are based off of the content. I can provide other examples of YouTubers that do this well if anyone is interested.

* 1.35 A traveling salesman animation without a reference. I really wish people would use references or citations more! This is a personal pet peeve.

* 1.58 Okay, he's actually coding up a traveling salesman problem in Python. I'll see where he goes with this before any further comments.

* 2.44 Why a global variable?! This critique is not on the content of the video. I happen to catch it since I'm pausing the video to check what he's doing. 

* 3.01 He seems to imply that this problem can be solved only by recursion (first by explaining what recursion is), and that's why it is slow. However, recursion is a subset of dynamic programming and he makes no mention of that. Again, it seems to me that his targeted audience is not technical. 

* 3.53 He finally manages to stumble on the core idea behind P vs NP.

* 4.15 Well, he skipped over all technical details while skimming NP-hard and NP-complete. Not only did he say very little, but I believe he stated the definition of NP-complete problems incorrectly. He obviously has no idea what he's talking about, since all he is doing is loosely describing the intuitions one would garner on studying P vs NP problems in more details. I'm guessing he read Wiki to understand why P vs NP exists, instead of what P vs NP means.

* 5.00 I don't know if I can finish this video, and I'm not sure if it is even worth it. 

I went ahead and finished the video. It's actually a challenge to get through content like this. Not only was the content inadequate in explaining this famous mathematical problem, but I believe it was also inaccurate. 

I happened to click through OP's history because I was curious to see if I could gauge what sort of content he likes, and maybe understand why he likes this particular video. It turns out OP is the video producer and every time he posts something, he submits it to EVERY related subreddit. He used a small amount of Python in the video and probably decided to submit it here. It appears he's decided to submit videos to subreddits the way I tag my stackoverflow questions. Isn't self promotion against the rules here on Reddit?

/u/llSourcell - it must be frustrating trying to make a living off of YouTube videos, where it feels like everything has to be eye catching and fun otherwise it won't get any attention. I'm not asking that you don't make videos like this, since they may be useful for someone just getting into the field, possibly a 11 year old watching this with his friends might find some of the images and references to Harambe funny. I personally believe it is a disservice to even them, but that's your prerogative. All I ask is that you please don't attempt shoving your videos down everyone's throat (posting on every subreddit), or at the very least post only when you are proud of the content you produce. Are you proud of this content? I would venture to guess not. It may result in a few more views, but people like me who used to watch some of your videos early on have very little incentive to now subscribe to your channel.
what on earth :O
yes,  gspread uses sheets api v3. I needed some functionalities which was not offered by v3 so wrote pygsheets. The basic interface is similar to gspread , with additional functionalities like batch updates, sharing from terminal, pandas support, exporting etc. Also v4 supports more features like graphs , formatting which i haven't implemented.
Oh shit! Gotta give this a try. Is there any functionality that gspread has that yours doesn't?
If most tutorials out there cover OpenCV2 then I think that the community would benefit from more OpenCV3 tutorials. 

Rather than updating the whole book at once, you could consider writing a series of blog posts that are roughly aligned with the chapters from your original book. This would break up the daunting task of updating your entire book into more manageable chunks. It would also allow you to get feedback from the community sooner. You can always take the blog posts and refine them into a more structured book later on. Ongoing interest and support from the community might also give you more drive to continue writing the blog posts and help you on your way to completing your book. 

Just my two cents. Hope that it is food for thought. 
If all the libs you are covering are usable with Python3 then stick with that.

I don't know about OpenCV. If there aren't good reasons to still use v2 for new projects I'd stick with v3. If there aren't that many tutorials about v3 that will make yours even more valuable.

I wouldn't care about backwards compatibility unless it doesn't need much more than a few remarks.
Yeah, as someone who uses OpenCV as a teaching example, I can say that the Python 3 tutorials are still in short supply. Though to be fair, it was hard getting OpenCV to work with Python 3.x. But that was back in 2014...now, Anaconda makes installing the opencv wrapper for 3.x fairly straightforward. I think updating for 3.x (and for OpenCV3) would be a useful resource.
I wrote 'Game Programming - The L Line' a few years back, in Python 2.7 with PyGame.  I haven't updated the book and don't really plan to, but I've actually been teaching Python3 to beginners with very few problems.

Honestly the dysfunction within the publishing world is the main reason I may never write another book, but honestly the current 'controversy' over Python3 is completely silly to me.

I actually prefer teaching 3 to beginners over 2, because honestly beginners should not care about their language.  A programming language for beginners should try hard to get out of the way.

Most beginners don't really need to know or care about the differences, and they only ones they'll see are simple, but occur in nearly every program.

First, getting rid of the insanely dangerous input() function from 2.7 and renaming raw_input() to input.  I love that, because I don't want them using that old input at all.

I like that integer division is now explicit with the // and that dividing two integers with a single / will produce a float, like they expect.  I'll teach about data coercion and its dangers another day, but the first week of programming, division signs should pretty much do what the user expects.

Changing print from a statement to a function was a necessary move, and it never bothers them, but I still have motor memory from years of Python 2.7.

Oh, and the capitalization of Tkinter has changed.  From a beginner's point of view, NONE of this matters, because it's all new.  Silly set of arguments, as I've said.  

My newest video series (no longer doing books) does cover Python in the Blender Game Engine, and does use 3.4, as that's the version currently included in Blender.  I've had no real problems.


2017 will be the year of Python 3, imo.  By 2019 if you're still using Python 2 you will likely be in the minority and due to legacy or political reasons.
Please do what you feel best.  Zed Shaw hasn't got the faintest idea what he's talking about, all he wants to do is sell as many of his books as he can before people release what a complete pratt he is.
You should really not care about Zed Shaw. He has no clue and just markets his anger.

I think Python 3 is the way to go, even when libs are still lagging behind. They'll get there eventually or, sadly, die out anyhow.
Start by converting your book to Python 3 and OpenCV 3. Sell it as a digital download and include as a free bonus the old version for people that need to support Python 2.

You are obviously targeting a different demographics than Zed Shaw, so you can probably ignore his rant about Python 2 vs Python 3.
> the thought of updating it fills me with dread

Update it to work with the latest Python 2 and do a separate version for Python 3.
try statements should be small blocks of code that might fail.  You really only to wrap the open in a try/catch.

Anytime you find yourself doing the same line over and over you should right away think if you would be better off using a loop.

Given the file size I'd also consider reading the whole contents and then working with it as a list.  Since lists have indices you can find the first line and then start from that index with printing.  The enumerate function will include the index while looping.  This should get you started.

    lines = infile.readlines()
    print_line_idx = 0
    for idx, line in enumerate(lines):
        if line == 'Variables/Columns':
            print_line_idx = idx
            break

Now you can use list index sugar to get just a list of what you want to print

    print_lines = lines[print_line_idx:print_line_idx+6] #you need the first line and the next 5 so that's 6 total
    for line in print_lines:
        print line

/r/learnpython is often a better stop for questions like this though
    def main():
        while True:
            filepath = input('File name: ')
            try:
                with open(filepath, 'r') as f:
                    lines = f.readlines()
                    break
            except FileNotFoundError:
                print('File not found..')
    
        for i, l in enumerate(lines):
            if 'Variables/Columns' in l:
                for line_to_print in lines[i:i+6]:
                    print(line_to_print.rstrip())
    
                print('\nAll done!')
                break
    
    
    if __name__ == '__main__':
        main()
I paid attention over ten years ago and saw the fair forewarning that Python 3 would contain a few minor backwards-incompatible changes, so I began then using \__futures__ features to make my 2.x code compatible.

I also ensured my code respected the true representation of data, so if it was unicode text I would .encode() and .decode() into/from bytes at I/O boundaries.  I had to advocate this position in a workplace where the codebase was very much "we're all 8-bit US ASCII around here & Unicode is hard/un-though of"

I also began removing external libraries that were recalcitrant in supporting the transition to Python 3.x, and advocating the general use of alternatives that were.

After Python 3 was released, people started creating libraries like six and future (note: not "futures" the concurrent library, the compat one is by Python Charmers) which were more cheaply integrated than essentially doing what they're doing by hand.  Depending on the code at hand I'd either use or not use them as appropriate.

There is no "one size fits all" when you're talking about the insane hodgepodge that is most codebases, particularly the more developers are working on them.  You need to understand the code, understand the environment, and make good choices.

After Python 3.2 when they settled on the "right" way, it was significantly easier to Python 3 everywhere - which has been the case for the past 5 years.  I find this week's trend in "P2 v Py3" posts in /r/python strange and cute.

https://docs.python.org/2/library/2to3.html
Have you tried it?  Do your tests pass?
https://pypi.python.org/pypi/six
I've not had to go through the process, but YPlan recently blogged about their experience migrating their backend codebase.
https://tech.yplanapp.com/2016/08/24/upgrading-to-python-3-with-zero-downtime/
Python-future (http://python-future.org/index.html) helped me a lot. The auto conversion didn't work but with a little work the code works with python 2 and 3. The random errors that will drive you mad are string/unicode/byte errors, but future helped a ton with fixing them with 0 work. Definitely check their quick start guide http://python-future.org/quickstart.html

Eevee has [a pretty extensive FAQ](https://eev.ee/blog/2016/07/31/python-faq-how-do-i-port-to-python-3/) on that exact subject.
I'd start by reading [Porting Python 2 Code to Python 3](https://docs.python.org/3/howto/pyporting.html).
> smoothly upgrade

No such luck.
In my personal opinion any python book list that doesn't include [Fluent Python](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) is pure garbage.
> Learn Python the Hard Way

Ehhhhhhhhhh
Hmm scrape amazon.com , include affiliate links, claim amazing ai,  profit
No web development? ð¤
I have the Python pocket reference, it's okay but not that much.


I think that curated lists of books are hugely useful. 
So I linked to it from my curated list of python articles. 
http://blogory.org/python-articles
Comprehensions.
It's difficult to choose just one, but one thing I really miss in e.g. C++ is `zip` and `enumerate` because I use them in my python code all the time.
If I had to pick just one thing, it's the iterator protocol. I find Python's for loop extremely intuitive and being able to hook into it with no fuss is fantastic. And then there's the whole suite of things that use it as well. 
    import this
for _____ in _____
map/filter because list comprehensions can go *straight* to hell.  
yield !!
really nice pattern matching, namely 
    
    a, b = b, a
Json dumps and loads. Use them all the freaking time for data parsing requests that come in. 
From an interactive prompt help(xyz).
Are you the author of this?  Or just a fan?  Or a student?
I would suggest to create a ticket on their GitHub page, since your question is about a very specific problem in a very specific Python package.

If it's not a bug they gonna tell you.
`|` and `or` are not the same! `or ` is logical or (written as `||` in many languages), while `|` is bitwise or.

`a or b` = a if a is tru-ish, else b

`a | b` combine the 1 bits of a with the 1 bits of b, for example, `5 | 8` is `13`, since 5 is `0101b` and 8 is `1000b`, which gives `1101b`, aka 13.
Just to close the loop on this, the mypy issue I submitted was quickly closed by GvR himself, saying it was a known bug not in mypy but  [typeshed](https://github.com/python/typeshed/issues/649).
There is no way to know the URL structure of a website, because it's arbitrary.  You can spider the site, starting at some page and following all links until you stop seeing new URLs; or guess URLs randomly or based on some expected structure.  But neither of these are perfect, because a site can still have URLs that are not linked from anywhere and/or have unguessable URLs.  (It's even possible for a site to have an infinite number of URLs, since they can by dynamic.)  There is no way to discover such a URL without getting lucky and guessing it, or exhaustively trying every combination, which becomes infeasible very quickly for anything more than a handful of letters.

In other words, while some sites may have a site map-type page that lists their entire hierarchy, that's by no means necessary, and URLs are just arbitrary strings that can be anything, and there's no way to tell if a URL is valid without making a request for it and seeing what the server responds with.  (And in addition, some URLs will be hidden behind form submissions, authentication, etc. so it's even more complicated than that.)

The only solution to this problem is to crawl the site and find all the valid URL's/links. There's no simple, universal method to return a directory of all available pages on any website without crawling the site 

That said, this would more than likely do the trick: http://wummel.github.io/linkchecker/

No, there isn't, because that is not how URLs work. Unlike filesystems, HTTP does not provide means of requesting a directory listing, all you can do is request a document from a URL, and that document can contain references to other URLs, encoded according the document's content type - for example, HTTP can reference other documents in `<a>`, `<img>`, `<link>`, and a few more tags.

You have three somewhat practical options here.

Option 1: Brute force. Take the parts of the URL you already know (the protocol, domain, and the string `"weather"`), and then enumerate all the possibilities for the remaining parts. For each possibility, issue an HTTP request; if it returns `200 OK`, you have found the target, if it's a `404 Not Found`, keep searching. Of course you will be hammering the target site with what will look exactly like some sort of DoS attack or some other malicious activity, so I actually recommend against this or you might get blacklisted.

Option 2: Crawl. Start at the site root, parse the HTML, extract all useful links, and recursively crawl those; skip the URLs you have visited before. This will give you a tree (or if you flatten it, a list) of all the URLs in that site that are reachable from the site root. If there's a `sitemap.xml`, using that as your starting point will probably be very helpful and speed things up a lot.

Option 3: Use google with a search query like `site:www.examplewebsite.com weather`. Seriously, Google has pretty much done Option 2 for you already, might as well use their index.
As well as what the other people have said, some websites also self-publish at least some of their valid URLs with a sitemap. Check the site's robots.txt file for any sitemaps, and if they have one you can try and check in there for any links matching your interest.

The sitemaps aren't guaranteed to show *all* URLs the website will service, though, as it's entirely up to a website to create their own sitemaps however they wish.
if it is getting deleted on a simple reboot/restart than you have something very very odd going on. I would be tempted to diagnose that issue first.
One way to maybe to work round your issue would be to use a virtualenv (maybe use virtualenvwrapper to make things easy), and always install the modules you need into a specific virtualenv for your project. Since Virtual envs exist under your /home directory system they are less likely to be uninstalled by whatever is messing with your system on reboot
If the module disappears from /usr/local, then you should investigate that. If it does not disappear, but is still not available after a reboot, perhaps your path is not correct upon reboot. In this case there are various methods for setting the path. Other posters recommend virtualenv, regardless of your other issues you should be using this to isolate your application from the system installed dependencies.
I'm the moderator who removed it as a resource. I did not do it for any political agenda. It was just years out of date and there were better resources for 2.7 available. I (rightly) did not imagine this would have any impact on Zed's sales, and also imagined (incorrectly) that he would not care either way. If he wants to update stuff, or have me add it back in, that would be fine. It was removed the better part of a year ago.
wow, the moderators sure didn't show zed, the author of the most popular beginner resource for python, wow.

zed is such a big boy, fighting against the python 3 Illuminati.

> To put it bluntly, the reddit community responsible for teaching beginners to code censored my book as a power play to get me to force Python 3 on unsuspecting beginners

censored? not recommending something is censorship now?


> I decided I needed to work out a list of reasons why Python 3 is broken for beginners as of today.  Originally I was going to write it [but then i wrote a blog post about how the Illuminati is attacking python, so I can feel good about myself without making substantial points]

nice

> Who gives a fuck about what a bunch of angry lonely coders think about my thoughts? [because I sure as hell don't, can't you tell?]

nice

> the coder illuminati made node js popular, and then wanted to update code, and convince everyone that its okay. They are scary because they are uninformed and have no humanity? and for some reason a VC forum has influence over VCs?

nice

> this illuminati has no influence now, don't know why I'm still bitching about them then, but whatever. they are so bad. Like, they don't even know what is going to be successful, even though I lumped them in with the node.js folks and node.js has been widely successful. Also python3, node.js, and openssl are all the same group of people

nice

- - -

I'll give a pizza to anyone who can convince alex jones to run this as a "liberal attack on america's technology infrastructure"
Being someone who has served over a million "beginner" programmers, I've **never** come across a beginner that was confused about something that would be any different fundamentally if they were on Python 2. 

I've never felt that, for a *beginner*, that there was actually *any* difference between Python 2 and Python 3, other than some syntax changes. The real differences don't show up until a bit down the road, and they're certainly not challenging at all.

I'm still convinced that Zed's just doing this for the publicity. Of course his sales are momentarily up. With all this drama, let's say a new 100K people have come across his content. Maybe 90% of that 100K people are just there to see how stupid it all is, but maybe 10% are sympathetic and are convinced he's right. That's still 10K new people.

Drama is good for business, and he's milking it. 
I'm kind of confused of why the 2 vs 3 debate is still continuing.  Do some people think that eventually Python 3 will be cancelled and we'll all go back to 2?

And his response seems kind of...juvenile?  I mean, the basic tone of this is "You are all a bunch of 'lonely coders' and you don't matter because my sales haven't budged." 

I get that he feels that Python 3 doesn't make for as good of a tutorial, but regardless, why not teach to the future?  Or heck, he can do what he wants, but then again, a subreddit can also decide that it would rather recommend a different book.  Why put this down as some sort of fascist "censoring" made by a "tribal" community of <strongly implied> amateurs?
Holy shit that guy is a complete twat.
"Everyone I don't agree with are code iluminati"

A child's guide to programming discussion.

Acts like a condescending man child, writes a book full of angry opinionated anecdotes.

Due to this book is removed from recommended sidebar.

Replies to criticism by writing an angry condescending article.

Yea ... reddit is the problem Zed. Remember when that guy pointed out mistakes in learn Java do you wrote an article ripping him a new one? 
His main problem is his reliance on the premise that Python is some sort of training-wheels programming language that needs to be maintained as such.

The language is purposefully simple, but its main purpose is not to ease the way for beginners; it's to be effective and Pythonic for real programming. A nice side effect of this is that it's easier to ramp beginners up. We should not hobble the language to maintain that.
Is he repeatedly going through his own code and play-pretending he's a beginner who only knows Python 2 and making the same mistakes about strings even though he knows better, then using that as reconfirmation that Python 3 sucks? 

What a lunatic.
I'm lazy, can someone link to the relevant threads where Shaw feels he's being attacked, censored, abused and belittled? I've seen the man move from Ruby to Python because apparently the Rails/Ruby community was toxic, and now he says the same thing about the Python community. I'm trying to make up my mind of Shaw is a thin skinned primadonna or if he actually has a point.

I have read his stuff, so I know he's objectively wrong about a bunch of things (like the Turing completeness bullshit, dissing 2to3) but that means he deserves to be corrected, not insulted.
> but at the same time were horribly uninformed about basic computer science

Says the guy who claims Python 3 is not Turing complete
I think one of Zed's big complaints is about strings in Python 3, and that they are too difficult to use for a beginner. Does anyone know what the specific problem is? 
He says that Python 3 isn't good for beginners, but his own book is terrible for beginners (which is the real reason why it was removed from our sidebar).
I don't understand if he's playing dumb or doesn't get it.
He says:
> I get an email from someone who tells me that Reddit has decided to remove my book from their list of suggested readings for Python until I update the book to Python 3

like Reddit was an entity of its own. By omitting the specific sub he makes a claim that is uncheckable. Also, it sounds like they removed the book from the suggested materials two weeks ago:
> They made this decision about two weeks prior to when I received the email

As far as I understand, /r/learnpython mods [decided yesterday](https://www.reddit.com/r/Python/comments/5eljwc/the_case_for_python_3/dadkyqf/).

Oh good, another rant from angry nerd, I'm persecuted-and-smarter-than-everybody guy. Can't wait to read this gem.....
I don't want to give him money by visiting his site if he's just trolling for clicks. What'd he say about Turing completeness? Or did he not mention his fuckup in this post? 
Man is told his work is obsolete, pitches old man fit. Film at 11. 
>  I seriously doubt you have any idea why reddit censored my book

Someone teach that man what censorship is.  
https://en.wikipedia.org/wiki/Censorship
I teach Python to middle schoolers on the side.  I have insisted on Python 3, because there's no point in muddying their minds with 2.7.  By the time they graduate from high school, Python 2 will have been EOL'd.  

The reality is that yes, we can have debates about whether Python 3 made the right call, and whether PyPy is the future of Python instead of Python 3.  But CPython does seem to be the Python version with the best name recognition and widest adoption.  

If Zed Shaw wants to be another Abe Simpson, let him.  I've taken that manuscript I've been working on halfheartedly for 8 years now and updated it to Python 3 already *because it's the right thing to do*.  


Old Man Shouts at Cloud
Honestly all of his complaints are just excuses for his laziness. His 'real problem' are the unicode strings and error messages in python 3? are you kiding me? We got finally rid of the ugly global error and have now the name error, something, even beginners can better understand. And the whole unicode thing, is he so ignorant to understand we need a codec for the world, because many people just can't us ascii alone?

I am from europe and I have to deal with alot of different languages all day. And to be honest the standard unicode in python3 saves me alot of time!

He didn't even update his tutorial series to 2.7. And he is arguing about some bullshit. I can't believe that there are real death threats
and some bullshit on his person... 

And the talking about his paintings are just there to give him some kind of personality, I don't care about, it is useless crap so he can try to convince us to be an actually carring person, boring writting trick.

Especially his 'international' critique shows me that Zed is just an arrgogant and lazy wanker, nothing more. Fuck him, really. 
FFS... can we give it a rest. This is just ridiculous now, as was his initial post. Do we have to care about what one guy (be it Zed Shaw) says?
Seems like he is trying to be controversial to get more sales. He is clearly very concerned with his "sales and traffic" as he mentions it multiple times throughout the article. He even admitted the article has gotten him a surge in sales. In that effort his article was a marketing coup d'etat.
I saw Zed Shaw at a grocery store in San Francisco yesterday. I told him how cool it was to meet him in person, but I didnât want to be a douche and bother him and ask him for photos or anything.

He said, âOh, like youâre doing now?â

I was taken aback, and all I could say was âHuh?â but he kept cutting me off and going âhuh? huh? huh?â and closing his hand shut in front of my face. I walked away and continued with my shopping, and I heard him chuckle as I walked off. When I came to pay for my stuff up front I saw him trying to walk out the doors with like fifteen Milky Ways in his hands without paying.

The girl at the counter was very nice about it and professional, and was like âSir, you need to pay for those first.â At first he kept pretending to be tired and not hear her, but eventually turned back around and brought them to the counter.

When she took one of the bars and started scanning it multiple times, he stopped her and told her to scan them each individually âto prevent any electrical infetterence,â and then turned around and winked at me. I donât even think thatâs a word. After she scanned each bar and put them in a bag and started to say the price, he kept interrupting her by yawning really loudly.
Really it is time to move on.
This guy is why programmers have a terrible rep in society at large
Why is there still Py3 vs Py2 debate? Is it like D&D 4ed vs 3.5 - a nerd battle or something?


Can anyone explain?


From what I understand legacy code is not going anywhere soon so support for Py2 is needed BUT Py3 is the new version and should be the way to go for new things.
[deleted]
Pretty reasonable article.
Very cool! I had similar struggles when looking up international companies like Volkswagen and all the tickers they have. That being said, I feel like more accessible data/insight that just a general score would be helpful. Like maybe explain the methodology and the weight given to each estimate (unless you did somewhere and I totally missed it). Just to make this useful and practical. However, this is already super cool and very different from existing tools that are available out there (as far as I can tell). Keep up the great work and hopefully you attract like-minded investors.
If i type "pri" into your search engine, I get "Primerica" as choice #1....so you may want to change your 'yahoo finance' example and/or your implementation :) 
Impressive tool, and a big need for younger investors.
Hearing about your tech design / strategy would be interesting.  Everyone someone builds an engine they remake wheels â sometimes with a new bit of genius.  

I doubt your startup will make more money / customers as a result of the description.... but if-and-when it comes, then thanks!

Also, where can we file suggestions without filling that entire form?  Your cohort analysis is weak in the areas I frequent.  e.g SYF is a cohort of ALLY, instead of the non-bank entities that you something associate, and all are far-afield from CIT, Visa, etc.  Also you don't index RADB at all. 

You do realise that there are 36^4 = 1.7 million combinations, right? It's highly non-trivial to try all of them.

Also, look at the [intertools.product](https://docs.python.org/3.6/library/itertools.html#itertools.product) function
This isn't specific to the API. You need to get a list of files and search by extension and put the ones with that extension on a list. Grab everything on that list.
Are you getting any errors when you run that code? What does the error message say?
It's well argued. But it's also five years old. He actually wrote a blog post just a few weeks ago where he makes some reflections about this. 

Here's an excerpt:

[Be Careful About What You Dislike (Armin Ronacher, Nov 5th 2016)
](http://lucumr.pocoo.org/2016/11/5/be-careful-about-what-you-dislike/)
> [ ... ]
> 
> In fact, I myself campaigned for some changes to Python 3 that made it possible to achieve better ports (like the reintroduction of the u prefix on Unicode string literals) and the bulk of my libraries work on Python 3 for many years now. It's a fact that in 2016 the problems that people have with Python 3 are different than they used to have before.
>
> This leads to very interesting conversations where I can have a highly technical conversation about a very specific issue with Python 3 and thoughts about how to do it differently or deal with it (like some of the less obvious consequences of the new text storage model) and another person joins into the conversation with an argument against Python 3 that has long stropped being valid. Why? Because there is a cost towards porting to Python 3 and a chance is not seen. This means that a person with a general negativity towards Python 3 would seek me out and try to reaffirm their opposition to a port to it.
You are doing arithmetic on string values not numerical values.

$ ~/tmp.py

    33, <type 'str'>
    21, <type 'str'>
    10, <type 'str'>
    33, <type 'str'>

$ cat ~/tmp.py 

    #!/usr/bin/python

    from functools import cmp_to_key

    l = ['21', '33', '10']

    def num_cmp(x, y):
        print "{0}, {1}".format(x, type(x))
        print "{0}, {1}".format(y, type(y))
        return x+y > y+x

    sorted(l, key=cmp_to_key(num_cmp)) 

Edit:

Is there a reason why you are doing?

    x+y > y+x
yes it is intended. So in the above situation

when comparing 33 and 21, 

'3321' > '2133' so '33' > '21'

'2110' > '1021' so '21' > '10'

'3310' > '1033' so '33' > '10'

so shouldn't it output

I am trying to do this problem: https://www.interviewbit.com/problems/largest-number/ that's why I am doing this :)

['10', '21', '33'] and when I pass in reversed=True give ['33', '21', '10'] ?


Going through Shaw's article, I can't tell if he's purposefully being stupid, or if he's a factory reject, cast aside from common sense.

A bytearray is not a string. You should not be able to throw those together. Bytearrays are for bytes.

As someone that lives in a country where common names have characters not included in ASCII - fuck off.
Cf. Zed Shaw's case against Ruby on Rails.  
Eevee's twitter is actually https://twitter.com/eevee
The fact he kept referring to strings as statically typed in python 3 is just one of many hilarious things about Zed's post.

This is a really good rebuttal.
All I know is that occasionally when I am googling around looking for solutions to some 2.7 code I am working on I see some snippiness about how the OP really should be using python 3. Did not realize there was a war going on.



I'm surprise it took Zed this long from his Rails is a Ghetto rant. That's how Zed is. Nothing is ever his problem, "Python 3 is all propaganda but let me just vaguely use incoherent mumbo jumbo to fear you from using it". 
> The Python project's efforts to convince you to start with Python 3 are not in your best interest, but, rather, are only in the best interests of the Python project.

This makes sense. Not saying it's objectively correct (who knows what's going on behind closed doors?), but that I totally get that as a reason 

But then. . .

> Ask yourself, why are they so keen on having you use a language that has only about 30% adoption, is constantly changing, and full of issues?

I'd like to see the same adoption metrics for Node 12 vs 4+,  ECMAScript 5 to ES6+, etc, using the logic he's using here. . .

AND THEN I'd like to know what makes Python any different from any other language. I'm betting that anyone involved in an ecosystem would say that it "is constantly changing and full of issues."

IOW I don't think the stated problems are any different than any other modern language. It's easy to stand in the walled garden and decry "python is busted".
I didn't like the lack of backwards compatibility and am still a little annoyed by the cavalier attitude behind that choice; but zed shaw's arguments are thin and shrill.
He's absolutely correct that Python errors COULD and SHOULD give the variable names. 

The problem with his argument is that python2 sucks in this regard in the exact same way. 
While I agree broadly that the Python core devs have screwed the pooch with Py3 (and are in no hurry to clean up the mess they've made), I honestly can't agree with a single one of his arguments. Hell, many of his arguments *against* Py3 are things I consider arguments *for* Py3.

I don't believe his <30% stat, but I also don't believe JetBrain's stats. They're based on PyCharm users, which isn't exactly a majority of Python devs. What's more, the stats are dominated by web developers, which is a group for whom Py3 is *unquestionably* better. They are almost entirely shielded from Py3's problems by the frameworks they're using (whose developers have dealt with Py3's all-text-is-Unicode shitshow for them) and by the fact that webapps run in carefully-controlled environments.

Py3's changes also haven't killed Python. But they *have* killed Python for a certain class of program for which Py2 is eminently suitable, namely UNIX command-line-oriented programs (and other bytes-oriented stuff).^*

Py3's fundamental fuck-up vs Py2, IMO, is that it not only insists on treating all text as Unicode when we still live in a world full of strings of unspecified encoding (URLs & HTTP, email, UNIX filenames), but is so fundamentalist about it, it just doesn't give you the tools to work with encoded strings or undo its magic decoding when it's picked the wrong encoding.

What I think *is killing* Python is that the core devs are sticking to the GIL, which makes Python (2 or 3) a second-class citizen in a world where even smartwatches are multi-core.

IMO, the core Python devs definitely fucked up in making Py3 incompatible with Py2 without offering any substantial benefits. If you have working Py2 code, there really isn't a lot to be gained by porting. This has been, IMO, the major reason for the slowness of adoption amongst seasoned Py2 devs.

Py3 is a much more newbie-friendly language, but offers at best trivial benefits for experienced Py2 coders (and is in many cases a total PITA).

So Zed might be right in that regard, in that developers faced with re-writing their projects to support Py3 may well decide there's basically bugger all benefit in re-writing *working* Py2 code for Py3, whereas re-writing in, say, Go may bring a 10-20x speed-up *plus* the ability to use multiple cores.

Certainly, as someone who mostly codes the command-line programs that Py3 is unsuited for, I'm starting a lot of new projects in Go, seeing as my weapon of choiceâPy2âhas been EOLed.

^* The UNIX command line is basically bytes. Py2's text model is also the POSIX text model, so it Just Works with other POSIX tools, like `find` or `grep`. You have to fight Py3 all the way to get correct POSIX behaviour.

Py2 is also largely insensitive to environment settings, and will keep on chugging in situations where Py3 dies in flames, like SSHing to a machine that doesn't support the locale set on your *local* machine.
Two days I hear about Zed. Seriously, you need to stop feeding the troll.
> The strings in Python 3 are very difficult to use for beginners. In an attempt to make their strings more "international" they turned them into difficult to use types with poor error messages. Every time you attempt to deal with characters in your programs you'll have to understand the difference between byte sequences and Unicode strings.

To be honest, this is already true in Python 2.7. I can't even tell how many times I've had mysterious errors because I tried using unusual characters.
what world is zed living in?
Ow no, now he will have to write a "Python is a ghetto" rant... The guy acts like a rock star, the type of colleague that only wants to win a conversation and pretend to be logical, but only react in emotional ways.
My reason for sticking with 2.7 is that's what I have to use at work. 3 is starting to get baked into various distributions, but until it's available everywhere by default, 2.7 is the only choice for me.

I agree with some of Zed's arguments, particularly the string handling mess, but arguing you shouldn't adopt it because the devs are pushing it seems a little circular.

yeah I just use both
My one real gripe about Python 3 lately is how sorting changed.

So, say I have a list of some custom object that I created that can't meaningfully be sorted by [].sort() or sorted().  In python 2, I'd write a short function that does the comparison and pass it as an argument to the sorting methods above.  In 3, I'm apparently supposed to override up to six methods in the class and hope that that's the only way I'm going to have to sort my objects.  There's a workaround where you can instead use a short lambda, but that really doesn't seem ideal.

Honestly, the old way didn't seem broken to me, why was it fixed this way?


Do people actually use PyCharm?
I'm just learning python and did not know there was a nerd war going on.  

Personally I think I am just going to use the latest version.  Hate me, flame me all you want.

I think there have always been coders who are unwilling to move on to the next thing.  If it were up to some of these people we would still be using assembly or punched cards.  

I have had a few problems learning using the latest version (PYQT5 for example) but the documentation was there and there is always google.
I got through about half of this article before deciding "yeah, this guy just went full retard". He's very clearly the same sort of person who might, for example, hang out in a C++ forum aimed at beginners and constantly go "VIM AND THE COMMAND LINE IS ALL YOU NEED, IDES ARE FOR MORONS." He's the sort of person who legitimately believes that programming **should** be unnecessarily hard and inaccessible simply for the *sake of being hard and unnecessarily inaccessible*, because for some unknown reason he thinks that the ability of one to handle that is a legitimate measure of their character. 
Zed Shaw's books are great and he's great at what he does, but after following him for a bit on twitter its hard not to conclude that he's a bit of a hair pulling wildman
Exactly the kind of trashing the original 'article' needed. This is why you shouldn't go "full McIntosh", spitting, cursing and rationalizing.

Zed asked for it, and now all his base are belong to Lexy ;-)
Zed really didn't need to go past his "Poor Design Decisions Prevent Adoption" section. Python3 not maintaining backwards compatibility with standard python was a huge mistake. 
This Zed guy is probably stuck with a giant mess of a legacy python 2 codebase and feeling alone and left behind. 
I find the 30% adoption number hard to believe.

I'm looking for work and have not had one employer, either in person, on the phone, or in an online posting, make any mention of Python 3.
> You could use Python 2, until it diesâ¦ or you could use Python 3, which might die. What a choice.
> By some definitions, Python 2 is already dead 

They're talking past each other. By Zed's account a living language is used and developed in. She ignores this rather obvious definition for some reason. 

> But this is not static typing. Thatâs strong typing,

Semantics. Irrelevant. Once you go here you're looking desperate. No one cares about your debunking of your misunderstanding of an argument. You know exactly what he means.

> the alternative is to silently produce nonsense in some cases

The alternative is to produce output. This goes against the whole duck typing philosophy python was based on. Or you know, you could read the article and see the alternative he suggests. Which could provide an error in the case the utf-8 conversion could not happen. 

> How would Python even report this error when I used literals instead of variables? 

Gee, maybe print the fucking literal. 

> Why do you have a text string and a bytestring in the first place? 

Because libraries are garbage. 

> I could swear Zed, an experienced professional programmer, just said he couldnât easily figure out these new formatting systems. 

No he said it was stupid to have to teach three to a beginner.

> What âconstant changing statusâ? The language makes new releases; is that bad?

Backwards incompatible and program breaking changes. You know the thing you encounter when you actual use the damn thing. Starting to suspect she doesn't by the way.

She's done amazing work through out at missing the point and being condescending. She is exactly the kind of thing she rails against. It's so easy to argue against a deranged reading of an article. Bit more difficult to actually tackle the reasons behind the writing of one. Which in this case is the fucking frustration of dealing with python 3 and the unnecessary changes they've made for fucking language purity.  

I rather her 1.5 Zed Shaws out of 2.
Well Lexy's response is just what Zed expected. No surprise. 
You have no scapy module that works in 3, forget it. I program on the stack. If you can't accommodate, I'm not interested. 
[deleted]
The list to string method uses `__repr__` rather than `__str__`

`__repr__` is intended as unambiguously telling you what the object is and `__str__` is human readable.  

Eg: if you have two "John Smith" `Runner` objects you can tell which one is which with `__repr__`

You can either implement the `__repr__` of `Runner` or write an iterator to loop through the list and print yourself.
You're going to need to provide an actual testcase.  (And preferably a reduced testcase, i.e. remove everything extraneous.)  What have you actually written for your `__str__` methods in both classes?  That output would indicate that you're missing a `__str__` method for the Runner class.


I must concede that I haven't tried your program yet, but I like the idea quite a lot! 

Where do you plan to go from here?

I might suggest that it could be designed to be more sophisticated than an alias manager for text files. As it stands, you are basically creating a program that sets aliases from a list whenever it is run, and provides an interface for updating that list. Your project looks very nice, but to be brutally honest, I don't see the advantage this really has to simply making a bash script that is run on startup with a list of alias assignments. It even saves a step when calling the file up to be edited, as I could just say, for example, "vim tmux-config" as opposed to "cfm edit tmux-config". 

Since package management systems tend to provide records for conf file locations, you can probably use the host's package management system to actually automate the import of conf files. From there, users could add custom locations or flag favorites to create a curated list if that is your main goal. However, I think automating the import of conf files during setup would be the expected and appreciated behavior.

Additionally, while you are interacting with the package management and file systems, you have the opportunity to get additional data that you may want to use to add new features. For example, you could:

1. Collect the name of the package maintainer to display as metadata along with the package title.
2. Try to locate conf files that have been orphaned by packages that were installed/uninstalled using the package manager.
3. Use checksum from installation to determine whether the conf file has been modified since installation.
4. Restore the original config file from the package by utilizing the package manager itself.
5. Manage and make recommendations regarding the permissions on the file relative to the current user and the program it belongs to.

Lastly, concerning your overall design of using the aliases:

1) Does this not prevent using the name of the application itself as the argument designating the conf file being edited?

For example, the command "cfm edit foo" where "alias foo=~/.foorc" -- in many cases, foo would be the name of the executable itself, and setting the alias would pollute your shell as to prevent calling to the executable I think? Maybe I'm wrong and you prevent that from occurring somehow. Regardless, my humble opinion is that it is highly desirable to edit the conf file just by calling the name of the program itself as the argument. 

2) This may not be the best design for the sorts of features you may want to add in the future. For example, it would be really cool if the program could manage multiple versions of a conf file and provide an interface for swapping. You could even create *groups* of conf files across multiple programs that could be swapped at once, useful for deploying customizations across multiple programs (tmux, vim, emacs, etc.)  While each program will have a different method for loading conf files, you could control which file is loaded by default for any program by relocating the conf files found on setup to a central directory, and then creating symbolic links in the default directories. 

I think that the program needs to store all of the data for a particular conf file in some kind of database or simple list of records, and then handle the argument containing the application name by looking it up internally, rather than calling to an alias that has been set externally.

Anywho--interesting project, got me thinkin bout some stuff and some things. 

Edit: Just wanted to add that the above would be difficult to implement across multiple platforms since it relies on specific package managers. You'd likely need to treat every package manager as special, and in general any file system operation is going to be different on Windows.

However, I suggest not trying to be cross platform for a project like this. It is platform specific. Most tools operating in this space are *not* cross platform.

If this releases on schedule, I'll likely be teaching my winter programming class in 3.6. Since it's a class for novices, the change that will impact me the most is the f-string: https://www.python.org/dev/peps/pep-0498

As a long-time Ruby programmer, I'm a fan of a more concise way of interpolation and am considering teaching this as the canonical way of doing interpolation, vs format(). Though knowing about format() may make understanding things like jinja templating easier to grok. 
Christmas is coming early this year! I can't wait for my new favourite f"toy"!
Too bad they didn't make it in time for Debian's Stretch freeze.
IIRC I heard that the dictionaries being ordered by design may not make it in the actual release of 3.6. Anyone know anything about that? 
Have you confirmed that you have an up to date Java implementation on your system ?
It seems like you're saying we shouldn't import things because they might depend on things (and so on) and your compromise is to do local imports - which will load the dependencies into `sys.modules` anyways -  but this just ends up obscuring your module's dependencies. 
Is importing actually a problem for most cases though? Will it affect anything other than startup-time and memory usage? I am mostly using Python for web development, where neither is a huge issue. Is it really an issue in other parts of the eco-system?

The proposed solution of delaying imports seems a bit error prone. Imagine a long running report script that crashes at the end because it turns out you forgot to install termcolor or some other output prettifier.

I am a bit confused by:

> Well, the most standard way is not putting the imports in the top-level scope. Just use local imports and try to keep your public API simple -- simple APIs are much better than complex APIs ;)

Does it matter if I have the imports deeper down in the library when I import from those files in my top level scope (which I assume is my main ``__init__.py``)? Will dependencies not be imported anyway?
Good questions, I'll like to know too.
https://www.logilab.org/project/logilab-constraint
Do you need a specific Python environment?

I've used [Choco](http://www.choco-solver.org/) with Jython, and it worked out pretty well.
I'v successfully used [gecode-python](https://pypi.python.org/pypi/gecode-python) in the past. IIRC I had to install gecode itself separately.
I would do a size check before any hashing.
Jobs where you primarily write in one programming language and that language is python? Yes, there are many, which should be easy to verify with a quick look at job sites.

There's plenty of good information about this at [r/learnprogramming](https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_how_do_i_break_into_the_industry_and_get_an_entry-level_job.3F) and r/cscareerquestions.
    import json
    try:
        from urllib2 import Request, urlopen
    except ImportError:
        from urllib.request import Request, urlopen
    r = Request("http://steamidfinder.com/Converter.asmx/SimpleData", data=json.dumps({"UserInput": username}))
    r.add_header("Content-Type","application/json")
    print(json.loads(urlopen(r).read())["d"]["steam64"])
I don't think there is such a web API call.

The username is only used for login.
I was willing to give the benefit of the doubt until the part where Shaw claims Python 3 is not Turing-complete. I can't understand how he could say something so demonstrably false.
After reading both articles, I'm totally behind eevee here.

Seriously, fuck Zed. His article is not just a criticism of Python 3 (which is totally fine - I'm more than willing to read criticism of Python 3, it helps me learn more), it's a very deceptive, sloppy hatchet-job. I'm actually at the point where I think I should petition the moderators of /r/learnpython to remove Zed's book from the wiki - I would hate for a beginner to be turned off Python 3 just because of his duplicitous statements about it. 

Also, it is *so* abundantly clear that Zed has never used anything above ASCII. My entire job is dealing with non-ASCII characters, and I would be unbelievably crippled if I was stuck with Python 2.


"Zed Shaw, your behavior here is fucking reprehensible." Jeeze, this is my first intra-language flame war since starting coding.
I only write Python 3 at work. I only do Python 3 for my new personal projects (and most of the older ones have dropped Python 2). I only write Python 2 for the OSS projects that I contribute to.

In my opinion, Python 2 can't die soon enough.
I only learned Python 3, and I think it is a good language.
In case you guys missed it, as I'm not sure how many of you may also be C coders, but Zed Shaw is the guy who said that the K&R C book (written by the **creators** of C, Kernighan and Ritchie) had examples in it that were completely unsuitable and unsafe. Again, he cites string handling as his example (he has some issues with strings, this chap).

You can see Zed's C rant [here](https://web.archive.org/web/20141205223016/http://c.learncodethehardway.org/book/krcritique.html). Tim Hentenaar picked apart his C book [here](http://hentenaar.com/dont-learn-c-the-wrong-way), with focus in part 11 on the rant itself. Makes interesting reading if you're a C programmer or have an idea what he's talking about.

Long story short, Zed is an arrogant arsehole.
By the way, anyone looking for an actual criticism of Python 3 by a very widely and well respected member of the community responsible for a number of the most popular libraries out there, should look to this by Armin Roncher:

http://lucumr.pocoo.org/2011/12/7/thoughts-on-python3/

Edit: As the top reply to this points out, here's a quite recent blog from the same author about the dangers of group think: http://lucumr.pocoo.org/2016/11/5/be-careful-about-what-you-dislike/

As it relates to Python 3, I'd love to hear about what his current opinion of Python 3.5+ is compared to e.g. 3.2.
Incoming rant:

So, I've only known Python for about a year and a half. I started out doing Kirk Byer's "Python for Network Engineers" class seeing as, well, I'm a network engineer. He teaches the class using Python 2. I however, decided that I would download, install, and take the class in Python 3, because that's the way of the future, right? 

Throughout the class I quickly learned that Python 2 and Python 3 have some differences, however, whenever I ran into a problem, I was only a quick Google search away from the answer. This process forced me to learn the terminology of the language and what it was actually doing under the hood, rather than just the surface level "My code matches his but doesn't run" attitude that Zed seems to hold. 

This process was a great learning experience for me and it made me a better programmer. In my use case I ran into the typing errors quite a bit, as most of my strings came from sockets and weren't formatted in a way I could use.

I guess my bottom line is this: Python 2 and Python 3 ARE different, and they have to be, but they're not that different. Get over it Zed.

Good job on the article Eevee!
Python 3 is great. Every time I see print declarations without brackets I die a little inside.
I like eevee and this is a great rebuttal but does anybody take this guy Zed Shaw seriously? Honest question.
Anyway, I enjoyed reading eevee's post (it's fun and informative) so thanks for sharing.
I agree with the article.  In the C world, everybody had to take a step back some time ago when we realized that we couldn't do everything with char\*, but instead have to start using actual strings, because everything is not in ASCII anymore.  There are still people that cling to to using char\*, even after all of these years, yet most people have appreciated the new libraries, even if they did have to change their ways.

The original author still seems stuck in the past where everything is thought of as byte streams and other fundamental types.  Computers and software is more complicated now, and Python has changed to wrap up this complication and provide a better foundation to build upon.  This is a good thing, but it is change.  I would think you'd want to recommend to new people to use strings as strings, and to quit doing the weird type conversions.
TIL Zed Shaw is an asshole

I don't know this Zed guy, but... the only thing I agree with him about is that it would really be nice if Python showed the variable names it could not concatenate in error messages instead of just their type.
I started slowly learning Python with LPTHW 2 years ago. Last year I ran into a ton of issues trying to make my first "for-real" project in Python 2, because all the files I need to process use utf8.

I'm glad I switched to Python 3.5 before getting too accustomed to 2.7; print(), "{}".format() and Unicode are wonderful improvements for me - and I heard that dicts will soon be ordered by default? Glorious.
[Python 3 was an inside job](https://i.imgur.com/seDzcrO.png)
I can't believe Zed Shaw is still being shared around these parts. I guess that just shows you that positive word of mouth will be effective no matter what the quality of the product is.

Edit: Just actually read the articles. It seems that he has upgraded from not just disliking the language to forming... conspiracy theories? Jesus.
> Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete and should not be used by anyone.

...yikes
I honestly don't understand how this conversation is still a thing. I use Python 3 daily in my work and I have absolutely no problems with it.

It's true that until 2-3 years ago the collection of available modules was a bit lacking, but, from my experience, I think this issue has gone beyond it's tipping point. I regularly need to add new requirements in my work and very rarely encounter a module that isn't compatible. Even when it isn't there's usually workarounds. In the worst case scenario you can just compile the module using Cython and you'll get a x3-4 speedup for free (without doing changes) apart from the compatibility. For the record, I've never reached the point where this was necessary.

I use Python 3 pretty much just to be "proper". I've heard that it's marginally faster, the unicode support is nice and it does have some new shiny features that are pretty useful. But, other than that...

In any case, both versions are barely different for most day-to-day work and specially for beginner work. Other than the print thing and iterating over dicts, a vast majority of code is compatible for both versions. I really don't get the phrase "teaching python 2/3", it's the same thing, they are not mutually exclusive, a beginner can trivially write Python 3 after just reading and introductory Python 2 book. The only factor that avoids this is the actual book saying not to use Python 3 because it's inferior.

Additionally, nowadays there's good tools that make writing code compatible for both versions trivial, which is what most important libraries do.
Thanks for outlining this in such a complete rebuttal. 

I am slightly at a loss for figuring out why exactly Zed has decided to double down here, as well as post such an inflammatory-response-inducing article. I am finding it hard to believe he's buying what he's selling.

I am torn between him simply doubling down for his ego's sake and him going with the "any press is good press," just to get his name/book/site back into the spotlight. 

I am inclined to think this is purely an attempt to drive some traffic. Sure, a lot of the traffic wont be sympathizers, but who cares about them? He'll surely get some new traffic. 

Drama is great business. It's just unfortunate what it does to the community. 
Really nice post :)

Seriously, I'm a bit fed up with people complaining about Python 3. They should spend this precious time actually learning it. This would be better for the community at large.

And honestly, how big of a leap is there between Python 2 and Python 3, when you compare it to, let's say, Python 2 and Java, or Python 2 and node.js? Shouldn't this be enough to convince most Python 2 programmers to switch to Python 3?
As a beginner I had no problems translating a majority of my python code from 2.x to 3.x. My code, in my opinion, is still pretty basic but I've had no problems with either python that I couldn't attribute to my own ignorance instead of the language itself.

Seriously though, how do I subscript the unsubscriptable.
> Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete and should not be used by anyone.

Zed...oh Zed...

I never realized you were stupid enough to write something this dumb.
Somewhat predictably, Zed [doesn't seem to care](https://twitter.com/zedshaw/status/801495976284332032).
So should I start learning 3 and stop listening to Zed? I've been debating the switch for a while now and Zeds curmudgeoness has been the driving force  so maybe I should stop listening to him?
I originally learned C and Python from Zed.

Have had to relearn everything with K&R and 'Fluent Python' (Ramalho). Cannot recommend that second book enough.

The trouble I find with Zed's stuff after learning things properly is that he doesn't try to actually get the learners to understand the language and why constructs exist. It's very much an approach of, "I want to do this thing and this is how I can do it in this language" rather than taking the time to show the language's particular strengths.

For example, which chapters of his book explain abcs; properties; the data model; generators; or anything that makes python good?

And sure, Python 2 is great, provided you don't think co-routines are interesting or you legitimately think having to declare something as inheriting from 'object' every time is the ideal.

Anyway fuck this guy.
[Zed is dead!](https://www.youtube.com/watch?v=y7Yp2L6c2KM)
I started using Python 3 for my personal projects, buy I am not going to rewrite my old code at work just because it's a better language. And in 2016, at least two big libraries we depend on, OpenCV and Panda3D, don't have prebuilt Python 3 binaries for Windows. And I prefer to have an easy way to get things running anywhere.
Python 3.6 is a huge one up (technically 0.9 up) on 2.7. My room mate uses 2.7, and whenever we talk python, it usually ends up with me preaching about asynchronous comprehensions, enums, and small dicts.
What makes me upset with one of the point is that we should only use ASCII. From someone who has learned several programming languages I always hated ASCII because it was used in the 80s and 90s and was a pain in the butt to use with language than English. It was quite happy to learn that unicode was invented to introduce other languages than English. In a country where English and French are being used on a regular basis this makes programming easier now than in the past. 

As for the print function I don't see the problem with tagging 2 parentheses to print a set of characters. Most of the editors will do it automatically for you. Even the printf function in C uses parentheses as well. What is the big deal. 

I still use Python 2 right now but I will switch over to Python 3 as most modules that I use have switched over. I could bring other subjects in the discussion but I like the way Python is going with unicode. 
> Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete and should not be used by anyone.

It have to be a trolling.
By age alone, at this moment, if your software isn't compatible with Python 3, it is the equivalent of software that was incompatible with PHP 5 (a similarly big update that introduced a lot of incompatibility) in **2012**.

Eight years are enough to learn how to update your code.
> Strings are difficult to use

They are, so you come up with a strategy to deal with them.  Set your encoding at the boundary of your code and stop touching it.

Better error messages would be great, but I'd rather have horrific error messages as opposed to autoconverting madness.  It's not possible to fix Python 2 code using just Python 2 if you only throw a unicode character through a function 1% of the time.

I like how easy Python 2 is, but strings are broken.  It took me forever to figure out my data files are not in utf-8, but rather latin-1.  They are not compatible.

Who really uses bytes anyways?  Not beginners.  They just set an encoding and they're done.  You can just pretend your data is always in say latin-1 or utf-8 and it's probably going to work on an ASCII string.  Bytes are a higher level feature.  People just got used to using `'wb'` because they didn't want stupid `\r` characters at the end of the line.

> Too Many Formatting Options

Why would I ever use `.format(...)`?  It's worse than `%s` and slower.  There are now 2 methods in my book and 1 that I can use because I write Python 2/3 code.
I am not sure what their (e.g., the author's) issue is: Python developers decided to push forward with Python 3 to make improvements that wouldn't have been possible otherwise. They do it mainly for free, and I think the effort should be appreciated. Now, businesses and companies who use open-source tools like Python for free, are complaining because they want contributors to spend more time on their preferred legacy version since they don't want to invest resources in porting code? I find this a bit outrageous to be honest.1. 
The idea that Python 3 is harder for newbie programmers is beyond baffling to me. My job got noticeably easier when I switched from teaching Python 2 to Python 3. The stuff Zed is talking about aren't issues for beginners.
WHY on earth would you write a rebuttal to a troll? The troll doesn't care or pay attention to responses. That's the point. Start a fire for no reason and leave. I thought it was transparent clickbait.
What a load of horse shit.
Is there anything in Learn Python the hard way that you can't do on Python 3 with only the most minor syntax changes? 
If I'm not mistaken Zed's been railing against Python 3 for a while now.
I started with Python 2, and moved to 3 almost as soon as it came out. From what I saw it isn't even that different, probably the biggest changes are print needs parenthesis, raw_input and xrange aren't a thing, strings are now in Unicode, and [some back end changes](http://sebastianraschka.com/Articles/2014_python_2_3_key_diff.html) (all of which are better things)

Personally I think it is way better, and has added some cool new libraries for handling IP addresses, new generators, and performance improvements.
See... I don't always agree with what zed says, but he's not stupid. This:

> And you show up to piss all over it, to propagate this myth that Python 3 is hamstrung to the point of unusability, because if the Great And Wise Zed Shaw canât figure it out in ten seconds then it must just be impossible.
>
> Fuck you.
>
>> Sadly, I doubt this will happen, and instead theyâll just rant about how I donât know what Iâm talking about and I should shut up.
>
> This is because you donât know what youâre talking about, and you should shut up.

Is totally out of line. You, the author, should feel ashamed of yourself for writing it.

You know that python 3 arrogance zed mentioned? *this is it*. I've raised a few issues with py3 in my time, and I've met the same hostility.

What are you *doing*? Dont be a jerk.

There's this thing people do when they see an opinion they dont like:

1) point by point rebuttal of every item in it, without really covering the high level issues.

2) personal attacks.

So *none* of the points he raised are even remotely valid? Why *are* there 3 different ways of string formatting now? Why *cant* python2 libraries be loaded directly and run in a (slow) sandbox'd environment something like cffi? Having pip in python 3? Wow! Did you know you can use it in python 2 too?

I'm not agreeing with what Zed wrote; I actually disagree with him; I think python3 and type hints *is* the future for python... but I'm not going to magically pretend there are no issues with it.

Here's the real question to ask:

How do you get more people on board happily using python 3?

How do you justify that choosing python 3 over python 2 is the right choice *for the developer*, not just for the python community (which, I think, is the core of the issue Zed raises)?

here's a couple of hints:

1) make it great for beginners

2) dont tell people to shutup and fuck off.
You know it's kinda funny, but after working on Fortran codes I always bitched and complained about going through legacy libraries which were written back in the 80s in Fortran 77 and how the code syntax was a pain to deal with compared to modern Fortran syntax. 

But on the flip side I can also see from Python what kind of issues can arise if you don't include backwards compatibility and how much work goes into converting libraries. 

I guess both have their ups and downs. 
Talk about a community that can't handle criticism: this submission has more downvotes than upvotes - https://www.reddit.com/r/Python/comments/5efe3t/the_case_against_python_3/
Turing completeness is impossible to prove. To show that a language is Turing complete you have to feed it the entire set of all possible programs to show that they can be read by it... it's just so obvious pointless to call a language Turing complete when it cannot be proven.
Maybe type checking will finally help people recognize that Python is not just good for coding small scripts!
Naive argument. Type hinting is a very long time away from giving benefits right now. Witness how long Python 3 is taking to make inroads and add how is static-typing-disliking ingrained in the community. I think it's fairly possible that it will never be commonplace enough for it to be on par with say, Java's primitive type system. 

While I am in the static typing camp (but I like Python and code it everyday), I can accept that the question of static and dynamic is not an objective matter, though. 
Nice work, thanks!

Was browsing on my iphone and you should know that it's not easy to read. The sidebar scales proportionally as I pinch-zoom and the main bar never reaches readable size unless I use Safari's Reader mode. Best to use a media query to hide the sidebar for all phone width screens.
very nice, chance of code please?
Can you give a tl;dr of the algorithms/libraries you used to accomplish this?
That's pretty cool! Now if you were able to add beat matching to match up similar tempos... hmm.. 
Also remember that all input are strings so if you want to use 70 you would need to convert it to and integer first. 
So, there's a lot going on here. But first, if you want to put your main function in a loop, you can do so just as you said 

    response = True
    while response:
       main()
       if raw_input("Again?") == 'y':
          response = True
       else:
          response = False

This is a very basic version of what you might want to do with it to allow the user to choose to run the program again. Also notice that you can reorganize your functions so that everything is more modular and easier to read and comprehend. 

As far as checking to see if the user input is correct, you'd need to construct your program to take into account how the user inputs data and what the user might input. 

For example, if you ask the user a yes or no question, you might want them to respond with either a 'y' or 'n', and have any other input to be ignored. Then, you can check for this using proper if-elif-else controls in something like a while loop (or something a little more easier to use, like a recursive function) 

    end_loop = False
    while end_loop == False:
       res = raw_input("Some Question?") 
       if res == 'y':
          (do something here)
          end_loop = True
       elif res =='n':
          (do another thing here) 
          end_loop = True
       else:
          (do something else here) 

Obviously the more possible responses the tricker this can get, but there a lot of methods and strategies you can use for planning and building a user interface that you can look into it you wanted, but would be over kill for a project like this.      
    def main():
        #first of all you should change type for temp variable
        #from string to integer
        temp = int(input('What is the temprature? (Enter 0-100) '))
        weather = input('What is the weather? (Sunny, Cloudy) ')
        water = input('What is the water clarity? (Clear, Murky) ')
        
        #then I check value of temp variable. 
        #in case of temp <= 70 a key will be 1
        #in other case it will be 0
        key = int(temp / 70)

        #I use dictionary for avoid of many if statments
        result = {
            0: {
                "sunny": {
                    "clear": "Use a dark roboworm dropshot",
                    "murky": "Use a bright/slow moving crankbait"
                },
                "cloudy": {
                    "clear": "Use a black and blue jig",
                    "murky": "Use a light color jig"
                }
            },
            1: {
                "sunny": {
                    "clear": "Use a Yamamoto Senko",
                    "murky": "Use bright spinnerbait"
                },
                "cloudy": {
                    "clear": "Use a topwater frog",
                    "murky": "Use a chartreuse chatter bait"
                }
            }
        }
        
        # and I just return result from dictionary structure
        return result[key][weather.lower()][water.lower()]
    
    #you can use main() function in loop or as how as you want
    #for example
    while True:
        print(main())
        tmp = input('Once again?(y/n): ')
        if tmp.lower != "y":
            input("Press Enter to Exit")
            break
Sorry for my English
PyQT is my go-to. If you don't want to write the GUI code by hand you can use their Designer tool to draw it instead. It helps get the GUI stuff out of the way so you can focus on the rest of the application.
I just finished mine with Pyqt!! I used vlc to do the audio but I know there is a photon extension to play media in PyQt. I honestly don't know much about about pyglet but pyqt is a good GUI and has QTCreator which makes the beginning design very quick.
Pyglet isn't really a gui library, but if you are keeping the GUI very minimal might be OK.

As well as pyqt you might consider kivy, it also supports android giving you a route to mobile.
Thanks guys .. I will try PyQt :) 
You might want to look at Jupyterhub. You'll have to think about security when implementing this since notebooks give people ability to run arbitrary code and even shell commands.

Edit: Take a look at [this repo](https://github.com/jupyter/try.jupyter.org) the README links to the repos with the code for https://try.jupyter.org.
Jinja2 it might not be the lightest, but it will fit the bill. Do a loop over files in the directory, filter for images, concatenate rendered results from Jinja2 and write to a single HTML file. 
Since you won't need advanced features (like inheritance), this could be done in pure Python without much hassle, no need for adding another dep to the project.
You can try ``bottle`` it's not just a HTML template, but it's a single file package.
I don't know about vscode or sublime but if your used to using Intellij why wouldn't you use PyCharm (assuming your asking about this for Python development since this is /r/python)? They are both by JetBrains so there are likely features in Intellij that similar in PyCharm. I'm certain that PyCharm has the feature you asked about.
You could install the following "python" plugin for vscode .
https://marketplace.visualstudio.com/items?itemName=donjayamanne.python

This supports searching through symbols in your project
I first discovered WordNet when I was looking for an English dictionary that I could access from a script. After using it for a while, I realized that WordNet might be the most powerful dictionary/thesaurus in the world. In this post, I share some the amazing capabilities of this database. The examples are in Python/NLTK.
WordNet was last updated in 2006. I wonder how many words have been added or changed since. 
This does look very interesting to me. Has anyone played with it already? First impressions?
Still no SSH improvements?  Option to use a key agent?  Multi factor auth support? Proper proxy/tunnel support?

Come on JetBrains...
[What's new in Pycharm 2016.3](https://www.jetbrains.com/pycharm/whatsnew/)
Pro is free for students, just a reminder
I won't link to it (to not over-promote), but I'm doing a webinar on Wednesday, showing the new features in 2016.3
Is buying the other version of PyCharm worth it?
> Terminal with Virtualenv pre-activated

Yes! This is awesome, thanks.
No.
I couldn't seem to get the built in terminal to work with conda environments, but may need to work with it more. Previously I could activate a conda environment, but now not only does it not automatically activate it, it seems to make it impossible to manually do so.
For me it is faster than 2016.2 but it's consuming more RAM

Great update
Great improvements! Keep up the good work PyCharm!
You can get this for free with a .edu address no?
Glad to see improvements to Git. /u/pauleveritt, is support for `git add -p` (partial addition) in the pipeline?
I just downloaded community edition and figured its a great tool but with some short coming:

1. Does not respect shebang. My script is pointing to python3 which is not default but it shows External Libraries from default 2.7 version.

2. Just like visual studio code it shows error in print() method when used with "end" parameter. E.g. **print(c, end="-")**

But overall a bliss for Linux users.
[python-ptrace](https://pypi.python.org/pypi/python-ptrace) sounds exactly like what you are looking for. Its fairly simple to get the hang of :)
You could make a numpy array that uses that area of memory as its buffer: https://mail.scipy.org/pipermail/numpy-discussion/2010-September/052953.html

In Linux, your target process would have to be a fork of your python process to have access to that memory I believe. Not sure about windows.
there's /dev/mem


So I only know linux so this might not be useful. Linux has this interface known as ptrace. It's the only way that I know of to manipulate another process. If you have ever used gdb then you have used ptrace as its a small wrapper. 
This is really interesting. The documentation is great, but how are templates defined? I mean I see there something about "invoice", "reports", but how can these be defined?
There is so much more to `import`.

https://www.youtube.com/watch?v=0oTh1CXRaQ0
Just like last time someone posted about Scrapy I am at a loss as to what it can do that the standard library + requests can't do in the same amount of code.

This is an honest question; I have not used Scrapy myself but I have written scrapers^([1]) and not found any part of my code that could have been abstracted without losing functionality. Every website is a little different and you still need all the custom logic to reflect that. For a simple crawl & mirror you can just use `wget`.

The only thing I found in the linked article is that Scrapy simplifies parallelism. In my opinion it is debatable whether parallelism should even be included in an all-purpose scraping library â after all the primary use case is scraping arbitrary websites, where good tone dictates that you should rather throttle than parallelize so as not to impact the site's performance.

^([1] mostly single-purpose, <100LoC)
Can scrapy trigger JavaScript commands? I thought I heard something like that but I keep reading these reviews and stuff and can't find any more about it.

I have a working solution with Selenium but if I could replace that with something that's slightly less reliant on acting like a person I'd be a bit more comfortable with it.

I know I should just do it with scrapy and see what comes up, but you know, what I have now works....
[deleted]
Very nice. I'll keep this in mind if bs4 doesn't work out for my current project. Nice to know there are more options out there.
I think you are looking for something like [pyinstaller](http://www.pyinstaller.org/)
also a search gave me this http://stackoverflow.com/questions/5458048/how-to-make-a-python-script-standalone-executable-to-run-without-any-dependency
Check out Pynsist. 

From the docs - "pynsist is a tool to build Windows installers for your Python applications. The installers bundle Python itself, so you can distribute your application to people who donât have Python installed."

Link - https://pypi.python.org/pypi/pynsist
reddit uses Pylons, Pyramid was just officially adopted by the Pylons project as it's replacement web framework.

You can see a list of project that use Pyramid on the [Powered by Pyramid site](https://trypyramid.com/community-powered-by-pyramid.html). Look at the "shootout" project source code for an example of a simple Pyramid app and "warehosue" (the PyPI replacement) for an ambitious and complex app example.

Kotti is a nice CMS written with Pyramid that uses SQLAlchemy and traversal. See http://kotti.pylonsproject.org/ and github.com/kotti/kotti
Appenlight.  See the clone-url in the middle of the screen:  https://code.rhodecode.com/rhodecode-appenlight


If this is a legit complaint, you'll hate almost any language... parens are pretty common in the majority.

That said, depending on your editor, look into "snippets", "live templates", or similar names. You could type `p<tab>` and it expand to `print(|)`, where | is your cursor location. Snippets are much more powerful than this even shows.
Like any other function call.  It's not a big deal.

If this is such a big deal to you, what happens when you get a job and need to write some javascript or something?
Is it really such a big deal for you? It makes things more consistent, too.
Get over it!
Relative paths are relative to the current working directory, not the file that is currently executing. If `./someWebpage.html` is somehow calling `./scripts/someScript.py` then your current directory is probably `./`, not `./scripts`. In that case the correct relative path to your text file is `data/someData.txt`. You should output your current working directory from python to be sure (`os.getcwd()`).

If you want to find the correct subreddit for asking python questions, you could try reading the sidebar.
    ../ down one level
    ../../ down two levels

Getting lost is fun.
http://www.blog.pythonlibrary.org/2013/10/29/python-101-how-to-find-the-path-of-a-running-script/
`this_script_dir = os.path.dirname(os.path.abspath(__file__))`
I'm exactly struggling with the same problem right now!
To answer your question in your "P.S.", the best place to post Python programming questions is under /r/learnpython. It's written in the sidebar.
You can use

    os.path.abspath

To get the abspath from a relative path of your /data or /scripts folders by navigating relative to the location of the file you're in. 
I believe you can use this, unless I'm not understanding the question correctly.

    import os 
    dir_path = os.path.dirname(os.path.realpath(__file__)) # folder name of this particular file where this command is executed

    print os.path.join(dir_path, '..', 'path', 'to', 'folder', 'file.py')

    >> dir_path + '../path/to/folder/file.py'
    OR 
    >> dir_path + '..\path\to\folder\file.py' 


You can also do this

Alternatively, if you want your current working directory you can do the following.

    import os
    cwd = os.getcwd()


First I would say to learn pandas, numpy, scipy, etc. That being said there is a good course on Coursera about this

https://www.coursera.org/learn/computational-investing

It depends a lot on what area you are working in.  Any company that requires real quantitative research will have their own historical database/backtest/trading systems.  They aren't using open source projects that popped up two years ago.

Excel is pretty much the only constant.  In practice I've found that interfacing between Excel and Python is rarely optimal because it makes your work challenging to share.  Excel and Python also have huge feature overlap so if you start in one system there isn't really a point in adding another.

When data needs to cross between systems I'll dump to CSV or interface with a database instead of tying together a mess of Python/Excel/VBA.
First learn python. Second learn some packages like Pandas, Matplotlib.Third learn how to use [Quantopian](https://www.quantopian.com/), which is what "Quants" in hedge funds use.
You could try https://github.com/quantopian/zipline if you are interested in trading algorithms.

But honestly, most work in finance is just like any other field, custom business rules around custom data models in a regular relational database. The only crux is that finance regulations are a vast minefield of exceptions to the rules, so it can take more time to grasp than other fields, for a general developer.
There is an O'Reilly Book on the matter, and a very good one at that (haven't finished it yet), called [Python for Finance](http://python-for-finance.com/). It also has an accompanying website that has all the code and the IPython notebooks available for free [here](http://oreilly.quant-platform.com/nb/portal/register)
I have seen a lot of sci kit learn used in the finance field.
Coupon Save 100% . You will Learn Manual Testing, Python and Selenium. All you need to secure your dream job in automation testing or improve your skills in automation testing.
PYTHON IS BROKEN. :-(
I guess the lesson is: If you're going to mix the types you use as keys, you need to understand the type hierarchy.
    True == 1 == 1.0

This has nothing do with it.

    class MyThing(object):
        def __eq__(self, other):
            return True
    
    {True: 'maybe', MyThing(): 'nope'} # returns as written

However, what's really happening is that `True`, `1`, and `1.0` all *hash* to the same value -- that is 1 (because ints hash to themselves).


    class MyThing(object):
        def __eq__(self, other):
            return True
    
        def __hash__(self):
            return 1
        
    {True: 'maybe', MyThing(): 'nope'} # I got {True: 'nope'}
It might be worth to prefer `async/await` and target at least Pyhton3.5 rather than `asncyio.coroutine/yield from`. I don't see the point of trying support Python3.4
This should be really good for people looking to get their feet wet. The module docs for asyncio are intimidatingly large. I definitely felt like I was stumbling through my first attempt at using it when it showed up with Python 3.4
I started diving into asyncio and ended up using gevent.  :)

I wish gevent (or something similar) were added to the standard library.  The whole monkey patching part feels well. . . like a hack.  No surprises there.
All asyncio tutorials seem to become irrelevant to me since they (mostly) try to show examples using asyncio.sleep(). It really is the worst way to demonstrate asyncio.

Sleep isn't io, the only reason you have to wait for it is because it is literally a sleep function.

If you demonstrate on something like reading and writing from disk or socket, then people start to see why they would even bother with asyncio in the first place, because the benefits are so evident in cases where your app has to wait for real io.

I have some example 3.5 code that you can run and observe to see the benefit of asyncio for yourself. I'll post it here later (it's on my work pc)
Skimmed the article - could anyone give a new developer an ELI5? I believe I know what threading is (giving different threads on processors different tasks to run at the same time) - how is AsynchIO different and/or the same?

As someone getting into Django, is it worth it to use this on something like a really basic PythonAnywhere or RackSpace server? Or are they not really powerful enough to take advantage of this?
This article has one of the best explanations of event loop, coroutines, and futures that I've seen so far!
First of all, **excellent** tutorial, definitely the best on the subject and the only one that gave me a proper insight of asyncio. For people that are a bit confused,I'm thinking of the following analogy when considering sequential execution concurrency and parallelism:

Imagine you  have 3 glasses and want to fill them with Coke.

1) **Sequential**: You have to fill one glass completely before you move on to the second glass. When you pour coke, you have to wait for the foam to settle down (i.e. the task of pouring is **blocked**) to continue pouring coke to the glass.

2) **Concurrent**: You fill one glass but when foam starts to form, you start pouring on the other glass. This way you don't have to wait for a certain task to finish but instead of waiting, you continue with another task. However, note that you always are pouring coke to one glass at a time.

3) **Parallel**: You call some friends and hand them a bottle. All three of you are simultaneously pouring coke, each one in his own glass at the same time.
    $ python3 1b-cooperatively-scheduled-asyncio.py
    gr1 started work: at 0.0 seconds
    gr2 started work: at 0.0 seconds
    Lets do some stuff while the coroutines are blocked, at 0.0 seconds
    Done!
    gr1 ended work: at 2.0 seconds
    gr2 Ended work: at 2.0 seconds

I don't understand why the output comes in this order, and in fact it doesn't work this way when I try running this code myself. Why shouldn't the `print` call after `asyncio.sleep(5)` run last?
Great, thank you! Do you have something similiar for twisted ?
What is the difference between Pyston and pypy ? only speed ? pypy seems have the better performance now.
If speed is not the only thing, what is the most noticeable downside of pypy comparing to pyston ?
Meh a new interpreter with no python3 support. I hope its in their plans at least. I really want a jit with asyncio support.
The exciting thing about pyston is the potential for high compatibility.  Having said that the performance numbers are impressive http://speed.pyston.org 

I look forward to giving this a try with some of my older projects.
Pypy's ancestor Psyco was written in C++, like Pyston and Pyjion. Not sure why they moved away to RPython?

Also PyPy mentioned that LLVM failed for them with multiple attempts. Not to mention Unladen Swallow. We see that Pyston had to introduce two-level optimization with lighter JIT than LLVM. So is LLVM IR even a right choice for JIT of highly dynamic language? It seems that LLVM is only well-suited for static languages. Note that the way Numba successfully uses LLVM for compiling numerical code is quite different.
PyQt / PySide are Qt bindings for python. You can use those with UIs created by Qt's designer.
This is also my favourite GUI library for python, because of the powerful features and good looks (and the mentioned designer program).

I have also worked a little bit with MATLAB's GUI designer. One feature you probably won't find in Qt Designer (or other graphical UI designers) is the "Jump to source code" feature from MATLAB.
Hello,

I'm working on the REMI gui library.

Look at this library https://github.com/dddomodossola/remi. This is the link of the entire gui library.

Here is the link to the editor https://github.com/dddomodossola/remi/tree/master/editor.

;-)
GTK application development is pretty easy in Python, and window layout can be done using the Glade design tool: http://python-gtk-3-tutorial.readthedocs.io/en/latest/. The applications are cross platform, but Windows and Mac aesthetics are less of a priority for GTK than Linux. Qt may give better results across platforms, but for Linux, nothing looks better IMO.
I just did it yesterday on my 2014 Macbook Air. I'm a beginner programmer and it took me about 10 minutes. No problems at all with the GUI based installer!
Ok. That's a relief to hear. Thank you.
    wget https://repo.continuum.io/archive/Anaconda3-4.2.0-MacOSX-x86_64.sh
    sh Anaconda3-4.2.0-MacOSX-x86_64.sh

And follow the prompts.
Any scripts your OS has that depends on python is probably not run by your user or any user (root, daemon, etc) whose environment would be affected by Anaconda being installed. Some likely call the system python directly.

When you install Anaconda you can optionally ask it to add it to your PATH via your .bashrc (or similar). This makes it simple to call executables with just the executable's filename like `python` or `conda`. If you didn't modify your .bashrc then you would have to specify the full path to run those commands, `/path/to/anaconda/bin/python`.

So long story short, it doesn't break your system because you aren't installing it as a *replacement* for your system python. The executables are just sitting on the file system and aren't usually installed in a default system location like "/usr/bin/". As mentioned before, you don't usually modify the environment of root or daemon or other system user so they don't search `/path/to/anaconda/bin` for the commands they run.
could you explain why exactly you think this should break your system? The python on mint / ubuntu is just "pre installed" it is not "baked" in. Did i miss something here? To be honest i never heard about anaconda before...
Anaconda by default installs as your default system Python. That also routes stuff like Pip (which is a part of your Python installation) and makes sure every package gets installed to the right place.
I suggest that you [don't](https://www.reddit.com/r/coding/comments/5ehd8k/my_blog_about_learning_python_3/) [cross](https://www.reddit.com/r/Python/comments/5ehbg9/i_am_learning_python_3_and_blogging_about_my/)-[post](https://www.reddit.com/r/learnpython/comments/5eh8s4/i_am_learning_python_3_and_blogging_about_my/).

Beyond that, it's very nice that you're blogging about what you learn! Keep up the great work! :)
Noteworthy updates include: 

* Argon2 & Scrypt hash support
* TOTP support
* PBKDF2 now has faster builtin backend, and utilizes other backends where available
* Lots of API cleanups and internal refactoring
* HtpasswdFile reader is now more flexible, and with improved security options.
* Refreshed documentation

Release notes:  http://passlib.readthedocs.io/en/stable/history/1.7.html
It just wraps around the coinfee web service. There's not really any python here at all.

I mean yes the title is technically true but you should have wrote "coinfee python wrapper for accepting bitcoins" instead. I was hoping to see some python block chain handling/interaction.
Release changelog here: https://docs.python.org/3.6/whatsnew/changelog.html#python-3-6-0-beta-4
I already downloaded it, and now I just can't live without format strings.
> * PEP 487 - Simpler customization of class creation

I *really* dislike how this ended up. You now have metaclass definition, baseclasses, and all of the custom class creation keyword arguments inside of the same parenthesis..

    class Player(BaseEntity, IInventory, prototype='m_iEnt2', metaclass=_PlayerMeta):

Although it might be that there's absolutely no need to use this new method if a metaclass is being used. Regardless, I find it awful that they can't come up with a new syntax...
release DL link:
https://www.python.org/downloads/release/python-360b4/

I'm really excited about the new File System Path objects. Going to be so useful.
I know this will sound like heresy, but they've been developing Python for 27 years now. It's really great! It's so great that I wonder if they really need to keep adding new features? I mean, can they ever just be finished with developing it? Maybe just pushing out security updates? Seems like a lot of open source mindshare going to a product that's already fine.
Broken link?
That's a nice hack. But there are fantastic open-source, actively-developed libraries for this sort of thing. My go-tos are [dask](http://dask.pydata.org/en/latest/) and [joblib](https://pythonhosted.org/joblib/). 
The last time I looked, more than a year ago, I didn't find anything. And I was/am still relatively new to testing. But what I ended up doing was something like this (example uses `unittest`, but `pytest` worked and `nose` would too.

    from unittest.mock import patch, MagicMock
    
    MockRPi = MagicMock()
    modules = {
        "RPi": MockRPi,
        "RPi.GPIO": MockRPi.GPIO,
    }
    patcher = patch.dict("sys.modules", modules)
    patcher.start()

    def teardownModule():
        patcher.stop()

The rest of the testing could now be done normally, with a caveat that it doesn't really test interactions or reactions etc. You could, though, check many other things. For instance, that it was:

* set up correctly: `GPIO.setup.assert_any_call(pin_name, GPIO.OUT)`
* called with the proper values: `GPIO.PWM.assert_called_with(12, 2800)` or `GPIO.output.assert_any_call(pin_name, GPIO.LOW)`
* cleaned up: `GPIO.cleanup.assert_called_once()`

I hope this helps. If you learn anything new, please let me know.
Without mentioning what you think it's difficult it is difficult to say what you can do.

But one question: You know all the pieces is isolation, but you know how they interact with each other? E.g., "a request comes through the WSGI responder, which Django routes through the main `urls.py` to find the app responsible for it; then it changes the app `urls.py` to find which view will answer for it; then it calls the view, which could in turn call the form, which would call the model; with the results from the form, it will call the template, return it to the WSGI as a Response and then the browser will see the results."
It sounds like your having trouble grasping the 'Model - View - Controller' (MVC) concept, and also how WSGI works.

I've found the Django 'poll app' tutorial gives you some confidence to play around with Django, but still leaves you feeling lost when you venture into making your first app. Don't give up! I used [this YouTube tutorial](https://www.youtube.com/watch?v=yfgsklK_yFo&list=PLEsfXFp6DpzQFqfCur9CJ4QnKQTVXUsRy) on Django and it really helped me grasp the MVP concept. WSGI is still a little fuzzy to me, but I understand enough to setup my URLs in Django and get the site running on a server. 
Just use [pyenv](https://github.com/yyuu/pyenv/) to install it.

I just tried `make`-ing it and it doesn't run any unit tests so idk why you are seeing anything different.
I'm learning so will be exploring use of JSON data. Trying to build a simple script for converting currency using data from a JSON feed. Script only and no interface as it's early days. Basic I know but it's like magic to me. ð 
Currently writing an interpreter for Brainfuck. 
Learning tkinter and writing an application to help me annotate a bunch of scans of old family slides.  Whether I'm learning tkinter in order to write the app, or writing the app in order to learn tkinter isn't clear at the moment...
I've just written a script for someone other than myself and installed Anaconda/Python 3 to their machine for the first time.

Script: Scrape data from website to CSV using an Excel file for input.

Learning: BeautifulSoup, OpenPyXL, the value of exception handling/logging to trace errors/debug solutions for which you're not the sole user!
Just wrote a little script to send out emails for something work related, and a couple programming puzzles. Got the hang of docopt and loving it.
Working on a game like Football Manager but for American football.
I'm working on an inherited project that's way overdue and the completion date is slipping by the day.

Working with Raspberry Pis and Python / Processing mainly - yesterday the image I was working on corrupted just for loffs; luckily I'd scp'd the bulk of the code only about 20mins earlier.

Today had my boss get (understandably) shouty about the situation as it turned out some previously working code now wasn't (RFID reader binary run as a subprocess of a Python script which parsed STDOUT & then toggled a pin). Had to abandon that code & take another approach which mercifully worked.

Do you know that if you `apt-get install arduino` on raspbian you get some old version that's totally incompatible with current SPI / EEPROM libraries?  It's not obvious if you usually run simple sketches so can be confusing when you start to get weird errors.  The current ARM-compatible version requires a manual install.

Also Python really wouldn't be my first language, although I think I'm kind of starting to get the hang of it.
I'm working on a plugin for [Sunflower](http://sunflower-fm.org/).  I haven't coded in Python in ages so this will be a good refresher.
Studying Matplotlib more thoroughly. Love some of the things you can do with it, but I'm not too familiar with it yet at this point.

Wrote a script that randomizes a bunch of options for people watching so regulars at the bar can play bingo during peak times this holiday. It outputs to a BINGO grid. Got the idea on day before thanksgiving. Options include things like: puking on bar, ugg boots, make out, crying, etc.  it was a huge hit on Weds lol. 
Headtracking via webcam in pure python without OpenCV, which I consider overkill.
Writing my first program! It just a little rpg.
I'm working on a web scraper using aiohttp. I found a couple of pages that made async programming in Python sound much more useful to me.
Solving a bunch of coding puzzles with Python. 
I'm building a unittest module to auto test my code that parses through Heroes of the Storm replay files (heroprotocol) and outputs map specific and hero specific data to two different csv files.  Though those files are no where big enough to justify the use of apache spark, I plan on using the Python API of apache spark to become familiar with spark, and to apply machine learning algorithms to determine which "pre-game" stats can best predict the outcome of the game.
This week I am working on a client/server to be used to send keystrokes to another PC for use with a larger project. The larger project being making Street Fighter II bot for [Fightcade](https://www.fightcade.com). I hope to use Fightcade's replay database to take a machine learning approach for the bot's logic.
Writing some classes and functions for dealing with quantum espresso calculations. Primarily learning python after programming for years in LabVIEW (G). Quite the paradigm shift, but I can see the potential for python so I'm sticking with it. 
I'm converting some old rails project into django. still not used to django's testing style (i'm using lettuce). overall doesn't seem too difficult
I'm going to be putting Vim stickers on my keyboard and then probably writing stuff in moonscript. Because I'm a heathen.

**Edit:** specifically, an [IRC bot](https://github.com/wiseguiz/Moon-Moon)
Just finished up a Flask app (with some JavaScript) that generates reports on shooting victim's known associates for my local police department that they use for officer safety and awareness.
Working on some research to write an ebook on the basics of how to use python to scrape ecommerce sites.  Does anyone have any pointers or tips on this?  
I'm making myself a file manager - with the ability to find duplicate files and recently added files. Well I'm just a newbie but I hope this can be the first project I actually finish...
Working through [Grokking Algorithms](https://www.manning.com/books/grokking-algorithms). Pretty fun read so far and learning a lot. 
I'm doing a bunch of different data modeling projects over Thanksgiving break. (Yep, homework.)

One example I just finished is taking a list of stocks and their historical prices (from a csv for each stock), and linear regression modeling them against an index to find the stock that historically most closely follows the index. i.e. Citigroup (C) follows the Dow Jones Industrial (DJI) nicely, but no surprise because C used to be part of the DJI.

Mostly I'm working with numpy, matplotlib, and most recently scipy.
I am creating a cli tool to interact with aws s3. Thinking about adding some neat cli interface like curses. Wip available at https://github.com/guitmz/bucket
running a ton of MCMC fits with emcee (aka my excuse to browse reddit during work), trying to make my model calculations more efficient.
I rebuilt my site with Lektor and I love it. I might move my other site to Lektor as well.
I'm going to do a web scraper to get some data off reddit, a couple of subreddits.

I'm very new at this, but I found a couple of nice tools. There is some data I really want to look at.
I started working a project that retrieves data from my company's lab data, analyzes it, and then makes set point changes to industrial PLC controllers to try and adjust the lab data in a desired direction.

Trying not to (literally) set anything on fire.
I'm writing an application to migrate documents out of SharePoint and into a different document storage system supplied by our POS vendor. Yea!
Building a Red-Black tree for my algorithms and data structures class
I am working on getting our deployment working with salt. Any tutorials or documentation is appreciated.
Working on Sphinx-style docstrings support for [Clize](https://clize.readthedocs.org/). Got it to a basic level and feature-parity with the previous system.

Next up is dealing with RST's tables, autodetection and also using `napoleon` to support Google and numpy-style docstrings.

I haven't pushed my changes yet because I'm still making sure that my refactoring of the help mechanism makes sense. I really do edit my commits through interactive rebases a lot :)
working on building a recommendation engine for movies for a school project.  Yay for impossible deadlines and sleepless nights!
Running a reddit bot with Docker to cross-pollinate websites to reddit.
I dont know much about python so I'm doing simple stuff. I just finished a convertor where you can translate Celsius to Fahrenheit and the opposite. You also have the ability to change the laungage settings between English, German, Italian, an Greek 
Started learning it after I got some grasp on Javascript. Pretty neat transition. Learning it on Pluralsight, looking good right now.
I'm working on a Coursera sequence learning how to utilize Pandas.  Been rough going so far, but making slow progress.
Maybe an "easy" way to do it would be with "pyautogui". [Start here](https://automatetheboringstuff.com/chapter18/). Basically you would just "open" League launcher, move the mouse around clicking "Launch" (Getting the specific coordinates beforehand) then waiting a bit for the login screen to pop (sleep will suffice) clicking on the username, giving keyboard input, press tab, input password and then enter. Looks like a fun little script actually. Ill hop on my windows partition right now and try something maybe.
Not sure if anyone cares but I have found a way to do what I was trying to do without using the .get_rel() method.

Basically I manually calculate the mouse movement every iteration of loop by comparing the result of the get_pos() method against what the mouse position was last iteration. I then feed this to the my update method.

Not sure if I was just using the built-in method incorrectly or what, but I guess I'll run it like this :/

EDIT: SO this in fact does NOT solve the issue... still confused.

    # --- Main event loop
        for event in pygame.event.get():
            posNew = pygame.mouse.get_pos()
            mouse_mov[0] = posNew[0] - pos[0]
            mouse_mov[1] = posNew[1] - pos[1]
            pos = posNew
            windows_manager.windows_update(event,mouse_mov)
Python is clearly open source while Java has had recent license disputes.
```
class myfirstjavaprog
{  
        public static void main(String args[])
        {
           System.out.println("Hello World!");
        }
}
```

VS

    print "hello world !"
https://pythonconquerstheuniverse.wordpress.com/2009/10/03/python-java-a-side-by-side-comparison/
Python is scripted, which means that it is interpreted at run-time. If you have an error, the program will execute until it gets to that error. JAVA is compiled, which means that if there is a syntax error, the program will not run. This makes JAVA faster than Python.

Python supports object-oriented programming, but JAVA can only be programmed in an object-oriented manner. This makes JAVA better for larger applications and Python better for smaller applications and scripting, though there are certainly large programs done in Python and small programs done in JAVA.

Python uses indentation instead of braces, which makes good programming style mandatory. JAVA does not, so you have to consciously use good style in JAVA to keep it readable. 

Finally, JAVA is named after coffee, and Python is named after a British comedy troupe.

Those are the high-level differences.
They're very different languages, so there are lots of differences - but I'd say the most important difference is Python's *dynamic typing*.  How this affects you depends on which language you're going from and to, but assuming you know something of Java and are looking towards Python:

In Java a variable "is" an int, or a float, or a FileReader or whatever, but in Python there's (usually) nothing in the written code to declare the variable type, and nothing in the running code to enforce it.

This has many implications: it often makes documentation less clear; lack of compile-time type checking means you need more of a focus on proper test coverage, or at least comprehensive testing of every release; it makes IDEs unhelpfully vague at times.
Static typing vs duck typing
One is a snake and the other is an island in the South Pacific.
I've skimmed that article.  The author's an idiot.
Third posting to /r/Python. Whatever else it's pulling in the clicks.
This is a good place to start.
https://www.maxmind.com/en/ipv6-information-and-faq

IPv6 is going to be tricky because of it's portability. I currently have native IPv6 through Comcast at home, but I also maintain a IPv6-to-IPv4 tunnel from Hurricane Electric's TunnelBroker.net (completely free for anyone) for my laptops when I'm on the go, since IPv6 isn't available natively from most open WiFi access points. Since HE.net's IPv6 assigns each user a static /64 block, I can have a static IPv6 address for my laptop and use that address no matter where I am in the world, thus making IPv6 GeoIP pretty inaccurate and useless...at least in my case.
Have you checked if Maxmind can offer you this service/dataset?
Looks like exotic.

Anyone used it in a real project ?
This looks great. The javascript version of "foo in bar" gave me nightmares though.
Awesome, been waiting for this. Thanks for this fantastic library
https://automatetheboringstuff.com/ is a popular book on pretty much this topic. Chapter 11 covers web scraping, which this would be an example of.
This sounds REALLY cool.  Looking forward to playing with this one.

I learned long ago that no one likes the "PEP8!" guy, but I gotta ask...8 space tabs?  
Does anyone have a proper example of this?
learn python 3 they said.. it's the future they said.. 
What I really want is a Vin Scully bot...could this do that?
Sounds cool. I wonder what'd happen if I used a series of audiobooks then read by 2 separate people, alternatively.

Rusty on my python, but [this](https://github.com/ParhamP/Speech-Hacker/blob/master/src/generate.py#L31-L51) looks like it could be


    keys = myDict.keys()
    for i in range(len(textList)):
        try:
            for j in xrange(1, 6):
                x = " ".join(textList[i:i+j])
                if x in keys:
                    output_file.write("file " + myDict[x] + "\n")
                    break
        except IndexError:
            continue

Is this yours?

Your commit messages are absolutely useless.
I love the idea... Kind of what Bumblebee does, only with one character only 
Awesome
Can someone package this with Docker?
Not in the standard library, but 

http://www.grantjenks.com/docs/sortedcontainers/

may be up to what you want.
What about using heapq?

Ultimately there aren't many good choices. A balancing tree based on ndes will need to be written in C to perform adequately, unless you use a list as your primitive storage structure (like heapq does).

Its definitely one of the more frustrating things about python. There aren't really any datastructures beyond lists or dicts.
It looks like the answer is "no". There are lots of third-party libraries that do it, but no standard lib stuff.
I've used bisect with collections.deque to try to get closer (O(1) for append/pop from either end, but rotating to get there is [not necessarily efficient](http://bugs.python.org/issue16398), and the real efficiency for that depends on the platform and memcpy implementation). The unfortunate issue with going this route for the sake of efficiency is that indexed access gets worse as you get closer to the middle (O(1) at the ends but O(n) in the middle), effectively negating the efficient insertion :/
Bisect plus dict or deque.

Here's some code from peewee orm:

    class _SortedFieldList(object):
        __slots__ = ('_keys', '_items')

        def __init__(self):
            self._keys = []
            self._items = []

        def __getitem__(self, i):
            return self._items[i]

        def __iter__(self):
            return iter(self._items)

        def __contains__(self, item):
            k = item._sort_key
            i = bisect_left(self._keys, k)
            j = bisect_right(self._keys, k)
            return item in self._items[i:j]

        def index(self, field):
            return self._keys.index(field._sort_key)

        def insert(self, item):
            k = item._sort_key
            i = bisect_left(self._keys, k)
            self._keys.insert(i, k)
            self._items.insert(i, item)

        def remove(self, item):
            idx = self.index(item)
            del self._items[idx]
            del self._keys[idx]
This course will walk you through: 
Variables, 
Strings, 
Numbers, 
Comments, 
Lists, 
User input, 
Conditional tests, 
Dictionaries, 
While loops, 
Functions, 
Classes, 
Files, 
Error handling and Testsâ¦Phew!
As pointed out on HN, the author tries to make the point that Python 3 is not turing complete, which is so insanely not-correct that it brings into question the validity of any of his thoughts.

> Currently you cannot run Python 2 inside the Python 3 virtual machine. Since I cannot, that means Python 3 is not Turing Complete

That is precisely not at all how turing-completeness works. I think what the author is getting confused about here is the idea that you can use a turing-complete language to write an interpreter for any other turing-complete language, which is of course a completely different concept. You very well could write a Python 3 interpreter in Python 2, and vice versa.

> I should also mention that as stupid as that sounds, actual Python project developers have told me this

I would *really* like to see a source for this.
This article just reads as a rant against something (Python 3) that someone (Zed Shaw) just doesn't like, and is upset other people do like it.  It's not written to persuade or convince anyone, but to open the door to an echo chamber where people with similar views can hop in on a circle jerk.

**Why Adoption Rate Doesn't Matter**

Before getting started, lets address why Adoption Rate, the primary argument of why Python is dying and why it's a bad language, is a horrible metric and isn't representative of anything other than adoption rate.

Python 2.x is supported until 2020 (exact date hasn't yet been provided).  In the world of business and sciences, there is a *HUGE* aversion to changing what works until it's a requirement to do so.  To make big changes takes resources, which no business wants to use to make their code do the exact same thing.

When (and if) additional features or support are going to be needed, then the code will be updated.  It's why Python 2.6 is still being used, despite it's end-of-life being late 2013.  COBOL, which has been around since 1959, refuses to die because there is still a ton of legacy code in the big corporate world that would cost money to port.

**Unsupported arguments and false statements given as fact**

This entire article is filled with exaggerations, speculations and unjustified (absurd) statements.  Take for instance, the very first unsupported claim:

> THERE IS A HIGH PROBABILITY THAT PYTHON 3 IS SUCH A FAILURE IT WILL KILL PYTHON.  

I'm sorry... What?  Python has [recently overtaken Java for growth and popularity on GitHub](https://github.com/emmanuel-keller/github-language-statistics/blob/master/README.md).  As I pointed out, no evidence is provided, beyond a non-cited adoption rate metric (which I've already pointed out, is a bad metric), to support that Python is dying, or as he later states, is already "dead and will not advance".

> Also, it's been over a decade, maybe even multiple decades, and Python 3 still isn't above about 30% in adoption. 

Python 3 was released on December 3, 2008.  That means, from the time the article was written, 7 years, 11 months, 2 weeks, and 5 days had passed.  So no, it hasn't been multiple decades, it hasn't even been a decade.

> the Python project uses propaganda, social pressure, and marketing to convince you to use it

This is another grandiose statement which is, again, unsupported.  The Python project is actively continuing to support Python 2, and [recommends it if it is more suited to the project you are starting, or to your targeted users](https://wiki.python.org/moin/Python2orPython3).  

> Some people go so far as to ban my book [...] my book is the most effective method for learning to code.  The second someone starts banning books you know they don't care about anything but their own agendas.

This is a completely subjective statement being passed off as fact.  The authors "methods", teaching order, and goals have widely been criticized for being a horrible for beginners (or anyone) and have been removed from recommended lists and discussions because of it.  Python themselves don't ban the book, people and groups ban the book.  From personal experience, this is because (much like my wasted time arguing with this article), people are tired of explaining why the book is such a horrible introductory resource.  This subreddit recently started a [Meta thread to remove it as a recommended resource](https://www.reddit.com/r/Python/comments/40s6dm/meta_can_we_take_learn_python_the_hard_way_off/), which was supported by a number of arguments against it.  

**Complete Misunderstanding of Turing-Completedness, Translators, and Transpiling**

The majority of the remainder of the article argues about a "complete" programming language, turing-complete, translating code between languages, and transpiling code.  Without spending a ton of time, I can't pick out all of the problems/fallacies of his arguments, as it's a big interwoven ranting mess.

All of the arguments about Turing-Complete miss the mark, and really goes to show that the author has no idea what it means to be a Turing-Complete language. Instead of addressing it myself, see /u/Turbosack comment [here](https://www.reddit.com/r/Python/comments/5efe3t/the_case_against_python_3/dac1i3m/), who beat me to it.

Further to this though, are the following (not exhaustive or all inclusive) statements:

> - "Translating one programming language into another is a solidly researched topic with solid math behind it. There are translators that convert any number of languages"  
> - "Translation is a fully solved problem."
> - "Writing a translator from one language to another is a fully proven and fundamental piece of computer science."

Which are all absolutely absurd. Translation of one language to another is incredibly difficult *to do right* and is by no means a "fully solved problem" in any practical sense.  There's a very very big difference between "theoretically possible" and "supported out-of-the-box".  The author knows this, and is purposefully misleading you (which he says is a horrible thing to do), as he later writes (emphasis added):

> I can then simply compile any other langauge into that virtual machine and **it will work fairly well**. I may run into little **issues with compatibility between libraries** when I am working with wildly different langauges, but they **should work fairly well** together. 

Really, the entire "The JVM and CLR Prove It's Pointless" section just shuts down his own argument of transpiling and translating being 100% easily-implemented-real-world options, not just theoretically possibilities.

**Complaints about Bytes vs. Strings**

The complaints about bytes vs. strings may have some validity in that it can be annoying for beginners to understand.  However, identical arguments could be said about sets vs tuples, or any other similar data-types.  As soon as the author starts thinking of them as different types, that don't have all the same 

Furthermore, this whole "Bytes vs. Strings" came about because of *severe* frustrations with Python 2's handling of unicode and string types, especially with the implicit conversions that the author so dearly wants back. [This](https://pythonhosted.org/kitchen/unicode-frustrations.html) article, [this](https://www.azavea.com/blog/2014/03/24/solving-unicode-problems-in-python-2-7/) article, and [this](http://www.pgbovine.net/unicode-python.htm) article all appeared on the first page of google searches for "Python 2 Unicode".  

Two common points were made in these articles: 1) The str type isn't a string, it's a collection of bytes. 2) The unicode type represents a string.

Python 3 addresses both of these, with the <str> being the old unicode, and <bytes> being the old string.  I think changing the language to actually represent this is a significantly better approach, as did the Python project (seeing as they made this change).  

As soon as the author learns that *bytes and strings are two different object types* and stop assuming they are one and the same, he'll be better off.  His argument that the problem stems from them being "statically typed" shows his ignorance of this.  This has nothing to do with static vs. dynamic typing, this has to do with object/type interaction.  They can't be added together for the same reason an offset-aware and offset-naive datetime object can't be: one of the two can represent a large number of different values relative to the first.  Again, history showed this was just a bad, bad idea.


**Too many formatting options**

This just seems like an absurd attempt at more complaints.  There are a number of functions that the `.format()` allowed that wasn't available with the old style, as identified [here](https://pyformat.info/).  PEP 498 is really just syntactic sugar for the `.format()` option, making it less verbose. I'm hoping I don't need to defend why his argument of "why didn't they just do that in the first place?!?" is (yet again) absolutely absurd. 

**Conclusions**

The entire article is filled with straw man attacks, false dilemma's, ad hominem attacks, begging the question, circular reasoning, hasty generalizations, and a list of other logical fallacies that make picking out relevant complaints nearly impossible.  None of his arguments such as "PYTHON IS DEAD" are supported with any evidence, and most of his complaints about changes and direct have logical reasons and a history behind them.

Python 3 is doing nothing but growing, and there's nothing to indicate this trend will stop.

*EDIT: Fixed a few typos, and corrected some missing words.  It was late, sorry!*
There is 3 main topics in that article, which goes over and over:
author can't run Python 2 code on Python 3;
2to3 does not always work;
when you tried to concatenate bytes with string in 3 you get an error without variable names.
Also there's lot of angry rant, logical fallacy and personal opinion there.
> The fact that you can't run Python 2 and Python 3 at the same time is purely a social and technical decision that the Python project made with no basis in mathematical reality.

    â¯ python2
    Python 2.7.10 (default, Oct 19 2015, 11:51:06)
    [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)] on darwin
    Type "help", "copyright", "credits" or "license" for more information.
    >>>
    
    â¯ python3
    Python 3.5.0 (default, Oct 19 2015, 10:55:26)
    [GCC 4.2.1 Compatible Apple LLVM 7.0.0 (clang-700.0.72)] on darwin
    Type "help", "copyright", "credits" or "license" for more information.
    >>>

huh seems easy enough to me
Oh man, you just made my day!

I spend a lot of time on the Python tutor mailing list, and other forums where we get a lot of beginners, and I cannot begin to tell you how many newbies to programming are needlessly confused by the backwards way the Hard Way book teaches things. Now I have a better idea of why he starts by teaching while loops instead of for loops even though for loops are **much** more useful and easy to learn.

It's like you wanted to teach somebody how to iron a shirt, so you start by teaching them to take a half brick, wet it down, stick it in a hot oven until it is hot, then pound the shirt with the brick. Then, after they've wasted weeks perfecting their pound-shirt-with-half-brick skills, you say "Guess what? That was a complete waste of your time, you will never in your entire life need to iron a shirt with a hot brick, because we have these things called 'clothes irons'!"
This article seems to be about 80% bullshit to me. Neither "dynamic typing" or "Turing complete" mean what this guy thinks they mean.

Like claiming that because the Python 3 interpreter can't run Python 2 code it isn't Turing complete. That's total nonsense. Any modern programming language is Turing complete. Of course, being Turing complete doesn't actually mean that much. Postscript and Brainfuck are both Turing complete, and I don't see programmers writing many programs in either of them.

If you wanted to spend the effort on it, you could write a program in Python 3 that could correctly run any Python 2 code. You could do the same for any language. But nobody really wants to bother with writing such an interpreter. If you want to run Python 2 code, it's much simpler to just use the Python 2 interpreter.

He's got a point that the `2to3` porting tool can't reliably convert Python 2 programs to run on Python 3. But that's usually because those Python 2 programs are buggy or ambiguous (e.g. they only worked correctly on ASCII or Latin-1 text and their programmers just never noticed their shortcomings). If you give them input that can't be handled in their assumed encoding, they'll either choke on it, or worse, silently garble the data.

Python 3 requires you to be up front with your assumptions about things like encodings, and it will usually give you an error message if you get it wrong. Unicode strings and byte strings are not the same and aren't ordinarily used for the same purposes. It makes some sense that they don't have all of the same interfaces.

This is what the guy somehow believes means that strings have some weird new typing system. Nope, they work just like any other types. You may need to know if you have a `str` or a `bytes` when doing operations on them. But that's just like how you may already need to know if you have a `list` or a `dict`, since they don't have all of the same interfaces. And of course, sometimes you don't care about the differences because you're only using a small part of their common interface (e.g. iterating).

I'll admit that the error messages you get from Python 3 encoding errors are not always clear. But they're better than what you'd get if you were actually trying to write Unicode aware code in Python 2 (where you can get `UnicodeDecodeError` exceptions when trying to `encode()` something and other non sequiturs).
lol wut.

In addition to the BS others have mentioned, I like how he says in Python 2, `bytes("hello") + "hello" == "hellohello"` but not in Python 3.  Yeah, that's because `bytes` is literally just an alias for `str` in Python 2!  He _could_ have talked about `"hello" + u"hello" == u"hellohello"` in Python 2 (it would still be a bad argument since it isn't very good behavior IMO), but he didn't.  In fact, his mistake is a good example of why Python 2's unicode / str problem needed to be fixed in Python 3.
TL;DR: Dude wrote his course in 2009. Does not want to update it. Picking up 29$ per book, very popular, still recommended by some maniacs, cash rolling in - why change? Makes prettier CSS and writes shitty articles (which took longer than to run his course through `2to3` or `sed`) to approve his laziness.

Just move along, guy had a schtick for being 'that egomaniac arrogant programmer' for PR, but it seems that he became one.

He's too lazy to update his courses. Probably easier to talk bullshit and write insanely incorrect articles, to sell his outdated courses, than to update 30 lines of code. 

His courses are for beginners - there's almost nothing to change in there. Mostly change print statements to functions and move along. Easier to write `super()` in OOP part, etc. Could extend courses with new python stuff like `asyncio` as well. I am not sure if there are generators/iterators in his course so he could extend there as well, as in python3 they are more commonly used and usually make life much easier.

Just look here: https://learnpythonthehardway.org/book/ex0.html

Python 2.5.1. He even does not update to 2.7.

    Last login: Sat Apr 24 00:56:54 on ttys001
    ~ $ python
    Python 2.5.1 (r251:54863, Feb  6 2009, 19:02:12)
>Some people go so far as to ban my book because it does not support Python 3, even though my book is the most effective method for learning to code.

Arrogant much? Even if that were true it's totally unprovable.

The rest of the article is verging on insane. I used to recommend LPTHW but I'm not sure I should any more.
Let's all promise to just ignore Zed. He jumped the shark ages ago.
>  In an attempt to make their strings more "international" they turned them into difficult to use types with poor error messages. 

This line is the most offensive one for me. Because it shows that Shaw never ever dealt with different languages than english or emojis, because customers will paste every kind of shit into formulars...
"Startup" I work for uses Python 3 since few years and there is no point for us to use Python 2 since long time ;) Initial Python 3 migration required few pull requests, but that was doable without problems.
Wargh, what crap article. Full of repetive claims, rants and nonsense. That does a really bad service for the cause it adress. Very hard to take it serious. And it really doesn't help that he constantly pretends that python 3 is hard for beginners, yet most problems he have are differences between python 2 and 3, not even the language itself.

I seems he has more pissed on the fact that his outdated tutorial is becoming useless and he can't anymore earn money with it till he reworks it. Probably lost some through refunding.
> If I couldn't use Python 3 reliably then there's no way a total beginner could manage it.

lol, did Zed Shaw just admit he is a beginner? This guy is a joke.
There is no case anymore.
The author of this article says about Python's typing: "That means I do not have to know the type of variable to use it. " 
This is not really true. If the type of a variable is string, then you can't do arithmetic on it, because Python is strongly-typed (it's not statically typed, but it is strongly typed). Any programming language that fails to present beginners with strong typing is a bad language to start with, IMO; both Python 2 & 3 share the same approach to typing. Personally, I enjoy coding Python 3 much more because of the fairly elegant type-hinting. I only use Python 3 for my projects, on Windows and Linux, and it's fine. There is hardly any stuff not ported to v3, as long as you're happy with 3.5, and why wouldn't you be. 
The performance improvements in python 3.6 seem very promising. 
The abstraction required to understand the difference between unicode strings and bytes doesn't seem very challenging to me: if you can't master such a basic abstraction, you will certainly struggle with modern programming in any language, including many other parts of Python. I suspect that it wouldn't even be an issue if you have never expected characters and bytes to be the same (after all, we are all quite happy dealing with numeric types which are abstractions of implementation details we mostly don't care about).

[deleted]
Code in picture form? 

...
license?
At present, this code just screams "Intro to Programming".  There's a lot of VERY bad code, and a lot of improvements that could be made almost everywhere.

[card_game.py](https://github.com/pythonGuy/card_games/blob/master/card_game.py):  
First, it's likely more suited that a Card, Deck, and Game should be separate classes. A card would have all the typical attributes of a card (card number/netter and card colour), it probably shouldn't have a value, since that will vary based on the game (let the game decide this). 

A deck will be a collection of cards, with methods to shuffle, deal, add cards, remove cards, etc. (ie. things you would do with a deck).

A game would have the rules of the game, card values, how many decks, players, etc.

Furthermore, there's a lot of poor code being used.  At present, there's no "good" way to have more then the four basic suits, or two colours.  What if I want Wheels and Rackets?  

The entire `deck = ( Card(...), Card(...) ... )` is a perfect example of my "intro-to-programming" statement.  Everything is hard-coded, with zero options for customization.

Instead, consider the following:

    from itertools import product

    suits = ['Spades', 'Clubs', 'Hearts', 'Diamonds']
    values = ['2', '3', '4', '5', '6', '7', '8', '9', '10', 'J', 'Q', 'K', 'A']
    cards = list(product(suits, values))

Suddenly, games like Euchre become possible very easily by overwriting suits/values when the deck is being created.  


[black_jack.py](https://github.com/pythonGuy/card_games/blob/master/black_jack.py):  
There's just a ton of questions.  Why does the `Player` class inherit from the `Black_Jack` class?  A player is not an extension/subset of the Black Jack game.  Why is the `Dealer` class not a subclass of the `Player` class?  are black jacks and non black-jacks resolved differently (this could all be merged and code made much simpler)? 

All of this just really highlights the lack of planning/understanding of objects, and good succinct code writing.  The rest of the code has many further examples of this, too, but I'm not really going to get into it.
https://github.com/pythonGuy/card_games/blob/master/card_game.py

Sorry, this is horrible code.
have you looked at whether your chosen random number generator has enough entropy/randomness to shuffle a 53 card deck. As far as I know the normal default Python library cannot uniquely shuffle a 52 card deck (i.e. cannot possible generate every possible combination - it might not be important, but it might be (only you can tell).
Perhaps a bit off topic but this is a python solitare program:  https://github.com/shlomif/PySolFC
web2py, django, turbogears, pyramid, cubic web
I'd add Moya. (https://moyaproject.com)
Thanks for posting this. I'm always confused about why other languages get so excited about closures, makes me think I should be trying to use them more in Python. 
You could also use a library with even more out of the box, such as easily sending attachments and html. It also has a context manager in case you're wondering. I wrote a post https://kootenpv.github.io/2016-04-24-yagmail. Disclaimer: I wrote both the post and the library :)

Example code: 

    from yagmail import SMTP
    with SMTP("user", "pw") as yag:
        yag.send("someone_else@gmail.com", contents="<h1>big title</h1>", 
                 attachments=["image.png", "audio.wav", "text.txt"])

You can also use the keyring to avoid having to have your username+pw in your script.
How do I attach a file I've built in memory? Say a zipfile of documents that a user had requested? 
It seems that you could save a lot of hassle by spending more time building something in pure Python to input to pandas, than creating the DataFrame step by step. This also makes the code more portable, because you don't start with pandas as a dependency. A generator is perfect in this situation:

    def amortize(start_date, present_value, interest_rate=.04, years=30, additional_payment=0):
        
        annual_payments=12
        periods = range(1, years*annual_payments+1)
        principal = np.ppmt(interest_rate/annual_payments, periods, annual_payments*years, present_value)
        interest = np.ipmt(interest_rate/annual_payments, periods, annual_payments*years, present_value)
        payment = principal[0] + interest[0]
        final_adjustment = 0
        p = 0
        
        while present_value > 0:
            present_value += round(principal[p] + additional_payment, 2)
            final_adjustment = max(-present_value, 0)
            yield OrderedDict([('Month',start_date),
                               ('Period', p+1),
                               ('Payment', payment),
                               ('Principal', principal[p] + final_adjustment),
                               ('Interest', interest[p]),
                               ('Additional_Payment', additional_payment),
                               ('Balance', present_value + final_adjustment)])
            p += 1
            start_date += dateutil.relativedelta(months=1)

The final adjustment needs finessing but shouldn't be too difficult. Also note that `annual_payments` is defined within the generator definition; your code will not work with a number of payments per year other than 12, because `pd.date_range` has input `freq='MS'`; if you entered `payments_year=1` you would end up with 30 months.

You can then easily find the last payment month:

    a = amortize(start_date=dt.date(2016,1,1),
                                    present_value=200000,
                                    additional_payment=-50)
    max([el['Month'] for el in a])

or plot various outcomes:

    additional_payments = [0, 50, 200, 500]
    results = list(map(lambda x: list(amortize(start_date=dt.date(2016,1,1),
                                               present_value=200000,
                                               additional_payment=-x)),
                       additional_payments))
    fig, ax = plt.subplots(1, 1)
    
    for result, payment in zip(results, additional_payments):
        ax.plot([x['Month'] for x in result], [x['Balance'] for x in result], label='Additional Payment = ' + str(payment))
    
    ax.legend()

finally, if you want to do more complex analysis you can get a pandas DataFrame with:

    pd.DataFrame(start_date=dt.date(2016,1,1), present_value=200000)

Because you have used a generator, pandas will keep getting the next output from it until it gets a `StopIteration` error, so you never have to deal with additional rows with zero balance.
Add beancount and enjoy!

http://furius.ca/beancount/
To be curious, why are you doing money math with floats instead of Decimal objects? 

Yes, it's slower, but it's designed to be accurate with discrete values (like money). 
Executable build descriptions are a bad idea IMHO. It's always the same:

* People start to fix their broken project layout in their build files, instead of following conventions. They get lazy and try to be smart, just to not have to type some explicit dependencies. They put way to much logic into something that is supposed to be static. This results in platform or build-system-version dependent builds that break all the time and are impossible to reproduce reliably. The "It's building on my computer" syndrome. 
* It's impossible to parse these files without executing them, which means you have to have yet-another-build-system with the exact version installed in order to reproduce a build or just analyses a source package. Distro package maintainers will *love* you for that.
* If the build system evolves, you cannot automatically migrate old build descriptions because you cannot know what dirty tricks the developer may have put into them. You have to maintain backwards compatibility for all time, or break it and break builds in the process. Which means you have to keep outdated, possibly insecure versions of the build system available if you want to build non-bleeding-edge source packages. Packaging hell, here it comes.

I'm not talking exclusively about Python, its the same in all ecosystems. Some projects get it right (Python wheels, Rust cargo, package.json) but in most other ecosystems that allow Turing complete build descriptions, you see the same problems: Building stuff grows more complicated over time, the build systems get bloated, slow and unmaintainable and you have a new build system every couple of years. Java (ant->maven->gradle), JS (???->webpack->???) and so on.

tl;dr; https://xkcd.com/927/

**Edit:** Some links with more discussions:

* [#6: Discouraging overly complex Pipfile definitions](https://github.com/pypa/pipfile/issues/6)
* [#7: Clarify that a Pipfile is a tool to generate Pipfle.lock, and not a build description on its own.](https://github.com/pypa/pipfile/issues/7)
* [#8: It will be very hard for tools (IDEs) to change dependencies programmically.](https://github.com/pypa/pipfile/issues/8)
* [#9: Risk of outdated Pipfile.lock after editing Pipfile.](https://github.com/pypa/pipfile/issues/9)
* [#10: Executable File Format, Yes or No?](https://github.com/pypa/pipfile/issues/10)

**Edit 2:**
> "I've been sufficiently convinced that the use case for wanting/needing full Python powers is sufficiently weird that it's not worth trying to keep it over [other] benefits. At this point I think it comes down to a Python-esque DSL (really just a restricted subset via AST parsing) or a **static file of some kind**." https://github.com/pypa/pipfile/issues/10#issuecomment-262166543

I'm happy with that. Everything else (YAML/TOML/JSON) is [bike-shedding](https://en.wikipedia.org/wiki/Law_of_triviality). 


It wasn't clear to me initially, but this is an actual project by the developers of pip. This will eventually be baked into pip.

What's scary to me is how little discussion I can find about this. Python language changes are accompanied by proposal documents, filled with rationales, alternatives, etc. People then discuss the proposal and edits are made, until a final version is agreed upon by the core devs, or it's rejected/withdrawn.

Here we have a tiny bit of discussion scattered across some gists and GitHub issues, and then *someone started solidifying it into code*.
what does this do, that `pip-compile` (of https://github.com/nvie/pip-tools) cannot?

`pip-compile` collects and "locks" requirements of requirements incl their versions. does pipfile do that too? in the examples it does not look like it.
I don't like this on the slightest. Seems like fixing something that isnt broken.
Can someone ELI5 what this is about? I don't quite understand what is being discussed.
Oh god. The python web stack folks are on their way to fuck it all up again. Please get some scientific python folks (that actually know about native code and build issues) as founding contributors so you don't shit the bed for the 4th time. 
If it doesn't support installation of dependencies from local files then it sucks just like the current solutions. Why everyone always assumes every package a piece of software depends on is on pypi (or equivalent internet source)? Or did I miss the memo and it is only allowed to do community and open source work in python?
A lock would be nice--it always sucks when a maintainer doesn't follow semver and I have to dig through compiled assets to figure out what changed. Otherwise this smells like a fix for something that simply isn't broken.
Am I missing something or is there just nothing in the repo aside from promises? 
Give me cargo for Python and I'm set. Executable definition is probably a bad idea, but the .lock file is pure gold.
I see a lot of people relying on requires.txt. Why not use install_requires option in setup.py? It seems to have all of benefits this is implementing, and the dependencies are also enforced in wheels created.

requires.txt is IMO only useful when you want to recreate the same setup a developer had, and for that case you do want file to be static.
I've been using [pip-tools](https://github.com/nvie/pip-tools) for a while now and am very satisfied with it.
If this _doesn't_ make the install of local packages better than the mess that pip offers now - then I'm not really interested.
Just what we need, another way of doing the same thing.

why not just use tox?
Great to hear it is maintained again.

One problem I always had with livestreamer was skipping into a Twitch VOD. Twitch itself accepts time offsets in the URL (?t=2h30m) and similar, but livestreamer would just ignore that and run it from the start. Typically I wan't to skip at least 15 minutes in for the stream to start. Does streamlink fix this particular issue?
I heard about [TinyDB](http://tinydb.readthedocs.io/en/latest/intro.html) recently on [TalkPython](https://talkpython.fm/episodes/show/80/tinydb-a-tiny-document-db-written-in-python) as well, but I haven't had an opportunity to use any of these yet.
I'm the mantainer of djondb, happy to help and always open to receive feedback, I've created this for my personal projects, then realized that other people may wanted to have a NoSQL supporting transactions, it will be always free to use. I love python and I've created a couple of projects using the python driver, let me know if you think it's useful and any improvement recommendation is always appreciated. 
Haven't read the readme yet... Does sound data go out to the Internet in some way? Like Google or something? I don't like the thought of knowing that anything I say at home is transmitted to some company or someone else who doesn't belong to my private space. 
How difficult is it to change names / voices? I want a Jarvis for my shop.

Have you gotten it working with Bluetooth headset?

I assume it works just fine on desktop machines? 
In regards to functionality, how does this compare to Amazon's Alexa?
Very quick intro but thats it.

I can also recommend to use css selectors, that will be _much_ faster (as long as you know what you want to select.)

Here is an example:
https://www.crummy.com/software/BeautifulSoup/bs4/doc/
"If you want to search for tags that match two or more CSS classes, you should use a CSS selector:"
css_soup.select("p.strikeout.body")

I have done some quick n dirty performance test for my rpi scraper where it became obvious that "findall" etc will make you iterate a lot and that consumes CPU. lxml xpath and bs4 css selector is much faster.
Wouldn't it be better to use requests instead of urllib?
Hey, I've actually used this! A pain to get setup but very useful. 
For the example of a title tag, .string would be more appropriate than .text. The text property concatenates all child strings together, which loses node information and could be more resource intensive. The string property recursively finds the first child string node if all children are only children.
Authentication and authorization should be two different services. You might want to check permissions for a user that is not logged in, for example (think about background tasks that work on behalf of a user). 
We're currently thinking through some of these same things. :-) We've decided (for now?) to have a service that only handles authentication. It then issues a token (jwt) which allows any of our other services to identify the authenticated user (i.e. the verified token proves that this is the user 'Bob').

Each other service would then be responsible for determining the authorization/permissions of that particular user for itself (i.e. is the user 'Bob' allowed to modify this data?). I recall that this lines up with much of what I read on the subject - though I have no links at hand to support my thinking.

One idea we are kicking around is having the authentication service also roll group membership information into the returned token, which some services may use in their process for determining authorization (i.e. this is the user 'Bob', and he is in the group 'Administrators'). Currently, our authentication service queries our Active Directory, so this idea feels pretty natural.

Granted, we're still in the early phases of considering this architecture shift at my organization, so I am also curious to see what some more seasoned members respond with.
Had a similar dilemma recently, wound up with an authentication service and a separate permissions service. It's a bit of a bear to deal with at times, but worth it in the long run. Most of our other services use the permissions service but don't care about the authentication service, so its logical for them to be separate services.
python is case sensitive. use 'bs.BeautifulSoup' instead of 'bs.beautifulsoup'.
You should *really* provide criteria for what you want if you're going to be excluding all of the most common methods because you want/need something else.  Why is `pip freeze` or `>>>help("modules")` insufficient?

If you want to recreate what `pip` does, review [its source code](https://github.com/pypa/pip/tree/master/pip) and recreate that functionality yourself with tools that fit your requirements.
``pip freeze`` shows all the installed packages.
Not sure what I'm seeing but it's pretty neat
Hahaï¼Let me explain you the story behind this gif image.

This image is generated by a python script, no third-party lib/software, nor PIL/tkinter-like graphics modules, just pure python, there is no drawing command in it!

This image shows you how Wilson's algorithm works on a 2d grid, so to understand this image, you must understand this algo first.

Consider the following problem: given a finite, connected graph G, G might have many spanning trees, how can we choose one from them with uniform probability?

Wilson algo says:
1. Choose any vertex v, and maintain a tree T. initially T = {v}.
2. For any vertex w with w not in T, start a loop erased random walk from w,
until the walk hits T, then add the result path to T.
3. Repeat step 2 until all vertices are in T, then the final T will be we want.
This algorithm is short in words, but quite tricky to prove, and the proof in Wilson's original paper would take one more than a few days to understand and even more time to absorb it. 

But it's not that hard to implement into code, The first animation  I saw was [Mike Bostock's  awesome Js animation](http://bl.ocks.org/mbostock/11357811) , which inspired me to make my own animation of Wilson algorithm, but with Python ! 

Python has its graphics modules like pygame/pyglet/tkinter, and there is no doubt that one can use these libs to make his animation, but what I want is a gif version. The first thought was to implement it in pyglet/pygame, and then save many frames into .png images, and then convert them into a gif file. But this way is very very inefficient:

+ For a reasonable size (150x120 cells) the animation would contains several thousands of frames, saving so many frames into image files in disk and read them back would be a horrible task.

+ I'm not sure if other gif tools can be smart enough to see there are only 4 colors in the animation and set the minimal code length to 3. I have seen many implementations use 8-bit length as default.

So I hacked into the gif coding standard "GIF89a", and manually encoded each frame into byte streams with LZW encoding by recording each frame's window size, this approach is comparably succinct and fast. For a 1000x800 version, I got 7600+frames but only 2M file size!

The code is on my [github repo](https://github.com/neozhaoliang/pywonderland), it's not commented yet and not very clean -- I have just finished it just this afternoon, but it will be cleaner soon.

Hope you like it , and don't forget star the repo!

BTW: currently the code only works for python2.7, not python3  ... I'll look back to the code later ...
/r/titlegore ?
Very similar to [Maze](https://www.youtube.com/watch?v=-u4neMXIRA8), from xscreensaver.
This is infuriating to watch.
All i can hear in my head is "NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE NOPE **YEAH**"
I'd like to see the code of this if its up anywhere?
Cool stuff, OP. Nice job riding the GIF format bareback. :-)

For people who want to read Wilson's paper: [[ref]](https://www.cs.cmu.edu/~15859n/RelatedWork/RandomTrees-Wilson.pdf). That was 20+ years ago and it was a big deal. Still is. I think Wilson is a Microsoft researcher now.

BTW, OP, I think you have a broken anchor on your GitHub page: `#wilsn-algorithm-animation`, missing the `o`.
This algo seems very inefficient given the amount of times it just retries each path over and over and over.
 
That's pretty cool!

I honestly thought this was in /r/phish for a moment! :) 
I assume this is inspired by [Mike Bostock's version](https://bl.ocks.org/mbostock/11357811) from [Visualising Algorithms#wilsons](https://bost.ocks.org/mike/algorithms/#wilsons).
I'm not your guy, buddy!
You should post this in /r/WoahGifs
a-MAZE-ing....I'll see myself out
These snakes are drunk 
indecisive sneks
First he saves Tom Hanks from going crazy on that island and now this. Wilson FTW!
Haha that's fucking cool man. I dig it
That is beautiful code at work.
At first it looked like a hyper-active uni-light-cycle. ;)
The final image is mostly covered by 6 connected pieces.  Might be a math paper in this interesting feature for somebody.
  
https://app.box.com/s/isfg4mf3hstipz8rizztp1zd911rgz2x

Fuck this blue line. 
So which was the correct way?
http://i.imgur.com/0XCHE8L.jpg
Wilson's algo or Window's Pipes screen saver?
Don't drink and drive your light cycle.
What is it ?  
  
Path finding ? Maze generator ? 

Looks neat
Ah, the endless search for the pink
[VTK](http://www.vtk.org/) or [ParaView](http://www.paraview.org/)
[PyWavefront](https://github.com/greenmoss/PyWavefront) + Pyglet to actually view it.
VTK isn't going to do it without work setting it up.  I'd punt you my GUI, but again setup time.  Just use Paraview; it's made by the people that make VTK.
    from requests import get
    from json import loads

    response = get('http://api.forismatic.com/api/1.0/?method=getQuote&format=json&lang=en')
    print('{quoteText} - {quoteAuthor}'.format(**loads(response.text)))
Nice! 

I wrote a quick Flask example app last week where you can call Scrapy programmatically, within a view handler function -> https://github.com/mjhea0/flask-scrapy-test. Just an example. Should not be used in production.
This is something I've done myself, and it worked out well for me. 

Some notes though:

1) Don't raise SystemExit. If you absolutely *must* exit the program, call sys.exit(). Otherwise, give the API's user a chance to handle the exception in a sane way.

It's trivial to define a new exception, and if it's not handled, it will just bubble up and exit the program anyway, with a stack trace attached.

    class NotLoggedInException(Exception):
        pass

2) You probably shouldn't hang on to a password longer than you have to. Also, getting a password from the user doesn't mean it's accepted by the system. You should get a nonce or session id, or something like that. If you have one, then you can consider the user to be authenticated.

3) Return the value from func on line 8.
It's a fine way to do it, but you probably want to send a 501 forbidden response rather than crash your program.
I wrote a similar program a couple years ago. It didn't have the stipulation that there should be no pairs, but it did make sure that people from one group didn't match with people in another group. 

I'm pretty sure this is actually an NP-hard problem (someone correct me if I'm wrong), but my solution worked well for me. I was doing this with a rather small group, so what I would do is I would come up with a randomized matching and see if it passed all of my rules. If it failed for some reason, I'd reshuffle and try again. If it passed all of my rules, I used it as a solution. This may not be efficient or elegant, but if you have a smallish group, it should work just fine. 

Don't underestimate the power of brute forcing, and don't prematurely optimize. Even if your naive solution takes an hour of runtime, it's still faster than an instant-time solution algorithm if it takes you an hour to write the fancy code. :) 
This sounds like an optimization/constraint fitting problem. 

It sounds like your problem is compatible with something called partial solutions, meaning you can have some of a solution and check if just that is valid.

You might want to look into a guess and check with backtracking solution. Backtracking is often implemented recursively.  The basic idea is that you are intelligently checking every possible solution, building partial solutions as you go along. The difference being that instead of true brute force you simply never pursue a partial solution as soon as any part of it fails one of your constraints.

I know all this sounds a bit abstract. The Wikipedia article gives a good background and should give you a general idea for an approach it you want to try backtracking: https://en.wikipedia.org/wiki/Backtracking?wprov=sfla1
I'd roll with brute force. Randomize the pairings, check if the outcome matches your criteria, loop until things match.

If that doesn't perform, I'd go "genetic", that is, start with a randomized solution attempt, find rule violations, and fix them with random swaps (take one person from an offending pair, and swap them for a random person from another pair), then after each swap, check if the situation is now better or worse, use that to weigh a coin toss on whether you should roll back or not. Repeat until solved, re-randomize after too many iterations to avoid getting stuck.

And finally, you could use Dijkstra's Algorithm to perform a best-first tree search: randomize, add all possible swaps to your list, keep searching into the current-best branch, cull branches that run in circles. Lowest number of violations is your scoring metric.

You could, in fact,even apply A-Star, using "number of violations" as the heuristic (assuming that every violation takes at least one swap to fix, however it is possible for a swap to solve two or even three violations, so you may have to divide your score by 2 or 3).
Most fun will be if you make it into one big cycle: A â B â C â D â E â F â â¦ â Z â A. If so, your first requirement is automatically satisfied (unless you only have two people), and your second requirement just says that people next to each other in the cycle need to be from different departments.

I'd start from an approach like:

1. pick the department with the most people, and spread them evenly over the cycle (e.g. if you have 100 people and the biggest department has 10 people, put them at 0th, 10th, 20th, â¦ 90th position).
2. if there are still departments to place, go to 1.

Unless the biggest department is more than half of the all people (and in this case, no solution is possible, I think), this should work.
Sorry if I misunderstood the problem, but can't you just do the following:

1) Shuffle every department list

2) Pull the names from the shuffled lists in a round-robin fashion into a list and use that list as pairings?

For example, if you 3 shuffled department lists A, B, C, you can just do this:

A1 -> B1 -> C1 -> A2 -> B2 -> C2 -> ... -> An -> Bn -> Cn -> A1
This was excellent and timely for me personally.  Thank you for writing this.
Props for resisting the temptation of trying to roll your own CSV parser.
What are the main benefits compared to the standard library csv module?
This will likely be an unpopular opinion, but I really dislike this. Auto-generated API docs lead to people not writing actual documentation (prose), something I've noticed especially in golang (and to some degree in the JS world), where there's barely any prose documentation. So everything is "documented" in a sense that it tells you what the function names etc are, but nothing tells you *why* you should use a certain function or how the whole thing fits together.

I'm a huge fan of readthedocs, because it made writing documentation a lot easier and taking away some of the excuses we make up for ourselves not to write docs, pydoc.io is a step backwards in that now you have an excuse that you've already "documented" your library because it's on pydoc.io.

Hopefully I'll be proven wrong and people will only use this on top of RTD...
Very cool. I'm interested in how well this works out in terms of quality and how many projects actually use docstrings on PyPi. Edit: At a glance(finally got on). These docs remind me of the times when I would have to read auto-generated documentation from poorly documented Java APIs but worse because there are no types. I think for some of these libraries I'd rather just read the source code than a function statement with no docstring.

By the way, Chrome is blocking the fonts readthedocs is trying to load from media.readthedocs.com because the blog.readthedocs.com is over HTTPS but the fonts are being requested over HTTP.

The link to https://pydoc.io doesn't resolve properly. Going to http://pydoc.io redirects to https://pydoc.io and properly renders the page however.
Even though the guy "doesn't see much need for new Python code", my opinion is that he should just start a new project in Python 3 (be it a personal project or not). Because the only real way to get used to a technology is to actively use it.
One of the most useless articles I've read in years.
Looks nice! I wish I had know about this last week before writing https://github.com/tomaugspurger/skmca :D
Sweet. I've been looking for a package in Python to do factor analysis for some of the surveys I'm analyzing at work. 
No ethical scientist should touch this data.
Flawed data == flawed analysis.
r/mildlyinteresting 
I find py2exe etc a massive pain:


I'd recommend writing this using JavaScript (JS single page app) and hosting it on your company website. Everyone has a browser and those that don't have access to The Internet can be directed to save the page as an archive file
In point for you say "other app in Windows". Are you saying you are making a client application for your piece of hardware that needs to work in Windows.

Would it be an option for your device to provide a web interface that you could implement in Python?
Windows applications are usually distributed as an installer, not a standalone app executable. Make an installer that includes a private embedded copy of Python and required dependencies. You do not have to wrap it into a single executable with py2exe.

The shortcut will start the application using the included pythonw.exe to avoid opening a console window. The user need not know or care if the application is written in Python (unless they are in the habit of digging into the application directory). 


https://google.github.io/styleguide/pyguide.html?showone=Deprecated_Language_Features#Deprecated_Language_Features map/filter is not recommended
I'm not sure that

    from itertools import accumulate
    a = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
    results = list(accumulate(a, max))

is more readable than

    a = [3, 4, 6, 2, 1, 9, 0, 7, 5, 8]
    result = [a[0]]
    for item in a[1:]:
        result.append(max(item, result[-1]))

I'm looking for feedback, feature requests, example use cases, or general comments on my new pypi package: [gzint](https://pypi.python.org/pypi/gzint/)!

Feel free to comment here, or submit [issues/pull-requests](https://github.com/pirate/gzint) on github.
Do you have any examples of the type of data you've used this on?

And if you're just comparing, why not just doing hashes and throw away the number?
Interesting idea.
> normal_int = 10**1000000        # huge, but compressable (lots of 0's)

Lots of zeros? Are you storing integers in decimal format? Why?
Details? Code? Wanna check out.
I'd love to see the source code, I've been wanting to make something similar for bass practice but I'm pretty new to coding. 
[deleted]
Commenting for posterity 
Check out [bokeh](http://bokeh.pydata.org/en/latest/).
I've used bokeh and [plotly](https://plot.ly/python/getting-started/). Plotly's plots have much better interactivity. 
Not related to Python,  but you should look into R shiny and R markdown.  Great for data visualization and you can set up your own sever on Ubuntu
There are a couple web dashboard frameworks: [spyre](https://github.com/adamhajari/spyre/blob/master/README.md) and [pyxley](https://github.com/stitchfix/pyxley/blob/master/README.md) and a newer viz library called [altair](https://github.com/altair-viz/altair)
Take a look at the Jupyter Incubator projects, specifically Dashboards and Declarative Widgets.  It's incredibly easy to use these to make simple data-driven single page web apps directly from a Jupyter notebook.   They also have preconfigured docker containers that you can use to deploy.

https://github.com/jupyter-incubator
plotly, just use .iplot instea of .plot after installing their stuff and all the magic is done for you.
I recommend bokeh. Plotly is also nice (and has a flask based server option called dash). It's also fairly easy to save matplotlib png's and server them. A while back I base 64 encoded matplotlib charts and sent those out. Quick and dirty.
Don't bother with Bokeh, use the jupyter notebook included in the anaconda distribution and then it will directly render it to HTML.
I use Pygal because it generates really nice looking interactive .svg files. You can insert those into a webpage using a template engine like Jinja2.
FWIW, [Altair](https://altair-viz.github.io/) is based on [Vega Lite](http://vega.github.io/vega-lite/), which was designed to provide an holistic [Grammar of Interactive Graphics](http://idl.cs.washington.edu/papers/vega-lite/). 
Please, immediately switch the name away from `f`. It has already been taken, but much more importantly: people use `f` as the name of a file handler all the time! And also, `f` does not describe something related to logging at all, I would then prefer `l`. And actually, 1 letter imports are not pythonic at all.
How is this better than just redirecting `python foo.py >tmp.log`? For anything more than that Python provides a logging framework.
It's pretty simple and straight forward, you don't need to learn anything, just add a line of code when you need it, and comment it out or remove it when you don't.

Issues and prs are welcome.
This reminds me of redir_stdio as refered to by ray hettinger.


If you're running the program with Python 3 (or Eric is) you'll need to install the versions such as `python3-numpy`.  The `apt-get` command you listed installs the Python 2 versions.
Regarding the problem at hand, it can be reduced to three lines of python:

    import numpy as np
    sample = np.random.uniform(-3, 6, (100, 225))
    mean = sample.mean(1)

The second line will generate a 100x225 element matrix of random numbers, while the third line will calculate the mean over  the second ~~dimension~~ axis of the sample matrix.
Make sure that your IDE is picking up the same version of python that the apt-get installed all those packages in.

Or skip the IDE entirely. Use a text editor. And install the python packages using pip instead of apt-get. This is the path of least confusion, although if you are used to using IDEs, you may not like it.
Pycharm is the best IDE for python imo, just a suggestion :)
You have to install numpy via pip
I'm going to quote an old Nike ad and say Just Do It - try it for yourself. BS is trivial to install, likely faster than waiting for Reddit answers to such a niche question. 

Note you obviously won't get the lxml backend.
When I evaluated python static site generators last year, **Pelican** was the only actively maintained one that didn't more or less force a blog-style site structure on either the source files or the output files. (Getting the bloggy stuff out of the way required a good understanding of the available config settings, but once configured, it worked pretty nicely.) For this, it gets my +1.

Nikola was one of my contenders, but it didn't work well for non-blog sites. 

I haven't tried Lektor. I guess I'll have to take a look.

See also:
https://www.staticgen.com/
Wow, I have never seen any of these before. Can I ask what is the advantage for using one of these, over Flask/Django?

How much of a competitor to WordPress is it?
sphinx
I built a static page with Jekyll recently. Surprised I haven't seen it mentioned. Is it outdated or something? I'm not an expert but it seems active and like a nice framework. Plus GitHub pages has built in support for Jekyll if you host there
I'm not super-qualified to talk deeply on this topic, but I think it's worth noting that Lektor is a project by Armin Ronacher, the author of Flask, Jinja, Wekzeug, Twig, and more - and he's a pretty respectable programmer IMO.

And so what I've seen of Lektor is pretty cool, but I don't have even a single static site in production, so take my thoughts with that grain of salt. Looking forward to using it though, when the opportunity arises.
Statik: https://github.com/thanethomson/statik/ makes it easy to build content from yaml/json models, which are transformed into sqlalchemy and are thus queriable.
I use Pelican.. and I really like it.
Hyde.
Its basically Jekyll but written in python.
Hugo :S sorry, became a fan. 
 Nikola. Developers behind that care a lot. 
Any example of sites generated with these? Specifically interested in pelican. 
Statik is really cool, it focus beyond static blogs:

https://getstatik.com/
Nikola.
Grav all the way.
Pelican all day every day.
I use this method: https://nicolas.perriault.net/code/2012/dead-easy-yet-powerful-static-website-generator-with-flask/

Converted from jekyll to this in an hour or two. I set up a git hook in my VPS which builds automatically and publishes on git push as well. 
One of the unsung benefits of a static site is that you can't hack the content.  Sure you can still attack the site or hosting, but you don't have to patch your CMS.
I built [athena](http://github.com/apas/athena). I like it and I think you should use it, too.
It's unfair that the poll is on twitter, because I don't have an account.

&nbsp;

My vote goes to Nikola.

&nbsp;

Nikola for the win!
I have a related question. For those of you running static blogs, do you just use a 3rd party comment system such as Disqus?
I like Maching Learning, and prefer Pelican with ipynb plugin.
You can try [GraphDash](https://amadeusitgroup.github.io/GraphDash) if you are looking for something more picture-oriented.
Dvidsilva/Gloria 
[I like Visual Studio Code](https://www.reddit.com/r/Python/comments/5dgah4/vs_code_vs_pycharm_community/da539cf/) (it works on windows/osx/linux).

PyCharm is a nice IDE, but it is the exact opposite of lightweight!
sublime or vim, but in both you gonna need setup plugins
You might want to try out http://thonny.cs.ut.ee/
I recommend Spyder https://github.com/spyder-ide/spyder because of numpy and pandas
Winpython (https://winpython.github.io/) has all, numpy, scipy, pandas, jupyter, spyder (light IDE); if running Windows are the best option.

Spyder still work in Linux and Mac.


This is a bit out there but you could use jupyter notebook?
why not use pydev?based on Eclipse.not very light,but much better than pycharm.
From the looks of the answers here there seems to be a lot of suggestions that *aren't* IDEs but are text editors.

Vim is great, but it's just a command line text editor.

Sublime Text / Atom are fancy text editors, but that's what they are.

PyCharm / Spyder / Visual Studio Core are IDEs but as many people mentioned they use more resources, because that's needed to *be* an IDE instead of just a text editor.


Have you checked out [Rodeo](https://www.yhat.com/products/rodeo)?  Its pretty lightweight and runs on windows/osx/linux.  Its also gotten a lot stabler recently
I like [PyCharm](https://www.jetbrains.com/pycharm/). Especially with the linter enabled for both 2.7/3.5.
this is not an easy solution, but consider it. 

if not already, put arch linux on your system. they have an amazing user community and wiki support.  arch is fast and lightweight compared to bloated systems like windows or resource intensive ones like macos. 

second, let the unix environment be your ide, it can do all the things other ides can, and it's very efficient and powerful. 

for an editor, try vim, there are lots of plugins available for python including autocomplete and syntax highlighting and linting. if you're comfortable in the shell, vim will be natural because it's already there! 

last, if you can live without graphics your system resource utilization will be greatly reduced by not starting desktop environment. 
If you're stuck with shared hosting, PHP is the way to go IMHO. Why?

Well the reason is what you've already said. Python scripts (or any other executable) takes time load up and start. With CGI, the server has to load your Python script plus the interpreter for every request.

Python is usually deployed UWSGI, which solves this problem by only loading your Python script/module once and serving all requests from the same instance.

PHP is a good choice for shared hosting because Apache has a module for PHP with is almost similar to uwsgi. Almost all shared hosting providers have it setup. Load once and then use the same resources to serve every request.
Your site doesn't already use a back end scripting language?
Regardless what language, don't use cgi when performance is a concern. Use a dedicated process spawned with something like fastCGI or uWSGI that can keep your code in memory.
/r/webdev
Huh
No, I type `:wq<up arrow><up arrow><enter>`.
Nah, I generally Alt+Tab, up, enter.
I use idle so I just save my code and it runs.  I love f5
Nice project - even though it sounds a lot like what [trakt.tv](http://trakt.tv/) is doing for several years now ;)
I've kept a record of every movie I've seen, when and where since January 1st of 2014. You can find *that* list in YAML format [here](http://pastebin.com/y3RxuVvG).

I've been waiting to do something with that for a while. My high school's hackathon gave me the opportunity to both do that *and* finally learn Flask. Because nothing like a twelve-hour rush to try and win cash in order to learn things, right?

Didn't win the hackathon, but I like to think it was a nice learning experience. I apologize for the rough shape it's in; commenting was days after to save time during the event. As well, it's far from feature complete, since I had to prioritize main features for judging.

The hashing system was a clever way on my part to dodge around learning oauth2 on the fly, since making my own user registration system would've taken up too much time. Probably get replaced by an actual user system for release.

I hope you guys find it interesting; I'm excited to finally push a real project instead of just a [wrapper for an API](https://github.com/JacobLandau/pykcd). Even if that API is for a pretty great comic. Please give me feedback; I like the opportunity to work on things.
This code doesn't display anything. Nor, as far as I can tell, have you said what's displayed. You'll probably be given a link to /r/learnpython but I don't think that'll help. Unless you've missed copying something significant, I suspect your assumption "This code displays it" is wrong, and your question has nothing to do with this snippet of python. What are you asking?
One important point is that free jupyter notebooks are hosted in Linux on Azure, probably because jupyterhub does not run on Windows. This is a pain point for me.
is there no pandas integration? seems a bit weak without
I would consider PySide or PyQt. Both are python implentations of Qt. Qt has got Qt designer, which is a WYSIYG user interface in which you can click and draw your GUI. Good luck!
I wrote a [blog post](http://takluyver.github.io/posts/so-you-want-to-write-a-desktop-app-in-python.html) about the options. It's a couple of years old, but the landscape hasn't changed much.
TkInter. Its bundled with python already so you avoid the mess you will have trying to gett pyinstaller to accept any dependency on Qt. It looks a little dated but not much. And also no stupid gui designer only pure code.
you could head over to [CodeTriage](https://www.codetriage.com/?language=Python). They list a lot of open source projects you can participate in.
Maybe we can start something together!

I do a simple dictionary [dictio](github.com/bbuccianti/cliâdictionary) recently.

Do you have any idea for a new project?

What do you like to do? Something that you actually are going to use.
Honestly, I'd recommend either going through the trending page on Github for a specific language and see how if there's anything you can do for a project that interests you or start making your own projects
paramiko.SSHCLient should be paramiko.SSHClient


Please post your code.
Python is case-sensitive.
Is it better than Google's own [Takeout](https://takeout.google.com/settings/takeout)?
Is this better than, say, using IMAP to backup and/or transfer between accounts?

I use gmail apps on my own domain (grandfathered into being free) and that is how I transferred my emails. It worked pretty well, though kind of slow.
What's up with these dll files in etc/libs/win/Microsoft.VC90.CRT/ and how do they work with your repo being GNU AGPL 3.0 licensed? 
Just used this last week. Great app!
Is there something similar for contacts? 
great piece of software - I struggled for couple of hours trying to restore imapsynced data back to Gmail, with this tool it was a matter of minutes 
I don't know too much about datetime objects so your article was enlightening.

It raises a question in regards to datetime object. Why python's datetime isn't it time zone aware by default, and why, when using a timezone, makes things even more complex?

Local timezone should be available on a server (/etc/localtime), so why python isn't it using it?
I really liked this a lot. This library is frequently criticized as being confusing and unfriendly, but your guide makes it quite clear.

There are a lot of alternative libraries that get discussed in these parts, such as Arrow, that attempt to make working with datetimes more intuitive. Perhaps looking into those past discussions can help to illuminate what it is that people find so confusing. 

That said, I think you really knocked it out of the park with this recommendation:

>When dealing with datetime objects, I've come across two pieces of advice with which I generally agree. First, always use "aware" datetime objects. And second, always work in UTC and do timezone conversion as a last step.

Offhand, it is difficult to imagine having too many problems working with datetimes as long as you adhere to that advice.

Everyone is happy if they get even a glimpse of sense about what the hell the datetime module is about. 
Good article. A couple of points. 

You mention offsets a few times. An offset is not the same as a time zone. A time zone maps to a particular offset at a particular time, but that mapping can and does change. That is, timezones can alternate between day light savings and not. But governments can also change when they transition is, cancel it, or make the offset 30mins instead of 1 hour. 

Some apps like to work with offsets rather than time zones. Don't do this. 

You don't mention storing datetimes. Usually you should store utc and convert on display. But for things like appointments you want to store in the users timezone because, as mentioned above, offsets mapped to a timezone can change. 

If I set an appointment for 10am and you store that in UTC. The government changes the offset from +10 to +11 for that date. Now I'm an hour late. 

Time zones are tricky. 
> A datetime object is an instance of the datetime.datetime class that represents a single point in time.

As you explain in the rest of the article, by default datetimes are naive, which precisely means that they don't carry enough information to represent a single point in time.
Great article, but two points I want to bring up.

You said you do either:

    
    import datetime

or

    from datetime import datetime
    #I would actually do:
    from datetime import datetime as dt
    #Saves you time when you continue to use the module

Anyway,  these two are not the same actually. The from datetime import datetime line is actually making a reference to the class, while import datetime is a reference to the module. This has been known to cause some AttributeErrors with method descriptors and module objects.

Second, I really like the datetime objects, but it's caused too many issues on the simplest of things. Here's an example of a simple problem I had with the datetime module. I'm hoping they make it better in the future, but I'm not sure they'll be able to:

    def thirdProblem():
        from datetime import datetime, timedelta, time, date
        timeInput = input("What time are you leaving your house to run?")
        newTime = timeInput.split(":")
        newTime = [int(i) for i in newTime]
        timeLeftHouse = datetime.combine(datetime.date.today(), datetime.fromtimestap(time.time(hour = newTime[0], minute = newTime[1])))


**EDIT:** Lots of formatting

If it's not normalized, it'll effectively brighten or darken the image as well.
BTW, it might save you typing: `blur_filter = np.ones((3, 3)) / 9`
It works perfectly fine for me. (3.5.2 and VS 2015 Update 3) You should submit an issues on their github page if you think this is a bug. https://github.com/Microsoft/PTVS/issues

Good luck!
I've been using Python 3.5.x with Visual Studio for about as long as both have been out. There shouldn't be an issue with compatibility. What is more likely is that you have another version of Python (eg Python 2) installed, and it is causing these issues. If you could post an example of code that does/does not work, that would be appreciated. Also, try running `py -2` and `py -3`.
I think the `Generate sequences` one is missing a `from`, but other than that I admit I've been a 2.7er forever and this dope generator cheat sheet has opened my eyes
If you decide to call a variable '_' you are supposed to not use it

http://stackoverflow.com/questions/5893163/what-is-the-purpose-of-the-single-underscore-variable-in-python
Maybe add unpacking of generators in list literals and tuple assignments as well? For example:

    >>> g1 = (n for n in range(3))
    >>> g2 = (n**2 for n in range(3))
    >>> [10, *g1, 12, *g2]
    [10, 0, 1, 2, 12, 0, 1, 4]
    
    >>> g = (n for n in range(3))
    >>> a, b, c = g1
    >>> print(a, b, c)
    0 1 2
Very nice reference. Thank you .

Maybe you can add links to relevant docs.

Also, you have a typo. Explanation, not explation :)
Excellent project, thanks for sharing. I was thinking it would be nice to have cliff notes, or a cheat sheet for the whole of Python 3.6. I've been meaning to get into Async IO for awhile.
It annoys the fuck out of me when people write their code like this.

    if n>0:
        pass

You ***must*** put spaces!

    if n > 0:
        pass

It's even more infuriating when they're not consistent and do a mix of both in their code.

    rant.end()
This is great.
So this uses threads wtf?

The factorial function can be computed via [tail recursion optimisation](https://en.wikipedia.org/wiki/Tail_call#Example_programs). Its inherently no parallelisable.
But... Why? Why all of this?

Firstly, what's wrong with this:

    factorial = 1
    for i in range(1, number):
        factorial *= i

Secondly, why would you do this in a thread? You don't totally free up the rest of the program to keep running, you're just fighting with it for CPU time.

Also, the code on your blog isn't even formatted as Python...
/r/dailyprogrammer and /r/roguelikedev. Make stuff you care about or need or want, and don't worry about following a path. I realize that is really pithy and unhelpful, but it's the best method.

For example, when I started to learn Python, I decided to try my hand at making a chess program. So I killed myself over a really shitty chess program for a couple months. And then I decided to try my hand at implementing Chess 2, a variant by David Sirlin. So I found someone else's open source chess program, and hacked at it until I got something close to "workable." Then I went back and tried again with sunfish.

At each stage I learned something drastic about my own abilities and about how Python worked under the hood. All driven by a stupid feeling of, "This should be easy. Why is this so hard?!" and the dogged determination to have a finished product.

Play around until you find the same, and you'll learn Python soon enough.

Also, don't learn Python 2. Look to the future!
If you are on a desktop, please read the sidebar.
Thanks NoahTheDuke for the pointers, much appreciated! Annnnnnnnnd thanks to edimaudo for pointing out my lack of observation, haha.

I don't visit reddit often, and am very accustomed to assuming all content in the sidebar of webpages is purely shitty ads, and didn't bother to pay the side bar any attention.

I think I have all I need, thanks again!
Please add to the sidebar: www.codewars.com

Btw: great place to find exercises!
I'm going through the ThinkPython book right now, along with Project Euler. Highly recommend both. Afterwards, I might do some OpenCV stuff with it
Pyglet is not dead, it's development community is small and right now they are mostly bug fixing. It's still a great platform though I do recommend using cocos2d with it
Kivy and specifically KivEnt for games. 

Also, Pyglet is not dead in my opinion. Work is still being done in the development branch as far as I know. 

Cocos2d is alright and you can always drop down to the Pyglet level in it if you need finer control of the rendering. 

Finally, I hope that there will eventually be a Vulkan equivalent to Pyglet.
What do people think about panda3d?  http://www.panda3d.org/
Just use PySDL2. Honestly, the actual graphics part of a game is usually 10% of the code anyway and should be abstracted away so your logic isn't dependand on one particular renderer. Once you have that up and running you soon find your other 90% of your game has nothing to do with drawing.
Pyglet contributor here. It's definitely not dead, and is currently seeing bugfixes and cleanups after a merge to a dual Python2/3 compatible codebase. The audio backends (Pulse, DirectSound, OpenAL) are undergoing a major rewrite. I'm personally working on an SDL2-style GameController API for pyglet (please get in touch if you want to help testing). 

Long winded rant incoming: 
After using PyGame, PySDL2 for several years, I finally gave pyglet a try. I wish I did sooner, because I think it's the best of the bunch. There are several reasons why I think pyglet is awesome, and why I'm interested in making sure it has a bright future: 

* 1. Pyglet is pure Python, with no external dependencies (Avbin is optional). Standard Python library only - no extra installs or modules necessary. It does make heavy use of ctypes for OpenGL/etc. bindings and internal low level data structures, but the codebase is perfectly readable and fixable by Python developers. This means YOU can contribute to pyglet, and make it great. Even if you're not familiare with ctypes, the codebase is very readable and, I think, well organized. 
* 2. Pyglet is very Pythonic. Unlike libraries such as PySDL2, you don't need to write C-ish code, or learn another language to write a game in pyglet. In particular, using the rendering, input, and audio code in PySDL2 (and even Pygame) feels really funky as it's a different style. 
* 3. Pyglet has a lot of easy to use classes for audio, sprites, text, and input. However, the full power of OpenGL is right there if you want to use it. You don't need to set up any special contexts or use an additional OpenGL library - you just use it if you want to. If you don't want to go full OpenGL, but still want something lower level than the high level Sprite/Image classes, there is a awesome "graphics" module that has support for drawing lots of different primitives efficiently. 
Godot engine is a free, open-source, unity like game engine that uses a Python dialect as it's main programming language.

It's the most advanced game engine for python. 
Has anybody heard of the Python Arcade Library? Seems to be small but promising: http://pythonhosted.org/arcade/


Kivy with KivEnt is about as good as it gets right now.  And it's not... great...

Pyglet isn't dead.  It's just in maintenance mode.  It's really a tool for making game frameworks, and not a game framework itself.  Like Cocos2d.

Pygame isn't only not pythonic, it's also completely dead.  The website is unmaintained.  Visiting the documentation pages is as likely to deliver an attempted exploit of a browser vulnerability than the info you're looking for.

I've given up on Python for game development.  The Python community seems to have largely abandoned the idea, with a few struggling exceptions.
I think there's room here for a new library.  If I had my pick at a completely new project:

   * Use cffi so pypy is a viable option
   * Use GLFW (and opengl) for graphics
   * Use Bullet for physics
   * Use Enet for networking
   * Sound (?) SDL (?) -- I'd really rather avoid any SDL2 at this point.

Just connecting those pieces alone is difficult to do well.  But then building a great pythonic library on top would be fantastic.
damn, I have always thought that with a decent documentation and actual real examples pyglet could be a good library.
There is [PySFML](http://python-sfml.org/) - Python bindings to SFML. It's pretty pythonic and should be fast, since it written in Cython, but unfortunately, it seems abandoned.
PySDL maybe?
pygame is active on bitbucket, the website is outdated tho.
Don't make games in python. It's the wrong tool for the job.

:(
C++.

Game dev on Python has always, and likely will always be, terrible.
If you start a big new project at this time you should either just use Python 3, or write code that works in both versions and run tests on both.

Neither solution is terribly hard.

numpy is available for both Python 2 and 3.
Python 3 for everything. The more you use it, the more libraries get ported.
Unless there is a very specific and compelling reason to use Python 2, use Python 3. There were some painful updates in the earlier versions of 3, but more recent updates have had far fewer breaking changes while adding lots of powerful new capabilities you might want to be able to take advantage of in the future.
> So I'll be starting a year long project next semester using python. While discussing python with my supervisor, he expressed concerns regarding how fast python is growing and thus wanted to make sure I knew how to get around my code breaking simply because I update python.

That is very much bullshit. Python is mature, with billion-dollar businesses relying on it; it is absolutely impossible for breaking changes to be introduced overnight without a really good migration plan to go with it. Python 3 introduced a truckload of breaking changes, by design, which is why Python 2 is still a thing 8 years later. However, code written for Python 3.0 will almost certainly still work on 3.4 and any future 3.x versions, and code written against 2.0 is extremely unlikely to break on 2.7 and onward. In short, this is an absolute non-concern. I would, however, strongly recommend Python 3 for new projects, unless you absolutely must use some library that absolutely can't be made to work with Python 3.

Libraries are a slightly bigger concerns, but the tooling around Python's library ecosystem (most notably, PyPI and `pip`) is good enough to handle this flawlessly.

That said, I highly recommend `virtualenv`, a very simple tool to "sandbox" your Python projects, such that you can install Python interpreters and libraries on a per-project basis. Quick rundown:

- In your project directory, create a virtualenv: `virtualenv venv`
- Activate the virtualenv: `source./venv/bin/activate`. Until you call `deactivate`, the `python` and `pip` binaries will now do all their work inside the virtualenv.
- Use `pip install` to install libraries
- Once you have all the dependencies you need, do `pip freeze > requirements.txt`; this dumps a list of currently installed libraries into a `requirements.txt` file, which you can later use to install the exact same versions again (the command to do that is `pip install -r requirements.txt`).
- In case anything goes wrong and you want to start from scratch, just nuke the `venv` directory and create a new virtualenv.
- When using source control (git, or whatever you prefer), do not check in the `venv` directory; do check in the `requirements.txt` though.

Finally, if the Python 2 vs. 3 thing bothers you, look into `2to3` (which should ship with your Python distribution), and the `six` library. `2to3` is a utility that attempts to automatically convert Python 2 source files to Python 3, and it does a pretty good job. The `six` library contains a bunch of utility stuff that irons out the differences between Python 2 and 3; for example, it contains an alias for the unicode string type in both, pointing it to `unicode` in Python 2, `str` in Python 3.
Python 3. Python 2 is a dead end it is already in maintenance mode, and soon will stop being supported + programming in python 3 is more enjoyable to use.

Also, with python 2 vs 3 differences. Those aren't big enough differences that you couldn't pick up in few minutes.
Everyone in this thread who tells you to definitely go with Python 3 is pushing their own agenda instead of looking out for your interests.  Either version will work for what you want, and Python 2.7 will not dissapear as they hope.  In my opinion, Python 3 just keeps adding silliness to the language, but maybe those are features you care about.
> While discussing python with my supervisor, he expressed concerns regarding how fast python is growing and thus wanted to make sure I knew how to get around my code breaking simply because I update python.

Solution - _never_ update Python.

I'm serious about this - if you're doing serious development, then you pick a minimum version of Python you're developing to and then make a [virtualenv](https://virtualenv.pypa.io/en/stable/) that includes that exact version of Python and any other libraries you need.

Then you never ever change that virtualenv.  When you want to use a different version of libraries, you create a new virtualenv and test your program with that!
I will reiterate that Python 3 or both probably is the choice. In 2020 Python 2 will likely be unsupported by the PSF (https://www.python.org/dev/peps/pep-0373/). Though it is possible someone will make a fork and maintain it, that is a long shot. This means no security or stability fixes and you would have to port your library then instead of saving work by choosing Python 3 now.

If you want to use Python 2 I suggest writing using a subset that is compatible with both Python >=3.4 and Python >= 2.7. It is pretty trivial nowadays.
Just go with python3. Stick with the current 3.5 or wait for 3.6, becaue the comming f-strings could be interesting.

Most of the important and highly used libraries are ported to py3 and some new ones are only available for py3. 

Personally I only need py2 just for one lib and that is very special and isn't widley used, so porting is just a time waster. It ran as a single cronjob to gather some data and push it into a database, so no big deal to use py2 for this one thing.

`numpy`, `pandas`, `sympy` and `networkx` are already ported, so everything you need for number crunching ;)
The only two (major) issues I've run into with 2 > 3 is print statements versus functions, and strings versus bytes. 
Some readme with an explanation what diashapes is would be a start. 
If I recall correctly, it being the crazy days of the first (or maybe second, or third) dotcom boom/bust, that was actually the name of the company, hence legitimately the copyright holder, regardless of domain name status. Licensing tends to require that you continue to reproduce that information, it's not necessarily important or possible to check it as you go. 
Being the current registrant of a domain does not somehow give you any rights to of any of the assets of a past registrant of the same domain.  That would be absurd.  If you wanted to assert those rights you'd have to show documentation that you acquired them from the company before it folded; and those kind of transactions are backed by signed legal contracts.  You can't just stroll in and say, hey, I happen to have registered this domain name, give me all your stuff.

Downloading it now. This is the first I've heard of it.

It's probably a bit OCD, but for most of my code, I run it through multiple versions of Python in virtualenvs for testing (2.7, 3.5, pypy), even though I deploy internally to a single version most of the time. If nothing else, I have another interpreter in my testing arsenal now.

The Intel distribution of python is just Anaconda with the accelerate package from Anaconda included with it. That includes the mkl library to parallelize algebra functions. 
I must say, if there is one thing that's certain about intel, it's that their software is always amazingly fast.
You mean Anaconda?
My workload is web-based and so it's not the core focus of the Intel Distribution, but I was hoping it would offer some performance improvement on regular python code so I thought I'd do a little test. I cloned this [mako_v_jinja](https://bitbucket.org/zzzeek/mako_v_jinja) repo and updated it for python3, and here are the results:


    Python 3.5.2 |Intel Corporation| (default, Oct 20 2016, 03:10:33) 
    [GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] on linux

    jinja2 2.8: 4.9533123210130725
    mako 1.0.6: 4.368664958019508
    mako 1.0.6 using def: 4.310921513009816

And on my current Python:

    Python 3.4.3 (default, Oct 14 2015, 20:28:29) 
    [GCC 4.8.4] on linux

    jinja2 2.8: 4.5641348299977835
    mako 1.0.6: 4.316026560001774
    mako 1.0.6 using def: 4.251105604984332


Now there are admittedly quite a few variables here, what with different compilers and python3.4 vs Intel's 3.5. All that to say, I was hoping that the Intel distribution would show an improvement on regular python code, but it doesn't on this template test. 

Again, not that it really matters. I know it's not the target workload, so I don't want to criticize the Intel version...
Is this completely compiled with Intel compiler tool chain for C/C++/Fortran? If yes, how compatible is this with pip/conda packages compiled with MSVC?
Rest in Peace, Rob!
2016 won't quit.
Could someone kindly ELI5 this for me....Also, how come there isn't an example (with some code + data) to show me exactly what is happening.
Data science, data analysis for example, also some other stuff in that fields.
Devops. I use python, ruby, Java, groovy, SQL all the time for automation and validation.
Software QA.  A lot of automated testing is built in Python.
Automation Software Engineer
Where abouts are you located/looking for jobs?
Go to meetups. Python, postgres, data science, etc. Emailing a resume to a job board sucks. Having a beer with the hiring manager and other professionals and hobbiests is much better.

Edit: I work at a company that makes software for genetic diagnostics. Lots of python, git, bash, and Vagrant/VMs.  Our product is a vm with a web app, so there's some web dev, but it's not the majority of the work. 
Warning: I have strong opinions about the mock library and monkeypatching in tests in general.

    mock_animal.query.all.return_value = [test_animal]

Can we not? Mocking isn't something that should be done lightly and mocking an ORM response is bad juju for multiple reasons:

1. You don't own that interface. Mike Bayer or one of the Flask-SQLA contributors can up and change that flow at any time (they probably *won't* but it's possible). Now your tests pass but your code is broken and you've no idea why.

2. Depending on the size of your app, you'd probably benefit more from stuff the database details and ORM details behind a repository interface where you can stuff queries like `retrieve_all_animals` or whatever. If it's a smaller app...eh, you're just gonna make a headache for yourself. You need to gauge this one on your own.

3. I don't a see a mention of using the `auto_spec` feature which ensures that you can only call existing methods (and the various special mock methods) on your stand in. Assume you fat fingered your test and you end up doing `mock_animal.qeury.all.return_value` Whoops.
Www.pyomo.org is pretty good ..
Python-GLPK, PyGLPK and PyMathProg all integrate with GLPK. You can sort out the graphs and tables on your own from the output. 


Not sure if it's the right area for you, but [OpenMDAO](http://openmdao.org) is neat.
Personal preference is PyCharm of the two. Originally Python support was a plug in for IntelliJ, in much the same way you can get a python plugin in for VS Code or Eclipse.  

Over time PyCharm emerged as it's own full IDE, which allowed it to zoom in and serve as it's primary focus, while still being able to use other plugins from the base IntelliJ. PyCharm is just so focused it's miles ahead of other options. The fact that there is a pro version also helps drive constant support for the newest features and regular bug fixes. 

IMO no competition unless you are regularly switching between languages, or are more a script writer vs a developer.

(DK why some people view it as slow, I run mine in VirutalBox VMs for isolation and it still feels instant. Only 'slow' times might be when you change interpreter / install new packages and it has to reindex. So I guess if some people still don't run SSDs may be slower? )
PyCharm Community. 

VS Code is not a full-fledged IDE, it's an enhanced text editor, like Notepad ++ or Sublime Text. 

The debugging tools in PyCharm are top-notch. Git/VCS integration is seamless and intuitive, the plugins are handy, and the code completion is great.
VSCode hands down!

I have two python extensions installed:
1. [MagicPython](https://marketplace.visualstudio.com/items?itemName=magicstack.MagicPython) (better syntax highlighting)
2. [Python](https://marketplace.visualstudio.com/items?itemName=donjayamanne.python) (debugging, linting, intellisense, etc...)

With those installed, VSCode provides all the things that I want for python development tasks:

* Auto-completion
* Cmd + Click to goto definition
* Automatic linting on save

Most of the rest of the features that PyCharm provides beyond those I use very infrequently, so I see no point in using such a heavy IDE for development. I still love JetBrains products and use IntelliJ/Android Studio regularly for Android development, but there is a _very_ marked difference in speed between the two.
I actually have PyCharm Professional and VS Code, using both often for Python. Partly I like to vary the feel of my work now and then. They also both have great advantages. PyCharm automates a lot of magic and integrates a lot of different tools. VS Code is much faster to load and gives you easy access to step debugging and command line so nothing is hidden by magic. Both can be better or worse. If I had to use PyCharm Community, I would probably forgo PyCharm simply because I would want Jinja2 Templeton and JavaScript stuff that I need Pro for now. Both are fantastic though, and you lose nothing switching back and forth. I simply add my IDE related files and folders to my gitignore. I'd go a step further and recommend flipping between operating systems while developing so that you maintain your code as cross platform and get used to making projects that are easy to spin up for dev in different environments, but then I've already started far from your question. Both are free. Try both. Web might be limited if you're stuck on Community. Otherwise it's about whether you like magic features doing things for you, like a GUI for pip (though PyCharm still makes it easy to use a terminal too)
I've been using VS Code quite a bit lately and I really can't complain. The auto filename complete is super handy and I'm totally obsessed with the SETI Modified color theme for it (I made a custom theme in PyCharm to try and copy it, but it's not even close). I'm also quite fond of it for small(ish), one-off, type projects. 

But for bigger projects, I always end up in PyCharm at some point or another, for something. Being a full on IDE it has some features that VS Code just doesn't have (yet). Like being able to set custom interpreter parameters for running scripts or automatically adding docstrings with the click of a button. VS Code doesn't have a plug yet to do this (I haven't found one anyways) but MAN I wish it did. 

Like the poor fellow who forgot his password said in the comment above; Pycharm started out as just Python support for IntelliJ. So who knows? Maybe in time VS Code will become a full blown IDE as well.

In the end, use what makes you comfortable. And don't be afraid to mix it up a bit either. So till next time. Keep fit and have fun.
VS Code is nice; it's on par with Sublime. If you kit it out right, it will approximate PyCharm. But PyCharm's debugging is incredibly useful, especially once you start working with a codebase that is huge. I could do what I do (parsing large volumes of HTTP data) without it, if I made judicious use of ipdb and breakpoints, but clicking on the margin of the editor in PyCharm is a cinch. 

git integration is nice, too, but I honestly do most of my git on the command line. I like to think about each commit in its naked state. 
Try both and then decide. If you have heavy-weight python project, and you spend most of the time on it, then use PyCharm. If you have many small projects or even scripts, then VS Code is definitely better, because it's startup time is vastly better.
(I'm the dev advocate at PyCharm) If you're interested, here's a video series to introduce some features of PyCharm: https://www.youtube.com/playlist?list=PLQ176FUIyIUZ1mwB-uImQE-gmkwzjNLjP
I don't think that's fair to compare VS Code to PyCharm.

VS Code is a fairly young project and it's getting better and better. I use PyCharm Community on my python devs but keep an eye on VS Code and use it as my default editor.
I use both, daily. Been using PyCharm as my main IDE for the last 5 years or so, and switched from Sublime to Atom to VSC as my secondary IDE/main text editor over the same period. (I also use vim for quickly editing files from the shell).

What I like about VSC is that it provides a fair out-of-the box experience (i.e.no hours of tweaking, trying plugins, etc.) with just a couple of plugins. Also, it plays well with the main tools from the Python ecosystem (pep8, flake8, pylint, yapf, etc.).

PyCharm takes longer to startup, which is a bit annoying, but is better at working with large codebases.
None of them, I don't like java based apps they are too slow for me.
I feel as if this is finally a product that I can start to share out. There still isn't a battle or trade system, but you can move around the map, buy items, capture BitMon that have been encounted, and get some random items/bitcredits by exploring town type sectors. At this stage, everything works through the pythondialog library on the client side. Server side is a Flask server. After I make sure that all of the API calls work using the dialog based system, I will be creating another Flask server to work as a graphical client. It's being constantly developed by myself, and I hope to have a graphical web-client/Android app by this time next year.

EDIT: If anyone got an error when trying to move, that is now resolved. I forgot an "else:" -_-
8 days of developer time cost about $2000 in salary (not counting benefits, vacation days, office space, hardware, learning materials, conferences, etc.)

So, uhm, a small chance at $100 prize money for 8 days of relentless hacking, probably with massive amounts of overtime? Doesn't sound like a fair deal to me...
I see the post but does anybody use ReactOS as a daily driver? My first thought is for my Toshiba p233 laptop. 

Does anybody develop on this on this sub?
What a frustrating website! It has all the frills and foofarawas but where is the info? Where, for example, does it say Python 2 and 3 supported? And what does that mean, do the Python.org windows installers work on it or not?

And I spent ten minutes trying to find a simple list of what winapps are known to work on it and which not. Nothing but the extremely slender FAQ, 

>  we highly recommend to check if your favourite apps run by trying them and reporting either your success with the community, or any problems you encounter with our task tracker. 

Thanks, that's informative. Not.
Fill me up 
    Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32
    Type "help", "copyright", "credits" or "license" for more information.
    >>> from __future__ import braces
      File "<stdin>", line 1
    SyntaxError: not a chance
[why](https://i.imgur.com/yNlQWRM.jpg)
But... why...
Maybe it's gonna be useful if you do it properly. I hate python tabs... Extension or a complete new IDE?
Death to brackets.
If you want to go down this road I think the AST module will help you a lot. I would also recommend that you split you project into two separate ones: one translator that converts between C-style and Python style, as well as your text editor that will use your library. This way people can (if they find it useful) use your implementation for their text editor of choice.

However, I can see many problems with this approach. What happens when a py-file written by a normal Python developer gets translated to this C-style and modified. When converted back again from the new C-style to Python style some lines that were never modified may be changed. What I'm saying is I don't think the process Python -> C-like -> Python will always return the same Python file again. This causes traceability issues when using source control as bugs will be harder to pin down due to modifications.

In the end, if whitespace dependent syntax is not your thing, Python may not be the best language choice for you. There are other languages that fill that gap and Python is not one of them.
http://www.dabeaz.com/, Haven't took his course, but I attended a conference where he spoke at. https://www.youtube.com/watch?v=j6VSAsKAj98. I also had custom training taught by Continuum with my company, https://www.continuum.io/training and it was good.
[Sixty North](http://sixty-north.com/training.html) offers some good Python training. 
I highly recommend http://www.rmotr.com 
They sometimes post in /r/learnpython see here:
https://www.reddit.com/r/learnpython/comments/55um9l/were_doing_our_python_programming_course_again/

It's virtual but it's a live class. You have classes every week. Coding sessions three times a week. At the end you work on a group project. They incorporate git as well.
1. Use functions in cases of code that will be called more than once in a cell just like normal python. Jupyter is for prototyping. I wouldnt worry about the structure of code, but jupyter is a great visualization tool. Use it.

2. Use your own judgement. For me, if im creating a new tensorflow network, I will create a new jupyter notebook.
It's perfectly fine to just type out the commands without wrapping them in functions. If I end up wanting to reuse a piece of code I might refactor it to a function. Another reason to create functions is that you can give a piece of code a descriptive name to communicate your intent.

Regarding when to use a new notebook it really depends on who you are preparing the notebook for. For example, you often have to preprocess data before you do your analysis. It might be a good idea to put these steps in a separate notebook if it starts to hide the ideas you want to communicate. You can then either output the cleaned data to a csv or json and load that in your analysis notebook, or use the magic %run command to execute that notebook.
It doesn't bode too well when the community is downvoting you like hell on the very site you wrote your article on.
here's a tiny roadmap you could start with:

1) get a free tier amazon ec2 instance

2) write a script that will do the checking and log it somewhere, e.g. amazon's dynamodb

3) set up a cron task that will run the script periodically

4) use flask to make a little web interface for it. check out [this tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world) on flask

edit: even though this will have a pretty steep learning curve, these are all good tools to know about and could be used in future endeavors
I would go for django, django-celery and a postgres database. You will be able to schedule, monitor and do lot's of stuff without actually needing to write too much code.
The plus, is that you will have an easily manageable application and you can learn backend app development. It's the easiest path I think, once you get your head around it. 
8 absolutely killed my sides
Start python and execute 'import distutils'  If it works, distutils is installed, if it throws an error it is not.  You can also look in whatever folder Python installed to (I don't know where Anaconda puts it) and open the Lib folder.  Look in there for distutils.

And for future reference these types of questions belong in /r/learnpython
Go browse the Python docs and standard library reference. Youll learn what's included and how to check for that.
hmm, didn't you run your own code through your own code... so we have a CLI to generate CLI from code?

I did something similar, but using a YAML file in project root to define the commands using existing functions. http://github.com/rochacbruno/manage
Why not have cligenerator.main(function) instead of generating code?
Not to be mean or anything, but uhh...

your code looks bad. Like really, really bad. I would not approve of any pull request that looked like this. The blank lines, the tabs.. *shiver*.

Look over the [PEP8](https://www.python.org/dev/peps/pep-0008/) and format your code accordingly.

For future note, you should try to format all your code according to the PEP8 before making it public.
Jesus you really like blank lines do you?
Argh does this. 
Why won't you use docstring for description?

Not that I'd ever need such thing but why won't you just make a decorator function which reads args kwargs and docstring to print out description for functions?

We use similar construction in JSONRPC server for self-described api functions.
What is CLI?
Right now I'm working on a project where I would like to allow simultaneous input as well as output a background task, would this allow me to implement this functionality? 
I like how you 'generate' the code, it's a nice approach, didn't think about it but this is great. 
Good job, I will use it for pyspark CLI's i'm building right now. 
Thanks for sharing
Nice work.  I love these sorts of things.  I maintain a highly opinionated package that does something similar, https://github.com/mayfield/shellish.

See the decorator example (@autocommand), https://github.com/mayfield/shellish/blob/master/examples/decorator.py

The white spacing is excessive. 
Seems super cool if you want to test some functions without the hassle of making a full CLI.
It's nice to see that you can write ugly code even with Python. Putting an empty line after each line and doing inconsistently so was a genius idea. Congrats.
yay, the 13123098th one of these.
Needed a way to dynamically set the full license text at the top of each source file, without knowing what license was chosen until render time.

The pattern looks like this,

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    # >>
    |LICENSE,comment|
    #
    # <<


    class {{ cookiecutter.module | capitalize }}Error(Exception):
        """ Base Exception class for the {{ cookiecutter.project_name }} application. """


And the rendered contents look like this,

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-
    # >>
    #
    #      cli-application
    #      A basic command line application written in Python.
    #
    #      Copyright (C) 2016 Vivint, inc.
    #
    #      MIT License
    #      ..
    #      ..
    #
    # <<


    class CliappError(Exception):
        """ Base Exception class for the cli-application application. """


Or, since it can multipass...I used it to generate the `--help` from running my new app, and putting it dynamically into the `README.md` file.

Before,

    ## Getting Started
    ```bash
    $ mkdir {{ cookiecutter.project_name }}
    $ cd {{ cookiecutter.project_name }}
    $ virtualenv venv
    $ source venv/bin/activate
    $ pip install {{ cookiecutter.module }}
    $ {{ cookiecutter.command }}
    ```

    ## Usage
    ```bash
    |cli.output,code|
    ```

*CookieCutter generation step..*

`ctx.run('python -m {}.app --help >> cli.output'.format(item), echo=True)`

*Second injection pass*

After, 

    ## Getting Started
    ```bash
    $ mkdir cli-application
    $ cd cli-application
    $ virtualenv venv
    $ source venv/bin/activate
    $ pip install cliapp
    $ cliapp
    ```

    ## Usage
    ```bash
    Usage: app.py [OPTIONS]
        
          cli-application
        
          A basic command line application written in Python.
        
        Options:
          -c, --config PATH  Path to the configuration file (JSON)
          --help             Show this message and exit.
    ```

This release brings some code size reductions to the core as well as more tests and improved coverage which is now at 94.3%.

The time.ticks_diff(a, b) function has changed: the order of the arguments has been swapped so that it behaves like "a - b", and it can now return a negative number if "a" came before "b" (modulo the period of the ticks functions).

For the ESP8266 port the Espressif SDK has been updated to 2.0.0, the heap has been increased from 28k to 36k, and there is support for 512k devices via "make 512k".  upip is included by default as frozen bytecode. The network module now allows access-point reconnection without WiFi credentials, and exposes configuration for the station DHCP hostname.  The DS18B20 driver now handles negative temperatures, and NeoPixel and APA102 drivers handle 4 bytes-per-pixel LEDs.

For the CC3200 port there is now support for loading of precompiled .mpy files and threading now works properly with interrupts.

A detailed list of changes is available by the link in the title.

> - espneopixel.c: solve glitching LED issues with cpu at 80MHz

Been waiting for this :)
For the last question, I haven't read your code very thoroughly, but one thing I notice (correct me if I'm wrong) is that the recursive implementation doesn't do this bit:

    ZÃ¼ge[count]=copy.deepcopy(Spielbrett)

So I think it's reasonable to suspect that deep-copying most of the application state on every move would slow things down considerably.

Other than that: recursion is not intrinsically less performant than iteration, but it tends to be in Python. This is a language design choice; in a nutshell, the relevant Python developers do not believe in recursion as an important problem solving strategy, and so the language ends up not being very good at it. There are three strategies available to language designers to make recursion efficient:

1. Tail Call Optimization (TCO). Many recursive problems use a subset of recursion patterns known as "tail call recursion"; it means that the last thing your recursive function does is either short-circuit (the base case) or directly return the result of a recursive call to itself (the recursive case). Such a recursive call, at the machine code level, amounts to: push args, call function, pop args, run function body, push return value, pop return value, push return value, return. And this can be simplified to: jump to function, push return value, return. Doing this avoids adding a stack frame for each recursive call, so you drop the function call overhead, the stack overflow, and the memory leak.
2. Explicit recursion constructs. Clojure does this; the language doesn't have TCO, but gives you a limited syntax (`loop` / `recur`) for recursive calls that allows you to perform TCO manually.
3. Lazy evaluation. This is what Haskell does: instead of strictly evaluating the recursive call, you return a thunk, which will be evaluated after the function returns. The effect is similar to doing TCO.

Python does none of these, so recursion ends up being expensive. Doesn't have to be that way though.
For your first side question: sys.setrecursionlimit is documented [here](https://docs.python.org/3/library/sys.html).
10-15 is usually not a moderately high number of parameters for bayesian inference.

Why are you avoiding gradients? If that doesn't exclude autodiff look into pystan - hmc may help with sampling problematic posteriors (given your degeneracy/correlation issues). 
Fellow astroperson here!

My suggestion is to parallelize the model itself as opposed to MCMC in parallel.

I know that emcee supports running the model calls in a process pool, but in most cases the whole system gets throttled by serializing data and sending it to the child processes.

It _looks like_ PyMultinest at some level supports parallelization, but I'm not sure if the intended use case is to distribute the work among multiple machines. All I see is that `PyMultiNest/pymultinest/run.py` inspects `mpi4py`. Of course, this runs into the same problem with serializing data, so you need to be wary.

If you need to do a lot of math fast on a multicore machine, my best solution in Python so far is to use `@numba.jit(nopython=True, nogil=True)` and run in a `concurrent.futures.ThreadPoolExecutor`. This also has the added benefit of letting you do non-copying reduction operations.
The problem is that there are already commercial vendors that handle the described use case. For example artifactory.  
[deleted]
You could also simply use the [built-in hook](http://flake8.pycqa.org/en/latest/user/using-hooks.html) that Flake8 will install and manage for you. 
Thanks for sharing this! I've used post-commit hooks before, but hadn't thought of using a pre-commit hook to stop the bad code getting committed in the first place.
You can look into the different functions of `pythondialog`. I know they have a tree view window option, and different types of menus. I mainly work with regular menus, input boxes, and yes/no boxes of that library, though. I haven't tried a tree view.
Yes. 
if your goal is to create bots, python would be a good choice. 
Yeah, python has easier syntax the other languages and idle is very easy to use and understand with relatively simple error messages. 
You may want to try /r/learnpython.

Are the individual morse encoded characters always separated by spaces?  If so, you'll want to split the string by space and then match each element against the dictionary.  You can put a test in your loop to ignore the curly braces.
Homework?
    dictionary = {
        "..." : "s",
        "---" : "o"
        # etc
    }

    def test(str_arg):
        data = str_arg[1:-1]
        return "".join(dictionary[x] for x in data.split())

    print(test("{... --- ...}"))
So I may be misunderstanding you, but it sounds like you're trying to auth in the app, then tell your flask API about that. That's inherently problematic for a few reasons:

1. The client id and secret are in your app, these are easy to find. Now I can pretend to be your app
2. You need some crazy logic in your API for your app to be considered valid. Again, I can pretty much see whatever your app is doing
3. You want to add another provider (twitter or the new hotness, you are bound by the speed of the app approval process)

Instead you may want to consider having your app open a web view to your flask app. That handles the flow with whatever provider (google, facebook, the next hot thing, etc). Then your app generates your own token to be used with your mobile app.

This has a few benefits:

1. regardless of oauth2 provider, they app speaks your backends speak (you define the tokens and what you need in them)
2. I cannot easily see anything personal about your implementation - e.g. Only the server has the client secret. If it somehow leaked; you update it in one spot - not needing to go through the App Store approval process in order to get it updated.

Anyway, like I said I may be misunderstanding your flow. That's just how I read and understood it. Apologies if I got it wrong :)
why not set yourself a project where you webscrape the job listings in your area to look at the demand for python developers
>but i have heard people saying django suck and learn ruby on rail

Ahahaha what year was this?  Django is the current "safe" framework.  If you know django, some jquery, and a bit of Linux server management, you're bound to find a job.
There's nothing wrong with Django.  It's quite popular, and I'd encourage you to find a job that uses it.  Flask is also another popular python option.  It's very light-weight, but lets you easily plug in your own components.  Django takes the "batteries included" approach, which is more similar to rails.  There's nothing wrong with either approach.
> python sytax is really a sytax that only describes Love.

Wow, that's a new one.

> give me some suggestions that tells me what are the demand in python and what are the requirement for it?

Your best bet would be looking at job ads. You will see the most up to date (this week) info, and exact requirements listed.

> Or can i just get a simple python job that use dic ,list ,object ,join meth ,and etc? (Come on i just want to get job ,even the earning is simlar to Walmart job:D)

I doubt it. You might be able to get little gigs here and there on Upwork or similar sites, or if you know someone who trusts/likes you and is willing to pay you to write some small programs for them. But it's a long shot. 
I will be honest, other than full time developer jobs, most of the industry is based around freelancing.

So you are better off building a portfolio with your own project (like a website, github tools, etc), and expand your job search to contacting smaller companies with propositions. Both will want portfolios.

In my experience, knowledge of specific libraries is a benefit (not a requirement), but you have to sell yourself. This means if you can demonstrate that even if you don't know the library, you can learn it.
Don't think in terms of just *programming*, or *using Python.*

Think in terms of *solving problems* and *adding value.*

Python is a tool that you can use to do just that (and one of many).

What kinds of problems? Well, what floats your boat? What are you drawn to?

You might have a difficult time finding part time programming jobs. I'd love to find one, but I've never seen one. That said, I like the idea @lieutenant_lowercase shared in regards to writing a scraper to find such a posting. If you're a student, you can probably be an exception to my generalization by finding an internship. Some internships might not even require you to be a student, though they could be difficult to land without some college work.

Don't worry about people disliking Django. The web is full of strong opinions, and there are also a ton of people that adore Django. You'll tend to find far more jobs with Python than Ruby anyway since RoR is really only good for web. Python is highly prized in a number of other areas as well as web. If you want to start with something easier than Django, you could try something simple like Flask.

Finally, a lot of jobs where you'll write Python will be primarily a job in another language. I work a C# job on paper, but we have some Python apps written with Flask and SQL Alchemy. We've never posted a Python position officially, but there are usually at least one to two developers writing Python each week.

Your city is large enough to find "pure" Python jobs (as far as any job is only one language at least, which is usually never totally the case) and that's a great language to build a career upon, but feel free to find multiple languages to love.
Why not put some effort into it and do some research yourself?
it is certainly possible to make a living with django projects. look for usergroups/meetups in your area to find contacts.

also: what's wrong with your commas? :)
Not sure how much time you're playing with, but if you can pick up another skill that you will enjoy, marry it to being able to solve industry problems with Python (or any other language), it will get you in the door.  I did it backwards, I'm on the business side and learned python to use as a tool to solve business problems on the financial and admin side.  For example, I have a whole group of financial excel files that have to be pulled together each month to create a monthly report, then a summary has to be pulled together and sent to the boss.  one of the things that I did was write a script using xlwings which is a python module to grab all the excel files in the monthly folder, consolidate them into one workbook, then analyze them, chart progress and provide a summary in a text file which could be copied directly into an email to send to whoever was interested in how we're doing.  I've never seen so many happy faces around the conference table.  Approached it problematically, hard work up front, but now takes less than 3 minutes to run the script.  Most managers on the business side don't have programming as a skill, I'm sure the same can be said for other spheres.

You could do this in pretty much any industry with an additional skill.  If you like fashion for example, bust your @ss learning about the industry, network like crazy and then offer yourself out as a consultant (to start and prove you have value getting you in the door for permanent employment) analyzing/visualizing a section of their historical data such as retail purchase info to let them know where they can improve sole.  If they already do this, see if you can speed up their process and move them away from manual analysis. 



Seriously, I'm sure that creating your own cryptography module is a very good learning experiment. You should continue on this route, and continue to experiment and learn about cryptography along the way.

Cryptography is a complex topic, as others have pointed out. And you should not assume that you know everything about it, or that you have thought about every possible corner case or exploit.

For production code, my opinion is that you should stick to well-known libraries (that is, unless you're a cryptography expert). Reason: those libraries have been battle-tested, and involve many years of development and wisdom.
No. Use cryptography.fernet. Don't make your own crypto.
My favorite one is "Talk Python to me", but for god sakes the guy needs to change the intro song, its the most irritating nerdcore rapper or something .. Also he is always promoting pycharm making me sus
I'll take this chance to recommend my favorite programming podcast [Programming Throwdown](http://www.programmingthrowdown.com). It's not Python specific, so probably not suitable for your list. But they have episodes on [Python](http://www.programmingthrowdown.com/2011/03/episode-002.html) as well as [Scientific Python](http://www.programmingthrowdown.com/2016/03/episode-52-scientific-python.html). 


podcast.__init__ is ok, but it sounds like the host is so tired of this. Every episode. 
So many podcasts, so little time.  I can definitely +1 to:

* Talk Python to Me
* Podcast.__init__
This is great, thanks for posting! I've been meaning to listen to podcasts for a while now and I might try some of these out.
I can recommend Import This

https://soundcloud.com/import-this

by Kenneth Reitz, the guy who wrote requests
Thank you for including both Talk Python To Me and Python Bytes in your list Dan.
Here are direct links so you can listen on this site I made backed by Django.

Talk Python to me

https://www.podparadise.com/Podcast/979020229

Podcast init

https://www.podparadise.com/Podcast/981834425

Python Bytes

https://www.podparadise.com/Podcast/1173690032

The Python Experience

https://www.podparadise.com/Podcast/1165128787

Test & Code

https://www.podparadise.com/Podcast/1029487211

From Python Import Podcast

https://www.podparadise.com/Podcast/525611633
Snakes are awesome.
Thanks!!
A really good list, cheers
Excellent post, thanks.
thank you
Useful list, i appreciate you posting it. 
Thnx! :)
If you don't know of anything - would you be willing to collaborate on the mentioned rebuild of such a library?
maybe mongoengine?  it provides an interface to wrap mongo objects around the class (as does pymongo) and a factory interface to create document definitions.

i used to define a DynamicDocument model, with only the id defined, and save json to the model. 
https://github.com/chrisantonellis/pymongo_basemodel

I'm the author, this is still in heavy active development. it fully supports deep setting and getting of deep nested values via dot notation syntax
I tried `pip install detectem`, after running `det` with a webpage, it gives a `FileNotFoundError: DOCKER_SOCKET not found`.
1. You should try to avoid using pip, especially the way you are using it  (with sudo) because chances are that it might override files installed by system packages, and that only leads to further problems (it's possible that could cause issues)
2. If you want to use pip, you should use python3-pip package (I don't know exact name on Fedora)
3. When using pip, it's recommended to either install things with --user option (it install in home directory so no sudo needed), or create a virtualenv first (with python3.4+ you can just type `pyvenv my_env; source my_env/bin/activate` and then call pip. This way pip won't try overwrite system packages and also won't require root (no need to uses sudo)
4. If you use virtualenv pip should be installed, but if it's not after sourcing `activate` script, you can type `python -m ensurepip`. Again, run it only in virtualenv or you could mess up your system by overwriting system files.
[deleted]
Why not both?
But it really depends on what you want to do. I would recommend python, because you can do so much with it. Like run a web framework with Django or Flask! Or build games with pygame! Really you can do a lot with both, but javascript in my experience is better for making dynamic webpages, and python is better for behind the scenes tasks. Was there* a particular type of task you were looking to do? *fixed spelling
salary should be segregated by job types not language. you see javascript salary, for what? nodejs or frontend? i bet salary scale is very different. java is what, java ee or android? for python, i know web developer salary is different from a data science ones. except mabye for ruby, ruby means rails.

people get paid for the type of job they do (and their skill level) and not the language they use.
Thanks for sharing that... there is a ton of info there. Do you guys have a recommendation to find a Python job by state? I will be looking for Python work next year, and it needs to be in a specific state.
"Clean architectures in Python" alludes to some guide by which one can architect a Python project "cleanly".  Instead, this blog seems to try to describe the architecture of a single project, and one has to read page after page of text and code before any description is reached.  Not very well organized IMO.  How about a UML diagram or something as a preface?
> It is very important to understand that the models in this layer are different from the usual models of framework like Django. These models are not connected with a storage system, so they cannot be directly saved or queried using methods of their classes. They may however contain helper methods that implement code related to the business rules.

I disagree with much of this. I do agree that theses aren't Django or SQLAlchemy models. 

However, entities are distinct objects that have a lifetime outside of a request. They change over time: a room might be in a fault zone and after a particularly bad earth quake, it's location could change; prices fluctuate bad on demand and the economy; etc. 

As for querying, it depends on

* what you mean by querying 
* if it's a top level entity

You should absolutely be able to query for a specific entity or a collection of entities meeting criteria. That doesn't mean that you necessarily execute a database query. 

A query should take the form of "I need to know what rooms in this bounding box are free on the 23rd of November" and that would be translated into something the domain understands. Maybe it goes to the network, maybe it goes to disk, maybe it gives a canned response. 

But your query might end up looking like:

    rooms.filter(WithinBox(...), AvailableOn(date(2016, 11, 23))) 

What ever is done with that is up to the repository implementation. 

As for what I mean by a top level entity, there are entities that exist solely to serve this top level one. You shouldn't query for these directly or hold a reference to them. An example might be a rental agreement for one of these rooms, but it all depends on how you've modeled your domain. 

Divorcing your domain model and persistence model is important. The database should be beholden to your application, not the other way around. I think you're on the right track here though. 

But the part I disagree with most is 

>  They may however contain helper methods that implement code related to the business rules.

Your entities should be the backbone of your model. You sound think in terms of "what does this entity do" not "what data does this entity contain" 

What does a room do in your model? You'd probably ask it questions like "Are you free on X date?" You'd ask it to produce a rental agreement for a period. 

    class StorageRoom:
        def available_during(self, period): ...
        def book(self, period): ...
        def estimate(self, peeiod): ... 

You might have a separate domain model called RentedRoom that handles things like storage. 

But the methods publicly exposed in your entities are the use cases. 

What you have labeled "Use Cases"  look more like command objects to me. Some object that's basically a serialized method call looking for its instance. I'm ho-hum on these. They're handy if you're going to do async processing, just dumo them off into a queue and let someone else handle them. But in the other, you could just invoke whatever public API the domain exposes directly. 

If you're gonna ask about cross cutting concerns, that's what things like domain and application services are for. Functionally, these are the same - take related objects and stitch their operations together into a cohesive whole -  but it's more what semantically they represent. If something only talks in terms of rooms and agreements, it's a domain service. If it touches stuff like cookies and sessions, it's an application service (unless your domain involves cookies and sessions). 
I have general question about `from_dict` methods. If i have dictionary isn't easier and safer to put it into `__init__` ?

    StorageRoom(**mydict)


> Can someone tell me what went wrong?

Your understanding of the entire process is what went wrong.

HMAC specifically isn't resumable to avoid length extension attacks to which e.g. SHAs can be victim to.

Since PBKDF2 applies *iteration* rounds of HMAC it specifically can't be resumable either, on purpose.

And PBKDF2 does not just re-hmac the result of the previous hmac, it also XORs all of them together.

> However, the parameter "iterations" does not work as I expect it to.

The wikipedia article on PBKDF2 explains how it behaves and what *iterations* means.

> As the following simple code shows, when i try to call the function twice with one iteration, I get a different answer then when I call it once with two iterations.

Which is to be expected.

> Since hashing functions are deterministic, both methods should yield the same result

No.
I believe, that in the even operations, the previous result plus salt is hashed, in odd iteration the previous result plus the password is hashed, so you do not get the results that you expect. But the pbkdf2 is _not_ meant to be used that way.

Since you use small iteration counts, I'm gonna paste my opinion about iterations in PBKDF2:

The Idea is, that you use e.g. `2**20` Iterations when deriving an encryption key, to increase the cost of brute forcing the password.

A Good Password (10 chars of upper lower, numbers symbols, or better just 5 words) has something like `2**60` possibilities i.e. 60 bit information content.

By using PBKKDF2 with `2**20` iterations, the passwordstrength gets elevated to one with 80 bit which would be between 13 and 14 Characters.


My machine does `2**20` iterations per sec so each time I derive the key from the password it takes me that 1 second.

The entire Bitcoin network could do something like `2**60` iterations[1] per sec. With an iteration count of only 1, they can crack your password in 1 second, for $20. With an iteration count of `2**20`, it takes 12 Days and costs $21 Million.

You must use unique salts so that for every instance where stuff is encrypted, the whole effort has to be spend again, otherwise they do fancy rainbow tables and avoid all that cost.


[1]I checked a year ago they do `2**61` Sha256 hashes per second, not HMAC_SHA256 but it gives an estimate of large computing power and cost. They earned smth. like $20 per second.

**TL;DR**

Large Iteration counts protect a mediocre password from Bruteforce attack. The time your computer needs to compute is less than what typing/remembering a longer password would be.

This is not the place to ask for someone to do your homework.  If you insist on not doing this yourself, at least have the decency to pay someone to do it.
Use a loop to go through the letters in the string and then use the time lib to do the waiting for you.

Not going to provide more help than that. You got this on your own. If someone else does everything for you then you won't learn a thing and you might as well just do it in Batch instead.
    >>> False == False in [False]
    True

Have fun. :)

hint: https://docs.python.org/2/reference/expressions.html#not-in
One of the classics:

    >>> a = 256
    >>> b = 256
    >>> a is b
    True

    >>> a = 257
    >>> b = 257
    >>> a is b
    False
    >>> def foo(x=[]):
    ...     x.append(1)
    ...     print x
    ...
    >>> foo()
    [1]
    >>> foo()
    [1, 1]
    >>> foo()
    [1, 1, 1]
This is only for the python 3 reference implementation, but the id of an object is its memory address. Objects for small integers are preallocated in an array, so when python needs to get '4' it just grabs it from the slot where it is supposed to be. If you subtract ids you see that they are next to each other:

    >>> id(1)
    4543972432
    >>> id(2) - id(1)
    32
    >>> id(3) - id(2)
    32

This is kind of cheating and doesn't count as a true python trick IMO, but if you want to watch the world burn you can change the numbers in these memory slot and break arithmetic:

    >>> from ctypes import *
    >>> c_int.from_address(id(4)+2*sizeof(c_long)+sizeof(c_voidp)).value = 5
    >>> 2 + 2
    5

Warning: at this point the interpreter becomes psychotic and may not allow you to go back in the airlock, or more likely will segmentation fault.

    >>>True + True + True
    3
One of my favorites (from [r/Python](https://www.reddit.com/r/Python/comments/4ivd2k/what_is_your_favorite_python_error_message/))

    def a(b, c, d='foo'): pass
    a(c=1, d='bar')
    TypeError: a() takes at least 2 arguments (2 given)
The latebinding loop one gets me almost every time.

    lambs = [lambda : q for q in xrange(10)]
    lambs[0]()
    >>> 9

The easy trick is the following:

    lambs = [lambda q=q: q for q in xrange(10)]
    lambs[0]()
    >>> 0
Yeah this is one of those strange things to keep in mind with Python. You basically have read-only access to variables in higher scopes unless you declare them global or nonlocal. Global refers to variables specifically in the global namespace, while nonlocal just refers to objects in a higher scope. You would declare variables nonlocal if you were changing them from within a closure, for example.

You could make the code work by doing this:

    x = 1
    def f():
        global x
        print(x)
        x = 2
    f()
Another tricky one:

    In [1]: from datetime import datetime

    In [2]: def f(time=datetime.utcnow()):
       ...:     return time
       ...: 

    In [3]: datetime.utcnow()
    Out[3]: datetime.datetime(2016, 11, 15, 20, 29, 4, 858906)

    In [4]: f()
    Out[4]: datetime.datetime(2016, 11, 15, 20, 28, 47, 339686)

    In [5]: f() - datetime.utcnow()
    Out[5]: datetime.timedelta(-1, 86241, 6300)

    In [6]: f() - datetime.utcnow()
    Out[6]: datetime.timedelta(-1, 86239, 422526)

    In [7]: f() - datetime.utcnow()
    Out[7]: datetime.timedelta(-1, 86238, 302669)

Calls in defaults are done at the time of function definition. Better approach:

    In [8]: def g(time=None):
       ...:     if time is None:
       ...:         time = datetime.utcnow()
       ...:     return time
       ...: 

    In [9]: g() - datetime.utcnow()
    Out[9]: datetime.timedelta(-1, 86399, 999998)

    In [10]: g() - datetime.utcnow()
    Out[10]: datetime.timedelta(-1, 86399, 999998)

    In [11]: g() - datetime.utcnow()
    Out[11]: datetime.timedelta(-1, 86399, 999998)

    import traceback
    x = ([], )
    try:
        x[0] += [1]
    except TypeError:
        traceback.print_exc(0)
    print(x[0])

Results in 
>Traceback (most recent call last):

>TypeError: 'tuple' object does not support item assignment

>[1]

I found this surprising when I first came across it, though it's hard to imagine what else it could do:

    >>> def f():
    ...     try:
    ...         return 1
    ...     finally:
    ...         return 2
    ... 
    >>> f()
    2

Floating-point arithmetic has lots of surprises before you get used to it, but then it's hardly unique to python. Here's one:

    >>> 0.1 + 0.2 == 0.3
    False

You can make an object that is its own type, and it apparently causes a memory leak in CPython (it's explained in the "leakers" directory in the source code - there is also a "crashers" directory with some obscure bugs that cause interpreter crashes but are too awkward to fix):

    >>> class A(type):
    ...     pass
    ... 
    >>> class B(A, metaclass=A):
    ...     pass
    ... 
    >>> B.__class__ = B
    >>> B is type(B)
    True

Playing around with `globals`:

    >>> globals()['a'] = 5
    >>> a
    5
Thanks for all the examples! Fun stuff!
A lot of the behavior described here is python 2.x and fixed in python 3.x
def swap(a, b):

    return b, a
IronClad was great when it was supported. I hope with the renewed work on IronPython they will update this great tool so people can start using it again.
I found the error, when retrieving current conditions, use temp_min and temp_max, while forcasts use only max and min
Hi,

it is a simple query from yahoo:

    #!/usr/bin/env python
    # -*- coding: utf-8 -*-

    import urllib2, urllib, json

    baseurl = "https://query.yahooapis.com/v1/public/yql?"

    yql_query = "select * from weather.forecast where woeid in (select woeid from geo.places(1) where text='szentendre, hu') and u='c'"
    yql_url = baseurl + urllib.urlencode({'q':yql_query}) + "&format=json"
    result = urllib2.urlopen(yql_url).read()
    data = json.loads(result)

    print data

For json response look: https://developer.yahoo.com/weather/

--[sorry, but I don't use weather.com.
With the [darksky api](http://www.darksky.net) :


from forecastiopy import ForecastIO, FIODaily

apikey = 'a66c3d9fd49043109081f945a9d4abba'

Lisbon = [38.7252993, -9.1500364]

fio = ForecastIO.ForecastIO(apikey, units=ForecastIO.ForecastIO.UNITS_SI, lang=ForecastIO.ForecastIO.LANG_ENGLISH, latitude=Lisbon[0], longitude=Lisbon[1])

daily = FIODaily.FIODaily(fio)

print 'Max: {}'.format(daily.day_0_temperatureMax)
print 'Min: {}'.format(daily.day_0_temperatureMin)


Just make your own API wrapper. It's pretty simple.

My preferred way is to install the app for the API I want on my old android phone (rooted and installed my own security certificate on it for HTTPS traffic). Since just about every app uses API to communicate with the back end servers, I find this to be the easiest way (You can also do it on a PC, but I haven't tried it for my projects). I then run it through a MITM proxy on my computer. I use Fiddler, but Wireshark or any other MITM proxy will work.

Then on the app, do whatever it is you want your project to do so you can see what the API does to request the info you want. Once you have the packets captured, it's just a matter of deciphering what it is that's going on. Like how to generate a valid API token, what info is sent in the header, and what kind of info is sent back, sort through JSON data for what you need if the reply has JSON, etc.

Then just import requests into your project and replicate your findings programmatically.

Some words of caution, if they change their API, chances are you're project will stop working. Also don't hammer their servers or they'll probably ban you.

I've used this method for a couple of different projects (control my garage door opener, view weekly circulars) and it works fine. The back end servers think I'm just Joe Schmo surfing their app from my phone.
Netflix doesn't have a public API (it was shuttered two years ago, I believe) so you'll have to resort to screen scraping which is probably against their TOS (read it to be sure). 
https://doc.scrapy.org/en/1.2/topics/request-response.html?highlight=login#topics-request-response-ref-request-userlogin
Continuing work on Twitter bot. Finished the portion that reads tweets and edits them. Now I need to look into the reply/retweet function and getting it all on a loop.
Writing a RAT, also thinking of working on a web scraper
I am learning asyncio. Building a microservice using the "Sanic" framework (which uses uvloop to go fast) and motor. 
mine some data with pandas + numpy + pyspark and building an api to move data with flask
Learning Spotify's Luigi library for creating data pipelines. Very cool.
Still working on converting my Pentesting framework from Java to Python. Only have a couple more classes to convert. Still need to do tests and docstrings.
Working on a small project with scikit learn to predict their identities of 9 subjects and their corresponding 14 actions.

Also building an eCommerce site with django.
Learning python as a software engineer with 30+ years experience.  My polyglot portfolio currently contains Java, PL/SQL, XSLT, Javascript, and bash.  I've used (and mostly forgotten) Fortran, C, C++, Pascal, and Rexx.  I'm working with a new COTS solution that has a C# and python API.
Working on automatic admin site generation (like django) for asyncio/aiohttp, checkout https://github.com/aio-libs/aiohttp_admin
Writing stored procedures for Redshift with the help of Python UDFs.
Writing a report that gets the current and average heap utilization of my Elasticsearch cluster and e-mailing it to a distribution list.
Trying to work with some services, but wmi wont run, and im scared of pywin executables from sourceforge...
I'm working on [Surprise](https://github.com/Niourf/Surprise), a recommender system library aimed toward noobs
I'm working on a site where I can upload surveillance pictures from an rpi. I bought one for my father in law and now I need to provide him with a site and API for uploading pics.
Learning pycharm while I set up an automated test framework with selenium deployed on demand in aws. 

Well that's the goal anyway. 
I'm using Python for a science project involving weather and CSV's.
Thanks A lot! 
Updating a project from PyQt4 to PyQt5.

I have an old branch of code that runs in PyQt5 just fine. Unfortunately I neglected to continue to update that branch so there's about a year's worth of new features in my main branch. When I try to just update the main branch direct to PyQt5 all sorts of issues arise.

So for the time being I'm just going through the code manually and slowly adding the new features to the old code using PyQt5 until I can track down the major problems.
I am making a reddit bot using PRAW right now. 
Note, I am not a programmer, I'm a business-side manager who is learning to use python at work.
1. Auto Excel File Consolidation with Pandas Dataframe, Analysis and movement of relevant data back to an auto-formatted Excel file creating a hot-spot report for the month period.
2. Script to search a pre-set folder for zip files, if it finds them it unzips them, then looks for .txt files, runs search and replace using pre-set variables...What's stumping me is Regex...learning.  I tried using the standard python replace() function but for some reason it isn't working....not sure why...that's what I'm doing other than usual day-to-day business management.
Working on an algorithm called "Progeny clustering" to estimate the number of clusters present in a data set. There's an R implementation of it but no python one yet so I though what the hell.

Not sure if this is kosher but I'm fairly new to python so if someone wants to check it out and give me a tip, it would mean a lot to me: [pyprogeny](https://github.com/baasman/pyprogeny/blob/master/pyprogeny.py)
I am learning web development using Flask.
Working on my first sentiment analysis project!

Quick question about how to best store my data: I have 80 categories, each with about 1000 associated strings (tweets). Would this best be implemented with JSON, XML, CSV, or something entirely different?

Thanks in advance!
Rewriting some i3pystatus modules to fit what I want to see instead of just adjusting my expectations...
Hi I'm an accountant and novice in python. Now working with mongodb and pymongo trying to create a database for my work. 
I spent a day or two trying to move code from an ancient codebase (python 1.6-2.2) to a more modern flask based app. Ended up changing the authentication, ripping the old one out almost entirely and it WORKS! The old code (cgi) works together with the new (wsgi)! Managed to squeeze in unit tests (2) and migrations for two legacy tables as well.
I'm trying to build a website crawler that collects unique links on this site, runs through a list of these collected links, detects a specific logo and iterates through these unique collected links to find certain sign-up forms that adds the URL where that form was found to a new file/list.


I 'think' I'm halfway done. Probably not, because I'm new to this whole web scraping side. I've been able to figure out how to scrape a specific form off of a given URL, but haven't got to the point where I can iterate through the whole site with a given keyword and return the URL value that form was found on into a list. 


TL;DR: Create a web crawler that can find specific sign-up forms called eloqua across a website and puts all these forms into a list. I need h@lp
Im using python to compute skill calculations (accuracy) of real-time weather forecasts (nowcasts) for different historical forecast window lengths
I'm writing a wrapper to integrate Rospy with pytest, so that I'm not stuck using python2 and a strange xml based unittest wrapper to test my code.
Writing a new simple GraphQL parser/executor framework. I finished the grammar and am now moving on to the execution part of the system.

I expect it to have the minimum amount of code necessary, thus making it easier to hack on it. Also I expect to have multiple possible dynamic backends, the first being a SQLAlchemy core one.
Predicting customer attrition with Decision Trees =)
Creating a proper package for my multi-dimensional test parameterization tool [testdimensions](https://github.com/akaihola/testdimensions) and publishing it on PyPI. Also adding Nose support in addition to Pytest.

I'm now working on the readme file, so see [PyCon Helsinki 2016 slides](http://tinyurl.com/scipytest) for usage examples.
Implementing websockets using django channels
[deleted]
I'm just learning basic python on Udacity. 
The largest public company database of environmental, social governance ratings:

https://esg.censible.co/companies

If anyone is interested in finance, company ethics and corporate social responsibility it'd be great to hear feedback and desired enhancements.
I wrote an exporter for the unit definitions for my favorite video game. I though it would take three or four days of work, but it took a couple of weeks instead.

Hopefully people will use it fruitfully. I'd hate to have put all of that work into it and not have it come to anything.
Built my first neural network. Three layers using logistic transfer functions.
Finishing up a little command line app for checking and notifying when esport games go up called [gosutick](https://github.com/Granitosaurus/gosuticker) and working on a little webservice (with flask) that would be pretty much a wrapper around this cli app for users who aren't versed in cli and just want to know when the games are on.

I'm pretty happy with cli app already but the web service is a bit more work than I've expected. Flask has some tricky areas and I'm struggling with pushbullet integration since I've never touched oauth before. 
I'm trying to figure out how to phrase an idea I had for my project such that I can google it.

I have a task management program I wrote, that I'm trying to make accessible from my phone. I am currently using google drive as my storage container for my data, so my code works on a couple different computers. But even with Qpython I can't get Google Drive to act like a folder. So my goal is to find a way to have python reach out over the net and just use the files on my desktop.
I'm putting the finishing touches on a machine learning text analysis pipeline, using scikit-learn and xgboost... there are about 10 steps in total and it's a pretty robust process. I'm happy with the results. 
Finishing migrating an old legacy code-base (Django 1.6, everything run off 'runserver') to AWS with split out database & compute instances.  Currently trying to make the AWS instance talk to our existing CRM server's database remotely.  Working across 7 databases (two MS SQL, two My SQL, 1 access, one SQLite and one Postgres (mine, for 'New World'.), 4 local machines running variants of the software.  And oh yeah, when I arrived, we didn't have any proper git infrastructure or automated deployment, so I've mostly been monkey-patching the live server.  /Tuesday. 

I'm very green in Python, but I'm working on a way to sort and organizes files (QTs) into appropriate folders on our server. While I hear this isn't that difficult, it's still throwing me for a loop.
Working on a project involving triangulation of surfaces in 3D space.  There exist packages and methods already but in trying to rewrite them to better understand the algorithms.  My goal is to compare multiple  interpolation/triangulation methods and calculate the volume of the shape comparing to the analytical volume.  I'll use both mesh grid (uniformly distributed points) and randomly drawn points calculating the volume as n-inf.  Also evaluate computational cost of the various algorithms. Then build a GUI that builds in sliders, and animated some of the parameters discussed, as well as drawing or constructing a custom surface mathematically.
Typical yotube bot
Im updating a bot to send sms when a keyword is found when crawling a shopify site
Two things. Writing a script that handles files I drop into a folder and organizes them accordingly. Typically homework files or lecture files, but renaming them and putting them in the correct folder.

And MQTT Json Light component for Home Assistant with FadeCandy.
Fleshing out my twitter bot. 

At the moment, it sends me and my girlfriend two tweets a day.  The first one is a word, and the second is the definition of that word.  I also have configured the program to text me the word and definition also.

For the future, I would like to create a little webapp with a simple interface that will allow me to just type in a word and save it to a database (or something different that I don't know anything about) and the program will find it's definition.

Then maybe I can take it further and make it to allow different users to sign up and to make their own list of words that they don't know the meaning of.



If anybody has suggestions on what I should learn to implement this, that would be appreciated!


This was the first real world problem/project that I have done that isn't just a little "find all of the prime numbers up to x", so I'm quite proud of it, it isn't flash and the code could definitely be cleaner but for right now, it helps me to commit words that I didn't previously know, to memory.


It looks like automatically generated documentation, which *can* be useful, but not when it only states what's in the signature. 

Any documentation intended to be used by someone not on the team writing the software should have useful examples of use.
Including tests can be enormously useful for that - as long as they aren't too abstract.
 
I don't normally read entire blog posts, but I very much appreciate the writing style in this one.
No, `getaddrinfo()` did not originate in BSD in the 80s.  The original BSD sockets API used `gethostbyname()` and friends, starting in 4.2BSD.  `getaddrinfo()` was first proposed in the late 90s, and standardized under POSIX.1-2001.  It was needed to cope with the transition to IPv6.  As network APIs go, it's a wee young lad.

Edit: and this writing is insufferable.

Don't hesitate to start projects but also get back to the fundamentals to improve what you did.

It's sanity to read again code you wrote few weeks ago and think how different (better) you could do the same thing.

And that happend with:

- books
- experience
Nice post. Yea, it seems like a good idea if you can try to create a program around one of your main interests. Python is really good for this because it allows you to create a simulation or website quickly, when compared with other languages.
Nice article, even though I kinda knew before reading it, there are many people who don't and just keep doing exercises without any context (which isn't bad, but it's not as good as having that spark).
The main issue for me even though I know that I need that goal, is finding out what goal I want.
I agree 100%!!  
  
So many coders are grumpy introverts who will tell you that you're shit at coding, and shouldn't bother writing a line of code until you know how to do it perfectly.  
  
The reality is that everybody has to start learning somewhere. I learned Python by building a series of apps in PyGame (ironically not games) with custom GUI's that relied on loops.  
  
Contrary to expert opinion, you can make ANYTHING you like once you know the simple logic of a loop. It may not be pretty, but you can sticky tape ANYTHING into a loop. That's when the fun starts!!! Once you've sticky-taped together a POS app that runs off some byzantine loop, you can then teach yourself to simplify the code. By making REALLY stupid mistakes (which are natural BTW) you can slowly train yourself to not make those mistakes.  
  
IMO for too long neckbeards have ruled the world of coding with overly harsh opinions about what constitutes 'good' code. Having learned a few human languages (Japanese and English... Italian is my native tongue) I can say for certain that I learned both by talking to people (and being laughed up). If you just sit in a room cram-studying the theory then IMO you risk turning into a neckbeard who can tell everybody who's experimenting they are shit, but will piss everybody off at work because you'll be too much of a perfectionist. Being practical is often very good!  
I wish there was anything I care about and can manage with.
I've written several bash scripts to make my life easier over the past few years. I launched myself into Python a few weeks ago and am going through, rewriting all of them, marvelling regularly at how much better Python (or probably any actual programming language) does things.

I learned Pascal at school, then spent some time with Delphi, then a touch of C++ and then pretty much nothing but batch and bash scripts until I met Python. I can see myself using it exclusively from here on out, it's wonderful.
It seems all about motivation :) . Thank you.
This is absolutely a great idea.  My first experience of programming was writing a scraper for twitter data, and I've since written bots, basic analytics software and also started messing around with flask to build [this](http://threerandomwords.rocks/).  All of this with zero programming education.  
First project was a tip calculator that tipped based on a rating you gave the "server" on a scale of 1-5. Now whenever I feel I'm not good enough I just remember that I have seen a project from start to finish and hey, if I can make this than I can make anything I want if I put the effort in.

Now I'm working on my first Twitter bot. The start was riddled with non-coding errors, but since getting those solved it's starting to come together.

TL;DR - Title is 100% right.
This hits home for me, as I changed careers earlier this year from Systems Engineering to Software Development (at age 35, if that matters). I did it entirely from self-teaching, and the lynchpin of my "portfolio" was a project that was very near and dear to my interests, and I've refactored the entire site about 3 times. I did it as a learning experience, and I learned a ton. 10/10, would recommend. 
How is this a Python post, except for the fact you used PyMC3 for your MCMC computations? Nevertheless, you're describing the kernel of a process which already goes into most of the common polling analyses, like the one from FiveThirtyEight.
I think you have fallen into the trap of thinking there are only two possible answers

The poll questions should have these options

Q: Who will you vote for?

    A. Clinton

    B. Trump

    C. other, write-in

    D. nobody, will not vote

    E. undecided


Your premise that social desirability is the reason for polling error may be true in the Swedish case, but I don't see why it would be a factor in the case of Brexit and prominent statisticians (Silver and Gelman for example) have rejected it as an explanation for polling error in the recent US election. I would be more inclined to blame differential nonresponse and I don't see how your coin tossing game would solve that.
Thanks for sharing. That's an interesting approach.
Almost every person who knows what they are talking about recommends Python 3. People are using Python 2 because they have some legacy code that was built with it, or because their field requires none of the Python 3 features.
A lot of code is version neutral, so if you know Python 3 you know Python 2 minus few syntax features, some different imports and so on. Python 3 is the current, future and supported version while Python 2 will end in some time.
Learn Python 3. It's 1 better than Python 2.
omg, this sentiment still around.
If you are just starting learning just do 3, 2 is only useful for those in existing environments supporting legacy code and if you are just learning I doubt you are dealing with legacy code
why not python1 ?
Learn Python.
2 or 3 doesn't matter. (Altought 3 is regarded as the future of the language)
Most of the times, differences between them aren't painful.
The last three projects I've done at work have been python 3 only.
I recommend you to learn Python 3. And I bet that at some point, people will stop supporting Python 2.X for their packages/libraries (this is not the case right now, but my guess is that it will eventually happen).
We've also released a new demo video showing the features in use:
https://vimeo.com/189945022

Release notes:
This release has refined the use of Qt 5, with additional tools for tomographic reconstruction for electron tomography. The data pipeline has been tweaked and improved further, offering a unified view of the data sources, data operators, and visualization modules in a multi-threaded application where responsiveness is preserved. The volume rendering, reconstruction, and several other key pieces of the application have been improved, and benefit from the threaded execution of operators. The user interface has seen a number of improvements too.

New features in this release include:

Extend the data operators to run in a background thread, support progress updates, and cancellation
Use PyBind11 to wrap some of the C++ interface to make the operator Python API richer and more expressive
Improved pipeline view to unify all pipeline objects, show state of operators, and display child data when present
Many new segmentation routines exposed, numerical output can be viewed in a sppreadsheet view
Enabled full scene antialiasing to improve rendered scenes with minimal overhead
Exposed additional volume rendering options, with more to follow
Added the Tomviz version to the state file to improve future reproducibility
Custom interfaces in most module settings to improve presentation of options, display the name of operators when they are selected
Updated dependencies including Qt 5.7.0, and ParaView 5.2, now build with latest Visual Studio 2015 on Windows
Various updates to reconstruction routines including the addition of progress updates, executing in a background thread, and refinements
Save screen captures with a transparent background
Improved drag and drop installer on Mac OS X
First version of a Tomviz user guide was developed

As mentioned in the last release posted to this subreddit:
Additional Tomography datasets made open and public in "Nanomaterial datasets to advance tomography in scanning transmission electron microscopy" Scientific Data 3 160041 (2016) http://www.nature.com/articles/sdata201641
https://www.jetbrains.com/pycharm-edu/

Hard to go wrong with PyCharm.  I'd suggest looking into IPython/Jupyter as well.

> I suppose the existing libraries are mainly in Python 2, thus probably not worth going to 3 yet. 

This is a terrible assumption.  Check the ones you intend to use, decide from there.  Most, if not all, of the 'big names' in data processing are py3 compatible (numpy, pandas, scikit-learn, tons of graphing/plotting libs)
Total beginner here. Is the IDE the program that I input Python code into, that compiles and runs it?

I use Anaconda Navigator (Spyder) on the Mac? For a physics student with some intro to Python and a months-long itch for mastering it (which I'm hoping to scratch soon), is this a good IDE?

Sorry if it's beneath this thread/sub. It's difficult to even start to find my way around Spain when everyone's speaking Spanish.
Don't go for IDE yet :) Go for simple text editors and the terminal! Or you can go for Anaconda which comes with Jupyter Notebook.

I'm personally still writing Python programs in either Vim or Gedit and running them in the terminal.
I would'nt recommend starting out with an IDE Vim and Sublime Text are the way to go. Plus you can later install plugins to transform these editors into a nice Python IDE.
I don't think any list of techniques would really answer the question, because a mid-level job normally speaks to a period of experience in a low-level job. 

For a mid-level job, you need to have some experience in solving real problems with good code. Knowing how (and more importantly, when) to make use of functools or generators etc will come out as part of that experience.
Needed knowledge depends on the field of the Job you are looking for.

Looking for mid-level Web Python Engineering? Then Learn Django-Flask-Tornado maybe? 

Looking for mid level Data Analysis job? Scipy stack, plotting libraries, scraping maybe?

As u/ticketywho said, the only thing you need to know is the techniques and skills you learn doing low-level jobs. i.e: write clean code, understand other people's code, use pythonic patterns etc...
Neat.
It's not ideal, but from their web page:

>**Pexpect on Windows**

>New in version 4.0: Windows support

>Pexpect can be used on Windows to wait for a pattern to be produced by a child process, using pexpect.popen_spawn.PopenSpawn, or a file descriptor, using pexpect.fdpexpect.fdspawn. This should be considered experimental for now.
I think you're describing a [Circular Linked List](https://en.wikipedia.org/wiki/Linked_list#Circular_Linked_list). It can be implemented as described [here](http://stackoverflow.com/questions/29444140/how-to-create-a-circular-linkedlist). You could write a function that, given two nodes, would tell the difference in their values.




How are you going to use your data structure?
You want a graph library (not a graphing library). [networkx](https://networkx.github.io/) and [graphviz](https://graphviz.readthedocs.io/en/latest/) are popular options, but may be overkill depending on your needs.
First thought is `itertools.cycle`. While it can be used, there might be some builtin even closer to your goal.
Take a look at the [deque](https://docs.python.org/3/library/collections.html#deque-objects).  There's an article [Circular Buffers in Python](http://techand.coffee/2015/04/04/circular-buffers-in-python/) which might help.
I believe it is simply an option on py.test to continue after encountering an error.
I'd like to see some comments or reactions from other data scientist that have used this library-- this looks interesting.  What are the other similar python libraries out there that either complement or attempt to do many of the same things listed here?
Great work. This looks really interesting! Given that crab has been abandoned (almost?). How would you compare `recsys` with others? What is your long term goal with it?
Hi Reddit! I'm excited to share Flintrock with you and take your comments, questions, and constructive criticism. Trolling is OK too, as long as it's funny.

Flintrock is my first significant Python 3 project, as well as my first open source project. The README is pretty comprehensive, and covers [usage instructions](https://github.com/nchammas/flintrock#usage), [features](https://github.com/nchammas/flintrock#features) (including a [launch performance benchmark vs. spark-ec2](https://github.com/nchammas/flintrock#fast-launches)), as well as my [motivation for starting the project](https://github.com/nchammas/flintrock#motivation).

Interested contributors should check out the [contributing guide](https://github.com/nchammas/flintrock/blob/master/CONTRIBUTING.md), and if you bear the scars of configuring systems like Spark on top of EC2, there are [some mind-numbing issues I could use your help with](https://github.com/nchammas/flintrock/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22).

I'll be around on and off today to respond to comments and help people get setup with the project. I hope you like it!
[deleted]
Frame.__init__ return a class Frame. You need to use super(Yourclass, self).__init__ to apply properties of father class.
When to put widgets in your new class you can reference the parent with self.
Are you familiar with OOP? 
Do you understand? 
X-Post referenced from [/r/programming](http://np.reddit.com/r/programming) by /u/robertdelder  
[The Average Case Run-time For Checking If An Array Is Sorted Is e -1](http://np.reddit.com/r/programming/comments/5a8vfq/the_average_case_runtime_for_checking_if_an_array/)
*****  
  
^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
There's a typo in equation 5: the *n* inside the sum should be *i*.

Here's a short program to run an empirical test:

    from __future__ import print_function, division, absolute_import
    import random, math
    
    n = 10
    num_trials = 1000000
    
    def calc_expected(n):
        val = 0.0
        for i in range(1, n):
            val += i*i / math.factorial(i+1)
        return val
    
    def is_sorted_compare_count(arr):
        for i in range(n - 2):
            if arr[i] > arr[i+1]:
                return i + 1
        return n - 1
    
    compare_sum = 0
    for trial in range(num_trials):
        rnd_array = range(n+1)
        random.shuffle(rnd_array)
        compare_sum += is_sorted_compare_count(rnd_array)
    
    avg = compare_sum / num_trials
    
    print("\nCalculated expected is", calc_expected(n))
    print("Empirical expected is", avg)
    
Can we see the code?
So... am I missing something or is this just a gif? With a title like that, I expected to learn something....
hi, 

This looks very cool, try posting in https://www.reddit.com/r/generative/
For anyone wondering, [here is some code of this sequence](http://preshing.com/20110831/penrose-tiling-explained/). Unfortunately, I can't verify that this is the code used for OP's GIF.
Well, I am a newbie to reddit. When I was posting this link yesterday, I got a "human checking" again and again so I even did not know this image was successfully posted!

Here is the [code](https://github.com/neozhaoliang/pywonderland). It uses random parameters and renders a different pattern each time you run it. Just run

```
python penrose.py
```

Some math explanations:

The way in the page cited by @ChatterBrained is called deflation-inflation and it's the most common way to draw a Penrose tiling (used by almost all codes you can find on internet), it's elementary and easy to implement , but it does not draw all Penrose tilings. 

In 1981 de Bruijn found a new way to look at Penrose tilings by the "pentagrid method" he called. His method is a bit mathematically complexed, but still not hard to implement into code. A good introductory link to his method is [here](http://www.ams.org/samplings/feature-column/fcarc-ribbons), but you should refer to his [original paper](https://www.math.brown.edu/~res/M272/pentagrid.pdf) if you want to truly understand his method.
Wot? This is clearly from July
[Pandas](http://pandas.pydata.org/) makes this really easy:

    import pandas as pd

    filenames = ['file1.csv', 'file2.csv', 'file3.csv']

    results = []
    for filename in filenames:
        results.append(pd.read_csv(filename))

    combined = pd.concat(results, ignore_index=True)
    combined.to_excel('result.xlsb', index=False)

Otherwise check out the [XlsxWriter](http://xlsxwriter.readthedocs.io/tutorial01.html) tutorial, but pandas just makes it so darn simple.
[xlwt](https://pypi.python.org/pypi/xlwt) together with its xlrd counter library are very well known and supported libraries that reads and writes the Excel binary formats.
How important is it that the files be `xlsb`? It's pretty easy to do `xlsx` with pandas or openpyxl but I don't think there are any libraries that can handle `xlsb` in Python.
You could convert them all to xlsx using openpyxl & then manually save each one as an xlsb file from Excel?

I've never worked with an xlsb file but I imagine it's fairly straight forward to save as manually when it's only 15 files.

https://openpyxl.readthedocs.io/en/default/

I can write out an example if that helps.
You might get more help at /r/learnpython. 
Wow, this is...really, really nice. Would it be possible to add the ability to write to an image file instead of a drive? Kind of like:

    $ dd if=/dev/sda of=my_disk.img

The GNU Parted hyperlink is broken, FYI.
You shouldn't hardcode sudo, it's not always installed. You sure have users sudo your command.
So, if I understand correctly, this script automates the deployment of a dedicated tunnel user, generates keys, sets up an openssh server with *PermitOpen* configured to block free tunneling access and connects the client. I missed the line where you disable shell access on the server with a custom *ForceCommand* option but I bet it's there somewhere.

Interesting idea but, unless you plan to add some kind of GUI, a shell script would have been more appropriate IMHO.
Looks like you're approaching this with the wrong mindset. In my experience, those who get really really good at programming, or *anything* for that matter, are those who do it because they enjoy it for its own sake, rather than some external goal. So not, "I want to learn programming because autonomous cars are cool", or "...because I hear the pay is epic". Learn programming because you enjoy it in some way. If you don't enjoy any of it, then don't do it, because there are enough people out there who do enjoy it, and they will invariably do it much better than you ever will, without even batting an eye - not because they're more talented, but because they enjoy it so much that they think about it every waking hour.

I also think that your projects may be too ambitious at this stage. Autonomous cars are one of current technology's hard problems, they involve all sorts of undecidable problems, machine learning, computer vision, and a dozen other really complex areas.

But really, fix your attitude. You getting bored is not Python's fault, it's not anyone's fault except your own. Getting bored means you either don't really want it, or you're doing something wrong, and you should be more active about finding out what it is and how to not do it wrong.
Programming is a means to an end. Finally cracking it and making that thing you wanted to make WORK is an awesome feeling. 

You need to pick smaller projects in the beginning that's all. 
Difficult shit is difficult. Stop giving up you lazy ass.
Thank you all for the advice. I'll take this all into consideration.  So far it seems like I just have to stick to it till it's seems easier and fun again.  And I have to really force myself to get into. Thanks again everyone
I am currently teaching my self Python as well and I have had similar problems to you. From the sounds of it, you may want to get evaluated for ADD ( I have ADD). I find that getting in to python was the hardest part for me. Took every bit of willpower i had to get past the basics. However once I got to a point that I could start working on small projects I was able to stay focused longer with out help since it went from being a chore to something that I actually enjoyed. 
Oh sh*t, I posted in the wrong subreddit -__- Sorry folks!
Execute lynx --dump or elinks --dump


BeautifulSoup and find image links? 
I'm impressed by the place taken from Java by Python.
My Django project has so much JS libs in it that it became a javascript project according to Github :-/
What's the first? English? lol..

Edit: Please dont crucify me.
And again, this probably doesn't filter out the countless projects that are actually written in some language other than JS but ship with a whole lot JS libraries ...
This is very cool, but of course it can't account for the immense amount of applications locked away in enterprise repositories. I'd guess that Java (and maybe C#?) would be on top if you could count them too. 
Seems like a lot of distorted data caused by Hacktoberfest. Impressive but I wouldn't read into it *too* much.
Title should have been: there's JavaScript, and then there's everything else. ð
I'm surprised C++ has more than Ruby.  That's cool that Python is #2, I don't think I would've guessed that either.  I probably would've guessed Javascript #1 and Ruby #2.
Python will go to the 1st place if could replace SAP/Oracle stuffs by Odoo/alternatives Enterprise ERP solutions.
[Tiobe](http://www.tiobe.com/tiobe-index/) has more accurate estimates of language popularity.
I've read it "Python 2 most popular language". Not so far from true.
 This sub is pretty quiet for how popular we are
Complete guess, but there is support in Qt for high resolution screen scaling [described here](http://doc.qt.io/qt-5/highdpi.html). Would you be able to achieve what you're looking for using the environment variables described there?
You'll get a lot more advice at /r/learnpython. 
Automate more tasks. Tackle projects that you'd traditionally use other tools (like maybe Excel) with a Python notebook or script. Opportunities will present themselves as you continue to work, and you'll continue to learn more.

It's that simple.
What about cookies, user agents and authentication?
Sounds like you're a networking guy (i'm no python expert) but the obvious thing to me is to take stock of all the stuff you do day-to-day or at least once a week or whatever at work and just automate that out of your life. Thats how I'm learning at least! GL!
In order to solidify my knowledge and skills with a programming language, I always make an IRC bot. The duties of the bot change from implementation to implementation, but they all communicate with an IRC channel/user and... Well... Something else.
>I have also thought a good work related project would be to grab a backup from a Sonic Wall config file and write a python script that exports it to a readable .txt file.

Why don't you do that? Give it a shot and ask questions in /r/learnpython if you get stuck.  It's always better to work on a project that solves a problem for your work or is fun for you personally rather than do an exercise.  You are much more motivated that way and when you are done it is more satisfying.
I would suggest doing the work related project
I found I learn best when I work on stuff that is either fun or I can use for work.

When I first started learning python my work didn't have any backups of our network configurations, so when I device went bad we just had to reconfig it from scratch and hopefully make it the same.. bad!

So the first project I wrote was one that went through all 450~ network devices and copied their config to a text file, versioned it and kept a new one if it was different than the last one.  It was fun to learn paramiko (ssh lib) and how to write to files and compare them.  Maybe you can do something similar! 
I think a good general beginner project is to make  Telegram Bot, which is a chat bot that is built on the telegram messaging app platform. It's fun, not too difficult and you can demo the chat bot to people. You can check out the bot that I made while learning python at: https://telegram.me/MusicLyricsVideoBot

**Official Telegram Bot Api:**
https://core.telegram.org/bots

**Python API Wrapper:**
http://telepot.readthedocs.io/en/latest/

**Directory of Telegram Bots ( to give you inspiration ) :** 
https://storebot.me/
I prefer conda for this. 
Thanks for sharing. I am really struggling with getting my environment the way I want... it seems some things on my development box default to Python 2, while others Python 3. My jupyter notebook is a complete mess. It runs python2 by default, but python3 won't import properly. I've been spending a lot of time on Stack Overflow trying to figure out what is going on.
This is the exact problem that anaconda was created for. As a data scientist, I love the simplicity of managing my environments and not having to configure ipython, numpy, etc... 
I'm -1 on pyenv, and I've switched over to [vex](http://github.com/sashahart/vex). I've found things to be much more tolerable / similar to the rest of the bash environment.  

And for the most part, now that I use `vex` exclusively, I have not found any necessity of installing system level packages except:

* pip
* vex

And I install a couple of linters for my text editor.  Everything else lives inside of a virtual environment.
Seriously, where is Conda ?
What about the Python 3 packaged `pyvenv`?
Oh my god, this is incredible.

I'm the author of PyAutoGUI, which lets you control the keyboard & mouse. https://github.com/asweigart/pyautogui

Being able to register global hotkeys and have a "recording" ability to speed up making these macros has been on the roadmap for a quite a while, but I haven't had the time to implement them. I would love to contribute to this project and incorporate it into PyAutoGUI as well.

Making it work on all OSes and Python 2 & 3 is strategically brilliant.
Author here, happy to answer any questions or receive feedback.

There are other similar libraries out there, but they usually:

- Have many dependencies (requiring admin rights or headaches to install).
- Include C modules that require a compiler.
- Are platform-specific.
- Only work with American keyboards.
- Or implement either hooks or macros, not both.

So I took matters into my own hands. And if you look carefully you'll also see a `mouse` submodule that is in development, but fully functional.
Awesome. Any plans to support OS X? Or any way we can help support OS X?
Planning to use this soon!
Can this library distinguish between different keyboards? I'm using a USB numeric keyboard to trigger certain macros at work, but I haven't been able to find any Python libraries that can hook into keystrokes from only one device.
Interesting project, thank you for sharing this!

Do you think this software is fast enough not to cause input lag for fast typists?  
I wanted to see if you need X running to use it. While taking a quick glance at your source code, `flake8` reported several unused imports. I also noticed use of lists for static sequenced data .. have you looked into optimization at this point?  

Also, do you expect users to `sudo pip install` this software? I've read that it is commonly regarded as poor practice to `sudo pip install` software for two reasons:  

1. The installed files might conflict with other OS installed python files.
2. Privileged execution of untrusted code.

Your source code is available for everyone to read, but perhaps everybody trusts it without checking, thinking "It's OSS, so someone must have audited it..".

I hope I don't sound offputting. I like what you have done. I'm just trying to share my experience when trying to install and use your software, and hope you will benefit from the feedback.

Anyone care to share what they would use this library for? The obvious keylogger is advised against in the README.
This is really dope. I wrote a little module at work for automating some mundane tasks, and I used SendKeys with win32com, but the press and release method looks much cleaner. 
Would it be possible to use this library to implement Dual-role_keys: https://en.wikipedia.org/wiki/Modifier_key#Dual-role_keys

Currently I'm using Autohotkey with https://github.com/lydell/dual but i often get stuck keys with it.
Hi! I have a similar library, which I maintain [here](https://github.com/ethanhs/pyhooked).

I wrote it partially to learn how Windows does hooks. Then people started to want to use it :)

I am thinking of slowly deprecating it, as I think your library is better and more feature complete, and most importantly, I don't want to compete/divide user bases. :)

I will probably do so slowly, as the APIs aren't the most similar, so I will start by redirecting new users to your library, and then in oh, 6-12 months end support for my library. FYI.

(Also great work on the library!)
Good luck! I worked heavily on [pyUserInput](https://github.com/SavinaRoja/PyUserInput) - and they have hit a bit of a brick wall with the Mac stuff. Its not easy. I don't think you can solve this without using the C extensions. I'd like to be wrong but... its hard. This is my fork if its any help: https://github.com/willwade/PyUserInput/blob/master/pykeyboard/mac.py
> Requires root on Linux.

But why? This immediately makes lib so much less useful. [Here](https://github.com/rokups/paste2box/blob/master/gui/hotkeys/x11/global_hotkey_x11.py) is Xlib-based solution i made and it does not require root.
I want to write a python script to add a few global hotkeys. I did the following to keep the python process open and listening for events, but I imagine there should be a more elegant solution.  What should I be doing instead?

    keyboard.add_hotkey('f2', _open_enpass)
    while True:
        time.sleep(0.2)
I've never really understood the advantage of using make over just using Python. If you're creating a Python package, you are assured to have Python. Why limit to say Mac/Linux if you already have a full programming language to handle the same task?

I will use CMake for C extensions, but I'd likely not use anything but Python for other tasks.
1. Try /r/learnpython
2. Try [Flask](http://flask.pocoo.org/)
Setup is kind of annoying when you first get going with asyncio, there is a bit of ceremony with `create_server` being a coroutine (though it does make sense), all implementations give a coroutine (native generator) instead of the server object

It's common in asyncio to:

    loop = asyncio.get_event_loop()
    srv = loop.run_until_complete(create_server())
    try:
        loop.run_forever()
    except KeyboardInterrupt:
        pass
    finally:
        srv.close()
        loop.run_until_complete(srv.wait_closed())
        loop.close()

There isn't really a great way to get around it and you cannot create it before the loop exists since it effectively binds the loop to a socket and system events.

One option is to use a coroutine for your setup, since in many cases you may use other coroutine based initializers, but it's a case by case basis.
        
I think you should use `start_server` instead, look at the [echo server example](https://docs.python.org/3/library/asyncio-stream.html#tcp-echo-server-using-streams).
Be careful about the choices you make. If you develop anything during time you're at work and / OR on a company machine, the company is probably in a good place to sue you to claim ownership over your work if they were to want to do that in the future. You might be fine, but you know that best probably. Personally, I am hourly as a consultant, so if I work on something else, I lock my work machine, record the time, and I don't bill my employer for the time I spend on my project. If you are working on something of trivial importance that you wouldn't mind losing, then there is a chance your company wouldn't bother to pursue legal remedies against you later selling the software, but mentioning money leads me to believe it is non-trivial.

All that said, one approach that might make your work harder to notice would be to use Team Viewer (or another remote desktop app) to work on your home machine remotely. If you're working remote, leaving no trace on your harddrive at work, and you don't have a publicly viewable repository (showing timestamps), then it would be fairly difficult for an employer to build a reasonable case against you.
Think I may have just answered my own question. WinPython seems like it may work. I'll let you guys know what I think after I use it.
[repl.it](http://www.repl.it/) may be an option. It's a bit limited though...
Anaconda! 
The line about it not being secure enough for use in production should be before the tutorial rather than after.
One thing baffles me, why does he store pip artifacts inside repo? 
I am not sure if this counts, but I usually write the documentation first. Inputs, options, outputs, edge-cases, known issues, etc. Then I write out the code. 
You're correct that making a function for adding is silly, but for literally anything more complicated than that you're doing it right. Putting argument parsing and the work you want to do on the arguments in different functions is solid program design.

As a guideline, consider that you should be suspicious of functions that grow over 20 lines, and if the function gets greater than 50 lines long, it's worth breaking it into separate responsibilities in order to test it effectively.

If this is slowing you down, you should consider what parts of your toolchain make file management difficult, or make it difficult to dig into data. Most IDEs have tools that can find dependencies for you, vim and emacs have ctags, etc.
I always make something configurable using argparse even if it's a one-off and I could just as well hardcode a constant.
The (obvious?) answer for me is it depends. Your example is a little too simple because of the add operation that it seems pointless. In most other cases I would say you are probably just properly separating your code in to functions.

However, in my opinion separating this in to two modules is major overkill. There is no reason you can't have a `if __name__...` block at the end of `add_nums.py`. I write most of my code as a "library" like you say and typically have a command line interface via `if __name__` for testing and debugging at the very least. If the whole purpose of the code is for one single entry point by the user then I might put this in `mypkg/__main__.py` so it can be called as `python -m mypkg` to simplify it a little.

Edit: Maybe should have noted that I call the individual scripts like `python -m mypkg.add_nums`.
When you say library, I think the term you may have meant to use would be module -- as a module.  Yes I do that too.  Always a folder (for the repo) containing a folder(for an ``__init__.py``) alongside a ``setup.py``  ... the basic scaffolding is not so basic anymore.
Make it work, make it right, make it fast. That's the order. So option 1. 

You should use an editor that makes refactoring a keystroke away so it's not a trade off, just the order. 
> So which should I be doing? Option 1, or Option 2?

IMO the question should always be "does the complexity of writing a separate module outweigh the complexity of leaving the code in a single file?"

If you separate code into separate files you _increase_ deployment complexity. You will need to deal with paths, possibly with installers, etc. etc. If you keep everything in one file, you can side-step all of that.

If you decide that the code you have really should be separated, then you should do it _right_. Create an installable module, make your script the entry-point, only export functions from the module that are needed, etc.

> While it makes my code reusable, it also slows me down and introduces more complexity.

That really is the point. All the time I see small amounts of code that are separated into modules but are _never_ reused. In those cases, you basically gain nothing by the increased "flexibility" because you're not taking advantage of it anyway.

There really isn't a final answer. Option 1 is sometimes better and Option 2 is sometimes better.
So, its 2016, and because SaaS is *awesome* slack is now thing.
Ergo, lets reinvent the wheel cause Bots are now "allowed" by the generous walled gardeners of said SaaS environment.

While I admire anyone working on small projects like this, I find it fascinating that "text based group chat" is the new need-to-have corporate tool anno 2016, and on top of that, being allowed to run bots is *the* new cool feature those platforms come up with.

I can guess why though, as designing for a screen is getting more and more irrelevant with text-based assistants, the whole move into apps, and media rich websites has become more and more of a sidestep everyone eventually needs to steer away from again.

Lets see if open data api's with standardized protocols also make a comeback, or if everyone ends up having to pay/pray to the gods of voice command (amazon's echo, google and apple's siri) to get included in the platform like we saw with the whole walled garden approach to apps instead of responsive websites.
`import` only works for built-in corpora. If you want to use your own files, use `PlaintextCorpusReader()` method ([see the details in the NLTK tutorial](http://www.nltk.org/book/ch02.html#loading-your-own-corpus)).
The easiest way to find that URL would have been to look in your browser's network profiler as the page loads. Just look through the files for filenames or content that look interesting.

If you wanted to automate this programatically to find unpublished APIs, I would say you'd cover a sufficient amount of cases by simply spidering pages and checking if they contain valid JSON. You could also try checking for requests to pages that contain strings like "json" and "api" or content-type in the response header.
In chrome - ctrl + shift + i, then network tab, then look at the initiator. For the api.lever.co, it's angular.js which is making the call, which is a little more tricky.

To automate this search you would need to run a full browser. You can actually run chrome programatically, as to whether you can automate the search for these I doubt it.

You could probably inspect the response from every request on a page and scan for certain bits of text.
A good API usually returns the next URLs to use.

    'data': { 'something1': [1,2,3], 'next url': 'https://example.com/api/startat/4' }
If you find a bug that you can't immediately fix, it's a good idea to write a test to reproduce it, then mark it as an expected failure. When you do get around to fixing it, you can remove the decorator. If the bug is ever accidentally fixed, the test will show up as an unexpected success, and you can work out what you changed that fixed it.
I would say it is poor practice. As you point out later, if you are testing that a pathological condition correctly produces the wrong answer, then there should generally be an exception or some other way of handling "failure" so that the test passes. Getting into the habit of expecting failed tests - even if they don't show up as failed - is not a good idea.
I've noticed it being used in situations where a test fails on particular platforms because of an awkward bug that nobody wants to fix. Skipping the test arguably isn't appropriate, because the test is *supposed* to pass, and it's handy to have the reminder there.
Generally speaking, you want to use this when you have code that must raise a certain exception under certain conditions. Verifying that your code fails when you expect it to fail is just as important as checking the "happy case", if not more.

An example where this kind of test can be critically important is when you're writing authentication / authorization code. Suppose you have a function `createUser`, which requires `admin` permission; you would want to write (at least) two tests to accurately cover this behavior: one, a test that calls the function with a current user who *is* an administrator, and two, a test that calls it with a current user who isn't. In the first case, you want to verify that the call goes through; in the second case, you want to make sure that it raises the right kind of exception.

Of course you could rewrite the test to catch the exception, return `True` in the `except` branch and `False` in the `try` body, but that gets old quick, and introduces a lot of boilerplate.
pytest.mark.xfail is better
I'm afraid that I cannot work out what that code is supposed to do.

(this)[https://swcarpentry.github.io/python-novice-inflammation/] is a good place for basic data analysis using python
>Also, are there any modules for drawing figures (a-la Matlab)? Thanks so much in advance!

Yes, there's a few options but the main one is Matplotlib. I highly recommend Seaborn too, as it extends Matplotlib with a lot of useful plotting functions (and nice colour schemes).

I'm a biologist (neuroscience) and I do all my work with Jupyter, Numpy/Scipy, Pandas, Matplotlib and Seaborn. It's a great combination.

However don't discount R. It's a somewhat clumsy language, especially compared to Python, but it has bioinformatics libraries that don't exist on Python. I use it for my RNA-seq analysis, again using Jupyter. I don't use any other IDEs anymore.
After basics, after basics, after basics (important, so say it 3 times), you can check libraries like MNE-python, PYMC2, PYMC3... These are very good for bioinformatics.
A fun playground to try is Project Rosalind,  http://rosalind.info

There are a bunch of bioinformatics problems to solve. If you try answering them in python, you'll probably identify language features/quirks that you may not have. 
Check out biopython
For core Python just use [the official tutorial](https://docs.python.org/3/tutorial/).
If I were you, I might just learn Python by using it.
  
A Python framework for the analysis and visualization of trees.  
http://etetoolkit.org/  

Biopython Tutorial and Cookbook  
http://biopython.org/  

A Python package for precision medicine and proteogenomics  
http://pygeno.iric.ca/  

PS. My background is the same as yours. Dual Master of Science on Bioinformatics and Software Engineering. I left bio field 10 years ago after I did microarray genechip research.
Also, there is Orange, a nice bioinformatics wrapper around scikit-learn. If you want to mix data science and biology.


http://orange.biolab.si/
This isn't bioinformatics specific but I'm a computational chemist in a PhD program and I've pretty much just used a combination of numpy, scipy, and matplotlib for all my data analysis.

I have a question for you, though!  I think bioinformatics could be a field where I could utilize the skills I picked up as a PhD student in enzyme design.  Do you have any good resources on some good biostatistics material that might be industrially relevant (I'm a physical chemist by training, so I don't really know where to look).
Thanks! I've only been using a tiny subset of pdb's capabilities and didn't even realize it.
Even better than pdb, see: [ipdb](https://www.safaribooksonline.com/blog/2014/11/18/intro-python-debugger/).
Thanks, I've never had debugging capabilities in my code before.
It's obviously nice to know pdb, but for anyone looking for something more intuitive I've found that Visual studio code with the Python extension is the most lightweight option with a decent debugging experience.

Unlike PyCharm, for example, it still feels and runs like a text editor despite all of the features typically found in IDEs.
I don't know if it's the best way to do it, but I often just set the conditional break point right in my code

      if complex_condition:
            pdb.set_trace()

Just because typing in the editor is easier.
Could you clarify a bit what the functionality of your desired final result looks like, along with some specifics regarding the scale of the project? Are you expecting ones, tens, hundreds, or thousands of client connections per second? Is there a JSON file per client, or are they all trying to access the same file? What is the purpose of sending & receiving to the same file? How does the script know which portions of the JSON file to send back to the clients once it has written data? What is the purpose of the entire system? 

I'd love to help, but it's not clear to me what you're trying to do or why. 
You might have better luck using a standard websocket library in Python, so Python would do everything.  Your Python script would replace your websocketd server, and that way you would not have to re-load the Python interpreter every time a websocket connection was made, and the .json data would never have to be written to a file.  That should reduce your resource usage considerably.
The Perl Foundation has a [Perl5 core maintenance fund](http://www.perlfoundation.org/perl_5_core_maintenance_fund) that's used for grants to fund tasks or projects related to Perl5.  

The PSF has given grants in the past for core projects, though there isn't a dedicated fund -- it just comes from general reserves.  Maybe the PSF should set a target of $X/year to fund 1 or 2 people, and then try either crowdfunding it or finding corporate sponsors to meet the necessary goal.

Hey I just listened to this today! This... is perhaps the most boring episode, and if this is your first episode of Talk Python to Me, I suggest maybe checking out another episode first before passing judgement. Even still, this is highly recommended to anyone interested in understanding more about how the community is structured and funded. About as interesting as a city council meeting, but very relevant.
Is there an ETA for a incremental PyPy3.5 release? The 3.3 release would work for me except for the absence of scandir, which can't be pip installed in PyPy.
> Python 2 because he states that Python 3 hasn't pretty much taken off yet.

That statement is just wrong. 
https://news.ycombinator.com/item?id=12930082

It's not a waste, no, but it may be helpful to look into making the Python 2 code you write compatible with Python 3 from the get-go. I have written a lot of 2/3 compatible code, and I have upgraded a fair bit of Python 2 code to be 3 compatible. It's much easier to do it from the beginning. [This website](http://python-future.org/compatible_idioms.html) has a lot of great advice on doing just that.
Time spent learning is never time wasted.

You'll be able to move to 3 just fine, it's not that big a deal. Finish the lessons you're working on, then install version 3, and work out the kinks when working on your projects, when something's a little bit different than how you learned with 2. It won't take you long.

3 is where it's at now. 
3>2. Moved to 3 couple months ago and never looked back. I'd recommend automating the boring stuff over lpthw
My 2 cents is that you should learn 3, and just briefly familiarize yourself with the difference in 2. For me, I've only experienced conflicts due to print() and changes to the way strings are handled.
Any learning is good learning, but I find the snide tone and clear bias against Python 3 in LPTHW to be pretty... Demoralising. 

That said, you won't have a hard time migrating, the necessary syntax changes aren't massive (although some of the string logic is). 

When you're done with your current topic, why not see if you can find a tutorial that runs over all the new stuff? 

Nah, 3 isn't THAT different, and 2 is still much more widely deployed. You can learn most of the important differences in a day. Also there are things you can do now to help your 2 code be upwardly compatible with 3 code.
This may be an unpopular opinion but from experience I can tell you that depending on what you want to do learning python 2 might make you more productive faster. The reason I chose python was to be able to write computer security tools. Most books on that I KNOW are still written in python 2(I think it's because at the time of writing all linux system had python2 by default.). Although there isn't that much difference but having to deal with syntax when the actual topic is complicated enough is just frustrating. So my advice is look up books on the subject matter you want to work on and use whatever they use.


I would not say you have wasted your time since what you have learned so far would be more or less reusable in Python 3. However,  if you continue to learn and practise in Python 2, you will need to put some more time and effort into adjusting yourself to the changes in Python 3 later. For example, I still sometimes forget to encode strings into bytes where needed. So it would help to get used to these changes from the beginning. 
While I personally used and like that book, it is very old and dated.  His python 2 statement particularly irks a lot of people.

But don't worry, the differences between 2 and 3 are minor, and you'll have no real trouble, so if the book is working for you, continue and finish it.

If you learn Python 2, Python 3 is 99% the same, you'll be fine.

You should go with Python 3 when you can, it's definitely better.
Thanks for all the input guys! I decided to stick with 2.7 since a lot of the libraries I want to use still rely on 2.7. Also, everyone keeps saying it wont take long to transition once I have a good grasp with 2.7.



Where are you trying to download it from?

I just checked the version hosted [here](http://www.lfd.uci.edu/~gohlke/pythonlibs/#numpy) and my scanners aren't picking anything up so you could give that a try.
Almost certainly a false positive.

In the template, put your Angular code between `verbatim` tags, like this:

    {% verbatim header %}
    ... angular code ...
    {% endverbatim header %}
    
    {% verbatim main %}
    ... angular code ...
    {% endverbatim main %}
From:
http://www.daveoncode.com/2013/10/17/how-to-make-angularjs-and-django-play-nice-together/

$interpolateProvider.startSymbol('{$');
$interpolateProvider.endSymbol('$}');
You can change the opening and closing tag for AngularJS. 

[This SO thread](http://stackoverflow.com/questions/38089544/change-angularjs-opening-and-closing-tags) has example codes. 
It's not saying web scraping = $100k salary. Indeed doesn't decide themselves what skills are worth. It's saying the keywords "web" and  "scraping" appear in job postings that average $100k. 

The first job listed is Lead Software Engineer for Time Warner Cable. That person probably has a lot more responsibilities than doing simple web scraps and gets paid extraordinarily well for it.
I don't think it's saying just that skill gives you that salary.  I tried searching several prog languages and they all gave me low 100k. It's probably just most software related roles are in that range and those are the ones that have that skill listed. 
You could run a Jupyter Notebook server inside the container and connect to it from your browser. You can also use PyCharm, which allows remote debugging via SSH.
I think the best way to structure the program is to make a Line class has the first function inherently in the __init__. Third function can be a method within the class with arguments (self, line2, line3). As for the second function you might want to create a method that takes a coefficient as an argument and returns a string based on the coefficient value (empty, or with a plus/minus sign and x/y after) and then ' '.join the sign method for each coefficient. 
Questions like this should go to /r/learnpython.

/r/python is not for homework or assignments.


I don't understand the point of this example. AlbumCollection should just be a list. It doesn't offer anything that a list doesn't,  in fact I'm not even sure that append will work. There is no explanation of the benefit of inheriting from MutableSequence either.

This looks like python written by a Java programmer 
So I love python's built in types. If nothing else, they provide a consistent syntax for others to base their own API on.

For example, I deal with geometry a lot. It's nice to be able to borrow the set syntax (union, intersection, etc.) and apply it to my geometry objects and have this lovely, automatically understandable code afterwards for other python users.
That's not a good idea. Store your `teacher` instances in a dictionary, with the key being the name you want them to be searchable by, something like `{'prof': teacher(...), 'other prof': teacher(...)}`. Then you can check if such a name exists with `if temp in dict_of_teachers` and then retrieve the object with `dict_of_teachers[temp]`.
Or you could just implement WAMP.ws on top of redis. It's a standard. It does RPC and PUB/SUB. You got client for many languages, including Python, JS, PHP, Ruby...

Let's not reinvent the wheel.
Hey all, I posted this here because I want to know what other Python developers think about the idea of the protocol. All comments are welcome!
checkio.org is nice to start practicing basics
This is a good intro course to programming using Python: https://www.coursera.org/learn/interactive-python-1

You need to submit assignments and as well as grade your peers' assignments in order to pass the course.
[Ask Python](http://askpython.com/)

[Think Python](http://greenteapress.com/wp/think-python-2e/) and the rest of the serie that uses Python, e.g. ThinkDSP and ThinkBayes.

Python 101 and 201 from [Michael Driscoll](https://leanpub.com/u/mikedriscoll) were free recently...
Try automate the boring stuff with python, might be more of your thing. 

I'd recommend Zed Shaw's learn python the hard way, but the python 3 version of the book is still being worked on. If you don't mind learning while the language is python 2 (they're quite similar anyway), or by reading the error filled python 3 version, then I suggest those.

[learn python the hard way 3](https://learnpythonthehardway.org/python3/)

[Automate the boring stuff](https://automatetheboringstuff.com/)

While i'm not sure if they have 'answer banks', you're more than free to google the answers or ask around the /r/learnpython community. 
You don't get anything relevant because the search results are loaded asynchronously (with AJAX). So when your urllib.request is fired and returned, you only get the static html part without whatever the JS part loads.

You have a few options for solving this:

 * reverse engineer the AJAX calls and use those instead of the URI you currently use. Open Firebug/Developer tools/whatever and see what XHR requests are sent.
 * Use a full-blown scriptable browser, like Selenium, which will execute the Javascript and add the results to the DOM. Then you can traverse the DOM as expected. Beware of timing issues.
> the content of every span in a div with that class.

are there multiple spans per div? or does each div have just one span?

if the latter, and you select each div to a variable 'div1' you can just call
 
    div1.span.text
3.5 introduces a new syntax for handling coroutines.

Pretty sure 3.5 would work fine with Kivy as long as you don't use the new Asyncio syntax.
You can use Kivy with Python 3.5 on Windows if you download and install a wheel from here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#kivy

it worked for me. Try


    pip install docutils pygments pypiwin32 kivy.deps.sdl2 kivy.deps.glew
    pip install kivy
If it's just going to be desktop app and it's not a project for the purpose of learning kivy I would check out pyside. QT is an easy to use mature framework.
If mobile s in the future go for it. It's on my list of things to learn as well but nothing beats pyside and QT designer for quickly getting a UI together.
Kivy is not working at all for me on Windows-- followed the install steps (and stackoverflow help)-- no solution whatsoever.... I can't get the app to load at all (and it says my OpenGL version is 1.1 when it's obviously not that)

I'd stay the heck away from Kivy for Windows environment. 
The `__init__.py` is the only place I'd ever advise using `from x import *`. But even in a place where you have total control over the namespace, I'd still advise using explicit imports if you can as that is a big boon to readers of your code. Otherwise, you should really have documentation that details what ends up in each of the namespaces so people don't have to go hunting with `dir()`.
It's Python, you're not going to be able to hide everything.

That said, I wouldn't expect the common usage to be `import app.gui` an instead `from app.gui import uiloop, Button` or something like that. 
It's okay to use import * here as long as you set `__all__` in your sub-modules. 
"Fluent Python" from O'Reilly Media.
Perhaps "Dive Into Python"?
i'd pick up "python - essential reference" by beazley and then maybe sit at barnes and noble reading the "python cookbook" for part of an afternoon just to get a feel for things. google will fill in the rest.
This title is so clickbaity.
Two ideas:

* Install Spotify on the Android emulator (there are websites where you can download the Spotify APK, google it). There you have root and you can view the logs with logcat
* Decompile the APK and look directly at the source

For the next time, you should post such questions in /r/learnpython.
Nice summary but unfortunately skips mentioning the most important part: version compatibility 

Jython, unfortunately, seems quite dead in the water having had its last release (which brought 2.7 compatibility) in May 2015.

IronPython looks slightly better. Although it's latest release also only targets 2.7, there is an active development branch working towards 3.x compatibility.


PyPy currently supports up to 3.2 (3.3 is in alpha) and Mozilla is sponsoring work to get it up to 3.5 in the nearish future.

Pyston was started with the express goal of only supporting 2.7, this has since been slightly qualified that 3.x support is eventually desired. So far it also only supports Linux x64 and AFAIK doesn't yet (?) fulfill its performance targets.

Pyjion looks very interesting and will have full 3.x support since it's basically "just" a plugin to CPython, but is still much too early to tell how it will  work out.

Cython is proven and can be very useful in certain cases but can't be really considered a python implementation since it changes the syntax.

So to summarize the only real contenders (IMO) currently are CPython and PyPy with *maybe* Jython / IronPython if you *really* have to work in the JVM / CLR.
Something the article doesn't mention-- ~~Jython and IronPython are both GIL-free. This is fantastic if you need to write code that scales out to multiple core/processors while still having mutable shared state.~~

Edit:

Jython and IronPython have failed to implement the the glorious GIL of the CPython interpreter, so code that implicitly relies on only a single thread of Python code running at one time might experience problems. Additionally, you will not have the opportunity to demonstrate your advanced knowledge of the language by identifying which parts of your code can and cannot be executed concurrently, because all of it will execute concurrently.

I, for one, hope that IronPython and Jython get around to implementing the GIL as they push towards Python 3 compatibility.
... MicroPython
Random question about how to abstract a lot of this knowledge into a true-enough-brain-nugget:

I've been doing a lot of C# and learned about `interfaces`, which put forth a contract for a class to implement to adhere to that interface.

Is it safe to consider `Python` to be akin to an interface, while `CPython` `PyPy` etc, are the implementation?  Ie. They will all implement the same features, just differently?  My understanding is that features implemented in all of them, should provide identical results, just with different performances.  Or do some features fundamentally do different things?
A minor note: the CPython dev team and the PSF are unrelated and only vaguely overlapping at this point.
Nuitka just parses your code and creates C++ source files with calls to python C API functions instead of executing python code every time.
PyPy is already working on Python 3.5 support (you can already try nightly versions)

    class Smarthome:
      def lights_off():
          """ 
          Turn the lights off
          Lights off
          Turn off the lights
          Stop lighting
          Make it dark
          No more lights
          Shut the lamp
          ...
          """
          for light in lights:
              light.off()
          return True

    def execute_command(s):
        for command in dir(Smarthome):
            if not command.startsWith("__"):
                func = getattr(Smarthome, command)
                sentences = func.func_doc.split("\n")
                for sentence in sentences:
                    sentence = sentence.lstrip()
                    if s == sentence:
                        func()
I think that while what you are doing may be possible, you should consider whether it's a good idea.  A docstring shouldn't affect the execution of the code.

Instead, you should have a list of matching phrases.  Or a hashmap of phrases that point to that functions. Make sure that your code can be walked through easily.
Worth checking out [chalice](https://github.com/awslabs/chalice) as well. It's a cool flask-like framework for lambda.
Vendor lockin.  No thanks.
Too bad the latest supported Python version is 2.7...
[deleted]
How do I setup testing and staging environments for an infrastructure like this? How do I run all of this on a laptop so I can test new features and debug locally. Is there a version of aws lambda that runs locally or a good way to simulate it for development?
Python 3 is a better language, but the "Pythoncalypse" really took it's toll on the community...
Reflects only users of some random CI service.
Almost understandable the amount of *existing* python2 implementations. Legacy software is a thorn in all of our sides.

But for **new** development to be in python2??! Just makes no sense... I have a feeling that non-python people on a default machine are just typing in `python` and don't know of `python3` and aliasing in general.
[deleted]  
 ^^^^^^^^^^^^^^^^0.4049 
 > [What is this?](https://pastebin.com/64GuVi2F/25027)
Some people seem to be thinking nobody has a reason for new projects in 2.7...well, I can tell you our use-case: Maya. Maya is an awful piece of trash software but it's an industry standard for animation/vfx/etc with few realistic alternatives. Anybody that has to program for that industry is stuck with Python2. 

I've heard rumours that Autodesk will start to support Python3 in the next couple years, but I'll believe that when I see it.
Depressing.
Pretty logical and obvious.
I'm not saying stick with 2 (I use 3 exclusively) but 2 will be supported past the deadlines of 2020 (by a 3rd party) so there's no strong engineering reason to stop using it. 
Python2.7 will always be superior. Edit: omg
Ofcourse! Look into pyautogui. 
If possible, it's much cleaner and easier to read values out of memory rather than attempting pixel reading / screen-scraping. Try familiarizing yourself with memory using Cheat Engine, and then you can move your work into Python using libraries like PyMem or WinAppDbg.

Memory reading is difficult to detect, if you're worried about anti-cheat protection. If the game has rudimentary anti-cheat, memory *writing* is what you want to avoid. If it's a AAA game, you're liable to get caught regardless.
PyAutoGUI + Pillow
https://automatetheboringstuff.com/chapter18/
Is the game Old School Runescape?
Pyautogui is quite handy and great module for your task. Make sure you go through the documentation to explore all the tasks that you can do using it. Since you are new to programming, this habit of learning from documentation will be the best thing in long term.
[deleted]  
 ^^^^^^^^^^^^^^^^0.9360 
 > [What is this?](https://pastebin.com/64GuVi2F/56911)
Python 2 doesn't have an *incorrect* implementation of Unicode, it  doesn't enforce the distinction between a string and an array of bytes, or to be more precise, in Python 2 a `str` *is* an array of bytes, which it shouldn't be. You can write Unicode-aware code in Python 2 just fine, it's just trickier.
The difference isn't that Python 2 did Unicode "wrong" - it's that it defaulted to treating strings as sequences of bytes, with no real understanding of encoding. You can do Unicode in Python 2, but it takes a lot more effort because the distinction between `unicode` and `str` is a lot more fluid, and you can often combine the two types in operations. Python 3 makes`str` "proper" Unicode strings and introduces a separate `bytes` type used for encoded strings. At a glance, they look like `unicode` and `str` types in 2, but the important distinction is that you can't mix them freely - `bytes` objects have to be decoded before they can be processed further.
One example:

    b'\xed\xa0\xbd'.decode("utf-8").encode("utf-16")

This produces invalid utf-16 with Python 2 while it fails with Python 3.

Because Python 2 allowed surrogates in unicode by default.
Python 2 didn't implement unicode incorrectly. When people say "they got it wrong", they are referring to how the type that is called "string" in Python 2 is a bytestring, and how that is the default type for string operations, as well as I/O and code files. Unicode strings, that is, actual strings that represent sequences of code points rather than sequences of bytes, are called `unicode` in Python 2, and creating them usually involves explicit action (decoding bytestrings, or prefixing your string literals with `u`).

In Python 3, "strings" are proper unicode strings, and what used to be called `string` is now called `bytes`; string functions default to unicode strings, source files are parsed as utf-8 by default, and string literals are unicode strings unless you prefix them with `b` to make them bytestrings.

When transitioning to Python 3, some libraries have gone a bit overboard; some WSGI implementations, for example, incorrectly treat HTTP as a textual protocol, and uncritically expose things as unicode strings that should be bytestrings (e.g. URL paths and headers). On the whole, however, the situation in Python 3 is much saner than in 2.
Python 2 supposes that the files containing your code are in ASCII by default, and that the strings you declare will produce bytes objects, and will be text implicitly encoded with the charset of said files.

Python 3 supposes that the files containing your code are utf8 by default, and the strings you declare will produce generic text objects not tied to any encoding.

Bottom line: 

default settings in Python 2 will try to produce encoded ASCII text in memory, failing as soon as something that is not ascii enter in the game:


    >>> b = "Ã©" #  bytes, encoding depends of your terminal
    >>> import foo; foo.string # bytes , encoding depends of your file
    >>> b + foo.string # possible fuckery 

Most common fuck up are:

- people reading a file and not deocding it, getting byte in an encoding they don't bother to detect. Then later they manipulate it and it explodes.
- people putting non ASCII caracters in their code withour specifying the encoding, getting UnicodeDecodeError immidiatly.
- people trying to print() in their terminal something they got form the web/ a file/ the db without decoding and boom.


Default settings in Python 3 will mostly work out of the box, and if you do encouter something that doesn't (non UTF8 encoded byte incomming), fixing it is just a "decode()" or an "encode()" away. 


    >>> b = "Ã©" # non encoded text
    >>> import foo; foo.string # non encoded text
    >>> b + foo.string # happy coder


As a result:

- most of the time everything works;
- if something is unusualy and require you to know what your doing, Python will put an error very early in your processing, usually at the level of the text input, which make it easy to google the solution. The solution is usually calling decode/encode, with the proper encoding, the hard part being finding the proper encoding.
Check out https://eev.ee/blog/2016/07/31/python-faq-why-should-i-use-python-3/#unicode-by-default
    def build_n_gram(words=2, join_with=u' ' ):
        random.shuffle(funny_words)
        return join_with.join(funny_words[:words])

**edit** better yet

    def build_n_gram(words=2, join_with=u' ' ):
        return join_with.join(random.sample(funny_words, words))
The list is short and it doesn't even attempt to do some sort of mix-in.  It's a lot easier to deliver an endless stream of phrases with using adjectives, nouns, and qualifiers.

Maybe something you can extend an existing library like [Faker](https://github.com/joke2k/faker).

EDIT:

Took a few minutes to validate the theory.  By using the adjective ordering and splitting it up I came up with a script in minutes.

1. Quantity    four, ten, a few, several
1. Value/Opinion   delicious, charming, beautiful
1. Size    tall, tiny, huge
1. Temperature hot, cold
1. Age old, young, new, 14-year-old
1. Shape   square, round
1. Color   red, purple, green
1. Origin  Swedish, Victorian, Chinese
1. Material    glass, silver, wooden

And here is a small sample with a very short word list.


    cold ancient aardvark
    charming cold plastic book
    amazing middle-aged home-grown flower pot
    charming Europeen plant
    funny large boiling dog
    a few wide cardboard kids
    newborn yellow martain fiberglass croissant
    bankrupt newborn airbrush
    whimsical hot teen alien
    fourteen octagonal steel abacuses
    whimsical steel couch
    amazing young couch
    ten middle-aged orange men
    small ancient binder
    small round American cardboard couch
    boiling irregular flower pot
    delicious gargantuan irregular house
    average-sized Europeen couch
    ten frighening metal aardvarks
    stinky boiling dog
    bitty freezing newborn orange flower pot
    square pink plant
    teen red aardvark
    ten boiling moose
    square American aardvark
    whimsical middle-aged banjo
    lovely yellow martain plastic banjo
    ten irregular American abacuses
    a dozen octagonal aardvarks
            

Cool, but would be nice with some examples in the readme.
Add Python 3 
Can I suggest the addition of the words "correct horse battery staple", so it can be used to generate passphrases as well? :p
Wow, a lot of pompous assholes here huh? I think this is cool. Good job mate.
not even Python 3 compatible...
Congratulations?
Is there a benefit to using something like asyncio or curio over the multiprocessing module?
Is there any benefit to using this over grequests or aiohttp?
Don't stop! There is so much to do with: asyncio implementation, speed comparision, proxies, and so on, and so on.
Seems like spam to me.
Try /r/learnpython.
Make a function called letter_grade that takes a numerical grade and returns the letter grade. When you print out the table with your grades (before calculations) put the result of the letter grade function alongside the grade. You can do this with one print function by concatenation

Example:

 print("Score 1:"+str(score)+" Letter grade:"+letter_grade(score))
The following works:

    #Program 5
     
    #program will ask people to enter 5 different test scores
    #program will then calculate the avergage of the scores
    #program will then determine a letter grade based on the test scores
     
    #header
     
    print('CSC 122-W1 - Program #5')
    print('By Victor Alam')
    print('November 14th, 2016')
    print(' ')
     
    #main function
    def main():
        score1 = float(input('Enter score 1: '))
        score2 = float(input('Enter score 2: '))
        score3 = float(input('Enter score 3: '))
        score4 = float(input('Enter score 4: '))
        score5 = float(input('Enter score 5: '))
        print('---------------------------------------------------')
        print('Score          Numeric Grade   Letter Grade')
        print('---------------------------------------------------')
        print('Score 1:        {0}                {1}'.format(score1, determine_grade(score1)))
        print('Score 2:        {0}                {1}'.format(score2, determine_grade(score2)))
        print('Score 3:        {0}                {1}'.format(score3, determine_grade(score3)))
        print('Score 4:        {0}                {1}'.format(score4, determine_grade(score4)))
        print('Score 5:        {0}                {1}'.format(score5, determine_grade(score5)))
        print('---------------------------------------------------')
       
        average = calc_average(score1, score2, score3, score4, score5)
         
        alpha_avg = determine_grade(average)
        print('Average score: ', average , '             {}'.format(alpha_avg))
     
    #average calculating function
    def calc_average(score1,score2,score3,score4,score5):
        avscore = (score1 + score2 + score3 + score4 + score5)/5
        return avscore
     
    #grade determing function
    def determine_grade(score):
        if score < 60:
    	    alphascore = 'F'
        elif score >= 60 and score <= 69.9:
    	    alphascore = 'D'
        elif score >= 70 and score <= 79.9:
    	    alphascore = 'C'
        elif score >= 80 and score <= 89.9:
    	    alphascore = 'B'
        elif score >= 90 and score <= 100:
    	    alphascore = 'A'
        else:
            alphascore = 'Unknown'
        return alphascore
     
    #returning to the main function    
    main()

You can use format() on strings to insert text. Consult the docs.

I repurposed the determine_grade() function to act on each score, and then again for the average.

The scores you get from input() are now of type float, because that is what the required image suggests so might as well...

The only problem may be the spacing of the letter for the Average Score. It's dynamic data so it might shift to the left or to the right depending on how many characters there are for the score. You may want to poke at that.

As there doesn't seem to be a value suggested for the out of bounds grades, I just set it to return 'Unknown'. Refine that if you need to.

Note that you could also assign the number of scores required to a variable, then use a loop and perform the same operation for each one. The program becomes more extensible as it can cater for larger sets of data and you avoid hard-coded repetition.
I was working on networkx when I noticed we had no requirements.txt at that time. So, I thought of scraping entire package and listing all the imports, whether builtins or non-builtins. Later I had a thought of making it public. Please check it out and give suggestions :)
Spam bot?
he produces interesting videos but I cannot follow him because he tends to exaggerate a lot! All this movement, tone of voice... compare those to the people behind laracasts or khan academy for example.
The term 'pythonic' is overused these days.
There is also [rtv](http://github.com/michael-lazar/rtv). 

I haven't tried yours yet but I'll give it a spin.
Is it really pure Python if you are using numpy?
This is really awesome
Wow, super cool!
Are the algorithms for autocorrelation much harder to implement? Also has this worked for your needs or does it feel a bit buggy? 

I really want to make something that heavily involves pitch correction but I'm just not there yet in terms of programming ability/understanding of the specific problems I'm needing to solve I think.
Good work. I love anything I can learn about programming audio processing. Can't wait to tear this thing apart! I know some max/super collider. And some Python, but as for implementing them together, I've never tried tried music in python though. Super collider is amazing for making synths, but I hate the magic of it. The whole point is I want to learn how it works.


I've written code that does much the same thing as a side effect for my music visualization projects. [Here's](https://en.wikipedia.org/wiki/Harmonic_pitch_class_profiles) a wikipedia article that summarizes the algorithm.

Since it's running live in Unity the best way I could figure out to do it was getting the FFT of the sample once into a large array, then sum up each note's maximum frequency response in their respective pitch bands (which increase in size of course as you go higher). This gives you the total response in each given pitch class. As for why I used the maximum response instead of the entire amplitude of each pitch bin, I just found it looked better. There's a lot of variety in how these things, [Chroma features](https://en.wikipedia.org/wiki/Chroma_feature), are calculated.

This is much of the same approach employed by music recognition machines, so I figured that would give me good, distinctive visualizations that actually look different from song to song, and particularly genre to genre. I can also choose to make different keys distinguishable.

Then the fun bit is figuring out how to use that n=12 array of pitch amplitudes to actually make cool things! If anyone is interested, [here](http://travisdean.github.io/mez.html) is my page with some demo videos and some of my philosophy towards the art.
Cool! I wanna try this and compare against the [Hilbert transform](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.hilbert.html) for pitch detection. 
> Why does daemonizing the server change the cwd?

Because [that is one of the traditional steps of daemonizing](https://linux.die.net/man/1/daemonize).

> How do I fix it?

Use absolute paths, or change the current working directory yourself.

Create a small application that allows a user to input location data and displays the current weather information based on that location.  Allow the user to save the locations so they don't have to input them every time.

You could do it all of it client side as a SPA but use django/flask as your api:

- Proxy the weather calls to the actual weather API.
- CRUD the user's cities.
build a blog -- everybody starts with a blog
Djangogirls tutorial builds a blog and the official django tutorial builds a polls application. Those could be good starting points!
Errr.... Excellent presentation of the concept, but I have a MAJOR issue with the implementation you propose.

In the absence of a good trie implementation you'd probably go for a hash table -- a.k.a. as a dictionary in Python. The performance cost is that of:

- calculating the hash values 

- traversing whatever data structure (list? table? tree?) underlies the implementation of the dictionary.

A trie will help you avoid that cost if you implement it on a low level (i.e. via pointers to tree nodes...). Implementing the trie using dictionaries imposes on you again the overhead of hash calculation and lookup...
Nice read on tries but I had some issues with the solution you posted up on your gitlab link.

1. If you sort the words before storing them in the trie and then store the regular word in a list at the end of the trie you don't have to do any iteration trying to find a random anagram, you can just get all the anagrams and pick one at random.
2. Some random style stuff you probably don't want to hear from a random stranger on the internet but I found following the pep8 standard has made my code more readable by me and my teammates; ie most names are snake_case, you should use context managers when opening files, and if your function can't return a meaningful result it should probably raise an error.

Here is my simple solution:

    import random
    
    def generate_trie(words):
        root = dict()
        for word in words:
            word = word.strip()
            chars = "".join(sorted(word))
            node = root
            for c in chars:
                node = node.setdefault(c, {})
            node["words"] = node.get("words", []) + [word]
        return root
    
    def get_anagram(word, trie):
        chars = "".join(sorted(word))
        node = trie
        for c in chars:
            node = node[c]
        others = [w for w in node["words"] if w != word]
        if len(others) == 0:
            raise ValueError(word+" does not have an anagram in the trie")
        return random.choice(others)
    
    def main():
        with open("/usr/share/dict/cracklib-small") as f:
            trie = generate_trie(f)
        print(trie.keys())
        test_cases = ["are", "earth", "fringe", "impart", "limped"]
        for i in range(10):
            for word in test_cases:
                try:
                    print(get_anagram(word, trie))
                except ValueError as ve:
                    print("No anagram for {0}".format(word))
    
    if __name__ == "__main__":
        main()
    
Can I use Anaconda's package instead of Enthought's canopy? 
Used coupon code NOV1202 to drop it to $10
In "68 lectures spanning almost 9 hours of video", you can understand

    Regression analysis
    K-Means Clustering
    Principal Component Analysis
    Train/Test and cross validation
    Bayesian Methods
    Decision Trees and Random Forests
    Multivariate Regression
    Multi-Level Models
    Support Vector Machines
    Reinforcement Learning
    Collaborative Filtering
    K-Nearest Neighbor
    Bias/Variance Tradeoff
    Ensemble Learning
    Term Frequency / Inverse Document Frequency
    Experimental Design and A/B Tests

?

Sounds extremely extremely unlikely to me, but if it's true, sign me up!
Did anyone take this course? Would you recommend it?
This looks really interesting. Is this course enough to apply for entry level machine learning jobs?
Seems the content is packed and may well worth $19 for what if offers. Does anyone know if the access is permanent and they will not ever take the site down (well that's a bit optimistic) or at least I can download it locally?

I would probably add it to my knowledge base and give it a look during a high moon


Get your learning lineup ready with courses for only $12
Prices increase every other day until 11:59 PM PST on 11/25
Limited Time. Only available for a few hours. Don't miss out!
.
If recommend reading PythonÂ Programming: An Introduction to Computer Science by John Zelle, it's pretty good 
The very first thing I did to cut my teeth on Python was the Python course from Code Academy: 

https://www.codecademy.com/learn/python

Its a decent interactive overview to the very basics of python.  

From there Automate the Boring stuff is a good next step, but it will likely take longer to get through the book whereas Code Academy you can hammer out in a day or so. 
I have heard great things of Automate the boring stuff with Python,  so I think that's a safe bet. However I haven't heard of the latter, so don't take my opinion as infinite wisdom!
Is Automateing boring stuff better because it focus only on Python 3?
I have both and Automate may be better if you are totally new to Python but not programming but that's subjective (I liked Part II very much). 
Python Crash Course may have a better Part I if you are new to coding (it's very detailed) but I didn't like the Part II (projects) very much.


BTW you don't have to learn Python on the Raspberry Pi, you could code in any platform and run your programs in the Pi.
If your brand new to programing like me, I suggest

https://www.coursera.org/learn/learn-to-program/home/welcome
If you are a noob, then you should look at an intro python course.
FYI, I've read that you should still use a venv to install python deps, even when inside a Docker container.
Check out pycharm community edition.
Use the notebook to develop the code to start off with. You'll learn quicker with the fast feedback.

When you've made something substantial, factor it into a module and import it in the notebook to continue working on new parts.

If you know your editors well, then use an editor of your preference. I'm partial to vim.

If you're not familiar with your editors, then maybe try a notebook.
Doing science?  Install the [Anaconda3](http://continuum.io/downloads) distribution, then use `jupyter notebook` to try out ideas and test small bits of code.  Once you've got more than a few paragraphs, fire up `spyder` (a matlab-like python environment) to turn your code into an easy-to-execute program.

Basically the notebook will serve you very well until you need to write a program you can call from the shell, and then it's time to write some `.py` files :)
For a research project, I think a notebook is much better. Jupiter notebook is super easy and great for research-type code, where you're testing out and prototyping small chunks at a time. If it will be converted to a module/library/webapp then you should eventually use an actual editor.
Jupyter is hands down your best bet IMHO. I'd say I do 90% of my development in Notebooks.

It's a very straight forward and easy to use REPL and designed for research.

https://www.youtube.com/watch?v=G3mwNnGu5T4
I personally use a combination of both. The notebooks are create to prototype and to visualize things. However, when you are writing lots of code they tend to get cluttered pretty easily. My workflow looks like that: I start trying out things in a notebook. In the next step I start to refractor parts of it as functions and classes as needed. If I think, that one of these parts is important and reusable, I copy it over into a python module, I write in parallel for the specific project, I add documentation, clean up the code and maybe add unit test. As a module has multiple files for structure, I am using an Texteditor or IDE for that. In my notebook, I just import my module and and use the cleaned up functions. At the end, I have a readable notebook to present the project and a reusable module, that has all the tools needed to build a new similar one. 
It depends on what you want to do with it.

If you are analyzing large amounts of data and need a lot of intermediate results to know what to do next, an ipython notebook is great. You can copy&paste the code into a python file later.

In most other cases, or if your dataset is small and you can re-run your script fast enough, I'd prefer an editor. 
1. If all you want is to test out the syntax, you could use [repl.it](https://repl.it/languages/python3). This is an online editor in which you can actually execute your code and see the results. If you make syntax errors, it will also tell you. And you can also import packages.
2. Now, you could also simply [install Python](https://www.python.org/downloads/) on your laptop, then start the Python interpreter (console) and play with the syntax however you want.
3. As a complement to your course, I suggest you to get a good Python book, such as [this one](http://www.diveintopython3.net/).

As a side note: this type of question should be asked under /r/learnpython. You will probably get even better answers there, because people are used to answering beginner questions.
These guys recommending jupyter notebook are giving you good advice.
Cheers everyone, Anaconda3 looks the way to go
Emacs will be the best if you want fast results.
No.
Finding a good editor will help (like pycharm).  However, there is more to learning a language than the base syntax, there is also the "right way" vs the "wrong way" of doing things.  This is even more important with python which is very strict about its syntax.  I found the book 'Idiomatic Python' invaluable in helping both learn the syntax, and learn the "right way" for things.  You can also load a module 'pylint' that will tell you how good your code is.

Depends on what you are doing.

If you are developing a module, library, or working on a larger project use an IDE like Pycharm.  The code intelligence and refactoring tools are invaluable in navigating/modifying a more sophisticated codebase.

If you are only working on one moderately-sized script at a time, only USING modules someone else has developer --or-- are doing purely interactive work, Jupyter notebook is a better option.

In keeping with this philosophy, I typically develop my modules entirely in PyCharm and put the interactive usage examples for end users into Jupyter notebooks.




Wrong sub. Go to /r/learnpython
it's urllib :) 
And it's just 2 extraneous last characters wrong?
An explanation and an example of the correct approach would make this post much more helpful. Is this specific to python 2?
How about overriding the `excepthook`?

    >>> import sys
    >>> def hook(*args, **kwargs):
    ...     print('An error happened!')
    ...     return sys.__excepthook__(*args, **kwargs)
    ... 
    >>> sys.excepthook = hook
    >>> 1/ 0
    An error happened!
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ZeroDivisionError: division by zero
    >>> int('no integer')
    An error happened!
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
    ValueError: invalid literal for int() with base 10: 'no integer'

Now you can execute every code you like before a error happend. Mail you the error message, log every error, pushing it into a database and so on. `sys.__excepthook__` is the original hook.

As a little note, this doesn't work good with jupyter and ipython, because both already override the original python message with their more detailed traceback.
You submit this garbage "blog" post where you're just listing links from this very same sub. And didn't even change the title. Oh okay, there's "original content" in the blogpost: the advertisements you've put in.


Title | Previous submission | votes
---|---|---
PSA: Check this site , it has tons of usefull Python cheat sheets | PSA: Check this site , it has tons of usefull Python cheat sheets [2 days ago](https://www.reddit.com/r/Python/comments/5c0myl/psa_check_this_site_it_has_tons_of_usefull_python/) | +52
Data Science and Machine Learning with Python - Hands On! | Data Science and Machine Learning with Python - Hands On! [1 day ago](https://www.reddit.com/r/Python/comments/5c7gfr/data_science_and_machine_learning_with_python/) | +215
6 things to develop an efficient web scraper in Python | 6 things to develop an efficient web scraper in Python [5 days ago](https://www.reddit.com/r/Python/comments/5belws/6_things_to_develop_an_efficient_web_scraper_in/) | +138
Whatâs new in Celery 4.0 (latentcall) | Whatâs new in Celery 4.0 (latentcall) [5 days ago](https://www.reddit.com/r/Python/comments/5bfwfe/whats_new_in_celery_40_latentcall/) | +127
Heap automates away the annoying parts of user analytics. No manual event tracking. | n/a: it's an advertisement | 
3 Reasons For Pythonâs Explosive Growth | 3 Reasons For Pythonâs Explosive Growth [3 days ago](https://www.reddit.com/r/Python/comments/5btt3x/3_reasons_for_pythons_explosive_growth/) | +57
OSMnx: Python for Street Networks. A package to download, construct, analyze, map, and visualize urban street networks from OpenStreetMap. | OSMnx: Python for Street Networks. A package to download, construct, analyze, map, and visualize urban street networks from OpenStreetMap. [4 days ago](https://www.reddit.com/r/Python/comments/5bn6wy/osmnx_python_for_street_networks_a_package_to/) | +76
Date and Time Manipulation - You're probably doing it wrong. | Date and Time Manipulation - You're probably doing it wrong. [4 days ago](https://www.reddit.com/r/Python/comments/5bijdi/date_and_time_manipulation_youre_probably_doing/) | +45
New Python podcast: Python Bytes Python headlines delivered to your earbuds | New Python podcast: Python Bytes Python headlines delivered to your earbuds [2 days ago](https://www.reddit.com/r/Python/comments/5bvtq1/new_python_podcast_python_bytes_python_headlines/) | +68
Some thoughts on asynchronous API design in a post-async/await world | Some thoughts on asynchronous API design in a post-async/await world [5 days ago](https://www.reddit.com/r/Python/comments/5bdf48/some_thoughts_on_asynchronous_api_design_in_a/) | +44
Introduction to Random Forests in Python | Introduction to Random Forests in Python [3 days ago](https://www.reddit.com/r/Python/comments/5btwdl/introduction_to_random_forests_in_python/) | +45
Looking for a job? Join Honeypot and let companies apply to you... | n/a: it's an advertisement | 

And you're doing the same thing across different programming subs.

* [In /r/elixir](https://www.reddit.com/r/elixir/comments/5cdlvf/awesome_elixir_newsletter_week_25/)
* [In /r/java](https://www.reddit.com/r/java/comments/5cdlah/awesome_java_weekly_issue_26/)
* [In /r/node](https://www.reddit.com/r/node/comments/5cdln8/awesome_nodejs_weekly_issue_26/)
* Here in /r/python
Use the subprocess module, maybe a bit like this: http://stackoverflow.com/questions/5469301/run-a-bat-file-using-python-code
Your problem in an attempt to edit DB at one moment.

> But only one process can be making changes to the database at any moment in time, however. (http://www.sqlite.org/faq.html#q5).

Or maybe because that you don't use method like beginInsertRows, beginMoveRows, etc (http://doc.qt.io/qt-5/qabstractitemmodel.html#beginInsertRows) in your Qt app.
It's hard to say without seeing any code, but (if i understand the problem properly is that sqlalchemy doesn't return updated data from your queries) I ran into a similar issue in a flask application. 

I had accidentally instantiated sqlalchemy twice and was using them both. Which meant queries would return only the data in the db at the start of the app.
If I'm not mistaken, PyCharm has this feature built in, and it makes for some very professional and nice looking code (Albeit I am certainly guilty of ignoring some of the capitalization conventions...)
I love linters, and use flake8 in Atom. I think it should be noted though that you should understand why your errors happen, before you fix them. I have definitely had the linter outline errors that are not actually a problem.
The problem is that you have installed Python 3.6 but you tried to run Python 2.7. Try:
 

    python file.py

    py file.py
    
    file.py

    file

Any of these commands should work if you are using Windows.

[/rlearnpython] (https://www.reddit.com/r/learnpython/)
Another tip: Use powershell, not cmd
Save yourself a lot of trouble, and install the [Anaconda distribution of Python](https://www.continuum.io/downloads).  
The python installer doesn't add the bin directory to the path for some reason. You can add it yourself if you can find it. I've had a couple installs that didn't get put into C:\Program Files (x86).
This is why I always suggest WinPython.

Extract it. Double click the CMD.

Run everything in there.
I would try to get Linux running. Comes installed by default on ubuntu and fedora. I'm not sure if you've used Linux or not, but if you can at least get it running in a vm you'll have a much better developing experience.
Are you using requests or selenium.  Selenium looks like a user but they might not be sophisticated enough to be fooled by that. In general it's polite to add a delay proportional to server response time. Use a random delay. Wait for 10 seconds every now and then. But, you are a bot and are violating their TOS and are their enemy.  Use tor or change IP every now and then.
proxymesh.com
very cool and helpful!  

Wish it was 3.5 though
2.7 what is that?
> Simple Diffie-Hellman key exchange

This is a rather insecure example with extremely low primes. I mean it's fine as a toy exercise but why would this belong to a cheatsheet ? You should really be using a crypto library for something like this.
Looks like 2.7 and not 3.5+?
Theoretically, if you made enough cheat sheets, you would proactively generate every possible program. Then it's just a matter of indexing.
Wow! Surprising me! 

When I open the link, it's my demo website! 

There are a lot of topics which I do not finish yet...

Anyway, thanks for sharing it !!!

  
i think this is even more helpful than the learn python the hard way book 
Useful*
This is a super cool reference. I don't know if I've ever seen a resource structured quite like this.
[deleted]
The rows of Pascal's triangle follow n choose r for row n and element r;

    def factorial(x):
        y = 1
        while x > 0:
            y *= x
            x -= 1
        return y
    
    n_choose_r = lambda n, r: factorial(n)/factorial(r)*(factorial(n-r))
    row = lambda n: [n_choose_r(n, r) for r in range(n+1)
    pyramid = [row(i) for i in range(p)]

This is faster if you want a specific row instead of the whole triangle, if you want the whole triangle it might be faster to use the previous row to calculate the next row.
Why do you need to improve performance of your code?

What I would do first is to initialize pascal_piramid with two first rows and simplify the rest :)
Cheers for this, it looks interesting :D
Thank you so much brother.
Very nice, it is great to see so many people sharing the information they have about Python.
no idea about parsers, but you could try farming the conversion job out to let's say libreoffice

    lowriter --headless --convert-to html hurrdurr.rtf
    lowriter --headless --convert-to txt hurrdurr.rtf





too bad i missed the giveaway. Can you please share another one for me :)

I just bought it for 10$! IÂ´m really curious to see what pandas has to offer.

I have been using pandas for 6 months now, but it always amazes me how much it can do. 
Learning to tell people to fuck off is a lost skill in the open source community. Most FOSS dev are too nice, too respectful and PC. You need to learn to send people go to hell, and realize your life is yours, and you don't own anybody anything.

That doesn't mean you don't have responsability. You should always be respectful with people that are. But any asshole deserve a swift kick in the butt or being ignored if you don't want to spend the energy.

You give a part of your life to make something free and good for others.  Do not feel guilty. Do not try to analyse if your behavior was correct or not. There is no doubt to have here. Respecting yourself is the fondation. 
As a consumer of a OSS project, you are a guest in someone else's house. You'd better behave while your there.
I completely understand his stance, and see how contributing to a very successful open-source project could lead to this kind of situation. 

I also understand that Python is not officially backed by some big companies (I mean full-time), just like .NET or Java. Some core developers appear to be paid to work on Python (like [Guido](https://gvanrossum.github.io//)), and some companies appear to sponsor development sprints of Python, but I guess that the majority of the time spent on Python is the result of [volunteering](http://blog.python.org/2016/09/python-core-development-sprint-2016-36.html).
On the other hand, just because you don't like the tone does not mean you should ignore the comment for what it is worth. If the guy has a point, he got a point...
first ask yourself what you want to do with python. then ask yourself if you want just a book, a video course or something more interactive.

Since I've learned Python as part of doing NLP research, I found the NLTK Book a great place to start. But if your goal is not NLP, it is a terrible place to start.

I also found Udacity's CS 101 where they build a web crawler, great (they keep changing their website, so I'm not sure if it is still called CS101 - and they probably have several CS101 now...).  

Short informative videos followed by interactive problems, followed by informative explanation to said problems. Each problem builds on top of the last one as you slowly build a piece of usable software. No need to install anything, as you use a python interpreter inside the browser. One of the best web courses I've ever tried.
If Python is your first programming language, http://greenteapress.com/wp/think-python-2e/ is fantastic.
I just started on [this](https://pythonprogramming.net/) website.  So far I have liked it.  He's got tutorials going from the basics to raspberry p1 and all the way to tensorflow and AI. 

I already have some coding experience but I think the basics tutorials are still easy enough to understand.

Happy Coding!!!
Sounds terrifying, I struggle on 15".
You can always get a non-Apple laptop with liquid-safe keyboard. Some business models have such protected keyboards as well as up to quad i7 CPU with other goodies.
I use pycharm + chrome with multiple tabs + terminals on my 2011 macbook. MY biggest suggestions would be, if you can afford it, get a mac with an SSD (or upgrade the drive yourself) and have at bare minimum 8Gb ram. You can tune the JVM settings for PyCharm to allow use of more RAM.

I haven't run into any debilitating issues with sluggishness just yet. Obviously its slower on my laptop compared to my skylake desktop with 16gb ram, but not so much slower that its really detrimental to my work.
Judging by benchmarks [this](https://browser.primatelabs.com/v4/cpu/search?q=2013+macbook+air) and [this](http://barefeats.com/images16/lowlap_gees.png), the CPUs are about the same speed in the new machine vs the old one. However the supporting tech like the SSD and whatnot will be quicker.
I think you'll find that the macbook is meant for really good performance on short sprints, and not a long marathon. I would suggest you either replace it with a Pro model (my personal preference, one without that totally ridiculous touch bar, probably) or get yourself another air. My 13" pro runs a setup pretty similar to yours, but most of my work is done managing a doc. management program, or working on excel and tweaking macros. edit: clarity.
I have the first gen Macbook 12" retina (the slow one, base model).

I do not run PyCharm or Django, however I have fairly large Flask projects and use MacVim (along with Mysql/Mongodb), and a fair bit of kivy. I live with a few terminals and safari windows (plus all my background geeklets), and never have had a problem with regards to performance in development. The biggest problem I have had with it is screen size, but the core-m hasn't affected me on any of the projects I have worked on. 

I will admit however, if I could do it all again, would have gotten a pro. Foot print isn't much bigger, and not sure how long the core-m will stay relevant.
I used to work on a 11" MBA, worked fine for me (and I'm a tab-o-holic). I would worry more about MacBook performance.

That said I'm now using a 15" MBP and oh my god it's so much easier - but heavier to carry around.
You may also want to research good laptops for hackintoshing. I see very little professional value in the new macbooks
*Side effect: Might summon Cthulhu*
Are sourcemaps supported?
It would be awesome to see some integration between Transcrypt and Jupyter Notebook. Sometimes it's useful to write some client-side Javascript, but it would be even better to be able to write it as client-side Python.
Oh, wow, you translate pseudocode into pseudocode?

I'd be more impressed if you wrote something that could translate JavaScript to Python, what with all of the mindfuckery that can be done in JavaScript.

Edit: to be clear, this is still cool, I just wonder who there is out there who can't learn Javascript.
I'm sorry that I can't answer directly but does this [Why is my compiler not recognized](https://devtalk.nvidia.com/default/topic/672002/why-is-my-compiler-not-recognized-/) help?
there is not api ? 
Oh man, I can't wait to try it, thanks! 
Non-technical founders, producing a web based product?

I think that if your candidate accepts the job, you shouldn't hire them.
Consider shelling out the money for an interviewing/recruiting service.

This person could make or break you.  And you don't have the knowledge needed to technically vet them.

Perhaps find local experts in your area and contract them to do the technical interview for you.  (I'd do it for beer, honestly)
No.
To be honest it depends on the technology you are intending to use. Do you have something specific in mind or would it be up to the developer?

I would ask what languages and frameworks he knows. What are some of the advantages of his favorite framework compared to others?
What are some of the projects he has worked on previously? What is his approach to code testing?

How much experience does he have setting up and hardening a server? If he uses any server side language that is not PHP, how does he deploy the app? Does he know how to configure an http server like apache or Nginx? What is is favorite stack (e.g. LAMP, WISA, MEAN, etc)?

If none of you has any technical insight it is gonna be hard for you to evaluate his answers tho. I would consider asking somebody with knowledge in the field to sit in with you in the interview. As a startup, getting the wrong guy might be fatal. 

Edit: I just realized we are in the python subreddit. A few more questions:

What are some common Python web frameworks? What is the difference of approaches of Django vs Ruby on Rails? What are some of the key differences of python vs say java? Ask him to program something like fizzbuzz. Ask him to write a short script that calculates the sum of all the primes lower than 1000. 

If he has major issue with any of these questions, it might be a red flag. 
I forgot about wxpython or tkinter when I picked PyQt4 ;)
When you says in step6 *Now compiled and run the python program*... why you need to *compile*? 
I forgot about wxpython when I couldn't work out how to use it with Python 3.

IMO the big ones are PyQt, Kivy and Tkinter. Plus whatever that one is that does Android/iOS, the name of which currently eludes me.
Plugging py.test again here:


``py.test --durations=20`` will show you the slowest tests (with setup/teardowns included). You can also do some simple profiling (you can adjust the level of profile by changing the scope):


    @pytest.fixture(scope='class')
    def profile_suite():
        """
        This fixture will profile a full test class and dump the results to log.info
        after the test is fully run (sorted by total time).
    
        use via @pytest.mark.usefixtures('profile_suite')
        """
        import cProfile
        import StringIO
        import pstats
    
        profiler = cProfile.Profile(builtins=False)
        profiler.enable()
        yield        
        profiler.disable()
        stream = StringIO.StringIO()
        sortby = 'time'
        LOG.info("Dumping profiler stats: ")
        stats = pstats.Stats(profiler, stream=stream).sort_stats(sortby)
        stats.print_stats()
        LOG.info(stream.getvalue())


One quick example from a project I worked on:

    plugins: hypothesis-3.6.0, assume-1.2
    collected 68 items

    test_attr_conversions.py .........................
    test_attributes.py ....
    test_auto_c_array.py ...........
    test_encryption.py ..
    test_mechanisms.py ..........................

    ========================== slowest 20 test durations ==========================
    0.23s call     tests/unittests/test_encryption.py::TestEncryption::test_get_string_from_list
    0.20s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_long_list
    0.17s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_ulong_list
    0.17s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_to_sub_attributes
    0.16s call     tests/unittests/test_attributes.py::TestAttributes::test_full_dictionary
    0.14s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_to_byte_array_list_fail_big
    0.14s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_char_list
    0.13s call     tests/unittests/test_attributes.py::TestAttributes::test_rand_dictionary
    0.13s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_to_byte_array_list_fail_neg
    0.12s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_byte_list
    0.12s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_to_char_array_list
    0.11s call     tests/unittests/test_attributes.py::TestAttributes::test_null_dictionary
    0.11s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_no_type_fail[c_byte]
    0.11s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_ubyte_list
    0.11s call     tests/unittests/test_encryption.py::TestEncryption::test_split_string_into_list
    0.10s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_c_byte_array_to_string
    0.10s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_no_type_fail[c_char]
    0.10s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_no_type_fail[c_long]
    0.10s call     tests/unittests/test_auto_c_array.py::TestAutoCArray::test_auto_c_array_no_type_fail[c_ubyte]
    0.09s call     tests/unittests/test_attr_conversions.py::TestAttrConversions::test_to_byte_array_list
    ========================== 68 passed in 4.42 seconds ==========================
You might wanna look into the librosa library and the topic of music information retrieval. There's a **lot** to explore.
Love all the talks in Talk Python To Me, excited for this podcast as well! Keep 'em coming!
PSA: it's already available on podcast addict
> delivered to your earbuds

You monster! You're discriminating against normal headphone users! What are you, narrow-minded?

(JK, because some people on the internet can't read a joke. ;)
Is it a replacement or is it complementary to Talk Python To Me?

I hope both stay. What is the difference between the two podcasts? 
Great podcast, looking forward to more. 
probably the worst day to release this
I have been working on a NLP project where I needed to identify different forms of the same word. Typically, this is done by Stemming and Lemmatization. These methods are not accurate, and I needed high accuracy in my project. Since I found no libraries/packages that can do this, I decided to write a Python package myself. It works quite well now. Feel free to check it out, I would love to hear your feedback.
There are some inconsistencies with ambiguous words:

    In [12]: get_word_forms('will')
    Out[12]: 
    {'a': {u'willing'},
     'n': {u'will',
      u'willing',
      u'willingness',
      u'willingnesses',
      u'willings',
      u'wills'},
     'r': {u'willingly'},
     'v': {u'will', 'willed', 'willing', "won't"}}

    In [13]: get_word_forms('would')
    Out[13]: {'a': set(), 'n': set(), 'r': set(), 'v': set()}

    In [14]: get_word_forms('can')
    Out[14]: 
    {'a': set(),
     'n': {u'can', u'canneries', u'cannery', u'cans'},
     'r': set(),
     'v': {u'can', "can't", 'could', "couldn't"}}

    In [15]: get_word_forms('could')
    Out[15]: {'a': set(), ân': set(), 'r': set(), 'v': set()}

Edit:
Also this is unexpected:

    In [21]: get_word_forms('robot')
    Out[21]: {'a': set(), 'n': {u'robot', u'robots'}, 'r': set(), 'v': set()}

    In [22]: get_word_forms('robotic')
    Out[22]: {'a': {u'robotic'}, 'n': {u'robot', u'robots'}, 'r': set(), 'v': set()}

    In [23]: get_word_forms('browse')
    Out[23]: 
    {'a': set(),
     'n': {u'browse', u'browser', u'browsers', u'browses'},
     'r': set(),
     'v': {u'browse', 'browsed', 'browses', 'browsing'}}

    In [24]: get_word_forms('browsing')
    Out[24]: {'a': set(), 'n': {u'browsing', u'browsings'}, 'r': set(), 'v': set()}


Btw, look into "path similarity" from wordnet. It might be a nice direction to next. I've implemented a few lines of code that will do pretty smart "matching". We used a cutoff of 0.5.
"Politician" has "politicss" as a result, which I don't think is a word.
No.
What is that doc browser he's using at [33:06](https://youtu.be/qL19PoZEMX4?t=1986)?
Pythonista app is really good get the newest version supports python3 and 2

Pythonista 3 by omz:software
https://appsto.re/us/XxRUab.i
Awesome. Thanks a lot. I think I'll give it a shot!
Python is a language that allows this to happen:

"Hmm. I bet you I could write a script to automate that repeated process we do here in HR.  I used Python for a few months back in college and feel like I could put something together in a week.  You won't have to hire a developer or contractor. I know that you're an HR manager, not an engineering manager, so that would be a non-start."

And then later:

"Wow. That script Chip Dipson wrote really is saving us some time. I wonder what else we can automate? Maybe we should consider a part time position for this!"

And so forth...

Adding Python to your business is so non-committal.
I think the 1st and 3rd reasons (Growing Community and Universities Teaching) are basically effect  - not a cause. 

Simplicity is the most fundamental reason (cause) for explosive growth and adoption of Python.

**Python is *elegantly simple* and *simply elegant*.**

Nice info though. Thanks!
When I was in college they taught us C++ and I got a 10/10 but didn't become a programmer. I picked up Python a year ago and am now regularly using my scripts at work in a department that has come to rely on them... Wish I got more into it 10 years ago
I see Python has grown quickly for 3 different reasons:

1. **The REPL** -- [The Read-Eval-Print Loop](https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop) -- There's another popular language that allowed us to do this much the same way: BASIC. If you're a n00b, the REPL is super important for quickly figuring out how to code. As such, both languages have had quite a long run of popularity because it's been easy for people to pick up and try out.

2. **LOTS of Libraries** -- I think xkcd summarized it best here: [**Guy1**: But how are you Flying? **Guy2**: I just typed `import antigravity`](https://xkcd.com/353/)

3. **The Hype Train** -- For anything to really succeed, there has to be at least a little bit of cheerleading. At the risk of being downvoted, I'm gonna say that Python has a bit of the Hype Train thing going on.

Don't misunderstand me. Python is a really good language (that I code in almost every day.) Hype isn't a bad thing. You need just enough to keep things interesting. 

Or maybe, I should say that there's been enough continual development in the language and a willingness to improve (version 3.5 and formal Type Hinting, finally!) that makes Python something you feel like you can invest yourself in.

Now if only we could get the Python 2.7 lovers to finally come over to Python 3...  :)


For me it was just that blender had a built-in python interpreter.  DAE?
To all people in this thread commenting on Pythons quick growth...

Remember, Python is 26 years old. Older than Java, older than PHP, older than JavaScript.  2.0 came out 16 years ago.

I've been using it around 20 years. It's had explosive growth at least twice, around Django/web dev, then bioinformatics which sort of merged grew into larger scipy phenomenon.
I'm working on my next little project exclusively in my 1.5hr (to/fro) commute time. Coding using Python on an iPhone.

Doesn't get simpler than that.

Python to me is natural and super quick to get to from Zero to 60!
1. Usability in data science

2. Accessibility in data science

3. Jobs in data science
I think this is just great. I'm an experienced php developer by trade but overall it seems that python is a much better language & community. I even attempted to switch my career to Python before but got pulled back in to php.  
1. SciPy
2. Numpy
3. NLTK

The Python language is easy to grok and pretty easy to get into. The above libraries have got to have a huge impact on Python's popularity. A whole generation of people seem to have discovered k-means clustering...I mean machine learning and the three libraries above make it approachable for non-traditional programmers.
You can concentrate in "what the code does" instead of "have I written it correctly?"...changes the focus from its grammar to its usefulness.
[Live demo here](http://185.164.138.19:7311/).

Note: it's a *test* channel, unmoderated. So you can expect anything to happen there, people claiming to be anyone or me and saying s**t...

[Another live demo](http://185.164.138.19:7312/) in case the first is broken.
> easy to install

Nope. Please learn about `setup.py` (so the user can do `pip install -e .` to install the project with its dependencies), or at least put the dependencies into `requirements.txt` as it's usual for Python projects.
hi i have a question. can i implement it into web applications like for personal websites or blogs? Good job on this project!

[deleted]
> But what is helpful are the few really good decision trees that you also generated along with the bad ones.

You wouldn't call any individual tree per se wrong or right, what matters is that averaging over them will yield good results. You mention something similar later on, but this sentence is just wrong.

I do agree that it is very useful, and it is usually the first model I try alongside a linear one.
I would recommend using a random seed (`random_state`) for people who want to reproduce the results (e.g, here, it's used for the bootstrap sampling, feature subsampling, and tie-breaking, ...).
Can someone explain or point me to a simple real life example where it solves actual real life problem? All I can find is overloaded with abstractions without explaining what data we put into algorithm and why.
[Is it me or is there something weird going on in this image?](http://blog.yhat.com/static/img/log_lm_vs_rf.png)
1. Go to /r/learnpython
2. See the Numpy docs, e.g. [numpy.std](https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html).
I must admit, I already like this because of the home page, and I haven't even figured out what it is yet. Nice work!

**EDIT:** Though the docs for jam.py itself are a little too far nested. I mean, some of those individual pages could easily be joined together. Feels like trying to navigate a jungle...
Sorry for the incomplete answer, but tf-idf could be useful here. Perhaps you could bucket the entries by month or week and then find the words with the highest tf-idf values for each bucket!

https://en.wikipedia.org/wiki/Tf%E2%80%93idf
Depending on what data is captured in this journal you could look at trends in: words per post (probably at a min num chars), time ranges that you post/write, references by category (work, significant others, mental state, etc; by associating certain words to those categories).
You could also just use your browser history to answer that for you :)
If this is a long-term project, I recommend looking into org-mode in emacs, it is extremely good at both capturing and preparing into an analytical form these kinds of things. Lots of these features are made simpler/more cohesive under its framework. Since it's all plain text you still have Python (if you don't want to learn elisp) to analyze your collections.
Sentiment* ~~semantic~~ analysis would be good! I'm not sure of any Python packages I'm afraid (I don't analyse this kind of data) but I'd be surprised if there weren't any.

A bit basic but a word cloud?
What program are you using for your online diary? 
Saying that a tuple is like a list in one of the first few sentences is very confusing.
>>holds different immutable objects
Nope. Is itself immutable. Example you put a dict inside a tuple and the dict can still change.
Are there any more details? Maybe it could understand Pandas dataframes?
Just announced at TC16
Mwahahahahaha!

I now have both Python 101 and Python 201! FOR FREE!

Mwahahahahaha! 

:D
You made my day and it's amazing contribution but I think you should call it "pay what you want" kind of offer. That  way maybe more people would chip in, $15 per book is steep for many and if you call it "free" then by default people won't pay.

My plan is to go through:

* [A byte of Python by Swaroop C. H. (free)](https://python.swaroopch.com/)
* [Python 101 by Michael Driscoll](https://leanpub.com/python_101/c/48hours) (free if you are lucky)
* [Automate the Boring Stuff with Python (free + purchase option)](https://automatetheboringstuff.com/)
* [Python 201 by Michael Driscoll](https://leanpub.com/python201) (free if you were lucky)


PS Learn Python the Hard Way is for Python 2 so no thanks and stop recommending it.
Thanks. I was planning on looking into learning Python and this gave me the incentive and resource to get started.
    from datetime import datetime
    import time
    title = "Python 101"
    if datetime.now():
        for free in range(1, 48+1):
            print("{0} is free".format(title))
            time.sleep(60)

Hi Driscollis

Thank you for this offer.

If I like the books (101 & 201) when I find time to read them I plan to reimburse / support your future releases.
I just wanted to say that this isn't your usual free O'Reilly twenty-page booklet, but a full 300pg. book.

I too will reimburse the author if I find the book useful. 
Thank you. 
Thank you so much!!
Very nice. Thank you!
Thanks!
Why "101" ???
Thanks man. As I am a kid will it be simple enough for me to learn and use in conjunction with what I learn ay school
Thanks for making it available for free! I have been out of work on medical leave and money is super tight. I've been trying to make good use of my time while sick learning :)
Well isn't that nice of you, thanks a million Mr. Driscoll.
Hi,

Thank you for this offer.
But I only can download Python101 as a sample (10 pages)?
I use the link you have provided   http://leanpub.com/python_101/c/48hours

I know will like the books, if I ever get around to it :'(. 
But the 101 in my library is an extra incentive to start easy one day.
And when I do, I'll chip in.


  


Good!
I will take advantage of this once I get home, thanks!
Thank you!
Thanks. Downloaded. I'm teaching my girlfriend how to code, this may come in handy! :)
Thank you. I will read this and if I like it I will buy the second.
Superb! Thanks, was just starting out in Python!
Happy to see thisï¼I just learnt 5 hours from âlearn python in x minutesâã
Bought it. Thanks for coupon.
How is your book better than all the others out there? Including those recommended in the sidebar?
Thank you!
Oh yes thanks man :))
Please, notice that you only need an email for the download. No credit card info or anything else needed

This is important for people like me that tend to not bother at all when the word **FREE** is present :)

Ive been programming in python for a while now, but wanted to go deeper. Im currently reading the official python3 tutorial which I thought it was going to be too basic for me, but where i learned a few thing already and fluent python, which is intermediate level and im enjoying very much

Ill skim your book to see if I can find something interesting :)
this is perfect thanks so much
I love you!
Just got it, thanks for the offer!
Thanks, man!
Thanks a lot for your book! I'm liking it so far, it has a decent pace for an intro book as someone new to python but not to programming.

Are you planning on writing any more python books?
What is the difference between python 2/3 or if there is a python 1? I'm getting into coding for bioinformatics. 
Thank you so much!
Heads up /u/driscollis, something is off with the styling on the bottom of your blog homepage. getting some overlapping text.
Thanks!
Thanks, I've just started learning Python and this is perfect. Thanks a million. 

Do you plan to do any videos for the lessons?
Thanks a lot!

I got Python 201 a while back thanks to your similar offer.

Now that I have downloaded both, is it possible to make a donation at a later stage?

I saw that someone mentioned âPay what you want/canâ, it might be a viable option too: I've bought a lot of bundles, including one with a lot of Python books on Humble Bundle, because I could choose the price and decide who (author/developer, staff, charity) was getting how much.

Thanks again for sharing this!
Thanks so much! Got Python 201 as well when you offered it for free for the same amount of time a while back. Really appreciate you doing this! :)
This is amazing. You're amazing.
First 201 and now 101. Thank You very much!
I also got the Pytho  201 free a while back. Thanks for this one too. Planning on doing python professionally and this will b great help  THANK YOU
Thank you /u/driscollis
i get 101 and 201 for free, thank you very much!
p.s.: love the covers of those books :D
Thank you much. I hope to put some time aside to read this.
> While it is intended for beginners, some have claimed that they needed more hand-holding than this book provided for them.

I can understand that. 

I was wondering if this book was something i could give to a friend that wanted to start programming, and my conclusion was that it's not. 

It's a decent book if you already know how to program and is curious about Python, but not much help in learning programming itself.
Thanks!
Thanks!! I also got your other book Python 201 :)
OP good guy
Damn, I bought Python 101 when Python 201 was free.

But at least I supported the author :)
Wow.. thanks! 
Great. Downloaded :) I just need your sequel now. For free, please! ;)
That's very nice of you. Thanks!
Thanks a bunch
Have shared it with a couple of people already and will do it again when i get home, thanks for this
Thanks! Guess I just need to buy and read the other 101 books. 
Thank you!
Has anyone here read or reviewed this? Free books most often aren't very good.
If you have an open source python project you can display your download statistics on github by hosting this flask app on heroku and linking to it from your README: 

    ![download stats](https://my-heroku-project-id.herokuapp.com/)
Well, now you have enough grasp of the language to write something so... find a personal project to explore and go ahead! It doesn't have to be fancy or super-mega-useful or make-me-filthy-rich, just something you think you may use and then write it in Python.
Build a project! Something meaningful that you're interested in and that you'd be happy to show to a potential employer as a part of your portfolio. When you've done a few of these, (feel free to ask for help or reviews here), you can start throwing your resume and portfolio at companies to see who will bite. There's a whole lot of demand out their for capable programmers, and nothing is better evidence of your capability than projects done well.

I'd suggest creating a github account, getting familiar with git, and look into creating and hosting some basic web projects with [Pages](https://pages.github.com/) for free. Maybe there are some small businesses near you that you could help out by creating something that integrates with gmail, or maps, or spreadsheets, or etc.
/r/dailyprogrammer
Learn to make Web scrapers and sell them online.
Go forth and destroy!
Find something you need to do.

Do it in Python.
What do you do aside from programming?
X-Post referenced from [/r/datascience](http://np.reddit.com/r/datascience) by /u/rubik_  
[First project: exploration of Texas Death Row data](http://np.reddit.com/r/datascience/comments/5af1t2/first_project_exploration_of_texas_death_row_data/)
*****  
  
^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
omg ser
that guy needed a "tall glass of shut up"
wrong place, post on r/learnpython
You are welcome to share projects that you have written here, however, if you're asking for help or critique, you should probably consider submitting to /r/learnpython instead.
First, this is a very good talk and he makes a number of valid points.

The reason the talk itself was unclear, in many respects, is that the 'problem' he's talking about (exposing internals) is also a powerful advantage - allowing us to implement things in Python which would be difficult or impossible to implement from the dynamic side of other languages. He, himself, clearly uses these internals to advantage in his own code - and enjoys the flexibility that they offer. He also bemoans that exposing those interfaces makes the underlying interpreter difficult to change. These interfaces are clearly a double edged sword, and should be treated with respect. 
We use sphinx.  It works, and is fine.  That's kinda all I have to say there :)

I do *wish* were had settled upon Google style python doc strings.  I *hate* using rst markup.  

I mean, why use use markup to format doc strings and such, when you can use whitespace?  Its python, damn it!



Sphinx works pretty well for us, haven't had any real problems with it other than having to make places to host the html.
sphinx
pydoc
sphinx + napoleon
Awesome! 

I have tried to build some tool that downloads and visualizes boundary data myself before, but I had problems to get complete and consistent data for a specific bounding box. 

I'm glad you (?) made this, will check it out tomorrow :)

**Edit:** I had some issues installing fiona/gdal under windows, but once I got it running, it is pretty cool.  [This image](http://imgur.com/a/0ep46) shows a radial street network of Hamburg with a radius of 8km around the center point -- with only 3-4 lines of code. Of course this is only artistic, but the nodes and edges are available in a NetworkX graph to work on.

Some things should be noted, as the keyword arguments are sometimes not as stated in that article. For instance "type" is "network_type", and "dist" is "distance".

I can't wait to hopefully see a nice documentation soon. It would also be really cool to have some more built-in attributes of streets to use, or plot the actual boundary along the street network.

Dude. This is awesome.
Hi Geoff,
This looks really interesting!!
Gonna try it when i am at home!
Now traveling
Arthur
Thank you! This is amazing!
Can we export the data in GeoJSON format? If not, would you add this feature in the future?
In case anyone here knows:

I have an Anaconda distribution installed on my PC (numpy, scipy, matplotlib etc etc). Does anyone know how I would go about installing this package into my existing distribution? If I try to do it with conda, it doesn't know this package. If I try pip, it gives me an error message (I'm also not sure whether pip works well with conda).

Thanks!
Now make my files display like a virtual city!
Does it actually lock the system??
Uh-oh! only for Windows?

    dale@dalethink:~$ python
    Python 2.7.12+ (default, Sep 17 2016, 12:08:02) 
    [GCC 6.2.0 20160914] on linux2
    Type "help", "copyright", "credits" or "license" for more information.
    >>> from nedry_pass import access_main_program
    Traceback (most recent call last):
      File "<stdin>", line 1, in <module>
      File "/usr/local/lib/python2.7/dist-packages/nedry_pass/__init__.py", line 18, in <module>
    from ._main import YouDidntSayTheMagicWord, getpass, access_main_program
      File "/usr/local/lib/python2.7/dist-packages/nedry_pass/_main.py", line 30, in <module>
        import winsound as _winsound
    ImportError: No module named winsound

It's why I like WinPython.

It makes packaging my apps to not Pythoners easy, I send them a zip with a 'run this.bat' and everything is self contained.
nice writeup

I still wish doing the non-norm wasn't such a bother, my personal setup is, install python globally, and then `--user` install pip and all subsequent packages (don't need to runasadmin to update packages as a result), which means I need to manually find and add a directory to PATH as well, and then find the relevant visual C++ compiler hidden on the microsoft site, and install that too, and then still need to manually install things like numpy.

I guess I could use anaconda, but that doesn't sound as fun
Ooh I didn't know about the embedded installer. That's neat
Very cool, thanks!
At work: a distributed workflow engine
In my spare time, playing with:
- Whoosh to learn more about search indexes
- Sphinx, doctests and unittests to think about a new software development process
- And a little bit of Django for a few ideas I have for a website

Maybe a bit offtopic, but I also do this with Python in Termux (on Android)
I'm working a program that compares product data from distributors that sells some of the same and similar items. It then merges any duplicate items and separates distributor specific items. Its almost finished. Just need to work out a few bugs and finish search function. 
Writing a fairer mark generator for my sports teacher. We have to play basketball, and he just wanted to give someone who hits a better mark. I though there is a fairer way calculating difference into the equation, and so on...
I'm working on a program for Dota 2 to get the account ID of every person I have ever played with. It uses Pyautogui to click trough my match history in the game and PIL to identify the account ids from a screenshot.
Learning some WebScrapping with BeautifulSoup! I'm a total noob, but gotta start somewhere.
I was planning to build a logistical regression model taking CVS files as input (for learning) and I am considering if I should use numpy or pandas for it. ANy input would be greatly appreiciated.
Continuing work on a script to group my Google Chrome bookmarks by similarity by looking and the site contents of each url (with beautifulsoulp, pandas, k-means clustering) I am learning as I go. More info here:

https://hugoalvarado.github.io/bookmark-analysis-part1.html#bookmark-analysis-part1
I started working on a project that provides a graphic for the top 10 teams ranking in a sport throughout all the months of 2016, using **pandas** for reading a *.tsv* file, **matplotlib** and **numpy** to work with the graphics. I still have some issues with the fancy label I'm trying to do for this graphic, but things have been going well!
Data processing. Always data processing. Time series data, stored in hdf5 files, accessed via h5py and plotted via pyqtgraph. 
Working on a project that will classify F.R.I.E.N.D.S episodes according to their genre and characters(eg.Happy,Sad,Romantic episodes etc)along with picking random number of episodes to binge watch.
Working on a simple Twitter bot that will read select tweets looking for keywords, rewrite them substituting the keywords with a new one, and reply to the original tweet with the new version. It should produce some fun stuff. Planning to use BeautifulSoup and Tweepy for it.
A bunch of (poorly written) unit tests broke because of a module upgrade. Currently trying to decide if I want to deal with fixing all of them right now or push off the package update.
Trying to figure out why my C extension is crashing whenever I exit the interpreter.

Or if it's actually the destruction of an object that's doing this. I'm not totally clear which it is yet.

Error in question:

> Error in `python': corrupted double-linked list

> Error in `python3': free(): invalid pointer
Currently working on a UNI project which is basically to create the game Connect 4. Not so easy i tell ya
Django online learning webapp
Trying to figure out how to get started with learning django and flask.
Currently, I am working through, '*automate the boring stuff with python*' which is turning out to be a really informative book. 

I have a number of books that I will like to read and understand. I want to see what computer related field I'd do best in. First, however, I have to understand the concepts, grammar and punctuation of a language before I can start writing the novel. This way, after spending some time on these different books and having a taste of them all, I can hone in and do what I'm truly passionate about.
Extending my Flask-powered brew controller on my Raspberry Pi by automatically running recipes.
No.
Creating a row-level ABAC database accessible via REST api for secrets in containers, using cherrypy wrapping mysql.  Making it pure python3 helped.  It has been fun! [Reflex Engine](https://reflex.cold.org).
I am working on troubleshooting a python GUI crashing unexpectedly. I have a TraitsUI/PyQT4 application frozen using cx_freeze running a live image from a camera that will crash after a long period of running or crashes randomly while working. Doesn't seem to be a memory leak as task manager doesn't show an increase in memory usage.
I'm working on a little simulation project.

I'm calling it *The People Project*.

Essentially, it starts off with 100 randomly generated "people". These people will trade with each other and build "relationships" with each other. All of this is done automatically.

The community will start off with 100~ people and over time will mold itself into a self-sustaining community. It's basically a virtual ant hill.
Almost finished with my config file manager. It makes it easier to quickly edit a config file by saving an alias to the file's location so that it can be called later with an edit command (using a default editor that you've set) 
I am working on a python package that generates all possible forms of an English word. If you input "love", it will output ["loves", "loved", "love", "loving", "lovable", "lovers" etc.]. Initially I thought there would an existing package for this, but I found none and decided to do it myself. Had to hack around with WordNet to finally get it working. I just posted it on reddit.  [/r/python post](https://www.reddit.com/r/Python/comments/5bvgz5/word_forms_a_python_package_for_word/). [/r/programming post](https://www.reddit.com/r/programming/comments/5bt0q5/accurately_generate_all_possible_forms_of_an/).  [Github repo](https://github.com/gutfeeling/word_forms).
So, I am quite new to python (self-taught programmer. In high school. Worked as front-end dev part-time for a year~). Currently learning useful things (python cookbook, effective python) and trying out all kinds of libraries. A bit of everything, that's what kind of person I am, I want to have at least a bit of knowledge everywhere.

This week's accomplishements:

- Learnt using csv module
- Learnt the basics of matplotlib and gpcharts. Wrote a few practice graphs of csv data I got from worldbank. Damn, those population change graphs of different countries are interesting.
- Basics of beautifulsoup and scrapped a chinese novel website. They only provide books in chapters, so I had to copy paste every book I was about to read (I like reading from my kindle). Conclusion: python = useful for everyday life.
- Learnt some flask. Started working on a blog (not too practice, but I actually want to start blogging).
- Got annoyed of db (dunno why) while using flask and am taking a look at TinyDB. Looks very reasonable so far.
- Also, put a simple wp website together for a client. Hate it, python is way more fun. 

I am working on sending commands to Arduinos via Serial, based on Xbox controller readings, in order to control and underwater ROV.
I'm working on a simple web app for managing bills. Currently trying to wrap my head around custom widgets and fields for WTForms.
Working on a little static website that is pretty much a curated list of what can and cannot pet rats eat.

As a rat owner I'm having some trouble with this subject. The information is scattered around in various forum posts, articles and weird websites, so my goal is to put it all together in one place.

I decided to use `pelican` static page generation and github pages as hosting.   
Majority of the technical work went into making the theme which was surprisingly easy. I'm not a frontend engineer but jinja2 is just so fun to work with!    

The other part being the content itself. I thought of using webscraping to scrape those posts and generate the markdown files for pelican but the posts and articles don't have clear structure and lots of information need to be researched anyways - so it would have been more trouble than it's worth.   
This is by far the most time consuming part - the content itself.

All that being said, it's quite fun little project that hopefully will be of use to someone.
Trying to find time to continue writing my async API wrapper, but with school it's hard.
I'm building a framework for creating WSGI rest api applications. The main reason of why I'm doing it, is because I want to understand what are the challenges that bigger frameworks like Flask and Django are dealing. One day, maybe, I will be able to contribute with them.


Right now I'm working on routing.
Working on a practice project that will randomly pick a boardgame out of selection based on number of players and game length.
I coded a small program that will take user-specified image slices and generate the code for a (fairly simple) mobile responsive html email (link URLs and alt tags are the only things to fill in, can't find a consistent enough module to supply the alt tags from the images) for my team at work, but the rounding for the mobile calculations occasionally ends up not being pixel-exact, so I am trying to come up with a way around that.
I want to download all the episodes of a sitcom( FRIENDS in my case, yes I still have to watch it ) from this site - [the-watch-series.to](the-watch-series.to) using [youtube-dl](https://github.com/rg3/youtube-dl). 

Maybe I'll have to do some web-scraping using [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/). It might be difficult considering the urls are hard to get on this one.
A silly little flask web API for a Unity3D game to connect to, for downloading procedural enemy data from the internet. I'll also eventually be doing a Unity3D package with built in behaviour scripts for various attributes the API can serve.

Credit for all of the enemy variations goes to /u/garmichael. (http://www.reddit.com/r/gamedev/comments/23oxp6/build_a_bad_guy_workshop_designing_enemies_for/)

Example enemy:

Movement type: Wall Following,
Ability: Exploding,
Trigger: Proximity to player

The idea is that eventually, a game dev will be able to say either 'getRandomEnemySet(count=5)' or 'getEnemySet(id=123456)' and then create a specifically tailored set of enemies on my site, with combinations of attributes which can be altered post-release without patching a game, for server-side customisation of content.

Why? Not sure!
A simple game of hangman, and I'm failing.
Hey, I've started Python four days ago, all's good
Working on writing a mutation testing system. Hopefully nicer than the existing ones. At least less complex :P Based on baron. 
the Python Flight Mechanics Engine [PyFME](https://github.com/AeroPython/PyFME/wiki) I talked about in a [post](https://www.reddit.com/r/Python/comments/5bhlma/python_flight_mechanics_engine_v01_is_out/) yesterday!
I've just started learning Python. I'm very excited!
I think exactly the same thing: I hate adding a dependancy just for a small thing, even if I'm the author of the required package.

For this reason I love singole-source-file packages: just copy a single .py file in your project source tree and that's it. If you want to update it, just download it again. If you need that package in another project, it's only one cp command away. It couldn't be easier.

Obviously this applies only to helper packages, as you say.


Concerns off the top of my head:
I feel like there would have to be very strict guidelines to define what constitutes a bug fix or a new feature. By that I mean how much are these snippets allowed to change? What if someone wants to add a keyword to a utility function? Should that be made in to a new snippet?

Even if you say the snippets would never be that big, how big is too big before the code doesn't belong on the site?

Cool idea though.
A couple of observations:

- I think that adding another repository manager doesn't reduce dependencies, it just splits the dependencies between two managers eventually making things more complex, no matter how simple your repository will be. As already suggested here, it is best to keep things simple - either use established package management practices or just copy-paste the code snippets. You otherwise get yourself into tons of problems that were already solved such version management, external dependencies you cannot avoid (such as the Python version), access management, etc.

- If you feel you do need a private managed repository, the best IMHO will probably be [a private PyPi server](https://gist.github.com/Jaza/fcea493dd0ba6ebf09d3). If your main focus is managing your private inventory as a separate layer then there are all kinds of ready solutions such as [PyShop](https://pypi.python.org/pypi/pyshop) which I personally didn't try but looks pretty well documented.


There's no reason to see dependencies as a bad thing. I don't care how small, it is much better to use a modular approach than create monoliths of code.
This is awesome! Thanks
Maybe for the `DBAPI - PEP249` section show how to use parameters?
SQLAlchemy doesn't seem that difficult thanks for the tutorial
From what i remember reading about gaming in python is that pygame is good for basics but pyglet may be better- [source](https://www.reddit.com/r/learnpython/comments/3h8tky/is_pythonpygame_dead_when_it_comes_to_making/). However, I would stick to unity since i think the community may be a lot bigger for people who make games.
I know the Unity Engine uses c#, so I cast my vote for C#. 
I would stick with C# for game development. Though I love python.
Panda3D is almost 15 year old project used by some commercial games. It is supported by Disney and Carnegie Mellon University. Core written in C++ and game engine exposed in Python 2.7-3.5.

https://www.panda3d.org/manual/index.php/Features
Unity3d is so much better than anything in the Python environment for making games that you should stick with C#.
If you are sure that you want to program games then C#/Unity seems to be the way to go. It's also a question of whether you prefer Linux or Windows, as most Python development is done on Linux and C# works best with Windows.

By the way, there is no need to choose one. You can learn both simultaneously and this way you will be a much stronger programmer as well.
I'm contemplating doing python games in PyQt. Well, contemplating it. Whenever I start writing anything, I feel like I should have just gone straight Qt. Python just isn't good for multiprocessing :/
Eve Online is built in Python.
You can certainly make games in Python. There is a Python game jam called PyWeek that just wrapped up, and you can check out some of the entries here: https://pyweek.org/

Games like Pokemon or Zelda 2 are easily doable. 
If you want to get into professional game development, I think C++ is the best way to go. If you have your heart set on Unity, I would go with C#.
Well, there's this... https://en.wikipedia.org/wiki/List_of_Python_software#Video_games

I've never touched C#, but I also tend to avoid Microsoft software being a Linux guy.
This is a very interesting analysis, and I appreciate how completely you documented every bit of your work!
Why did you use word clouds in your analysis
I created a torrent upload script:
* If input is a torrent file, posts the file to my Transmission server at home
* If input is a webpage, looks for the first magnet link on the page and posts that to my Transmission server

Pythonista scripts can be loaded via the app extension / share sheet mechanism, so I can simply find a torrent or magnet link, tap open in / share and run my script. 
I must not be using it to its fullest, but on my commute there's a long old tunnel where I have zero LTE access and I use that time to block out code for work, or just play with new things I've learn in the std library.
Does exist a similar app for Android? I already know QPython, but it isn't so linked to phone environment.
Not really a "project," but I've been working through Project Euler problems when I have a few minutes here and there, have learned quite a bit.

Also made a little web scraper that would get my account balance for our cafeteria, where we got a set amount of "free" money for food every few months (which I figure comes from my tuition). The script would print out the balance, average spending per time, and whether I should eat more or less to last the full time but not have any left over.
I learned using [django docs](https://docs.djangoproject.com/en/1.10/intro/). I started off there, creating the tutorial project. Then worked on creating a mock restaurant search engine. 

If you are already familiar with python, the docs should help you get a long way there. 
Looking for [this](http://pygame.org/docs/)?
Not sure what you mean, please elaborate.
damn, that's ugly
So you know what linkedin is?
Check and see if there is a PyCon coming up in your area. It is a great place to do networking, specifically for Python.
Idk why you ask, with clients? Sure, just deliver good stuff and keep their contact info I'm case I need something or want to offer my services. With coworkers, be decent and keep their contact info too? 

2) easy
Did you cross-post?

https://www.reddit.com/r/startups/comments/5bq40u/quick_question_about_your_professional/

/r/startups is clearly a better choice for this type of question.
I have some sorting algorithms in Python I implemented a while ago if it helps. You may want to add TimSort to your list!

https://github.com/anfederico/Algorithms-through-Python 
If you pull from multiple sources and don't want to recreate those sources, just create a collection with a dict. IE

settings["FB_KEY"]

This abstracts the underlying "where is the key" logic, and your program just has to worry about looking up a value from a place that makes sense to your program. 

Then read the sidebar ;)
you could make a config.py file like

    FB_KEY = os.environ.get('FB_KEY') or 'hardcoded value'
    TWIT_KEY = os.environ.get('TWIT_KEY') or 'hardcoded value'

if those environment variables aren't set then those keys will be set to 'hardcoded value' or whatever the user puts there. then import the config in your other files, e.g.

    ## fb.py
    from config import FB_KEY
    ...
    fb_api_call(*args, fb_key=FB_KEY)
Cool, are there other simulations like this? For weather for example.
Could this be useful for high powered rocketry? 
This is really excellent, I've been looking for an API like this for a while. Forgive the amount of questions:

+ How accurate are the calculations?
+ The time-step functionality, what interval of time does this step?
+ The Binder example fails, Have you got any other examples running?
+ I was hoping for a getting started guide? at least for basic code boot and hello world?
+ What's your target purpose and platform? 
+ I notice some of your docs are Spanish - will you be translating them soon? Although - Google Translate does a great job.

Thanks in advance. This is awesome - I can't wait to try it.
Probably belongs on [r/learnpython](https://www.reddit.com/r/learnpython/) but as I'm feeling charitable I'd start with something like this [easygui](https://pypi.python.org/pypi/easygui).
[Tkinter](http://www.tkdocs.com/tutorial/), try it
I'm already using tkinker, but thanks ;-)

the main questions I have is "When I import the module, it displays the window. How do I prevent this?"

the code is simple "from modulename import *" and this causes the window to load.
Scan GitHub etc for AWS keys. Gain access. Mine Bitcoin until shutdown. Was, rinse, and repeat.

I don't do this, but it's a common bot-for-profit scheme. Happened to some friends who pushed their keys.
Please define bots.
I wrote a great bot to try and skim bot ideas on social media sites.
I'm not a developer or anything close, but if I had an idea that I was using to make money I wouldn't exactly post said idea online 
The one and only bot I have written was an IRC bot. Also, it wasn't for any form of profit, just to teach me socket programming.
Some of the bots I have written (but not making any money):

- Goodreads bot for reddit, which powers /u/goodreadsbot. [Source.](https://github.com/avinassh/Reddit-GoodReads-Bot)

- Goodreads bot for Telegram. [Source.](https://github.com/avinassh/Laozi)

- Recently wrote a welcome bot for Slack teams. [Source.](https://github.com/devupin/allie)
I've written a trading bot for the NXT asset exchange to trade Ardor. Using it when I am not at my computer, it runs in a 'cautious' mode. When I am at my computer, it runs in an 'advisory' mode.
https://nxtwiki.org/wiki/The_Nxt_API#Asset_Exchange_Operations
Not a professional programmer, but professionals will often automate testing and deployment. Also automated scaling is immediately important if you don't have access to a multimillion dollar data center. By automating scaling in AWS or the like, you can pay for only the service that you use, rather then having to fund the cost for an array of machines whether you need them or not. These things might not exactly be doing the actual act of making the money, but they can sure as hell help you save a shitload of time and money and headache.

Just as far as actually making you money, you could probably automate a script to complete certain types of tasks on Amazon mechanical Turk, although you might be breaching their TOS if you do
[deleted]
Nobody is going to tell you what kind of bot they wrote if they are making money. That said, you really have to have a business sense to understand where you can make profit with a bot. There are countless industries that can benefit from automation tooling and you can either carve the way yourself or find a strategic partner / company. Typically though, you can't really make a "bot" that will just run and make money. You will likely have to tweek it or incorporate some manual process to ensure that it runs smoothly and correctly.
I used to have a Steam market bot that would buy items from people that put them by mistake cheaper than they actually were. Not anymore tho, Steam killed that with buy orders.
I've made text generation bots in less than a week to test it out using Python. They are earning a consistent twenty USD a month with no manual involvement, sixth month in. I'd put more time into it but I'm busy with my day job in public relations.

I don't want to reveal much more, naturally, as this post seems like a way to fish for ideas - but if you need help you can reach out to me.
Wrote a bot to arbitrage crypto currency exchanges. It makes pennies a day! Pennies! Some days though it does a lot better. The volatility of the currencies usually make it a wash in the end. If I had more time and interest I'm sure it could do better.
I wrote /u/UnknownVideosMod bot and it is going incredibly well on r/UnknownVideos
I built a website http://nameamigo.com

It is a business name generator. My plan was to apply machine learning techniques to the generator to find the best names. Unfortunately I only learned later that machine learning performs terribly on natural language processing :D The site is lucky to get 1 visitor in a day.
I wrote a bot/script to spellcheck websites. If a particular word (medical terms, last names, business brands...etc) is not in the default dictionary it uses Google Search as a make-shift API to double-check it. If it is not in the default dictionary but the word is spelled correctly it is appended to an ever-growing .txt file. All misspelled words & their corresponding URLs are exported into a .xlsx file.  It isn't for profit but I do use it often for work.  
[deleted]
I've had no problems using pyvenv for my virtual environments. That said, if you don't have time to handle any problems that could arise then I would hold upgrading until you do.
I think I am running the most up to date version of Sierra `10.12.1 (16B2555)`. No issues so far
http://infiniteundo.com/post/25326999628/falsehoods-programmers-believe-about-time
So, the post is mostly a follow up and sum up of a discussion that occurred here: https://www.reddit.com/r/Python/comments/595tcd/please_stop_using_arrow_for_your_datetime/

As the author of Pendulum,  I admitted, in the end, that I misunderstood the purpose of Delorean. But I also said that the purpose of Pendulum is to be a full-fledge datetime library, well beyond the scope of timezone switching.

But I would like to take the time to respond to some points made in the article.

> it seems the author thinks all the other solutions are broken. That seems a little far-fetched doesnât it? Is it likely that so many other developers who use other libraries are wrong, and nobody noticed?

Well, when you see how many developers are using Arrow which is buggy, it leaves you wondering. So, Pendulumâs goal is to be a better version of what Arrow wanted to be, thatâs all. I started it when I noticed that I could no longer rely on it.

> Always use UTC when manipulating time.

I agree with that statement. What I meant was that Pendulum makes it transparent for the end user so you can do directly:

    >>> import pendulum
    >>> dt = pendulum.create(2013, 3, 31, 1, 30, tz='Europe/Paris')
    >>> dt.isoformat()
    '2013-03-31T01:30:00+01:00'
    >>> dt = dt.add(hours=1)
    '2013-03-31T03:30:00+02:00'

Pendulum will use UTC internally to accomplish this but what the end user wants in the end is just add one hour to a datetime in a specific timezone nothing more. Pendulum tries to ease this for them.

As for the bug in Pendulum, it was just in the `dst()` method not anywhere else since the final datetime would still be correct. So, it was pretty limited since the `dst()` is not widely used while `utcoffset()` is, which worked as expected.
I'll be honest: I probably would have preferred this post if it weren't a snarky rebuttal to a bunch of someone's comments on reddit. If you want to do that, reply on reddit.
> Deloreanâs epoch() assumes UTC and doesnât[sic]

Why sic after "doesn't"? I admit I'm not a native English speaker but that looks correct to me. 
Time wasn't important until the early 1800s, hum.  So why then did the [Scilly naval disaster of 1707](https://en.wikipedia.org/wiki/Scilly_naval_disaster_of_1707) lead to the [Longitude Act](https://en.wikipedia.org/wiki/Longitude_Act) and so on to [John Harrison](https://en.wikipedia.org/wiki/John_Harrison)?
If anyone is getting blocked by Cloudflare, please try here: https://gordol.github.io/date_time_manipulation.html Apologies!
excellent work!  <3 psutil
Why the major version bump?
I'm impressed! Well done!
I think you shouldn't need the one_shot() context manager. When reading the /proc file just get all the info that is there and cache it in the Process object.
http://interactivepython.org/runestone/static/thinkcspy/index.html

Also, learning questions are better posted in /r/learnpython
Although it doesn't guide you through tasks try pythontutor.com
> as thereâs a very vocal âanti-dependencyâ mob in the Python community

There is? Haven't noticed that in the last 10+ years of using it.
It is good to see the JSON serializer supports datetime/decimal conversion natively now.
Can anyone tell me what their reasoning was for switching to lowercase setting names.  To me uppercase setting names totally makes sense and also then the setting name will the same as environment variable equivalent for each setting.  Switching to lowercase setting names doesn't really make any sense to me.
Solar Schedules!! Cool! http://docs.celeryproject.org/en/master/userguide/periodic-tasks.html#solar-schedules
To whoever designed that new logo: you are a genius
> The --autoreload feature has been removed.

Damn it. I used that all the time for development work.

Celery ran on my Dual2011 server in the basement. Development was on my laptop in the living room.  Everything was on NFS. 
Look up ediscovery. A few tools exist, they basically process large tranches of common file types like .doc, .eml etc and allow powerful keyword searches to take place. 

It may sound like ctrl-f but it's the standard approach - even when multinationals sue each other. They would almost certainly use the same software for the Trump U case.
Probably Microsoft Excel.
Former USAF North Korean cryptologic linguist here, they didn't use a programming language. The intelligence community doesn't rely on programmatic algorithms to determine the classification level of information.
Question #0: why on earth are you using python 2.5?
Python 2.5 has been unsupported for a while, you should expect most things to not work with it.

It looks to me like the last version of numpy that supports Python 2.5 is 1.7. I strongly discourage learning on outdated packages; it's likely you'll learn patterns that are just wrong today.
You'll get a lot more help at /r/learnpython. I believe that error is something to do with needing Visual Studio for a compiled piece. I might suggest using anaconda and trying to find a precompiled version of the library you need. 
I've just read through some more of the python.org docs and have found out that I can use the following (albeit clunky) ways:

-----

**Python3**

*python*

*pip*

-----
**Python2**

*py*

*py -m pip ...*
Everyone I know who uses python on windows use anaconda: 

https://www.continuum.io/downloads


Either anaconda or via cygwin
Not sure what you have done with env variables yet so it is kind of hard to know where to start.  I have python 2 and 3 running on all my systems without anaconda but I do heavily use Virtual environments.

Knowing only a little about the environment variables.  I know the order in which they are in the PATH matters as far as what gets used (it just uses the first executable it finds).  

In my opinion I think you are probably a little backwards I would rather type python3 for python 3 and leave python 2 to be launched with python because this is more "out of the box" functionality.

However, with your use case in mind I took an chance and renamed my 2.7 python.exe as python2.exe (which means there was no longer a python.exe in the 2.7 path)  With this "python2" launched my python 2.7  and python launched my python 3.4 as I expected.

It is worth mentioning that is as far as I went in my testing and I am not sure what might have been broke deeper in with pip and such.  I think that it would be "ok" but I do not know enough to make any guarantees.  You can do that investigation.  

I again would encourage you to not do this kind of monkeying around and rely on python to open python 2 and python3 to open python 3.  Even better, use virtual environments.  

I wrote a very small CMD script which allows me to "switch" my running Python Environment. I will share the code with you when I get back home. It requires that there is some consistency on where you install Python, and that you follow certain naming conventions for installs paths. But after it is setup, all I need to do is:

> winpy set 35

Then, Python 3.5 will be active.

I still use virtualenv for everything else
Hi there, from the /r/Python mods.

We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there.

The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here.

However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers.

If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns.

Warm regards, and best of luck with your Pythoneering!
Use quote_plus instead of doing the space replacement in getDetails. Currently it looks like if a song name has an ampersand in it, the search parameter will be messed up.

Add a testing framework. TDD is the way to go for a maintainable project.

Read up on pep8. Specifically, the portions on exception handling and function names. Try using pylint and/or pyflakes.

Try using more constants. That way it is easier to mock/patch.

I hope that helps a little. Good luck with your project!
In addition to what was already remarked, don't put code in `__init__.py` that doesn't belong there, __init__.py is not a meaningful name for a module that does something other than actual module initialisation. Some more pointers here:

http://stackoverflow.com/questions/448271/what-is-init-py-for

Furthermore, keep your functions short and concise, and try to avoid many nested try/except clauses (also, never have empty except clauses, but that was already mentioned elsewhere implicitly)

Also you're using the requests module, but also use urllib further on. I suggest choosing one, for your particular use cases.

where does it get the meta data?
I like it. Great work.

Only thing I have to ask is why not user input or raw_input for asking the user if they want to manually add anything? Probably a bit faster and less of a hassle then how you are currently doing it.

Also instead of printing your errors you could log them :)
Very nice tool right here.

Would be nice if the script added album art in spite of the tracks having tags already.

Why are you using both urllib and requests?
I would use `logger` instead of ugly `print`.

This is particularly useful for errors, since traceback is automatically added to the output, so no need of `print(str(e))`.
    
    except requests.Timeout:
        logger.error("OOPS!! Timeout Error")
This a good start for a simple project but I think a good framework is required to simulate consistent behaviour with a ever growing ecosystem of web crawlers. I rely on Scrapy but you can look into reusing frameworks that already exists.
"Efficient web scraping tutorial".

Uses blocking http library ```requests```.

One of the points is to increase timeouts.

Seriously, do you even know what efficient means?
Should that be an `else:` clause in part 6 on line 15? If your script errors out, you do not want to try the rest. A `finally:` clause will have that code executed whether there is an exception or not. You should use `else:` so that the rest of the code will only be executed if there are no errors. One of your example errors is no `KeyboardInterrupt` but you are telling the code to continue regardless, so one of those outcomes are pointless.

For part 2, you can use a built in capability of requests, as you did with the status_code:

    if r.headers['Content-Length']:
        # continue your script


I don't really understand the "Efficient File Handling" though I'm not taking a lot of time reading through that long try/except/finally statement. But one thing you might consider adding is doing chunk-by-chunk processing of files, especially for very large files that may not fit in a computer's memory, with `iter_chunk`; 

Automate the Boring Stuff has a good example on Chapter 11 https://automatetheboringstuff.com/chapter11/

Two questions:  
Why do you think `if status_code == 200: # Do something` is worse than `if status_code != 200: return False`    

In the last section, how else would you save the data, and where did your `property_urls` variable come from?

Maybe you don't have pip installed. I can't remember if by installing Python, you automaticaly get pip... Are you able to run the "python" command?

Maybe you can try this command "python -m pip install requests"
Another thing to try is `pip3` instead of `pip`
For this type of question, you should go to [/r/learnpython](https://www.reddit.com/r/learnpython/).

Also, when you find the solution yourself, I encourage you to post it, so others can benefit from it as well.
StimulateMe! TreeQuiz
SimulateMe! I_SHOT_TWICE_ONCE
SimulateMe! iNeverQuiteWas
SimulateMe! Simulate_Me_Bot

Did I break it?
SimulateMe! AZIR_THE_EMPEROR
SimulateMe! bastih01
SimulateMe! Witonisaurus
do we get to take a sneak peek at the code? :-)
SimulateMe! fucks_with_ducks
SimulateMe! Scienziatopazzo
SimulateMe! simonorono
SimulateMe! Daenyth
SimulateMe! coriolinus 
SimulateMe! Potado
SimulateMe! Kamikai
SimulateMe! DrudgeBreitbart
SimulateMe! 03891223
SimulateMe! jonnypadams
SimulateMe! Blazerboy65
SimulateMe! kazi1
SimulateMe! LewisTheScot
SimulateMe! sweet_dreams_maybe
SimulateMe! bobcrotch
SimulateMe! SirLaughsalot12
SimulateMe! Laspimon
SimulateMe! nweatherburn
SimulateMe! ThePenultimateOne
SimulateMe! -AceStar
SimulateMe! redhedinsanity
SimulateMe! iScrE4m
SimulateMe! sfan5
SimulateMe! HomerG
SimulateMe! addcn
SimulateMe! TheCodeSamurai
SimulateMe! neilbryson
SimulateMe! ameoba
SimulateMe! borge689
SimulateMe! Corgan1351
SimulateMe! JosephRW
SimulateMe! Turbosack
SimulateMe! 0110010001100010
SimulateMe! travisdoesmath
SimulateMe! sportif11
SimulateMe! IsSuEat
SimulateMe! FrostedBits

SimulateMe! FourForYouGlennCoco
SimulateMe! DamagedFreight
SimulateMe! JinKaiRiu


SimulateMe! modern_knight
SimulateMe! apocalypsedg
SimulateMe! hlmtre
SimulateMe! binomine
SimulateMe! HorizonFoxtrot
SimulateMe! Hispanicatth3disc0
SimulateMe! BenjaminGeiger
SimulateMe! ginger_beer_m
SimulateMe! chad303
SimulateMe! Funny_Horsie
SimulateMe! kyle6513
RemindMe! 2 days
SimulateMe!  Phooey138
SimulateMe! xieng5quaiViuGheceeg
SimulateMe! d4rch0n
SimulateMe! velohell
SimulateMe! itsableeder
SimulateMe! jck
SimulateMe! DaemonXI 
 SimulateMe! 28f272fe556a1363cc31
SimulateMe! he_had_it_coming
SimulateMe! ziel
SimulateMe! Eurynom0s
[deleted]
SimulateMe! njosnavel
SimulateMe! LesterHoltsRigidCock
SimulateMe! njb42
SimulateMe! nafenafen
SimulateMe! LunarEgo
SimulateMe! Broker-Dealer
SimulateMe! catmoon
SimulateMe! CATHOLIC_EXTREMIST
SimulateMe! rafajafar
[deleted]
SimulateMe! Scriptorius
SimulateMe! Resonantmango


SimulateMe! wizard_mitch
SimulateMe! Soldierducky
SimulateMe! Anthrax97
SimulateMe! traviscalley
SimulateMe! bob_raider11
SimulateMe! StanGibson18


SimulateMe! TyrSniper
SimulateMe! Hackerstein91
SimulateMe! Corezon
SimulateMe! wilw
SimulateMe! holomorphological
SimulateMe! 
SimulateMe! LockeSteerpike
SimulateMe! dddanmar
SimulateMe! pavel_lishin
SimulateMe! bsdcolonel 
SimulateMe! MethMom


SimulateMe! balmanator
SimulateMe! rodgerthat7
SimulateMe! bmwill1983
SimulateMe! hexapus
SimulateMe! sil0
SimulateMe! raydeen
SimulateMe! 1esproc
SimulateMe! remram
SimulateMe! JQuilty
SimulateMe! Koriantor
SimulateMe! M_BISHOP
SimulateMe! g-money-cheats
SimulateMe! zorfbee
SimulateMe! Iguphobia
SimulateMe! NSWCSEAL
SimulateMe! whitewhim
SimulateMe! PolarCapsular
SimulateMe! deva_p
SimulateMe! shrugsnotdrugs
SimulateMe! ignisphaseone
SimulateMe! thurask
SimulateMe! LULZYKitten
SimulateMe! ewk
SimulateMe! tostono
SimulateMe! NegativeGPA
SimulateMe! k_nasty
SimulateMe! Nater5000
SimulateMe! DarkInsight
[deleted]
SimulateMe! gibbom
SimulateMe! ergane
SimulateMe! Shmoogy
SimulateMe! Infosciguy
SimulateMe! TheRoadHome
SimulateMe! Ennu
SimulateMe! Give_Us_Moth_People
SimulateMe! goat211
SimulateMe! H4rtland
SimulateMe! SirSplodingSpud
SimulateMe! LazinCajun
SimulateMe! r0ssar00
 SimulateMe! hi-polymer-nirvana 

SimulateMe! La-Fol
Simulateme! pnspi2
SimulateMe! I_AM_SAYING


SimulateMe! rajbabu0663

SimulateMe! nakedproof
[deleted]
SimulateMe! Sciguymjm
SimulateMe! qsxpkn
SimulateMe! IMAROBOTLOL


Definitely expecting all caps and Fuck.
SimulateMe! earthqwake
SimulateMe! tedivm
[deleted]
SimulateMe! MacGuyverism
SimulateMe! Gammaliel
SimulateMe! expiredgoatmeal

SimulateMe! ShakeableHippo
SimulateMe! DrVID
SimulateMe! SteveDougson 
[deleted]
SimulateMe! IamCarbonMan
SimulateMe! DanielFGray 
/u/iNeverQuiteWas, will you be releasing the source code?
SimulateMe! FireReadyAim
SimulateMe! Auntie_Social
SimulateMe! lw9k
SimulateMe! pepsi_next
SimulateMe! iron_baby05
SimulateMe! andlily
SimulateMe! rogersimon10
SimulateMe! anmousyony
SimulateMe! bheklilr
SimulateMe! errant1
SimulateMe! DrRx
SimulateMe! beegreen

SimulateMe! Milkmanps3
SimulateMe! Occamsphasor
SimulateMe! knocking_
SimulateMe! Poem_for_your_sprog


SimulateMe! dreadington
SimulateMe! Thirsteh
SimulateMe! VaderFader
SimulateMe! xrisk0
SimulateMe! arvi1000
SimuateMe! resonantt
SimulateMe! jsribeiro
SimulateMe! McGuirk808
SimulateMe! Xcen27
SimulateMe! joshuag
SimulateMe! NeedsMoreGoatYell
SimulateMe! second_to_fun
SimulateMe! Goojie

SimulateMe! Firefro626
SimulateMe! nomadthoughts
SimulateMe! jeffrife  
SimulateMe! DuyBach
SimulateMe! kirbyfan64sos
SimulateMe! oembob
Will the bot come back?
SimulateMe! kelaos
SimulateMe! herothree
SimulateMe! BUTTHOLE_SNIFFER
SimulateMe! beer__warrior
SimulateMe! myfavoriteanimal
SimulateMe! WeavShow
SimulateMe! IGOTTHATARTKNOWLEDGE
SimulateMe! BUM_BURGLAR 
SimulateMe! djaeke
SimulateMe! drags7er
SimulateMe! CosmosisQ
SimulateMe!  alternat 
SimulateMe! N0nexistent
SimulateMe! bjs2
SimulateMe! b38tn1k
[deleted]
SimulateMe! nikhilvibhav
SimulateMe! Seanp50

SimulateMe! TrivialPotato
SimulateMe! Commod0re
SimulateMe! teaandpeanuts
SimulateME! FondFondler

SimulateMe! sexbucket
SimulateMe! limbicslush
SimulateMe! Zabbrielle


SimulateMe! gindc
SimulateMe! KH405_TV
SimulateMe! monokrome 
SimulateMe! mehum
SimulateMe! Zavidovici
SimulateMe! Social_Lockout
SimulateMe! stishovite
/u/user_simulator simulate_me_bot
SimulateMe! Nnerisin
will you make the source available?
SimulateMe! Earthpegasus
SimulateMe! benofepmn
SimulateMe! Rndom_Gy_159
[deleted]
SimulateMe! tugs_cub
SimulateMe! atyxyt
SimulateMe! asusreddit
SimulateMe! Deydex
SimulateMe! natos20
SimulateMe! Anydegree
SimulateMe! FeMonky
SimulateMe! DrakeRoot
SimulateMe! sensual_rustle
SimulateMe! Laremere
[deleted]
SimulateMe! narzy
SimulateMe! lengau
SimulateMe! thngzys
Hope it's still up :(
SimulateMe! Nqoba4
SimulateMe! Aeon_Mortuum
SimulateMe! Boootylicious
SimulateMe! nxpe
SimulateMe! K340
SimulateMe! pure_x01
SimulateMe! lexan
SimulateMe! Mr_Adams
SimulateMe! tsirolnik
SimulateMe! w1nt3rmut3
SimulateMe! moigagoo
SimulateMe! nmdanny2
SimulateMe! plastikmissile


SimulateMe! not_rico_suave
SimulateMe! WillyTheDisk

 
SimulateMe! dewso
SimulateMe! grensley
SimulateMe! gebrial
SimulateMe! LithiumEnergy
SimulateMe! demonizah
SimulateMe! zurvanyazdi
SimulateMe! dilong-paradoxus
SimulateMe!  regeya
SimulateMe! Firworks
SimulateMe! brianchenito
SimulateMe! NotRightQuite
SimulateMe! DrGrizzluBear
SimulateMe! magicmad11
SimulateMe! WhatIsMyNombre
SimulateMe! ignoculture
[deleted]
SimulateMe! Megor
SimulateMe! cibyr
SimulateMe! Blitzkraft
SimulateMe! Telestrial
SimulateMe! TameNaken42
SimulateMe! dustractor
SimulateMe! namedbynumbers
SimulateMe! docwatsonphd
SimulateMe! Leon747
SimulateMe! Artgor
im dumb
SimulateMe! esbio
SimulateMe! LetsDoRedstone
SimulateMe! BlackHumor
SimulateMe! TheCynicalSun
SimulateMe! limbsincluded
SimulateMe! WetwareDefect
SimulateMe! CrambleSquash
SimulateMe! JustSomeRedditor_
SimulateMe! 123icebuggy
SimulateMe! 04h
SimulateMe! gitarg
SimulateMe! pmrr
SimulateMe! stinyg
SimulateMe! thebugswillbite
SimulateMe! Cordite


SimulateMe! a000h
SimulateMe! YeaISeddit
SimulateMe! elsjaako
SimulateMe! yew_wood
SimulateMe! Doxin
[deleted]
SimulateMe! travistravis
SimulateMe! ApoMechanesTheos
SimulateMe! arnedh

SimulateMe! Tuna-Fish2
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/programming] [Check out my new bot, Simulate\_Me\_Bot! It learns to speak from you and, when called, replies using its knowledge](https://np.reddit.com/r/programming/comments/5bezhp/check_out_my_new_bot_simulate_me_bot_it_learns_to/)

[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*

[](#bot)
SimulateMe! Plasma_000
SimulateMe! noteness
SimulateMe! ILovePlaterpuss
SimulateMe! Mitchfarino
SimulateMe! saynotovoodoo

SimulateMe! TheNamelessKing
SimulateMe! sonyhren1998
SimulateMe! ACBeeGee
SimulateMe! Zalifer
SimulateMe! nimmothemad
SimulateMe! mogoh
SimulateMe! postolka
SimulateMe! red_shifter
SimulateMe! GYN-k4H-Q3z-75B
SimulateMe! jefwillems
SimulateMe! Creative-Name
SimulateMe! tetroxid
SimulateMe! monkeyWifeFight
SimulateMe! Krakob
SimulateMe! lascruces
SimulateMe! onewugtwowugs
SimulateMe! Harkonnen
SimulateMe! IronManMark20
!SimulateMe thegame402
SimulateMe! JordyZomer
SimulateMe! tqPl0nk
SimulateMe! IronManMark20
SimulateMe! andbren2000
Simulateme! Squidraider
SimulateMe! triszroy
SimulateMe! FlockOnFire

Edit: whoops, didn't read that you took it down already. :(
SimulateMe! combinatorilliance
SimulateMe! UltimateAeroPosition

SimulateMe! jppresents
SimulateMe! babitoi
SimulateMe! lormayna
SimulateMe! SimplyUnknown 
SimulateMe! thefirstsuccess
SimulateMe! L0r3nz510
SimulateMe! senft
SimulateMe! Hellerick
SimulateMe! bobgle
SimulateMe! LeCyberDucky
SimulateMe! Ceryn
SimulateMe! much_reddit_so_amaze
SimulateMe! Mr_Again
SimulateMe! RabidPancakes
SimulateMe! EasyAsNPV
SimulateMe! marindom
SimulateMe! thegame402
SimulateMe! Oe-P
SimulateMe! mcbubblelite
SimulateMe! thegame402
SimulateMe! diogovk
SimulateMe! kitari1
SimulateMe! rock_neurotiko
SimulateMe! petermlm
SimulateMe! desmonduz
SimulateMe! MobocraticEgoist
SimulateMe! LvlAndFarm
SimulateMe! st3dit
SimulateMe! whonut
SimulateMe! localuser-
SimulateMe! timonvs
SimulateMe! illiterate
[deleted]
[deleted]
[deleted]
SimulateMe! tom_hanks_
SimulateMe! dysmas

SimulateMe! GovSchwarzenegger
SimulateMe! hddherman
SimulateMe! TRAIANVS
SimulateMe! v_maet
SimulateMe! WrenchLurker
SimulateMe! lost_send_berries
SimulateMe! WrenchLurker
SimulateMe! gempir
SimulateMe! Terran-Ghost
SimulateMe! Dantedog01
SimulateMe! ghenshaw
SimulateMe! HydrogenHydroxide
SimulateMe! StripTheFlesh
SimulateMe! Jayjader
SimulateMe! idreamapple
SimulateMe! forever_a_looney
SimulateMe! raghavk180
[deleted]
SimulateMe! pvkooten
SimulateMe! TheCesare
SimulateMe! Nebril
SimulateMe! CohoCharlie 
SimulateMe! SFSylvester!
SimulateMe! el_matt
SimulateMe! PiercingPancake
SimulateMe! zushiba 
SimulateMe! SmartAssUsername
SimulateMe! TheLonelyGhost
SimulateMe! bodhi_mind
SimulateMe! ypcrumble
Simulateme! Lordperzeval
SimulateMe! Astrofusion
SimulateMe! EMoorald
SimulateMe! Crowbarkz
SimulateMe! StaJeUsername
SimulateMe! unidan 
SimulateMe! admin-mod
SimulateMe! Hildingding
SimulateMe! IncompetentFox
SimulateMe! SonGokussj4
SimulateMe! The_Jeremy

SimulateMe! V1nk3
SimulateMe! bumfudhe
[deleted]
SimulateMe! cogman10
[deleted]
SimulateMe! puzzyonthechainwax
SimulateMe! KaiserUDM
SimulateMe! marcos19945
SimulateMe! Nigel_P_Winters
SimulateMe! devondashla
SimulateMe! ggrieves
SimulateMe! ziggomatic_17
SimulateMe! vopi181
SimulateMe! shadowycore
SimulateMe! Cherlokoms
SimulateMe! minorsecond
SimulateMe! cuchoi
SimulateMe! fucktoi
SimulateMe! DadAtH_me
SimulateMe! Poem_for_your_sprog
SimulateMe! leogodin217
SimulateMe! WhyIsYosarionNaked
Nice try, Mr Comey
If anyone is also looking about eml stuff I think the first "Received: by " is the receiver IP address and the X-Originating-IP is the address from the sender IP address. 
This isn't really a Python question, but more of a "Tell me how2eml".

Wikipedia's article on [Email Header Fields](https://en.wikipedia.org/wiki/Email#Header_fields) is a place to start.  Read the relevant RFCs (such as [RFC5322](https://tools.ietf.org/html/rfc5322) and [RFC2047](https://tools.ietf.org/html/rfc2047), and [RFC3864](https://tools.ietf.org/html/rfc3864)) for what to expect in fields.  

Read into each field as you come across them.  Create a function for parsing all fields, and then do what you want with the contents of each.
https://snowboy.kitt.ai/
Yes, I've done it
Edit: speed and classification is fine, just use Numpy and Sci-kit-learn to speed up some of the smaller things like training and what not
Check out flask. It's not as big as Django, but I'm fairly sure that they're using autodoc somewhere. Also anything on readthedocs.org

[Here's a good resource on autodoc](https://pythonhosted.org/an_example_pypi_project/sphinx.html). People often use it to generate a first pass and then edit the results manually to add stuff like tutorials and examples. 
When you install sphinx it adds a sphinx-apidoc command for generating the API docs, and other than that you just have to write the rst yourself. To change the look and feel just change the html theme. 
I don't know if it's good enough an example, but my pet project [Sloth CI](http://sloth-ci.moigagoo.space) is entirely documented with Sphinx, and all module docs are generated from docstrings using Sphinx's apidoc and autodoc features.
Looks a powerful set - you need a section on installation - which at least should give the package name on pyp, if not the installation instructions.

would be interested to know if your decorators preserve things like function name and signature and other key items, so that any deep code inspection tools continue to work.

Finally - do you have performance measures - compare to any equivalent python primitive functionality ? Are any (or all) of your methods in C or pure python ?
There are decorators which try to perserve the signature - automated code documentation is a very powerful tool and having a decorator on a public function which wrecks the signature will damage the documentation
You should use SystemRandom (or os.urandom), the standard random module is insecure and not suitable for anything related to cryptography. 
A few comments:

- Why are you using words to build the password? If it is so that it can be better remembered then (a) the special symbols are unnecessary and (b) you should use words that are very distinct, e.g. none of them has the same first three letters. You can take a look for example at the [Electrum word list](https://github.com/spesmilo/electrum/tree/master/lib/wordlist) which was very carefully selected.

- Regarding the strength of the password, that is just a matter of the number of bytes that you use as seed. 16 random bytes (128 bit) are considered unbreakable. 32 random bytes (256 bits) are considered collision resistant (if the passwords must be unique). Breakability has nothing to do with the way you format the password - as words, characters, streaks of 1s and 0s, etc., it is only a matter of the size of the seed.

- The way you test the timing is skewed - you'll get incorrect results. The proper way to time Python code is using the [timeit module](https://docs.python.org/3.5/library/timeit.html).

If you are interested in password generation you may want to take a look at a stateless password manager that I wrote (also a brain wallet) called [novault](https://github.com/novault/novault), it might give you some more ideas.
Wow, that's an awesome and insightful write-up!

I have one question though: if we get backpressure automagically through unbuffered, sort-of-synchronous (for the current logical thread) writes, don't we open ourselves to actual deadlocks? Like, a client isn't reading until its write completely completes, and the server isn't reading (any more data) until it fully writes its current response.
Do I understand correctly that what curio does to control flow is somewhat similar to gevent (with less hacky hell and monkeys)? And, in turn, similar to threads (with less overhead and sync concerns, of course).

And what asyncio does is, indeed, an addition on top of the callback-based eventloop, similar to twisted and tornado.

This together with unyielding have done what I have wanted for a long time: they've finally convinced me that `async`/`await` isn't just worth the colouring, the colouring is a good thing. 

Thanks!
Using a posix sockets inspired API in asyncio was discussed at the time.  In the end, we were persuaded by Twisted developers that the sockets API is too low level and error prone.  

Apparently there have been countless bugs in twisted apps/modules due to the fact that programmers are too lazy to check that the socket recv() call actually returns the number of bytes requested. The program should have a loop to keep reading into a buffer until all the needed bytes were available, but developers often forget that.  Likewise for sending: you ask a socket to send a bunch of bytes but the socket might accept fewer bytes due to the buffer being full.

This leads to bugs that are hard to track down because they are highly dependent on the computer speed, network conditions, the phase of the moon, etc.  Your program may work correctly usually, when it asks for 10 bytes and gets 10 bytes in a single call, but when you put it into production the socket may return 7 bytes in the first call, and would return 3 more bytes in another call.  These are the worst type of bugs, they don't manifest themselves in dev/testing, but appear in production.  Sound familiar?

To avoid this, asyncio streams offer a higher level approach and automatically sort out these details for you:
 1. You can ask to receive N bytes exactly and asyncio will take care of that for you;
 2. Even if you decide not to read now from the stream for a while, asyncio will read in the background and buffer the data for you;
 3. For sending, you just write some bytes and asyncio will take care of the details.

Yes, you have a point about buffer bloat, but there is an API in asyncio to configure the amount buffering asyncio does for you.  The defaults are usually good enough, but of course applications that require low latency can tweak the buffering thresholds.
There are a shitstorm of libraries availabe for frontend such as React and Angular. But in my opinion, especially in smaller projects, keep it simple! 

Take something as Materialize css or even Bootstrap and make use of Django's templating engine.
Hi, I use angular with Django, doesn't come without pitfalls. I write js in a more "pythonic" way with the fantastic livescript: http://livescript.net/ (and prelude http://www.preludels.com/).

I use those forâ¦ a webapp for bookshops ! where we can search books by isbn, do inventories, sell them, see stats, etc. Come have a look ! :)

- https://gitlab.com/vindarel/abelujo ([github mirror](https://github.com/vindarel/abelujo))
- the isbn scraping lib: https://gitlab.com/vindarel/bookshops (how to you get isbn ? pyisbn is pretty limited)
- related: https://github.com/apizzimenti/bookend
I quite like decoupling my backend and front end from each other.

For frontend take a look at: 

http://elm-lang.org/

(intro to it: https://www.youtube.com/watch?v=zBHB9i8e3Kc )

You will love it.

For backend I tend to choose between Flask or Django depending on the use case.

 
Check out webpack, or ngcli don't use Django static files. Let your front-end build process manage them
Try /r/learnpython. Also, to format your code as code on Reddit, indent it with four spaces. Also, you're missing a closing parenthesis on the previous line.
OPs code:

    
    
    def main():

    	print("To convert Celsius to Fahrenheit type 1 and press enter.")
    	wayround = input("To convert Fahrenheit to Celsius press 2 then enter: ")

    	if whichwayround == '1':
    		celsius = int(input("Input Celsius temperature: ")
    		fahrenheit=celsius*1.8+32
    		print(celsius,"degrees Celsius is equivalent to",fahrenheit,"degrees Fahrenheit."

    	elif whichwayround == '2':
    		fahrenheit = int(input("Input Fahrenheit temperature: ")
    		celsius = (farenheit-32)/1.8
    		print(fahrenheit,"degrees Fahrenheit is equivalent to",celsius,"degrees Celsius."

    	else:
    		print("Sorry. I didn't quite understand that. Please try again.")
    		print()
    		print()
    		main()

    main()

From the looks of it you never close a couple of your prints, you can also just do: '\n\n' in your last print to add two newlines rather than using empty prints.

Also for the love of all that is holy PEP8 my friend, using something like PyCharm helps you get into good habits in that respect.

>-> Variables aren't declared with a type but I find myself doing more type-casting than I would in C++ or Java. So if I don't get any "smart-casting" features like I would in es... why are there not variables types to begin with ?

You're not casting.  You're creating new objects using the old object as an argument.  Explicit is better than implicit.

>-> I hate the fact that there isn't a common iteration interface for the two containers listed above (e.g. for var1, var2 in containers which returns index&value for list key&value for map... similar to what Go). I mean C++ managed to implemented a unified-ish iteration interface for over a dozen containers... python only has two widely-used containers. Why the fuck are there 3 ways to iterate a list and 3 different ways to iterate a map ?

Because lists and dicts are fundamentally different data structures with fundamentally different semantics.  You need to be explicit in how you iterate over these things.

>-> I hate the fact that many common operator I'm used with are no in the language (e.g. ++, --, &&, ||) 

I mean... That sounds like a nitpick.  I think 'and' reads a lot cleaner than '&&', personally.

>-> I hate the fact that many of the built in functions don't really share and similarities in the way one has to think about them (e.g. there are some functions that are called with containers as arguments which give basic container properties... e.g. len(str) gives you length of str, str.split(...) splits str assuming str is a string. There seems to be no consensus, even among built in feature designers if the language or even its containers should be oo or not). I mean, in Java, I know that if I want to operate upon the members of a class that's built in the language I will do so with class-internal methods. In go I know that if I want to operate upon a structure or entity that's built in the language I will call a function external to it... even C++ manages to keep consistency among various std modules.

In Java you don't have a choice.  It's either an instance method, or an awkward static method.

You seem to be confusing built-in functions, too.  str.split is an instance method of str.  Len is a built-in function that works on all objects that implement __len__.

>-> I hate the fact that the various interpreters/compilers seem to diverge on arbitrary features that don't acutaly seem to matter that much and make code hard to port from one to the other

All languages with multiple implementations have this problem.  Have you ever tried using ML?

>-> I hate the fact that some many features changed between versions. Obviously some were due for a change but other (e.g. changes for the import system) just feel like a syntactic change that accomplishes nothing but to add confusion to someone who doesn't know the ins and outs of both languages.

I don't know what to tell you, there.  The language is evolving.  Nobody is forcing you to use the latest version.  Talk to a Perl developer about breaking changes.

>-> Finally, I absolutely hate the fact that both 2.7 and 3.X are still widely in use and I thus googling for anything related to python becomes about twice as tedious since I have to realize the person Is talking about 2 or 3 or if the feature they are talking about is version neutral

Is it really that hard to type "python 3" instead of "Python"?

>-> Oh, I also hate the fact that there seems to be various guides,so posts, libraries and framewroks which haven't been burnt to the ground by the community despite being written in an obviously... for lack of better term, "wrong" fashion.(by which I mean highly inefficient due to easy to correct mistakes) ... thought I guess that in a day and age where half the libraries of another language which I won't name failed their build because someone removed a whitespace padding module, its not so much an issue as another thing that makes me sad.

This is a programming language community.  Not a democracy.  If someone makes a library that does things "wrong", and lots of people use it, was it really wrong?  Make your own and get everyone to switch.

It seems that your issues aren't with Python, but rather with software development in general.  All mature languages have these issues.  If you want perfection, then make your own.

I'll wait. 
https://docs.python.org/3/
There are THREE basic data structures: list, dict and set. 
Your concerns are legitimate but you also need to realize that no language is perfect.   I use Python because there i s nothing better as far as interpreted languages go even if i find some aspects of Python frustrating.  

In any event you might want to look at Swift which seems to borrow much from Python but leaves behind the troublesome aspects.    

Oh and about variable declarations i to find Python frustrating.   I'm of the school that you define what you want as a programmer and rely upon the compiler to flag any improper uses.   Of course this is partially about choosing the right language for the task at hand.   
Python can be a pain on Windows but Anaconda should fix 99% of your student's issues without any configuration. 
There really is no point in that. Python works just fine on Windows 10 natively, zero hassle. I've got a MacBook Pro and a Surface Pro 2 with Windows 10, and I prefer doing Python programming (and any programming) on the SP2, because of how much easier it is.

I know my views aren't popular, but here're two secrets to creating a productive development environment on Windows: 1. Use PowerShell. 2. Use [scoop](http://scoop.sh) to install Python, pshazz, and other developer software. Maybe 3 is use VSCode with Python extension, which is purely amazing.

PowerShell is a great shell with familiar bash aliases but a lot more concise syntax. With pshazz you can easily make it a beaute a-la oh-my-zsh, with git autocompletions and stuff.

Scoop is a package manager that really fixes the whole "installing Python on Windows is pain" thing. It installs all your packages into one location in your homedir, so you won't need to provide admin privileges to install stuff, and you'll always know where your packages are (unlike with brew on macOS where there are three Pythons in three different locations).

Seriously, Windows 10 is a great OS for developers. It's no longer XP days, and the developer community should embrace the fact.
You should use Python natively in Windows. Anecdote: I have two computers, one with Win10, the other Ubuntu. I run Ananconda/PyCharm/Atom on  both, and the transitions are seamless. The only problem on Windows I've noticed is that Tensorflow doesn't work.

Bash python on Windows doesn't work with GUI things (like plotting), and runs into memory problems.
If your main use case is notebooks, then have you tried Anaconda? 
I've been teaching programming at university and Anaconda works great, even as students come in with Windows or OSX as old as 10.7.
I tried our entire Linux/OSX based stack on Bash on Windows (by downloading the Linux 64-bit Anaconda installer and just using that) -- worked flawlessly.  This is a modern Python data science stack; NumPy, SciPy, Pandas etc.

(Although I prefer working on the Windows Anaconda installation.)
I do a ton of data mining.  I live on Win 10, PowerShell command line, Python Jupyter and notebooks.  

Use Anaconda distribution of Python, with a slight hiccup of having to download two and install two powershell scripts to get "activate env" to have virtualenv work properly.

Switch.  Don't look back.


First off, if you're really that unhelpful to students with windows machines, that's incredibly depressing. Secondly, if you're mainly doing data analysis with python, Windows is extremely easy to use. I can probably spin up anaconda with jupyter running very smoothly in about 15 minutes on windows. Finally, you can definitely use Jupyter on Bash on Ubuntu on Windows (the anniversary update if that's confusing). Just install anaconda or pip install all the dependencies you want. Launch with jupyter notebook --no-browser. Then point your browser on windows to local host / wherever the output tells you it's hosted. Do not try to roll with XServer or whatever. Personally I think windows 10 with ubuntu is the best of both worlds for data analysis. 
I've ran Jupyter on [ALWSL](https://github.com/alwsl/alwsl) and it worked. Haven't used it much, but it did work.
I'm using it right now, installed all my usual stack (oh_my_zsh, vim and anaconda) and haven't had a single bug so far, you can even run jupyter notebooks from bash and open it from a browser on windows, you can use git on folder that are on your windows subdirectories, so far everything "just worked".
Slightly offtopic: a redditor who did some heavy number crunching once pointed out that his python in windows' linux subsystem actually runs faster than the "native" one, which i think has to do with a different dispatch mechanism, but i don't know yet.
Lines longer than 80 characters are bad- when I'm programming on my wristwatch it can only barely fit that.
Please, people, don't let this thread be about politics.
Is there a certain way to type spaces or is it not included yet?
I can't do "import this" this is outrageous!!! ððð nice work btw. 
Well done! Do you think that could be used as a replacement for Kivy launcher?
How does this compare to QPython?
I grew tired of wrestling urllib and urlparse to manipulate URLs. So I built furl.

If you work with URLs, try furl; furl makes it easy to create and manipulate URLs. Even complex ones.

I'd love to know what you think.
Instant star so I can use it later, I've had some problems with URL manipulation in the past because the URL itself had brackets and that caused problems with format. I ended up using some chained replaces, not proud of that at all.
Pygame gets a bad rap here sometimes, but there's been some cool projects made with it and great resources to learn from. Even the pygame documentation is pretty awesome in my opinion.

Al Sweigart has a couple of great online books that are completely free that use Pygame. The [first one](https://inventwithpython.com/inventwithpython_3rd.pdf) has a couple great projects at the end for pygame, though the whole book is full of games that teach many logical principles in general and the [second one](https://inventwithpython.com/makinggames.pdf) is purely pygame focused with very well thought out games! 

Also here's an excellent [youtube series](https://www.youtube.com/watch?v=nE5EeQPiznU&index=4&list=PL6gx4Cwl9DGAjkwJocj7vlc_mFU-4wXJq) for pygame as well.

The pygame site has many cool games, most being open source, but for those looking for something with a more professional polish there's also a few great examples out there:

[Tuxemon](https://www.tuxemon.org/ ) doesn't get nearly enough attention, but it's a very ambitious, fleshed out open source pokemon clone, built with pygame as a dependency. 

There's also [a very successful title](http://steamspy.com/app/442210) by the name of  [Switchcars on the steam store](http://store.steampowered.com/app/442210/)  made in pygame. The creator even posted in the[pygame subreddit](https://www.reddit.com/r/pygame/comments/4ck5zv/released_a_pygame_game_on_steam_after_3_years_of/).  He says that after completing the entire game, by transitioning it to pygame_sdl2 with little modifications it's performance was fantastic.

Pygame is still being updated slowly and available in 64 bit outside of the main site thanks to the opensource community.

There's lots of great resources and examples outside of these. I would say that pygame is much better for 2d games then 3d though, and I can't comment on the other python game modules out there. They're probably just as good or even better.

I think that it's exciting to develop with tools that aren't the most well known, because that means you can be the one who gives it a name and attract more creative talent to it's community. Pygame is powerful and has the tools though for great potential.

Despite how much I defend it am I advocating anyone use pygame in particular? No, I'm just making a point it's not to be underrated. The only thing I advocate is get a vision, then pick an engine or framework or whatever and stick with it and learn it inside out. As long as the tool you choose has have some building blocks to work with, the rest comes down to hardwork and persistence.

I understand that aspiring indie developers desire finding an optimal toolset, because you want to heavily invest into something and you don't want to regret your choice if something else has or will have a shiny thing. It's a natural dilema many smart people have, but here is the most important thing you will ever hear, when you hesitate you are practicing hesitation, hesitation becomes a habit, and in training in hesitation, hesitation will become your skill. 

It doesn't hurt to just jump into something, but I do acknowledge there is merit in doing a little research here and there. Just be sure to make the distinction between a little searching and just procrastinating. It may seem productive to hop around as you find a shinier or better or more powerful or easier toy, but this is actually a slow poison, because this is a red flag that will usually lead to burn out for most people, it just happens so slow people don't notice it until it's too late.

There's a lot of good opinions here, but an excellent swordsman with a wooden blade can overcome a bad swordsman with a steel masterpiece sharpened to precision. This analogy doesn't mean to start with a wooden blade though there's nothing wrong with doing so, but rather that when a bad swordsman focuses so much on finding the perfect blade this vanity becomes a handicap because it distracts them away from becoming the best swordsman they can be. Pick up any blade and focus on technique, find out what the limits are of that blade and get to know it personally and meaningfully. Other people will have stronger or longer blades, but most will be distracted with how shiny and powerful their blade is and miss out on crucial fundamentals, and shamefully quit believing they aren't good enough or don't have the dedication. This is because they came in from the wrong angle to begin with. This is what it means to learn the spirit of the thing itself, the artform. Some may argue the distinction between muscle memory and cognitive thinking since I'm comparing something like swordsmanship to programming, but cognitive thinking is applicable anywhere and complacency as a programmer isn't much different then muscle memory.

Just push yourself. I don't care if your idea of programming is playing with redstone in minecraft. I don't care if your idea of problem solving is sudoku puzzles. I don't care if you want to start in assembly or scratch. The only thing that matters is picking one thing and not giving up until you accomplish something you can be proud of, and it's at that moment you will realize how irreverent and detrimental it is to be too picky. 

I do feel that dynamic high level languages are a great sweetspot though regardless of what their graphic modules look like. I especially appreciate the pythonic philosophy because it streamlines the conceptual teaching and abstract thinking process and there's a great balance between having a fast workflow and at the same time enough flexibility to make any kind of game.

Once you can create text games with any degree of complexity that's much more important. That logic is the heart of the game, it's what makes it fun, and adding graphics on top of it is only an embellishment that any of the modules could do. Logic is the key component and your secret sauce. Things that can help this endeavor is to have a basic understanding of coordinate systems and how to manipulate them(with for loops, dicts, and lists), understand how different objects operate in terms of scope and how to logically arrange the code. Being able to deconstruct the logic needed to produce a game and reconstruct it in a way a computer can understand is all module and even language agnostic. 

Study new math or other peoples code. Use your default paint program or photoshop or get any of the many great freeware designed for spriting. If you're creating assets then you'll feel more personally invested and this is also module and language agnostic. There's lots of great free music out there but also so many free programs for making your own music. Maybe, draw out on paper how things should look in your game. Learn flowchart etiquette and chart out your game or problem for clarity (yEd is excellent graphing freeware, if adding flowcharts to your toolbox is appealing to you or your're curious). Just do something.

Have fun. Because it's a long road, and it's all about the journey. What sets those who succeed apart from those who don't is they worked hard and didn't give up. That may sound cliche, but discipline doesn't come easy. What sets the best game developers apart especially in the 80s and 90s is how much they were able to do with so little, and even with today's tools would take a long time to replicate. We're so spoiled in comparison with all the powerful free tools available today.

You suck at art? The first step to getting better is failing. Are you too stupid too program? The first step to getting better is still failing. Is your work ethic terrible? Then find out what you're serious about in life, and do that instead. If you're serious about this then I must be a magician, because if you just had that realization or even brave enough to dare to think this is something you're serious about then your work ethic will from this point be much better. You obviously care if you've read this far. Do you have a hard time getting up in the morning? Well the sweet nothings your seductress of a pillow whispers like binding incantations to a sealing ritual is actually just a low level illusion hex. It's easy to break it when you realize you'll have plenty of time to sleep when you're dead. Just don't go having an existential crisis now. 

No matter what your schedule looks like or how much you have on your shoulders, or even how much you've lost, if you think chilling or chasing booty or being led by the neck by society is enough to stop you, if you even consider this isn't for you and doubt your own limits, then you closed the door. What you could be becomes a what if and 10 years down the line you might want to pick it up again, and now is your chance to get a 10 year headstart on that person who gave up, your chance to rewrite the path your future is headed. The writer of Harry Potter J.K. Rowling had her mother die, a child, a divorce, and life of relative poverty before her first novel even got released. An [iphone developer on reddit known as WhitakerBlackall](https://www.reddit.com/r/gamedev/comments/stg2o/how_i_went_from_knowing_nothing_about_programming/)  came a long way in a year and his best advice was just keep coding.

I've essentially said the same thing about 20 times by this point but I'm going to reiterate it one more time to clarify my point. Don't be lazy. [JUST GOD DAMN FUCKING DO IT!]( https://www.youtube.com/watch?v=ZXsQAXx_ao0)

Have a lot of failures. The key is to fail quickly, not to avoid failing. You need not to get discouraged. This is the key insight to success in any creative endeavor. Creators learn it early or are never heard from again.

I say all this because what holds most people back is themselves...
Passion is also... language, engine, framework, and module agnostic. 

Deep down everyone knows all this though. It just helps to hear it from someone other then ourselves. 

Please...

[Stay determined.](https://pbs.twimg.com/profile_images/672154184674844673/Pzm0Jxq7.jpg )
Why pygame in 2016 ?
:(
Note that current <= 6 is always True, so having that in your loop conditional is not doing anything. Maybe you meant current != 6?

You can increment throw_num with throw_num += 1. 

You goal is not clear. Do you want stop after rolling two 6s in a row? Or after two 6s in a sequence of die rolls?

Edit: I'm guessing the former. Then your loop conditional should be while current != 6 or new != 6. You continue rolling as long as one of them is not a 6. 
No matter if you wish to have a degree or not, fill up your github with good projects.

One way to get a dev job without a degree is to get a job as a technician and continiously create handy tools that solves or automates problems at your position. Then slowly climb your ranks.

I dont know how it is in your country but in Norway I think experience, enthusiasm and Ã¥ network with good references is worh more
Friend was in this boat, try General Assembly if you can spend, it's cheaper than college or another course set like theirs that focuses on job placement as a selling point. And if not githubing it up like everyone saying (should do it on top of a course as my pal did) and if any specific companies in mind it's a good idea to start/work on projects involving related skills. 
Make sure your GitHub has quality repositories or you contribute to a quality project. However don't stress yourself about finding a project to contribute to, let it come to you naturally. Considering the fact you're just starting out I'd recommend you make a separate account which will house your "beginner" projects. As someone who has conducted many interviews, when I see a GitHub with very little or beginner tutorials, it's usually a red flag.
V.P. of Engineering here....

I don't usually look for a "degree" when I'm hiring (I work for a small enough firm that I screen my own candidates). I look for applicants who have good knowledge of "best practices" and "design patterns". I also look for people who program on their own and not just for their job, because people who are enthusiastic about programming are the ones who'll likely bring new tech and ideas into your company.

If you don't have a degree, you could look for 12 week programs like CodeCore and Lighthouse Labs, which are usually available in cities with big startup communities like LA, New York, and Vancouver. At least then you'll have "something".

As far as learning best practices (super important, at least for me, since you can teach syntax), I'm going to say something that will be deeply unpopular on this forum... Python is a terrible learning language. There are basically two frameworks in wide use, Django and Flask. Flask is a micro-framework, so it doesn't really teach you best practices at all (that said, we use Flask at work, so there's that). Django is set up in a totally different fashion from any other language's frameworks and is extremely opaque. It does a lot of things right, but the WAY it does those things is hidden from you, the programmer, so instead of learning the "right way to program", you're going to learn "the right way to program DJANGO", which won't help you as a general programmer at all.

If you're coming in with no education, you should try and make yourself employable by as many employers as possible, and that means learning languages that everyone uses. The Python community is tiny. Generally the only good reason to use Python is if your company does something that needs very efficient computing, like AI or search (I'm looking at Google and Amazon here). We use python because we want to use more AI in our solution. In order to cast as wide a net as possible you SHOULD learn javascript and php. Everyone uses javascript, and php runs something like 83% of the internet. Laravel is a great php framework that will very quickly teach you best practices. It's a good sign of how great that framework is when people start writing frameworks in other languages and call their solutions the "Laravel of node" (Adonisjs).

For javascript, there are two main technologies people use. Reactjs and Angular. Reactjs is a library, whereas Angular is a framework, so I'd suggest learning Angular 2, since it's harder to code the "wrong way" using that solution. Reactjs is great if you know what you're doing, but it's easier to hang yourself because it's less restrictive. The angular community is also way way bigger than React's (although React is growing), so that whole go where the jobs are philosophy also applies.

The very best thing you can do is to write a very small app and open source it using GitHub so that you show potential employers that you can make something that works and code it right. Don't worry about originality...write a "Honey-Do" list that families can use to keep track of which groceries they need or something. Host it on Amazon's free-tier or get a $5/month digital ocean box and host it there. Don't get carried away here...just write the simplest thing you can imagine and put it in a place where employers can see it. Writing something that works and hosting it on GitHub, where I can see that you've used best practices will put you miles ahead of even people with university degrees.
Apply for 300 entry level jobs and accept a cut rate, you'll get something
I help with hiring for a larger international company. I don't care if you have a degree if you have a GitHub full of interesting work and evidence of creative thought. 
/r/learnpython has a lot of info pertaining to this topic in the sidebar. I recommend you read [here](https://www.reddit.com/r/learnpython/wiki/index) and [here](https://www.reddit.com/r/learnpython/wiki/faq) to get started. Use Python 3.
codeacademy for the old version of Python. They will update it to 3.0++ this year I think.
Consider trying to work only with Python 3 if you can get away with it (others may disagree with me). The only difference here would be that print is a builtin function rather than a keyword.

`main` could be written a little bit more efficiently to avoid building up a string piece by piece, maybe illustrating the ease of working with higher-order functions in Python compared to Java (which is better with Java 8, but still not great).

    def main(argv):
        print " ".join(codecs.encode(s, 'rot_13') for s in argv)
Your code looks fine. Did you know there's a module for doing this in the standard library? It works with standard in or filenames.


    import fileinput
    import codecs
    
    for line in fileinput.input():
        print(codecs.encode(line, 'rot13'), end='')
What exactly do they mean by "real-time"? That's a really vague description.
It is very easy to get an update from an endpoint every (configurable)fixed amount of time, so there's no need for web sockets.
If by real-time, you mean within a few seconds, then you don't have to worry about web sockets.  You can just have the front-end poll an endpoint to ask for updates.  You could also do something with [push notifications](https://developers.google.com/web/fundamentals/engage-and-retain/push-notifications/) if the admin wants to be able to see new orders without having the page open.
Use pythonista 
Pythonista. Not to mention coding on a 6 inch screen is simply a terrible experience.
The closest thing I have ever found is SuperCollider and scBridge for python. But is nowhere near as good for audio/midi as PIL is for images... Aimed at performance and live coding
Mutagen can handle metadata tags for various formats
I would say pydub comes close to this:
http://pydub.com/
We are using this for a few things in papagayo-ng;
https://github.com/morevnaproject/papagayo-ng
You might take a look at the SoundPlayer.py in my working_vol branch, where I changed a few more things to use pydub:
https://github.com/steveway/papagayo-ng/blob/working_vol/SoundPlayer.py
Cool. But xpath? Why?
Peewee is trying to connect to an existing database, it won't create a new one for you. Peewee will create the tables *within* the database, but it's up to you to create the database first. 

Create your database directly in Postgres with the name/user/pass you specified and try again. 

    CREATE USER youruser WITH PASSWORD 'yourpassword';
    CREATE DATABASE test WITH OWNER youruser ENCODING 'UTF8';
Look into SQLAlchemy. It's pretty easy to work with but has adequate escape hatches if you end up needing functionality specific to your database of choice.
Peewee is your friend.
I think this post is more suited to /r/learnpython.
The first is called geocoding. The second would just be estimating based on travel speed.
When a human fills in a form and then clicks the 'Submit' or 'Save' button on the web form, The browser will collect all of that information that has been filled in, and will either make a GET or POST request to the web server. If your bot knows how to generate one of these GET/POST requests, and knows which fields are to be filled in, your bot can simply make the GET/POST request directly without ever have fetched the original form.
The best way to reverse engineer a web page with a form is to submit the form in your browser with the developer tools installed and then go to the network tab. Listed there will be the requests, headers and contents that your browser sent and using that info you can recreate those requests in a program.
By "load the page", do you mean opening the page in your browser? Or loading it at all?
You could try using [pywinrm](https://github.com/diyan/pywinrm) to connect to the remote machine and get the eventlog with a powershell 
[commandlet](https://technet.microsoft.com/en-us/library/ee176846.aspx)
Do you have access to the Windows system you need the logs from? It's probably easier to use pywin32 to get the logs from the local system first, and then send them over a simpler protocol (probably HTTP) in your own format (probably JSON).
Any reason not to just use Logstash with Winlogbeat to ship the log events to a a remote server running a suitable storage backend (MongoDB, Elasticsearch, RabbitMQ or whatever and then pull the log data from the storage layer with Python? Shipping the logs themselves is a solved problem.
How does it compare to AWS Chalice? 
KappaPride KappaRoss
If Celery looks too much, you have other options:

- https://huey.readthedocs.io
- django-q https://github.com/Koed00/django-q/
- and others !
My honest opinion is that you should try and see if it fits your needs. I have dozens of projects with just celery and custom code around it, and others with django-celery. 
My experience with django-celery has been good, it does the job and you're productive extremely fast. So just go for it ;)
This is the worst thing ever and the best thing ever.
Well, it would really suck if you did something like:

    from stackoverflow import delete_all_files_in_dir
    delete_all_files_in_dir('some_directory')

but the top-voted answer used `os.system('rm -rf /')`...
Owning a system never was easier, I guess.
Wow, this is the next level of Stack Overflow Driven Development!
Ill take "Stuff you should never do" for 500 Alex
And it's parsing HTML using regexes. It's truly a work of the devil.
>spec_from_loader(fullname, cls, origin='hell')

hah
Hire me please
This is so wrong! I like it.
So basically `eval/exec` Roulette...
Practicality/security aside, honestly, this is just a really cool idea for a beginner-intermediate level project. Nice one. 
"But it works on my machine."
This has gotta be a joke, right?
Sadly I know a few people who would actually use this. 
This made my day!!!
If we're ever gonna accidentally create an AI, it will be through something not unlike this.
Yes Great. I Will Use It
This is some next level shit right here. I like it.
What could possible go wrong?
Lol, new era of full-stackoverflow programming
There's already RSS. And I think there are apps out there that farm/use pictures from sites. So why not code?

This is a joke, though, isn't it? That aside, I still think it could be useful for learning.
Everyone agrees that this is both funny and epic. However, it's kind of a nice thought to try to standardize our main repository of code examples so that they are all reasonably consistent in their presentation, and even so that they can be implemented in a generic way without modification. 

I don't see it being so useful in an actual project so much, but I can imagine some kind of plugins that import (and display) chunks of code from SO, especially in some kind of specialized environment like jupyter notebook.

A lot of these types of tools already exist as reference materials without actually evaluating the code at all.
[deleted]
This is probably good as a learning experiment. And the idea is certainly interesting.

However, this probably introduces a licensing issue, as anything imported from StackOverflow is licensed under a [cc-by-sa](https://creativecommons.org/licenses/by-sa/3.0/) license. Therefore, you must distribute your code under the same license.
`ret.sort()` sorts `ret` in-place and returns `None`. You want `sorted(ret)` to get the sorted list as a new value. Also, post questions in /r/learnpython next time.
Try sorted (ret) == [...] as your test condition. Also, consider returning a list comprehension, like this:


return [word for word in str.split(" ") if len(word) > n]
`str` is a special word - so even if this isn't the cause, don't use it like that: it's the class that defines the behaviour of strings, and using it like this might give surprising results in some situations.

The reason your comparison doesn't work is that `ret.sort()` sorts ret *in place*, and returns *nothing* (well, actually, `None`), which obviously isn't equal to a list of any sort. As u/deathtospies says below, `sorted(ret)` is what you want, which returns a sorted version of the list.
A package is worth it when you consider the package mature, and the github related to it shows recent activity.

Long time Arg parse user: click is better.

The guy behind Pendulum is really pushing it, I think it will be preferred over Arrow.

In the end, it is more important to write quality code than which package you use for it. Granted, you should not put too critical parts of your app backed by something that's not been used in production before. 

Perhaps just bring the team together and let them argue their preference; end up with a preferred packages list.
Look up pip-tools.

Generate the file with proper comments regarding requirements
https://github.com/jsvine/markovify
For MCMC there's pymc or emcee
Markov chains are super damn easy to implement yourself, man. Do you have specific states in mind or just want to have something for arbitrary/dynamic states and transitions? If you just need the basic functionality, you don't need much code at all:

    >>> import random
    >>> transition_table = {'a': {'a': 0.5, 'b': 0.5}, 'b': {'a': 0.1, 'b': 0.9}}
    >>> class Markov:
    ...     def __init__(self, table, initial_state):
    ...         self.table = table
    ...         self.state = initial_state
    ...     def step(self):
    ...         old_state = self.state
    ...         r = random.random()
    ...         s = 0
    ...         states = self.table[self.state]
    ...         for next, prob in states.items():
    ...             s += prob
    ...             if r <= s:
    ...                 self.state = next
    ...                 print('{} => {}'.format(old_state, self.state))
    ...                 return
    ...
    >>> mc = Markov(transition_table, 'a')
    >>> mc.step()
    a => b
    >>> mc.step()
    b => b
    ... 20ish more steps ...
    >>> mc.step()
    b => b
    >>> mc.step()
    b => a
    >>> mc.step()
    a => a
    >>> mc.step()
    a => a
    >>> mc.step()
    a => b
    >>> mc.step()
    b => b
For words (not sentences) I think [gibi](https://pypi.python.org/pypi/gibi/) is pretty neat.
Here's a little lib I hack on from time to time 

https://github.com/justanr/markov-chains
Why not just implement the Markov chains in matrices with numpy?
Depends on the type of Markov chain analysis you want to do. 

Two good places to look if you focus on finite chains:

pykov: https://github.com/riccardoscalco/Pykov

quantecon: http://lectures.quantecon.org/py/finite_markov.html


Recording is available [YouTube](https://www.youtube.com/watch?v=jO9BM5pa398)
Could be Python 2 vs 3 problems. Also, post questions in /r/learnpython next time.
[deleted]
I know that this is intended as a programming exercise, but starting in Python 3.4:

    py> import statistics
    py> statistics.pvariance([9, 2, 8, 0, 4, 1])
    11.666666666666666

`statistics.variance` returns the sample variance, `pvariance` is the population variance.

So I checked out this weekly newsletter page a few times and... is it really just a recap of the top posts of /r/Python or am I not able to find the rest of the content?
Selenium through Python. Allows you to automate a browser instances.

http://selenium-python.readthedocs.io
First thing is to look at the website to see how it handles the vin numbers. If it isn't using javascript you might be able to use requests. But if it does use js then you would need to use selenium...

Setting up selenium can be a little tricky but once it's going should be quite easy.

Feel free to PM if you need help...
look at requests module.  It really doesn't get much easier to hit the api.  the only need you have is to fill the api input pieces.  You get back requests.content

http://www.pythonforbeginners.com/requests/using-requests-in-python
You're not going to be able to do this on safercar. I just checked the site and it uses reCAPTCHA, which is used to prevent automation like this. To automate it, you need to automate reCAPTCHA which TMK isn't publicly broken.

Otherwise, what I would do is download firefox and get the tamperdata extension. Then you go do it manually and look at tamperdata and what calls it made, might look like a POST to /api/checkvin or something. Then you just write something to do that in python with the `requests` module.

But you're not going to be able to do that here due to reCAPTCHA if you're considering this site: https://vinrcl.safercar.gov/vin/

Maybe Toyota's site, I haven't seen that one. If it uses reCAPTCHA though, they prevent automation.
Congrats on making that transition!
    def date_range(start_date, end_date):
        while start_date < end_date:
            yield start_date
            start_date += dt.timedelta(days=1)

Why this is not in the `datetime` module is beyond me.
I long gave up on attempting to write setup.py files, because it's impossible to get right. So I just always copy one I know works and edit the name/version/dependencies. 
I have one decorator in particular that I use a LOT, called `accumulate`. It basically lets you pull apart expressions that use generators and iterators into functions. At least, that's what I use it for. I have some complicated generator expression one-liner that looks like `'\n'.join(... some complicated stuff ...)` and I want to make it a function without either a temporary `result` variable or a wrapper function. 

It's very, very simple but it's just so applicable everywhere. It works like this:

    @accumulate(collections.OrderedDict)
    def files(ext, obj_ext='.o'):
        for fname in Path.cwd().glob('*' + ext):
            source_file = fname.relative_to(Path.cwd())
            yield source_file, source_file.with_suffix(obj_ext)

which would be the same as:

    def files(ext, obj_ext='.o'):
        result = collections.OrderedDict()
        for fname in Path.cwd().glob('*' + ext):
            source_file = fname.relative_to(Path.cwd())
            result.add((source_file, source_file.with_suffix(obj_ext)))
        return result

The issue I had was that I hated writing functions like the latter, because the temporary 'accumulator' or 'result' variable is horrible. But I don't always want a function that returns a generator, especially when I know that I am always going to be immediately consuming the generator with the same function. The other option is to always write a wrapper. So I wrote this **incredibly simple** and yet so useful decorator:

    def accumulate(acc):
        def outer_wrapper(f):
            @functools.wraps(f)
            def inner_wrapper(*args, **kwds):
                return acc(iter(f(*args, **kwds)))
            return inner_wrapper
        return outer_wrapper
I use SQLite a lot and I hate typing the all the connection/cursor/setup stuff. I have a template and long list of snippets I copy from for that.

I actually have snippets for everything. Regex, decorators, requests, commonly used functions, etc. I have a pastebin catalog with my most used stuff.
Getting lists of files.

So I made [get_files](https://github.com/DadAtH-me/get_files).

    get_files(".", extensions=".mp4")
Log and stdout setup. I work with a lot of multilingual/unicode stuff on Windows (Python will crash if you try to print("ä½ å¥½") in a standard console), want millisecond resolution in my logs, and want log file rotation. It's quick but fiddly to set up. Not something that should go into the standard library, but hard to imagine being productive without it.
I use this a lot for clean printing in threaded apps

    import sys
    import threading
    class ThreadSafePrinter(object):
    """
    Create one object and pass it to multiple threads:
    
        tsp = ThreadSafePrinter()
        tsp.write("Hello World") # No output
        tsp.force_write("Hello World") # forces output
        tsp.enable()
        tsp.write("Hello World") # Now you get output
    """
        def __init__(self, enable=False, auto_flush=False):
            super(ThreadSafePrinter, self).__init__()
            self.enabled = enable
            self.auto_flush = auto_flush
            self.lock = threading.Lock()
        def close(self):
            pass
        def enable(self, enable=True):
            self.enabled = enable
        def enable_toggle(self):
            if self.enabled:
                self.enabled = False
            else:
                self.enabled = True
        def is_enabled(self):
            return self.enabled
        def write(self, s):
            if self.enabled:
                self.lock.acquire()
                if isinstance(s, basestring):
                    sys.stdout.write(s)
                else:
                    sys.stdout.write("ThreadSafePrinter Error: attempting to write non-string: %s\r\n"%str(s))
                if self.auto_flush:
                    sys.stdout.flush()
                self.lock.release()
        def force_write(self, s):
            self.lock.acquire()
            if isinstance(s, basestring):
                sys.stdout.write(s)
            else:
                sys.stdout.write("ThreadSafePrinter Error: attempting to write non-string: %s\r\n"%str(s))
            if self.auto_flush:
                sys.stdout.flush()
            self.lock.release()
        def flush(self):
            self.lock.acquire()
            sys.stdout.flush()
            self.lock.release()


The most common thing I do all the time that's not in the standard lib:

    def strip_prefix(s, prefix):
        return s[len(prefix):] if s.startswith(prefix) else s

Boggles the mind that it's not in the stdlib. And the suffix version obviously. 
That one snippet that evolved from an example in the docs that let's me iterate over a sequence in slices of length n.
i have  script in pandas i made about  month ago that iterates through every column of a CSV and give top five max and min values. use it about once a week
From a standard Python interactive prompt:-

    help(xyz)

From iPython:-

    xyz?

or

    xyz??
I have a whole module of them and put them on PyPI. Aptly named [Reusables](https://pypi.python.org/pypi/reusables). 

Contributions (of any size) are warmly welcomed! [GitHub link](https://github.com/cdgriffith/Reusables)
[deleted]
My last job was almost entirely doing ETLs and then pulling that data for verification or reporting. Before I arrived it was done 100% manually, and I did automation on the ETL and querying side at first, but my favorite was creating some boilerplate code to generate formatted excel templates. I made a simple module that allowed us to automate tens of hours of manual work per project and really improve the quality of the reports.
I've got a few functions that I use for hitting my postgres databases. I pass in a SQL query and a list of parameters and the functions take care of everything else, including avoiding SQL injection and the likes. 

The two functions that select data return dictionaries instead of rows/columns. That way I can pass the data directly to my flask templates or web service without having to mess around with intermediate steps.

my sql calls end up looking like: 

    def getGames (week):
        sql = "select game_id, away_team, home_team from vw_games where week = %s order by game_date, game_id"
        return readAll(sql, [week])


** edut - they return dictionaries, not json.
    

I have a set of aesthetic tweaks that I usually apply to my matplotlib plots. In particular, I like to simplify my line plot legends by removing the line glyph, and simply coloring each label to match its corresponding curve.
    try:
        basestring  # py2 stuff
    except NameError:
        pass  # py3 stuff

The above adapted to my needs because I have to support Py2 like a neanderthal. 
[deleted]
Not really a piece of code as such - but I use cookiecutter and I now have a template which when the project is built will : 

   1. Build all the right directories - this is what cookiecutter does anyway.
    2. Build initial setup.py, code and test files.
    3. Build an initial readme
    4. Build an initial sphinx documentation set (blank but with some key sections completed already).
    5. Build init files for flake, tox etc
    6. Initialise a git respository and add ALL those files.
    7. Optionally Initialise a github repository for that code
    8. Optionally build Python2.7 and Python3.5 virtualenvs (and pre-install key libraries (flake, tox, six - if required)
    9. Build Config files for pYCharms including links to the virtualenvs, and setting up key files already open in the editor.
I seem to end up implementing compose in a lot of my projects:

    def compose(*fns):
        return reduce(
            lambda x, y: lambda z: x(y(z)), 
            fns, 
            lambda x: x
        )

    
    for line in somefile:
        row = line.strip().split(delimiter)
The down votes probably come from a fact that you misunderstood the topic (or maybe did this intentionally?)

I'll give you the benefit of the doubt and assume you just misunderstood. 

Secret trails in strings? Hidden messages? What the hell are you on about? 
> You could leave a secret trail in your code that leads to different places if somebody found it, coded messages for other people to find...anything really.

If you are this excited about manipulating and indexing strings 

you should read/watch some stuff on cryptography ...

your head will explode

Effective Python was a turning point in my Python career. What an excellent book, start to finish. It's like the book Raymond Hettinger would write.
I would also recommend "Automate the Boring Stuff with Python" i started it recently and i can say it's great so far.
The first one is very good. Not too hard for beginners, not too easy for advanced readers, just right.
Office neighbors' comment:

"Why does the Python book have a lizard on it?"

0_o

Looks great. I'm quite happy they didn't inculde Learn Python the Hard Way
The Flask book is so good
If we are recommending Python resources, I'll add [Peter Norvig's course "Design of Computer Programs" on Udacity](https://www.udacity.com/course/design-of-computer-programs--cs212). I think that's still the best online course I ever took.
How's the machine learning one? Good entry point?
Ive loved two scoops of django since the start, wish they made a book like this for express or haskell snap, it's all about best practices which is essential to not looking like a complete noob.
I have four of the books on this list. The only book I'm not really a fan of 'Data Visualisation with Python and JavaScript'. Just doesn't appear to be the best thought in presenting the content within each of the chapters. Considering there are plenty of blogs regarding data visualisation and python, I can't really recommenced it.


Fluent Python is really great book, definitely not a book for a complete programming newcomer. But reading the book really made me appreciate what could be done with Python and just how elegant the language can be.
As someone who just started python as their first programming language, which one of these books would you recommend to me, OP? I'm learning Python for DevOps purposes. 
All great books, especially fluent Python and flask.
I want to be webdev python, do I need to read all this book or just 5 and 6?
So many great books about programming in Python!
Am only I missing [High-Performance Python](http://shop.oreilly.com/product/0636920028963.do) here...?
I have most of these and I agree.
[Grokking Algorithms](https://www.manning.com/books/grokking-algorithms) is brand new, but so far the reviews seem incredibly favorable. It seems like a useful addition to this list. 
Wonder if the site uses Python on the back end.  Because then they might want to read a book on server load and connection caching issues to a DB.

"Error establishing a database connection"

Edit: Nope, it is wordpress.  wp-admin kicks to a login.  Someone needs to install a caching plugin.  Back up for me now and a great list.
I haven't looked at the article, but are these books mainly focused on Python 2 or 3?
What is the general consensus on Learn Python the Hard Way?
I am missing this one.

https://www.amazon.com/Python-Algorithms-Mastering-Language-Experts/dp/1430232374


first one is good
[*Hackers Guide to Python*](https://thehackerguidetopython.com/) for advanced developer.
I own both the Two scoops and Python Machine Learning and both are sadly outdated, not recommended purchases.
Fluent Python is outstanding though! 
Must read 7!?! books to learn Python.  Come the fuck on.  One or two books should do.

Edit: Comments noted.  I apologize for my use of bad words and for implying the books were about learning Python. However, I'd like to know how many people consider a 'must read' book about coding to be something other than learning about that code.  Ok, they're not all Python-specific, buy that too was implied in the title.  
Ultimately, I stand by my first and third sentences.  The second was not meant to offend, but to show my surprise of the implications of OP's title.
Would be interesting to see this applied to house prices instead of renting prices.
When I first saw the 'bedrooms', '-.014...' I was like alright this guys a total scrub, his ml implementation or data is whack, whata noob lulz.  


But then I read what you said about studios and realized that made a lot of sense after reflecting on my time apartment hunting as a  Berkeley student.  Especially in Berkeley, # of bedrooms doesn't necessarily mean $$$.  Consider a luxury penthouse studio on Shattuck vs a 2br dump maintained by an absentee landlord on south side.  Quality, I'd assume, is a confounding factor that confuses the relationship.  Sentiment analysis of the text might be interesting.


Anyway, nice job!  Enjoyed the article: it was well written, researched & implemented.
Funny how this isn't the first time I've seen someone do a write up on analyzing rent and finding deals in the bay area, in /r/python no less. Housing there is such a pain in the ass
Selenium is a _must have_ package. Saves me literally _hours_ of work every week. 
dont put color codes in python, use css class names.
How is this any different than just using the `or` operator that already exists?

    a = b = d = None
    c = 4
    v = a or b or c or d
    
Is the proposal suggesting that

foo = exists(bar) else baz

Should be equivalent to

foo = bar if exists(bar) else baz

**big edit:** swipe to type made my `Is` and `I'd`, now it's back to `Is`
> exists(foo) else bar

Why not `exists foo else bar` or perhaps `exists(foo) else (bar)` for consistency?
Not really a fan of the syntax. I'd expect `exists(foo) else bar` to evaluate to the return value of `exists(foo)` if `exists(foo)` is `True`, to be honest. Here, I think adding a new operator (or re-using an existing one) would make more sense. `foo ? bar` (or something like that) reads a lot better.
I don't like the idea of overloading `else` once more. It's already complicated for new developers to understand the `try/except/else` or `for/else` constructions. 
Well that is a bit heart-breaking, Adding another operator shouldn't be seen as so sinful (especially considering that reusing `else`, again, after it has existence in following `if` blocks, `for` blocks, `while` blocks, `try/except` blocks, and inline `if` statements. Keeping track of 5 different usages of a single keyword is a bit insane!)

The new protocol approach however is quite invaluable, and solves all the issues of the prior approach, and is somewhat incompatible with the `?` syntax too, damn shame

edit: It also seems to say that null propagation will work, but doesn't seem to suggest any method by how it would work? Which is somewhat far less useful than the prior proposal
It's early and I'm probably misreading this, but would

if x as y:

work for this? AFAIK such a feature is not implemented, but it would allow you to test the condition and assign it in the same line. Plus this follows the already used syntax of

with open() as f:
I'd rather use Ruby's inline rescue

    do_something rescue nil

Why not `x = prefer(a, b, c, ....)` rather than `x = a else b else c`?

That, to me, looks way more pythonic and eliminates all the if-else that is currently going on
I think I like this better than 531.
> **BACKWARD INCOMPATIBLE** Remove the attempted autodetection of requirement names from URLs, URLs must include a name via #egg=.

Is this something specific to eggs? or any url used as a source in requirements?
Here's the announcement by /u/donaldstufft on distutils-sig: 

https://mail.python.org/pipermail/distutils-sig/2016-November/029785.html

> This release features:
> 
> * The 9.x series will be the last pip versions to support Python 2.6.
> * Support for Requires-Python (will require additional support in setuptools/PyPI) to allow releasing sdists that will be ignored by specific versions of Python (e.g. foobar 5.x doesnât get downloaded on 2.6).
> * Ability to pass platform, Python version, implementation, etc into ``pip download`` to download wheels for other platforms.
> * Add a ``pick check`` command to check the state of installed dependencies.
> * Add new formats for ``pip list``, including a new columnar layout and a JSON format for ease of scripting.
Can we upgrade all outdated packages with a simple command?
I wish we could get pip-tools rolled in to pip...
Can I upgrade a package that is already installed to a specific version that isn't the latest version?
- Uninstall existing packages when performing an editable installation of the same packages

The old behaviour has been bugging me for quite a while now, I'm so happy they fixed it! 

I just want to add that if you are still disappointed because the lack of regex search, size, license and upload date indicator in pip search or just want to have nice formatting, colors and interactive menu you should defenietly check out [yip](https://www.github.com/balzss/yip)
I would love it if pip was aware of rpm databases and would throw an error if a package tried to overwrite something owned by an rpm. 
Check out locust.io 
Use aiohttp and asyncio, with the new async/await syntax it's SO easy.
Try https://github.com/Lispython/human_curl its the fastest http client for python. aiohttp stops at 800 rps while human curl can push 2k+ without any problems. Also the interface is like requests. Thats a nice bonus ^^
I wrote some software that scales into the millions using gevent and requests. One really nice thing about this approach is that you can write all of your authentication logic (in your case) synchronously, as if you only need to make a single connection. Then you "spawn" that into greenlets (or a greenlet Pool to set concurrency limits) and wait for them to complete.

How much you can scale a single process depends on many factors: expected response times, CPU time, etc..., etc.... For my purposes, response time measurements are critical, so I limit myself to about 100 greenlets per process, then scale my processes horizontally across CPU cores. In other cases it's not unusual to scale a process into the thousands or 10s of thousands.

edit: re: grequests, it appears to be a very simple wrapper API. I wouldn't bother with it personally. Just do:

    from gevent import pool
    from gevent import queue
    def work(task, q):
        q.put(<result>)
    q = queue.Queue()
    p = pool.Pool(limit)
    for task in tasks:
        p.spawn(work, task, q)
    p.join()

Incidentally, you don't *have* to monkey-patch everything if there's just some specific module you want to use gevent with. It's just awfully convenient in a module where you only expect to do IO with gevent.
Are you simply looking for an HTTP benchmarking tool? Or does it need to be written in Python? 

If not, I've used Apache JMeter, though it is slightly confusing to setup, it does make useful charts and tables. 
How do you know `threading.Thread()` won't scale, particularly if you decrease the thread stack size with `threading.stack_size(size)`? When you say hundreds of thousands or millions do you mean *at once* or *in total*? My guess is that that many at once would be hard by any means, especially in Python. But if it's only thousands at once I think threading might be fine.

Also, have you considered an existing tool like [siege](https://www.joedog.org/siege-manual/)?
I wouldn't use async at all. One tiny mistake, such as taking 30ms in a function call, and you can kiss your performance goodbye. Furthermore, threading or async, if your routines are CPU bound, meaning you're taking too much computation, you're hosed in python. You will only ever use one of your cores due to the GIL.

So here's my suggestion.

I would go threading all the way. Start your backend servers handling 200 threads each. Start them all on the same machine listening on different ports. Put Apache in front of them and load balance X of them. It is trivially easy to set up apache to be a load balancer. Here's how to do it:

    <Proxy "balancer://mycluster">
        BalancerMember "http://192.168.1.50:8080"
        BalancerMember "http://192.168.1.50:8081"
        ...
    </Proxy>
    ProxyPass "/test" "balancer://mycluster"
    ProxyPassReverse "/test" "balancer://mycluster"
    
Then if you need more capacity, spin up more backends. 

By the way, you are using wsgi, right?
python-libcurl scales very well if you are stuck in 2.7
[https://yandextank.readthedocs.io/en/latest/](Yandex.Tank) is great and can do ordered requests based on a config file. 
Tornado's async http client is very fast and about as simple as async gets.  Lots of examples around the web.  Check it out, see if it will work for you.
[Flask MySQL](https://github.com/cyberdelia/flask-mysql) uses [pymysql](https://github.com/PyMySQL/PyMySQL) to connect with MySQL. Check out [this](https://github.com/codehandbook/RESTfulApiUsingPythonFlask) example project. 
If you need blazing cpu speed, python is the wrong language in the first place. you need C or C++ (or Go or D....) for that kind of thing. 

Once you have prototyped you algorithm in python, you can selectively push the parts that need speed down in to one of the fast languages. 
From the link, "...it doesn't make sense to use Python for AES: modern CPUs have an *hardware* implementation which is super fast."

The benchmark shows that Python is slower when using an unrealistic number of int variables because that's not something you should do in Python anyway. The same changes might help other things. Really, it's only talking about using a long for int in 3, which is a fairly uninteresting discussion to most users.The linked writing also states that other benchmarks show a negligible difference.
All the slower ones are slower :P

Notice that a third of the benchmarks are faster and one of them is 32x faster. While the worst slowdown is 3x. 


Also not that in python3 more code _works_. I.e. is not boobytrapped with latent bugs riddle through the code.  
where did you even get that title from
Strong username
Any place I can subscribe for Liclipse news?

Looking forward to the switch to eslint since jshint doesn't work with es6
> 
It does have one new feature in which Ctrl+Shift+O (which fixes unresolved tokens by adding the needed imports) uses the improved sorting also used for the code-completion (so that tokens from the project appear before tokens from other projects, which in turn appear before tokens from the standard library). Also, the substring completion is now on by default (it may be turned off in the code-completion preferences).

Correct me if I'm wrong, but PyCharm can't actually do this, correct? It's pretty frustrating to do manually, so I'd love to know if there's a way. IntelliJ with Java is able to do automatic ordering/sorting of imports correctly...
Check out r/learnpython
Or even look at the sidebar: Online Books and Resources.
Step 1: read the tutorials on the python website. This will explain language basics.

Step 2: O'Reilly books are usually good, but the first and only python book I read was the Essential Reference (developer's library). Contains a good amount so that you can see how the language works, and prepares you for picking up new material.

Step 3: pick a module, and start learning it. You dont have to become a pro, but it will help you understand what goes into learning new tools in python. My first one was socket, and my first real project was a jsonrpc server. You can find the global module index on the python website. 

Step 4: find new technologies within python that can help you accomplish a goal you want. I started building a home automation package, but I abandoned this as there are already sufficient projects out there. It taught me a lot, like working with databases, multiprocessing queues, and configuration files.

Disclaimer: you will not be a coding guru over night. Initially many concepts may not make sense. Baby steps.
try 
https://www.coursera.org/specializations/python


Learning by practice
http://checkio.org
or similar http://www.codewars.com/

But checkio is dedicated to Python mostly with support for numpy or other libraries.

or try:
Kaggle.com for machine learning
I would start with selenium or requests.
Requests is ran headless and selenium you can watch it happen on screen.
In Python
run python script everyday http://stackoverflow.com/questions/3984134/how-to-write-a-cron-that-will-run-a-script-every-day-at-midnight#3984144
get mails https://docs.python.org/3/library/poplib.html#pop3-example
extract attachment https://pypi.python.org/pypi/emaildata/
unzip file http://stackoverflow.com/questions/3451111/unzipping-files-in-python
and then use this https://github.com/coolwanglu/pdf2htmlEX/wiki/Command-Line-Options with cli and python subprocess 
When it's done zip the folder again and then there are two solutions
Either use selenium to simulate a form request or you can try something simpler go through chrome and post that form with the  Developers tools on Network tab open. right click on the post request and copy the curl command. You know what to do next.
You can hit me up on fiverr.com/deerl0rd and we can discuss this job, if you want someone to write it for you.
Third online resource down in the navbar/help menu for this subreddit covers pretty much everything you asked.  

Piecing it all together may be another kettle of fish all together ;)
Regarding your first question, why not just create a view, and then put a model on top of that? All you need to do is set the `__tablename__` to point at the view's name, and define the columns as you would for any table.

As far as your second question, for retrieving the equivalent of a case statement boolean, I think [this is what](http://docs.sqlalchemy.org/en/latest/orm/mapped_attributes.html#using-descriptors-and-hybrids) you want. You can use it to add calculated properties. 
Based on your description, I might drop the use of the term "mesh", as it has a specific meaning in networking that sounds like it likely conflicts with the reality of the way your application will be designed.

see: https://en.wikipedia.org/wiki/Mesh_networking

"Social media aggregator" might be a more accurate description.

Offhand, I'd assume the design should likely be a fairly straightforward process of downloading posts from the API's supplied by the social media sites along with any metadata; possibly extracting some of your own metadata from the post if it isn't provided; storing it to file or a database in some way; and then representing that data however you wish in the GUI of your application.

I'm not certain as to specific libraries and things that you would use. There are likely python libraries already available specifically for interacting with these services, which should make the job of authenticating and pulling the posts down fairly easy. 


[Practical Business Python](http://pbpython.com/pandas-list-dict.html) is helpful. Reading through the docs may be your best bet. Pandas has multiple methods that complete Excel-like operations. As an example:

Text to columns: 
```dataframe['column'].str.split('_', expand=True)```
http://pandas.pydata.org/pandas-docs/stable/text.html#splitting-and-replacing-strings

Pivot tables:
```dataframe.groupby('column_one').agg({'column_2': 'sum'})```
http://pandas.pydata.org/pandas-docs/stable/groupby.html#aggregation
  


Excel concepts don't directly translate to Pandas - it's a very different tool with a different programming model. Approach it like that, and learn the idiomatic ways of doing things - it'll make things a lot easier for you in the long run.
Have you watched some of the videos from the PyData and PyCon conferences on pandas? In particular, Brandon Rhodes has made some inspired video tutorials.
And of course: xlwings can be part of the mix. It helps you interacting with a running excel instance. 
Doesn't look like writing decorators with classes (instead of functions) is explained. IMO class based decorators make more sense if you are writing a decorator that takes arguments, as you split the decorator args (the class' init method) and the function wrap/call (the class' call method). You can also create per wrap variables using the decorator class' attributes, such as self.attr. Still a good read/introduction!
IMO, the important thing to remember about decorators is that they are just functions with some syntactic sugar. When people are trying to figure out how decorators work, they're usually figuring out how closures work. 
The biggest short coming in this article is the lack of discussion on using `update_wrapper` or `wraps` (it's decorator form -  using decorators to make better decorators,  how very meta). 

These preserve metadata about the original function such as `__name__` to make debugging easier. Optionally, it can also propagate attribute access from the underlying thing.

These two are incredibly important to writing good decorators. 
I've been really impressed with [scikit-learn](https://github.com/scikit-learn/scikit-learn) for several reasons:

1. It's a *massive* codebase, but still manages to be very well organized in spite of this
2. Their documentation is excellent. If you are looking to see well documented code, take a look.
3. Similar to number 1, the models are well organized with base classes pulling in commonly used functions, with specialized classes handling more specific models, say Logistic regression for example.
[Reddit itself is written mostly in python](https://github.com/reddit/reddit)
I'm a big fan of the [Python error steamroller](https://pypi.python.org/pypi/fuckit).  To quote the docs: This module is like violence: if it doesnât work, you just need more of it.
The worst python code I've ever seen: https://github.com/zack-bitcoin/basiccoin

It's actually real code but the author took to the letter the advice that "less lines of code means more readable code". Author, if you read me, you're horribly wrong and I keep your repository with me at all time to remember the attrocities that mankind is capable of.
I think [django](https://github.com/django/django) is very well done.
Not on Github, but a beautiful example of Python (IMO): http://norvig.com/spell-correct.html
Oneliner-izer in a heartbeat. It's awesome that someone took the time to make a transpiler like this. 

Edit:

Turns:

    def fib(n):
        if n < 2:
            return n
        return fib(n-2) + fib(n-1)

into: 

    (lambda __g: [None for __g['fib'], fib.__name__ in [(lambda n: (lambda __l: [(lambda __after: __l['n'] if (__l['n'] < 2) else __after())(lambda: (fib((__l['n'] - 2)) + fib((__l['n'] - 1)))) for __l['n'] in [(n)]][0])({}), 'fib')]][0])(globals())
I'm kinda of a fan of elegant chunking functions. 

The one path.py uses to read files by chunk of x bytes:

https://github.com/jaraco/path.py/blob/master/path.py#L754

Or the one I use in ww to iterate on iterable of x elements (that I stolen from Hettinger):

https://github.com/Tygs/ww/blob/master/src/ww/tools/iterables.py#L147

I was looking at Hyper H2 recently, which is a Python implementation of the new HTTP/2 protocol. It's really interesting from a code design point of view because it deliberately avoids implementing the actual I/O portions - since you may want to use it with an asynchronous I/O engine like Twisted.

This also makes the code much easier to write tests for.

https://github.com/python-hyper/hyper-h2 - the documentation is particularly good


Anything associated with [Armin Ronacher](https://github.com/mitsuhiko), such as [flask](https://github.com/pallets/flask).
[Construct](https://github.com/construct/construct) is an amazing Python library for handling binary data. I used it to build a package to parse PKM data (data from the Pokemon games that details individual Pokemon in your party and PC boxes, like their IVs, EVs, exp, what ball was used to catch them, etc). It's so much easier to handle data in a declarative way.
The Requests library!

https://github.com/kennethreitz/requests
Not on github, but I loved this obsfucated "hello world": https://benkurtovic.com/2014/06/01/obfuscating-hello-world.html
I find [PyPy](https://github.com/mozillazg/pypy) pretty impressive. From the README:

> PyPy is both an implementation of the Python programming language, and an extensive compiler framework for dynamic language implementations.

A dynamic Python compiler written in Python... doge!
https://github.com/python/cpython/blob/master/Lib/this.py 

This is actually from the standard library and is terrible code but done in an ironic manner.
Not in GitHub but this is something I saw at work:

SOME_DICT = {
    'a key': 123,
    'other': 456,
}

def example(key):
    return eval(key, SOME_DICT)
I feel like the spirit of the question was 'which modules are coded in a really interesting way' and the answers are mostly about which modules do something interesting.
[Ansible](https://github.com/ansible/ansible) Configuration Management system
I while back I found this project called TrumpScript, which is pretty much just Python but with a bunch of limitations making fun of Trump. For example, all scripts have to end in "America is great" and certain words like "Hilary", stop the script from running. I'm on mobile, but will add a link when I get home.
My own quick and dirty stuff (not public)...uncommented, sometimes monolithic, non-idiomatic, garbage.
This: https://github.com/lxc-webpanel/LXC-Web-Panel

Gigantic functions, queries database directly from views, way to many nested if statements to reason about without loosing your sanity, not even the slightest concept of an architecture, horrible workaround to shoehorn an ini parser into reading and writing LXC config files, takes user input and sticks into subprocess.check_call with shell=True, and has to run as root.

I tried using this as a base for a thing at my previous work, ended up rewriting the whole thing from scratch, basically. My version had problems, too, off course, some pretty bad ones, but God, it was a thousand times better than this. 
[pyramid](https://github.com/Pylons/pyramid)
https://github.com/leo-editor/leo-editor is the worst codebase I've ever seen. Which is impressive, because they aim for better coding-abilitys.
I don't have the code with me, but manually parsing a list of strings from a config file using an if/elif block. It didnt help that the developer was super cocky and wouldn't take anyone's advice on anything.
https://github.com/onelogin/python-saml

Looks like some Java programmers were told they had to also support python so they ran a transpiler. 

It's mostly undocumented so doing anything requires reading the code. 

If you need to import anything, be prepared to type everything twice,  e.g. `from onelogin.saml2.auth import OneLogin_Saml2_Auth`

And this is the least terrible option I found. Another saml lib also depended on webob, zope, paste, etc because it packaged a web app as a demo, despite the actual parsing logic not needing any of that. 
I like the simplicity of mkdocs
Not python but https://github.com/itchyny/lightline.vim/blob/master/autoload/lightline.vim is pretty difficult to read.
I have a collection of bad code examples which I find in projects I am working with. Like this one: https://github.com/sobolevn/python-code-disasters/blob/master/python/PhyRe.py
I like [pyephem](https://github.com/brandon-rhodes/pyephem). It has great documentation and the author is super nice.
In this kind of situation I generally would print `directions` itself and see what its structure is like.

For example with the Youtube API you tend to get stuff that is annoyingly nested.

I'm guessing it might be a similar situation, just print out `directions` and if its minified json (all on giant line) use an online un-minifier to get a good look at it.

Edit: Just tried it myself and as I thought its one giant line of json with the element you are looking for near the end.

You only really need the distance matrix api though:

I'm doing this in Python 3.5.2 so its a bit different for me:  

    from googlemaps.client import Client
    from googlemaps.distance_matrix import distance_matrix
    api_key = 'API_KEY'
    gmaps = Client(api_key)
    distance = distance_matrix(gmaps, "White+House", "Golden+Gate+Bridge")
    print(distance)

That should return a much smaller snippet of json to work with.

Edit 2: I couldn't sleep because of this, had to figure it out:

    from googlemaps.client import Client
    from googlemaps.distance_matrix import distance_matrix
    api_key = 'API_KEY'
    gmaps = Client(api_key)
    data = distance_matrix(gmaps, "White+House", "Golden+Gate+Bridge")
    distance = data['rows'][0]['elements'][0]['distance']['text']
    print(distance)

There, that gives the distance. :)
You'll get a lot more help at /r/learnpython. 
Can no one read anymore?
Hi, I would like to help
Having worked in the hosting industry and played around with Django, I can at least give you the following, even though it won't answer all your questions.

Django provides a management/admin interface, similar in concept to wordpress. Provided you've designed your app correctly, in theory there is no need to edit code. You should be able to add entries (for example adding a blog like you do in WP) through the admin panel. 

Yes, hosting services typically support python, however you want to speak to your host to ensure they can support django (if that's the route you go), as it needs mod_wsgi, last I checked anyway. You definitely want to look into venvs. It was pretty common for django to be installed in say, /usr/lib on our  server, but be too old for the client. On shared servers, you can't have that changed. But a venv gets around this, as you can install a different set of packages for just your user. Deployment should be relatively easy with venvs, but you may need to edit the config file.


I like to use [responses](https://github.com/getsentry/responses) for this kind of stuffs (which - among other things - allow to assert on http requests)
I've used [vcrpy](https://github.com/kevin1024/vcrpy) for this sorta thing in the past.
Wow, this is quite something. "Fuck you" is not a good response to distributions having rules, and OP is not the kind of person that should be allowed anywhere near Debian repos if that's how they respond to things.
tldr
Try pyinstaller.
What's the name of the app? Can we pip install it?
You'll get a lot more help at /r/learnpython, especially if you post with formatted code (use 4 spaces and read the sidebar) and have more finite question. 
What exactly is the part you're missing?
just a small note - you might want to look at how you post code into this forum - as you know, formatting and whitespace are critical in Python - and as posted your code wont run as it is not indented correctly. - you might want to read up the formatting and edit your post above (hint every code line has to be indented by at least 4 spaces for them to be formatted correctly when posted)
thank you
I moved to learnpython and changed my format
Meanwhile, the same example with [Pyro4](http://pythonhosted.org/Pyro4/)...:

``pip install Pyro4``

*server.py:*

    import time
    import Pyro4

    @Pyro4.expose
    class PingPong:
        def ping(self, message, delay):
            print("Received message '{}', delay {}s...".format(message, delay))
            time.sleep(delay)
            return "Thanks, friend!"


    if __name__=="__main__":
        Pyro4.Daemon.serveSimple({
            PingPong: "pingpong"
        })

*client.py:*

    import sys
    import Pyro4


    if __name__=="__main__":
        pingpong = Pyro4.Proxy("PYRONAME:pingpong")
        pong = pingpong.ping(sys.argv[1], float(sys.argv[2]))
        print(pong)

... done :)
That being said, I can see the use of gRPC when dealing with other languages that it has a binding for.
/r/learnpython
In the past I thought the Sedgewick book Algorithms in C is a kind of good and understandable introduction. But to be honest, I think the best way to learn is just working on a product that forces you to make the right decisions. Think about real world problems like how can I encapsulate data in a way, that I combine things which belong together. How can I prevent writing (kind of) the same code more than once - even if it's just three lines.

For learning more about how computers work: I learned most of it when I was working on things which put me at the limit of the hardware at that time. Try to make sure your programs don't use more than 2MB Ram (or less), try to implement a file system (yes - that's possible and easier than you think)... read code lots of code!
Have a look at Thonny (http://thonny.cs.ut.ee), an IDE for beginners and students. I think it might fit your requirements.
Some good and well known IDEs include PyCharm and VS Code. They will more than likely wind up using the command line at some point, either to run their scripts or to mess around with the Python console. VS Code is great for this since it includes an integrated console. You might want to get some input from someone who does use PyCharm, since I haven't used it before and am not sure of what features it has, but from what I've heard it's one of the best, if not the best, Python IDE around.
It sounds like it will be a very basic course,  so it may be something like ipython notebook/Jupyter would be suitable. 
I am using [Spyder](https://pythonhosted.org/spyder/) and also taught some linear algebra with it. 
PyCharm community edition (free) all the way. It's probably not what some people would call 'lightweight' but frankly unless you are using very old laptops the advantages it has in terms of user friendliness far outweigh any concerns about speed.

There is also PyCharm edu which is a stripped down version of PyCharm for teaching -  personally I find that outside a python course it's a bit too limiting which can undermine people's ability to grow. On the other hand it comes with tools designed for creating lessons which could be very useful for you. https://www.jetbrains.com/pycharm-edu/concepts/
Pycharm licenses are free for students. It's excellent
Not sure you can get both super simple *and* IDE. It just generally doesn't work out that way sadly.

If you want a simple setup Notepad++ with the PyNPP plugin is enough but you won't get code inspection, debugging, and such like you would with a full fledged IDE.

Personally I use PyCharm, it has advanced features but they aren't shoved into your face and can be ignored, the interface is also relatively simple. By default you have a sidebar to display your project file tree and a codeview with tabs, that is it. You can quickly run code many ways, with the easy to access python console from a tab at the bottom, the terminal/cmd similarly from a tab at the bottom, or with the incredibly obvious green run button. You can also just right-click a codeview tab or file and run it from there.
I would recommend Thonny editor. Its very lightweight and should be good for teaching. I personally use it when writing small scripts.
Ninja is probably worth looking into - it was my first IDE before I moved to PyCharm and I remember it being pretty simple to use.

Link: http://ninja-ide.org
Personally I am a PyCharm user. However, for quick python editing I highly recommend Wing-IDE or Komodo Edit. Both have freeware lite editions. 

IIRC, Komodo has a portable edition which need not be installed - just unzip and run. Wing IDE may require admin privileges to install.

http://www.wingware.com/downloads/wingide-101

https://www.activestate.com/komodo-ide/downloads/edit

OP here.  
Thanks everyone, some great advice and links to follow up here.  
At first glance, Thonny looks most promising, but I will be sure to check each suggestion out.
Thanks again.
https://wiki.python.org/moin/PythonEditors
The power of the search engine!

[http://www.infoworld.com/article/3033047/javascript/4-tools-to-convert-python-to-javascript-and-back-again.html](http://www.infoworld.com/article/3033047/javascript/4-tools-to-convert-python-to-javascript-and-back-again.html)

Though perhaps you were just spurring conversation. In which case I have never used any of these.
The task you're referring to is code generation. In general it's a very difficult and very powerful thing. But if all you really need to do is fill values into a template and maybe copy-paste a bit, then it's just like any other string manipulation. What exactly are you trying to do? 
You want a templating language that can template javascript. Most web templating languages will be able to do that.

You will not be able to automatically convert python code to javascript.
The Python library Bokeh creates JavaScript code from either strings or from Python functions. Maybe check how they do it.
Not necessarily what you're asking for, but [Brython](http://brython.info/) is a Python transpiler written in JavaScript. It converts Python code to.JS, and executes it. 
First, it looks like the signal you're trying to identify the pitch of is only 1024 samples long.  At 44kHz this is only 0.02 seconds!  How accurately could you identify a pitch if it was playing for such a short time.

Second, I imagine your function AMDF is gonna be really slow, particularly if you increase the number of samples beyond 1024, because it is quadratic complexity.  You're gonna have to learn about fast Fourier transforms if you want to do real time audio!
For the first problem.. Maybe dont try to get the note played based on absolute frequency, but rather on the relative pitch compared to the previous note. Let's say the violin is out of tune by a whole note. If all the string are off by the same amount then playing the notes will sound right. If the fingering is a bit flat or sharp, as long as the relative pitch between fingers is close you could count it as the right note.
What you've mentioned, having one script that does all the API communication and acting as an intermediary forwarding things back and forth, is a good way of doing it. You could use a message broker like RabbitMQ, or something simpler (in some ways anyhow) like Redis. This way will give you the most power and flexibility but it's possibly a fair amount of work to refactor your applications; moving from a synchronous flow to asynchronous can be a bit of work in refactoring and testing.

A much simpler, though less flexible, option would be to use some sort of synchronisation (e.g. a file lock like those provided by the fasteners library, or one of the multiprocessing primitives). Make each of your scripts acquire the lock and sleep a second before doing an API call and you're guaranteed to not be making more than one call per second.
I'm not sure I follow the way you're doing this, but some type of mutex or lock could work. You'd still have to call the same function. Are you saying the API calls are duplicated through the different scripts or that several scripts call the same module with the API calls?

You might get more help at /r/learnpython. 
Using a lib that isn't written with async will be pretty common for at least 10 years I'd think.  
I find threads to be easy to work with and think about. I will continue to use them.
I've been tying to find a good primer on async/await, but it feels like something along the lines of doing http requests is akin to the animal/dog/cat example of oop: it's ubiquitous, boring and not that great at representing the concept. 

I feel like if someone pointed me at a solution of a different problem, I would understand it much better. 

In fact, this ties into the op's question: can a multiprocessing/threadding solution be replaced by async/await here? 

Imagine I had 20 input files and needed to apply a function to each of them, line by line. The function is an order of magnitude shower than I/O, so I want to read and store the results in parallel. 

With joblib, I would just map it onto the list of files. 

With async/await, I still have no idea. 
Every time Python calls into a C function that is properly written to release the GIL, other Python code (and other C code) can run.

Numerical code written with numpy will benefit from multithreading and will be truly concurrent, because most numpy functions release the GIL.

Threading in Python isn't nearly as useless as everyone thinks it is, and multiprocessing not the answer nearly as often either. Actual concurrency with threading totally happens all the time without anyone noticing, and yet you have people trying to shunt their arrays over to a separate process to do to Fourier transform and send it back again when that would have run concurrently in the same process just fine.
Yes, coroutines are not always superior to threads, sometimes they are easier to use. It is good to have the choice.
>Now that Python has added coroutines (e.g. async/await) as an alternative 
>method for concurrency, do you still see yourself using threading for 
>I/O-bound work?

I *understand* threading, as opposed to whatever the heck alien technology async/await is. :-) :-(
So with async - you can theoretically do many hundreds/thousands of connections.  How many threads in a threadpool can I reasonably have?
Basically if you're not doing networking code then, yes, you will need threads. You can actually use threads with async/await, which is sorta nice.
Honestly, I feel like asyncio was a horrible name. Asynchronous programming? Kinda, I mean there's a catch to it. I/O operations? I guess you could, but the only thing asyncio really solves is the problem of "waiting" for a file. However, it can't actually replace threading/multiprocessing libraries because python's async library uses cooperative scheduling. That means that your function, once started/resumed, has a monopoly on the thread until you release control. In a real life example, this means that with asyncio, in order for a heartbeat to work, you need to ensure that all code paths will hit an "await" every heartbeat interval, otherwise your heartbeat will never happen. By comparison, even with the GIL, a multithreaded heartbeat implementation will be called as soon as the heartbeat interval has passed and the current atomic operation (probably about a line of code) finishes.  
Tl;dr asyncio is concurrent, not parallel.
Python has had actual multi core processing for a while, it just launches multiple python instances however.
Unlikely, honestly. I rarely do anything in Python where the GIL presents an actual, *practical* problem and if I wanted to do something and needed great parallelism support where performance was an issue I wouldn't use Python at all, I'd use Closure or Go. Or Java. Or hell, Erlang.
Yes, I do still use threads. For some reasons:

* I'm very used to threads. I'm aware of the danger and I know how to be safe.

* async/await requires a very different approach to code structure. Whenever I feel that the thread's style is more suited to my needs and there are no other reasons to avoid threads, I use threads. I'm looking forward to see David Beazley's curio library reaching a production level quality in order to use async with thread's semantic. I think David's approach to async programming is better than the official one.

* Sometimes I rewrite performance critical code in a C shared library loaded through ctypes, and this lets me skip GIL limitations with threads and obtain true cpu parallelism.

Just my 2c.
As far as I can see, basically the entire scientific python stack will continue to rely heavily on threads for the foreseeable future. Huge chunks of that stack do release the GIL so threads do operate in parallel - the common example is numpy itself, but there's ton's of stuff both for doing CPU intensive work (like machine learning with scikit-learn) and doing I/O on large data files (e.g. GBs of weather data in NetCDF files). 

In general this needs repeating a lot more: a data/science applications is really huge part of the python community. We don't care (mostly) about webservers, async or otherwise. We get performance by writing critical elements in Cython/C/Fortran (and hopefully Rust in the near future). The GIL is not a big deal because native extensions release it.

That said, most people probably shouldn't be writing threads directly but using a schedular/task queue to do it form them (such as Dask or Joblib)



Fuck yes, preemptive multitasking. 
What is the difference between threads and async? How does async work under the hood?
Of course, everyone knows most real work is done on 2.7.
Most aren't that odd, but the ones that are are pretty bad.

The loop oddity is really useful. In multiple assignments `a, b = 1, 2` you don't want to face an arbitrary restriction like "b has to be a name" because then you couldn't do things like `self.x, self.y = foo.split(",")`.

Python Addition Oddity, yes all that `list.__add__` needs for the rhs is an iterable.

Python Hashing Oddity, yes functions are immutable.

Python Array Oddity, evaluation is left to right. The only question you might have is if it evaluates the entire RHS before assigning to the LHS or if it weaves it, and really "who cares." Anyone who uses multiple assignment with the same object on the LHS and RHS deserves the bugs they introduce for it.

---------------------

The isnumeric oddity... yeah somebody should get shot for that one. Either fix the isnumeric function or remove it from the string class right now it is more confusing than useful.

CPython Oddity... this is just dumb. Immutable base types should compare use `__eq__` for `is`. If someone actually needs to know if an immutable base object is duplicated in memory provide some other way to do it. Either that or don't call it `is`. "is" has semantic meaning and is not just an implementation detail.

Python Syntax Oddity... obviously a bug in the parser, presumably unfixable. But how useful are rawstrings?
my favorite one:

    d = {0: 1}
    for k, v in d.items():
        print(k)
        del(d[k])
        d[k+1] = 1

    print(d)

which outputs:

    0
    1
    2
    3
    4
    5
    6
    7
    {8: 1}
Haha! Agree to your points. ð
I can't find the difference between "Python Boolean Oddity" and "One More Python Boolean Oddity" 

Was the second one supposed to be with False instead of True?
Pickling is awesome if you don't need extreme performance or any guarantee of security.  As long as your pickled objects never fly over the internet in an automated way, you're golden.
I never use pickles for persistent objects. They're just not robust in the face of ongoing changes to the classes of the pickled objects because although objects are pickled, their classes are not.

Much better to use a persistent format that is under your control and which can evolve independently of your class definitions if need be.

I do use pickles for serialisation of objects where the serialised representations are transient and never persisted (e.g. sending objects to a subprocess) â in fact this is how multiprocessing works.
Using `pickle` is not wrong 100% of the time, but there are very very very few times where it's the best choice.

* Pickle will break if your code changes. Python hard-codes module/class/attribute names into the pickled value, so if you rename a class or move things around in basically any way your pickled values will be unrecoverable.
* Pickle works (roughly speaking) by dumping the AST/bytecode for a given value. This means that **pickled values are code that is executed**. All considerations that apply to arbitrary code execution apply to pickled data. If you allow an end user to supply pickled values your system is inherently vulnerable to code execution.
* Even if the source code hasn't changed, pickled values may or may not be compatible between even minor Python version updates.

These details mean that pickle is not a good option for long term storage of values, nor is it good for over-the-wire transmission of data. It is not durable, it is not secure.

Your description of the code doesn't clarify much about what you're actually storing, or what the code does overall. It sorta sounds like you're trying to store configuration values. If that's the case, you very likely could use [JSON](https://docs.python.org/3/library/json.html). JSON allows you to store several very useful and fundamental data types: strings, integers, booleans, maps (dicts), and sequences (lists). I'm firmly of the opinion that if you can't distill your information down to these data types, your data is poorly structured or overly complex.

Depending on the nature of this data that's being stored, a database may also be useful. You mention having multiple values (records) that you're updating in-place and then reloading periodically. You might want to consider using something like sqlite to provide a persistent data store for these data, which provides a whole realm of guarantees and features best described [here](https://en.wikipedia.org/wiki/Relational_database).

More concrete details, and a copy of the code, are necessary before any more concrete recommendations could be made.
If it's pure data, it's fine, but if your data structure has objects or your data structure ever changes, or your pickled file should work across python versions, just don't.
Pip allows you to install 'development/editable' versions of your library - which is a direct link to your live in development code; so you wont have to build->upload->download->install during your development cycle. 
why not just keep ithem as seperate git repos and add them to your Pythonpath ?

    $ export PYTHONPATH="${HOME}/git/project_1/:${HOME}/git/project_2/:"

add it to your **.bashrc** so it will be set every time you launch a terminal.

you can develop on every project and once you have stable versions you can

build packages.

/edit :

sorry..  I just realised I just assumed you are using linux :)
are you using linux ?
> a way to separate them into their own repos.

I know this will sound facetious but have you tried making new repos and copying your code there? That's what you said you want to do, so do that :p

As far as installing, just clone the repos into site-packages folder, and then you can push and pull changes directly.
at first glance this looks like massive amounts of NIH - why?

the scope is mega-huge - why?
Separate the two cases: if the length of the list is odd, then you want the element at the first integer index above the halfway point - using Python's floor division operator, that will be`len(mylist) // 2 + 1`. You should then be able to adjust that code slightly for the even length case, but remember you want to get *two* elements there and find their average.
/r/learnpython 

First you need to make sure the lists are sorted.  
myList's median is 3 at index 2 because the list is of odd length and the median lands squarely on that element.  Take length of the list, floor-divide it by 2 to get index=2. Bam.  
mysecList's length is even so median is numbers 2 and 3 averaged out using the run of the mill mean (x+y)/2.  To get the numbers required you need indices 1 and 2 which can be obtained with len/2-1, len/2.


If this is homework where the goal is to learn to 'roll your own', then by all means do so.

Otherwise, the [standard library](https://docs.python.org/3/library/statistics.html?highlight=median#statistics.median) has you covered.
    s = ",".join([number1, number2, number3, number4])

You should not use this subreddit to do your homework.
How about this?

First, let's use "with" when opening the file. When the statements in the "with" block are finished executing, the file will automatically be closed. Even if an exception is encountered, the file will still be closed, making it a good, safe practice.

Let's also get rid of the "for" loop. We can use a list comprehension to make a list of the random numbers. (Are you familiar with list comprehensons?)

Finally we'll use the print function rather then the write method of the file to write the output. Why? We can use "argument unpacking" to unpack the numbers in the list as if they were separate parameters. For instance, if we had a list of three numbers such as 

    x = [1, 2, 3]

and we called

    some_function(*x)

this would be the same as calling

    some_function(1, 2, 3)

!

We'll also use the optional "sep" parameter of the print function (which isn't available with the "write" file method unfortunately). This parameter sets the separator to use between multiple parameters. For instance,

    print(1, 2, 3, sep='-')

would print

"1-2-3" (without the quotes)

Putting it all together, if our numbers are in "nums", we can do this:

    print(*nums, sep=',')

and get the comma-separated list of numbers you're looking for!

    import random

    def main():
        #Open a file named numbersmake.txt.
        with open('numbersmake.txt', 'w') as outfile:
      
            #ask for amount of random numbers
            total_nums = int(input("how many numbers would you like to generate:"))
            #let's make a list of numbers
            nums = [random.randint(1, 500) for num in range(total_nums)]
    
            #Now we'll use argument unpacking and the 'sep' parameter
            print(*nums, file=outfile, sep=',')
      
      
    #Call the main function
    main()


You'll get a lot more help at /r/learnpython. I suggest looking at the docs for string formatting. 
I've worked in financial modelling a lot, the best tool for the kind of thing you're describing is excel...it can run forecasts and Monte Carlo etc. And if you are using the model to support a business case then you need to share it easily and transparently
It sounds like you'd want to design three functions -- one which computes your output calc based on several inputs. From there, write a fourth script which produces your average calc. Finally, write a script to iterate a thousand times, running the calcs and printing outputs to a log file. Copy-paste into Excel for sharing / analysis.
You'll get a lot more help at /r/learnpython, but even there is questionable since this sounds like homework. 
Has an email wall.
Go though each missing module and ask if you need it.  If you don't, then you're fine (e.g., you probably don't need PySide for a PyQt4 app).

Don't do:

    from qgis.core import *

That's so not going to help pyInstaller.

Also, you're running pyInstaller and trying to jump to the end (e.g., `onefile`) when at the very least you don't know if it even works with multiple files.  You gotta do a buildup.  Run with heavy debug, read everything, and treat warnings as errors.  In your main program, do a mass import of any missing modules.  You can clean it up later, but get something working.

Then there's issue of setuptools (use version 19.2), which isn't well publicized, but maybe it just works for everyone but me...

I strongly recommend using a spec file.  That way all you have to do is type `pyInstaller program_name.spec`.  Then you can handle all your missing DLLs/icons as well, which who even know how that's handled without making a spec file.

Here's my spec file  https://github.com/SteveDoyle2/pyNastran/blob/master/dev/pyNastranGUI.spec
[GitHub](http://alexprengere.github.io/currencyconverter), [PyPI](https://pypi.python.org/pypi/CurrencyConverter) links

Release notes:

* zip files are now supported as input
* urls are now supported as input
* the format of the single day file from the European Central Bank is now supported

This basically means that you can now do:

    from currency_converter import CurrencyConverter
    
    # Load the packaged data (might not be up to date)
    c = CurrencyConverter()
    
    # Load the up to date full history
    c = CurrencyConverter('http://www.ecb.int/stats/eurofxref/eurofxref-hist.zip')
    
    # Load only the latest rates (single day data source)
    c = CurrencyConverter('http://www.ecb.europa.eu/stats/eurofxref/eurofxref.zip')
Not the author, but an interesting read on not being lazy with virtualenv (or the lack thereof).
Backups are your best friend.
More usefully:

* [PEP 468](https://www.python.org/dev/peps/pep-0468/) - Preserving the order of **kwargs in a function
* [PEP 487](https://www.python.org/dev/peps/pep-0487/) - Simpler customization of class creation
* [PEP 495](https://www.python.org/dev/peps/pep-0495/) - Local Time Disambiguation
* [PEP 498](https://www.python.org/dev/peps/pep-0498/) - Literal String Formatting
* [PEP 506](https://www.python.org/dev/peps/pep-0506/) - Adding A Secrets Module To The Standard Library
* [PEP 509](https://www.python.org/dev/peps/pep-0509/) - Add a private version to dict
* [PEP 515](https://www.python.org/dev/peps/pep-0515/) - Underscores in Numeric Literals
* [PEP 519](https://www.python.org/dev/peps/pep-0519/) - Adding a file system path protocol
* [PEP 520](https://www.python.org/dev/peps/pep-0520/) - Preserving Class Attribute Definition Order
* [PEP 523](https://www.python.org/dev/peps/pep-0523/) - Adding a frame evaluation API to CPython
* [PEP 524](https://www.python.org/dev/peps/pep-0524/) - Make os.urandom() blocking on Linux (during system startup)
* [PEP 525](https://www.python.org/dev/peps/pep-0525/) - Asynchronous Generators (provisional)
* [PEP 526](https://www.python.org/dev/peps/pep-0526/) - Syntax for Variable Annotations (provisional)
* [PEP 528](https://www.python.org/dev/peps/pep-0528/) - Change Windows console encoding to UTF-8
* [PEP 529](https://www.python.org/dev/peps/pep-0529/) - Change Windows filesystem encoding to UTF-8
* [PEP 530](https://www.python.org/dev/peps/pep-0530/) - Asynchronous Comprehensions
How do you report a bug on core Python?


Downvote me if you like, but

After 8 years python3 finally maybe [gets close](https://bugs.python.org/issue25227) to the speed of python2 in [arbitrary file handling,](http://python3porting.com/problems.html#nicer-solutions) which most of my code relies on.

Maybe in the next 8 year I'll give it a try.

Better separate the audio decoding and the playback, these are two very different things.

That said, for playback I'm using pyaudio. For decoding, I'm running ffmpeg in a subprocess that decodes whatever audio file you throw at it to a PCM stereo stream (which is fed to pyaudio).   
Any reason you don't want to use an external executable to do the heavylifting?  Because I think it's not much work to add (time)seek support to my wrapper class...
It's good to learn C, because it's what the most popular Python implementation is implemented in. Learning a low-level language like C will allow you to understand better why Python behaves the way it behaves, and then how to fully exploit its features. For example, why Python lists allocate more memory than they actually need, or what trade-offs drove Python to use Global Interpreter Lock.
Instead of just one language, let me recommend the book [Seven Languages in Seven Weeks](https://pragprog.com/book/btlang/seven-languages-in-seven-weeks) by Bruce Tate.

It carefully picks seven languages each based on a different underlying paradigm  It then presents each in seven instalments, each of which can easily be absorbed in a day.

Itâs a great way to broaden your horizons without committing too much at this point.
Haskell or Scala will expand your mind. Go for something that has a real type system, functional idioms and and pattern matching. 
In my opinion, it's best to go as wide as possible.

* A working knowledge of Python is a pretty good starting point.
* Following that with some abstract CS from [SICP](https://mitpress.mit.edu/sicp/full-text/book/book.html) in Schema.
* Then go low level and work through [The C Programming Language](https://en.wikipedia.org/wiki/The_C_Programming_Language).
* Then I'd probably go about learning SQL; I don't have a good resource, but I'd definitely recommend PostgreSQL over other dialects.

At that point, you've got a pretty solid foundation to build on and then it's a matter of exploring specific topics (type systems => Haskell or Rust; OOP => Smalltalk; Enterprise => Java or C#).
Rust is now Python best friend.

You can call Python from Rust and vice versa.

Rust is as low level as C, but much more modern, robust, and can still use C libs.

Bottom line: 

- you want a high level language, you go Python.
- you want a low level langauge, you go Rust.

You usually can start writting a program in Python and reimplement the critical part in Rust later, as we used to do in C.

No need for an intermediary languages like Go that are not exactly low level or high level. Python + Rust allow you to exactly target what you need, with the exact flexibilty and firepower required.
I like haskell. It fits in the category something really different. It's where the list comprehension came from :) It has static types without having to declare them! Indentation matters! It will teach you about functional programming and about static types, but in a pleasant way. Can't go wrong trying haskell :) You asked for something different, be prepared to be frustrated.

As for the same thing in regards of web and general purpose, just try a bit of nodejs, and be amazed with asynchronous/callbacks/promises. I wouldn't stay too long :-) 

You could also try a frontend framework. ReactJS perhaps. Though I guess CS frowns upon that, so I might have to take this back.

Also, Rust is up and coming for a nice low level C++ replacement (competing with Go). This will probably start a discussion :P

You could also stay in python and work with Cython! That should be interesting as well.

Just my $0.02
Learn your python to be social.

Python can talk to interpreter (Tk, R), and it is nice learning the languages before the bindings, because it opens a door to a new world you can do with python (like python-tk).

Python can bind on C/ASM/fortran libraries. Thus learning C extension, FFI and others trick is nice.

Then, I would put on top expect that is really a nice trick of tcl (ported in python with pyexpect) because you can do amazing interactions with almost any interpreters and devices (like routers).

With this, you can embrace the  real strength of python; having the advantage of almost every language possible and more.
C really helped me understand some of the intricacies of programming and makes you appreciate some of the things you take for granted in higher level languages
Since you know python you could enjoy other paradigms with also python libraries. There are a few python variants: https://github.com/vindarel/languages-that-compile-to-python

- dg is very functional, a bit like haskell (it doesn't have types nor pattern matching, but it's useful !)
- hy is a weird lisp
- coconut it 100% python compatible and more functional

Also I wouldn't learn C, but a higher level language like Elixir http://elixir-lang.org/docs.html which is similar to Ruby but has many new concepts.

You will very probably need to know javascript later or sooner, but here again you have plenty of choices: a functional and terse variant (livescript, awesome http://livescript.net/), a haskell-like variant, etc
I'd pick Swift. More practically C. And for different a lisp or Haskell. But different isn't necessarily good :P
Carve a "UnicodeDecodeError" to make it really spooky.
> pip install pumpkin 

If you guys want this execute the command above

Imgur is leaking to reddit for once.
Thank you, very much appreciated. Looks amazing.
Technical question- how did you get the two circles to float that way?
pykin
I appreciate this.
I guess it's cool, but something about it is bugging me.

Maybe it's that it's a little cringey. I like Python, but when I go to a party or hang out with my wife and kid, I don't fly the geek flag so high. It's not that I'm embarrassed to be a nerd. It's more that something about this smells of desperation. Like you're begging for people to ask what it is so you can tell them all about it and they'll be impressed by how technical and smart you are.

Geeky t-shirts with esoteric "jokes" make me feel the same way. They seem designed to make the person wearing them  feel smug and superior to those who aren't in the know.

Then again, maybe I'm projecting younger me onto you
    df.groupby(pd.cut(df['id'], range(0, 110, 10))).sum()['orders'].plot(kind='bar')

Change range as required to match your range of ids; assuming your DataFrame is df and pandas is imported as pd.

**But mostly, /r/learnpython.**
What's your job, jw
I think you'd be better off with different processes listening to the same message queue. You might also get some better advice at /r/learnpython. 
That sounds like what you get under the Community Edition. The Pro edition should just handle Cython and syntax highlight everything properly out of the box. Check your version.
In settings there's a 'File Types' page which sets what syntax type to use for file extensions. That's what would have been not set. 
What web framework do you want to use ? Django, or something else. Answer that question and you might get closer to your answer (or at least narrow your search).
 django is a web framework so it's not specialized with e-commerce. you have 2 options:
 
* use any e-commerce solution built with django and then use ready made templates for that solution
* find any html/css e-commerce template f.i. at https://wrapbootstrap.com/themes/e-commerce and just use it with your hand made solution

Why would you want that kind of visual distraction? Your IDE will be already loaded with syntax highlight colors, visual cues for changes/errors/columns and cursors, etc. Why add another layer of visual noise on top of that?
I know the Qt framework allows this as an option for windows/widgets - you can set the background color as (r, g, b, a) where setting the alpha channel allows you to toggle the level transparency. 

Off the top of my head I'm not sure if there are any python IDE's based on Qt, but if there are - then in principle its possible. Whether or not the option is available to the user is another story.
most desktop environments should be able to set transparency for individual windows these days
if you like work with console you can use console editor f.i. vim:

 * http://imgur.com/a/hwoWl
Not optimized for mobile: [wat?](http://i.imgur.com/QQb4A3m.png )
I hope libs should be searchable by class or module names just like 

http://www.findjar.com/index.x
Worth it just to find out about [this](http://libi.io/library/2154).
I'd say your best bet is to optimize by way of building a specific application with web.py, profiling it, and then optimizing based on what the profiling tells you. Generic optimizations like running PyPy are useful, but they're generic -- they don't speed up what specific bottlenecks might exist in the application you've built.

http://ubiquity.acm.org/article.cfm?id=1513451
Probably going to get downvoted for this since it is /r/python after all, but why don't just start with something like Go then if you really need high performance that badly and are already using low-level frameworks like web.py anyway, rather than going for such an obscure stack using the JVM or LLVM.

Edit: or even just plain old python3 with asyncio should get pretty decent performance also.
Don't think that llvm example is for what you are looking to use it for.

The two mainstream options at this point are asyncio with uvloop, or pypy. Or use another fast framework that is built to be fast, like falcon.
thank you for tips guys!  I'll have a look at the things you suggested!
+1 for asyncio. I just wrote an asynchronous server yesterday, you can DM if you want the link. Its not thoroughly tested, but you can write your own handlers for it. Looked to handle about 1300 connections on an old AM3 dual core workstation. 
Miguel Grinberg's https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world has to be one of the best I think.
yup at https://techarena51.com/index.php/category/flask-framework-tutorials-and-examples/page/2/ or you can even check my project at https://github.com/Leo-G/Flask-Scaffold
Was all scipy document pages been hacked!? I need it so much....
Not Found

The requested URL /doc/scipy-0.10.1/reference/generated/scipy.integrate.trapz.html was not found on this server.
this is interesting - it appears all the scipy/numpy pages are down
Looks like it's down, you could try looking at the source: https://github.com/scipy/scipy/search?l=reStructuredText&q=trapz&utf8=%E2%9C%93
When a website is down you can use [the Wayback Machine](https://archive.org/web/)

e.g. https://web.archive.org/web/20150908162801/http://docs.scipy.org/doc/scipy-0.10.1/reference/generated/scipy.integrate.trapz.html
Some context:

Morepath applications can be composed of smaller sub applications. Views are added to models dynamically. This makes Morepath powerful but it becomes harder to get an overview of what paths are exactly published to the web by your Morepath applications.

To help with that I've created a command-line tool that can extract this information from Morepath's configuration system and dump it into a csv file which you can then view with your favorite spreadsheet program. Quite a bit of information is in there, including what model class is published, what permission is used to guard access, what request method was used and the source file and line number where this was declared. Without a configuration system to query this would be a lot harder to expose, so yay Morepath's configuration system!

Massive (in numbers) qr-code generation using pyqrcode, pillow and celery to handle the flow.
I do a lot of small projects using flask, so I am writing a flask project starter called Flask-NewProject. I have it on Pypi. Its very basic and my fiarr project on Pypi. If anyone would like to give me some pointer, that would be great.
Constantly getting ChunkedEncodingError and IncompleteRead exceptions in my Twitter streaming... Halp plz
Going to be learning about the https://www.xlwings.org/ module which lets python interface with Excel... so I can do more automation at work!
Pandas, Pandas all the time....(maybe times to tensor flow...)

I am working on a twitter application where almost everything will be a plugin - including the gui, filtering and much more besides. The core app will handle the raw date from the twitter servers, and co-ordinate it through any selected plugins to get a resultant data stream (which may be tweets, but could be something else entirely). The GUI plugin currently being planned will allow the display of one or more data streams - which could be in tabs, or in side-by-side panels.
USSD API of telco.
Polishing a tiny little library that (hopefully) will let me randomize program responses (Think yes/no GUI boxes) with synonyms. (yah/nah, yup/nope) Mostly works right now, but still wrestling with representation of responses from a .txt

Totally useless in actual programs, honestly it will probably slow things down if anything, but I get very bored when testing and the same response box comes up for the 50th time. I'm weird :/
Trying to create an editor in pygame to allow for easy creation of items/characters for a game I eventually hope to make. Not that experienced so it's a tad slow-going. Fun nonetheless.
I'm working on trying to prove something about my networking project. I'd like to be able to mathematically quantify the number of hops between two people.
I wrote a sports betting bot using the Pinnacle API, and my first [tutorial](http://cyber-omelette.blogspot.ca/2016/10/the-programmable-web-vice-city.html) to go along with it. 

I've decided to start documenting all my projects, and trying to boil them down into straightforward reproduce-able steps.
Quant work related to xVA's (CVA and FVA). Used CUDA to do Monte Carlo simulation of all OTC derivatives on book. PyCuda + Pandas + Numpy/Scipy work really well for this.

This week I'm trying to calibrate a PCA interest rate model to observed swaption vols. Also wrote a slack bot so that traders can check their xVA's.

At some point I'd like to move all the code to PyPy but Panda's doesn't work with it yet.
Learning all my syntax.
I've worked in Java for a long time now, but I have a lot of friends I wanna do things with that only know Python. Next step is to figure out a good replacement for JavaFX!
rewriting a tool to backup docker-compose peojects.
Im just now starting to learn python. Any tips for beginnners?
I have to write a lot of contracts, so I am working on a markdown template engine. 

As of now it is a flask app with jinja2 that lets you choose your markdown templates.  When you choose a template the app gets the template variables,  turns them into input elements and renders the template as html with some light javascript and a "save as"  button at the bottom. 

I am also doing a light cli version that uses Pandocs for more output options. This version turns the variables into input() functions.
Rewriting ned batchelder's byterun completely. Hopefully.
I'm working on a library for medium-data analysis using Postgres and pandas. Think pandas DataFrames, but backed by Postgres tables (instead of stored in RAM) so you rarely have to materialize the data directly until you want to read the result. 

If this sounds like blaze, it kind of is, except that it exploits Postgres-specific features as much as possible regardless of support in SQLAlchemy (or other ORM). It still uses SQLAlchemy when it can, it just isn't limited by it.

Basic skeleton is done (type inference, reading from input, assignment [`df['col1'] = something`], `groupby()`, `apply()`). Currently working on adding SQL expression support to `groupby()` and `apply()`, plus cleaning up and reorganizing the code to make it more familiar to a pandas user.
Making and launching an open source social network platform which will be free for any developer and reduce the ramp up time to deployment. I am also working on extra plugins which would be meant to complement the product. Mostly done in python/django
I'm finishing up some replication scripts that we use to make cut-overs between key/Value stores seamless.  It's pretty sweet, if I do say so, myself. 
Reddit bot that reverses gifs for comedy. Check out /u/gifreversingbot in a week or so

Having trouble uploading large gifs to imgur though. If anyone has any experience with doing that programmatically I'd love the help
continuing to learn data science using Pandas and Numpy
Python-wise, I'm working on AWS scripts for a client. 
I just wrote a rock paper scissors program - I started learning Python a couple of days ago, as you can probably tell.. It only took me about an hour though. Any feedback would be much appreciated! http://pastebin.com/HWZ1ZDB6
Rebuilding a wiki thing that uses file system directories for structure.  While in edit mode it currently uses Flask and ckeditor for the UI.  With each update/edit a static file is created so that in read mode it can be browsed directly or the whole wiki wrapped up in a zip.

Part of the rewrite I am using CherryPy and making an library that manages just the files/content while another handles transforms (live html or static html) as well as saving and keeping inventory of files per directory.
Working on my hacking toolbox
-phishing
_botnet
_key logger
_brute force password cracker
_rat
_some viruses
Three done . three to goð
Learning how to use Django! It's very exciting.
My Synthesizer library. I've just started implementing envelopes. ADSR is done, but I want to add a few more basic ones.
How to optimally distribute first responders around a city.
Neck-deep in extending with SWIG. Every fail at Python so hard you seg-faulted?
Wrote a welcome bot for Slack - [allie](https://github.com/devupin/allie)

Whenever someone joins your slack team, this bot sends them a welcome message.

Artificial Intelligence Lab for my high school. I'm making a program which solves an adjacent word puzzle when given a dictionary
modified a script that he doesn't use 100% CPU on a shared hosting server

you wouldn't believe how easy it is to use 100% CPU
[deleted]
Here, have a wee script to [sort a file while respecting the indentation hierarchy](https://bitbucket.org/sietsebb/dotfiles/src/default/bin/sort_indented). I am fond enough of YAML and glossaries that the time had come for a script that is able to sort them.

It uses the defaultdict-as-a-tree trick, type hints, and NewTypes to distinguish between various ints I keep track of. Apart from that, nothing v. interesting I think. Feel free to nick it, or to tell me how you'd have done it.
Working on a friendly _() method that returns a translation from ugettext or ungettext based on number of arguments.

This should have been implemented in gettext module.
I just finished a little project called [GitHubLog](https://github.com/JoshuaRLi/GitHubLog), a visualization of where GitHub's userbase is over time on the globe! The web app is html/css/js, but I made several Python scripts to collect and process all the data consumed by the front end. [Here's a preview of what it looks like!](http://imgur.com/OfiRTxf)
Trying to wrap my head around twisted and using it with autobahn to provide low latency video feeds.
Im working on a meteorological application that uses our modeled output with bias correction approaches applied.
I just gave this a go and with the default large dataset it looks decent (no other training etc). I used a single i7 core and it takes several minutes to do a 128x128 image w/ a 10MB data reference.

I downscaled a 480px image to 192px, upscaled it to 750px and it looked better than the original. If not for being at work I'd upload a sample.

Really looking forward to training this and using it instead of cubic upsampling.

I'd like to see it with a 1GB training file and an Amazon p2 instance w/ 192GB VRAM...

EDIT: Upside down Aussie land means I only just saw this blew up. See example by /u/malisle which pretty closely resembles my results. Keep in mind a more extensive training set would produce better results.
This algorithm (or similar ones) have the ability to enable amazing lossy compression algorithms. I mean, no one cares how each strand of hair looks, a fairly small data set is needed to describe how the hair is styled and the algorithm does the rest. And the same goes for a lot of other details.
Looks like csi wasn't far off. 
Would be great if this worked on video, and could take the information from other frames to construct one frame.

But I guess that would be a different technology.
I had used a similar service when I needed to upscale an image.  

http://waifu2x.udp.jp/

> Single-Image Super-Resolution for Anime-Style Art using Deep Convolutional Neural Networks. And it supports photo.

Result:

Twice Upscaled Soap Bubble Diffraction pattern : http://i.imgur.com/0ppWSEU.jpg

Anyone interested in how this works should head over to r/machinelearning - the tech behind this is relatively new from a general python perspective, but on a machine learning scale, with a few months it's already relatively old ;). 
Can somebody please run this

* on drawings/paintings
* on noise
* recursively
ENHANCE
[deleted]
Thank you.  I think I also have a basic understanding of what a neural network is.  But I'm definitely at square 1 for all of this.
Anybody know where that HD celebrity faces dataset would be?

I want to try making a new glamour photography method:

1. Train neural net with celebrity faces
2. Downscale normie photos
3. Upscale normies using neural net
4. Profit?!
Oh, glad it wasn't just me. I tried at work but because of our firewalls and stuff, a lot of sites don't work or have issues. I forgot to check when I got home. Either way, glad it's back up
Seems to be online again! :)
There's the infamous mutable default argument:

    def foo(a_list=[]):
        a_list.append(5)
        return a_list

    print(foo())
    print(foo())
    print(foo())

-----

Some things that you can regularly see in beginner programs:

    if var == 'green' or 'red':
        # Do something only if var is green or red.

-----

    >>> a = []
    >>> b = a
    >>> b.append(42)
    >>> a
    [42]

-----

Comparisons between different types in Python 2: `'a' < 1`.  
This would be more suitable to /r/learnpython if it hasn't already been posted there.
those are not most common pitfalls, 

1. public variables

2. functions make more than one thing 

3. using raw strings as `const`

...
http://isup.me/www.docs.scipy.org
Although isup.me says it is up it is down for me.
My open source library has lots of examples, but the PyPi package doesn't include any of them.  If it did, they'd be buried inside site-packages, which is kinda dumb.

Then just link to the examples on your github or do it one by one.  It's pretty standard to do it that way.  I'm even lazier, so I just say download/clone the actual github repository if you want everything.
`numpy.load('thefilename.npz')` will do the trick. Docs are down but you can `help(numpy.load)`.
use numpy
A lot of people like [anaconda](https://www.continuum.io/downloads) as a self contained python installation/IDE and the notebooks are great. I am not sure you can run it from a usb but I would think you could. 

I think the best option may be to set up a server somewhere like your house that you could ssh into through putty. You could use an old computer or even a raspberry pi. Then you can do whatever you want because its your machine, it's just located somewhere else. 
If there ever was a reason to take a drill to a laptop webcam, this would be it :-)

Whatever remote system you set up it'll still be a hassle. Suggest you try to get comfortable with a professional development tool that you'll be likely to use in your later endeavors.

Nowadays, building and deploying a Django stack means having virtualenv, a local DB server (like Postgres), a virtual container service (like Docker), version control (like git), and a good IDE/editor with decent editing, refactoring, and debugging capabilities. You'll also need network access to look up docs and examples as well as a decent HTML/Javascript editor/debugger if you need to have a web front-end. Or a JSON visualizer and API tester if using DRF. 

Trying to do that all remotely will slow you down and make the whole experience annoying.

If the objection to bringing your own laptop is only because of the webcam, I'd look into disabling or removing the camera. If it's something else you may want to carry an SSD drive with a bootable partition and boot your work machine to work off that drive.
There are laptops without webcams -- my partner has an old Thinkpad X201 without one. Thinkpads at least through the X220/T420 era (~2011) had a no-camera option. I suspect more recent ones do as well, but I don't actually know. I'd bet also anything that many business-class machines from Dell and HP also have no-camera options

If you trawl through EBay you should be able to find a Thinkpad X201 or T410 without a camera for $150 or under. Both should run PyCharm perfectly well. The key is that you'd need to make sure the individual machine is without a camera, maybe by contacting the seller.

[This page](https://forums.lenovo.com/t5/ThinkPad-T400-T500-and-newer-T/With-webcam-or-without-webcam-T400-series/ta-p/354103) has a picture of a Thinkpad T410 bezel with and without a camera, just so you can get a sense of the difference and to see if that would pass muster with your worksite.

Good luck!
Can't you run PyCharm off a USB stick? Other options are vim+jedi, visual studio code, sublime with the right plugins...
>I can't bring in my personal laptop because it has a built-in camera.

Drill out the camera.
>  It is designed to run on much larger crawls rather than speedily downloading a single file.

You do know that wget can also very rapidly/easily download whole domains?
[Isn't this what you're after?](https://pypi.python.org/pypi/goslate). It queries the Google Translate website so is free.
Single words is a dictionary. Sentences is super complex and really hard. Even google who is a clear world leader is so-so between indoeuropean languages and bad outside that family. 

That's why they're charging for it. Which makes sense: it was expensive to build. 

Probably not a good idea to rely on this to learn a language though. 
Check out translation service of Russian IT company Yandex. It's free and it supports many languages. Though I'm not sure whether their docs are available in English.

https://translate.yandex.ru/developers
I've spent a lot of time looking at translation solutions, and Googles translate API is unquestionably the best I've found. The rate limits should be more than enough for what you describe, and the translation quality is very high.

You can then use nltk on the returned translation to restructure sentences or adjust part-of-speech tags and such....nltk is great
Seems like it's covering similar ground to celery. As an interested newb to both, how do they stack up? Which one should i choose over the other?
This is not a vagrant replacement. This a *wrapper* for `vboxmanage`. Vagrant does a heck of a lot more and virtualbox is only one of the providers it supports. A good start would be also supporting `Vagrantfiles` or a similar syntax for a reproducible build.
Check out argparse
This is nice, but you may wish to emphasize that this is just an implementation of a simple response-surface methodology with a pre-set sampling strategy. Importantly, it could have problems on many different types of problems. For instance, I typically test my numerical optimization and model emulation strategies using the [Rosenbrock function](https://en.wikipedia.org/wiki/Rosenbrock_function), the [Ishigami function](https://www.sfu.ca/~ssurjano/ishigami.html), and a high-dimensional [G-function](https://www.sfu.ca/~ssurjano/gfunc.html). How well does your algorithm fair on these, and how does it compare to other surrogate modeling strategies (polynomial chaos expansion, LARS, etc)?

I've also found the multiprocessing package to not really be the best for these types of projects, because error handling (particularly when model evaluations fail) can be kind of brittle. I've used map-reduce strategies in the past to farm out work to a cluster, but these days I've found a lot of success with [joblib](https://pythonhosted.org/joblib/). You may want to check it out!
I'm another one who doesn't really understand it.  And that worries me. I got started on Python back in about 2000 precisely because it was both powerful and accessible, and I've never had reason to doubt that assessment. I still use it daily, for back-end development, for sysadmin, for mathematical modelling and other tasks.

But every time I try to do something asynchronously, I experience a heavy cognitive load, and I rarely achieve what I'm trying to do. It does worry me that although I have very little experience with Node, there are things I can do within a couple of hours of playing with Node that I _still_ don't know how to do in Python. I'm sure it's *possible*, I just haven't figured it out yet. 

I wrote an asynchronous, postgres-backed chat server in Node within hours of picking it up, 5 years ago. I still don't know the right way of doing that in Python, and I certainly have no idea how I would do that within the context of Nginx/UWSGI.

But I stick with Python because of how beautifully it handles synchronous tasks.  I'd hate to have to do, say, report production or analysis in Node, without having tools like Pandas available.

I have high hopes for AsyncIO.  But I don't understand it yet, and I certainly couldn't teach it to other team members.
Anyone staying with gevent in 3.5+ ? Are there any pros in asyncio beside that it's explicit ?
Check out curio, it's an alternative to asyncio that's a lot more intuitive.
I also spent some time learning asyncio casually and I also don't understand it. Maybe it's because async programming is hard by default? Look at Twisted.  People hate it so much and complain about its complexity all the time. Perhaps asynchronous code is just difficult to reason about and difficult to understand? We have all these mental models coming from common sense daily life reasoning - they are all synchronous by default. When we try to understand or develop asynchronous frameworks we get all confused because it is so foreign to our default style of thought. 
with asyncio you need coroutine-aware/non-blocking versions of every IO-related library. 

with gevent you just monkey-patch the core libraries, and the rest works out of the box. 

It's not asyncio that doesn't make sense, it's the ecosystem that still needs to grow a lot for it to be useful for every case in which I'd use gevent. 
Asyncio's idea is to be a common API so that libraries can compete regarding their implementation. If you dont want to write an alternative and only are a user of it, then the subset of asyncio that you actually have to understand is not that big. It also allows a common constructs for libraries and developers to express asynchronous code. It will make async libraries smaller as well as allow them to focus on their primary benefit for the ecosystem.
Check out https://sans-io.readthedocs.io/
Actually using asyncio tools is quite easy and straighforward. However, writting an asyncio lib, or god saves you, an asyncio framework, is really, really hard. Most attemp out there just ignore the complexity and works only on the author's configuration of choice.
I'm a heavy Python user, but haven't yet used asyncio. I used async/await in C# a little bit though, and one thing I keep wondering about is how it means you have to have duplicate APIs for a whole bunch of stuff: we have an http library, but now we need an async one; we have a db library, but now we need an async version; we have subprocess, but now we need an async version of the API; etc. Whereas in Go there's only one synchronous version of the API for everything, and you "go func()" to run any existing function/API async (in a goroutine). 

What I don't understand is: what's the technical reason, if any, that Python, C#, etc can't take the Go approach, which avoids all the duplicate APIs?
Oh boy, another article where "I've overcomplicated this to the point where I don't understand it".

> So here is the current set of things that you need to know exist:  
>event loop policies  

No you don't. The only time you ever need to know this exists is when you want to substitute uvloop into your application.

> coroutine wrappers

I have never heard of these before, and I've never even seen them used at all.

The rest, you may need a passing knowledge of, but even then you don't need an in-depth knowledge of them to use asyncio.

>  On the surface it looks like each thread has one event loop but that's not really how it works.  

Yes, that is how it works.  
`get_event_loop` gets the current event loop that is local to that thread. `set_event_loop` sets the current event loop in that thread. Coming from the Flask author, these are just thread local variables.

> as a coroutine or something similar does not know which event loop is responsible for scheduling it. 

Don't schedule coroutines from other threads on your event loop. This is a recipe for disaster. There's even a built-in function for this - `asyncio.run_coroutine_threadsafe`.

Now, I agree that the 3.3/3.4 design is very weird, especially in regards to `yield from`, with somethings (such as the aiohttp code) mixing both meanings of them. However, 3.5 cleans up the act of the code by enforcing that you use the newer, coroutine-specific syntax.

> Essentially these are all objects with an __await__ method except that the generators don't for legacy reasons. 

Don't use Python 3.4 coroutines.

> So now that we know there are two incompatible futures we should clarify what futures are in asyncio. Honestly I'm not entirely sure where the differences are but I'm going to call this "eventual" for the moment.

One is from asyncio, and is bound to the event loop.  
The other is from `concurrent.futures`, and is for use in thread-based code. 

> alternatively you require that the loop is bound to the thread.

This is the sane way to do it. Why do you have multiple event loops running one thread? How would that even work?

> Learn to restart the event loop for cleanup. 

No. 
1) Get all of the tasks current running on this loop `asyncio.Task.all(loop=loop)`.  
2) Cancel them all.  
3) Await them all, to allow the cancel to be handled properly.  
4) All cleaned up.  

> Working with subprocesses is non obvious.

https://docs.python.org/3/library/asyncio-subprocess.html#create-a-subprocess-high-level-api-using-process

> Writing code that supports both async and sync is somewhat of a lost cause

That's because async and sync are pretty incompatible with eachother anyway. 

> If you want to give a coroutine a better name to figure out why it was not being awaited, 

Why would you do this? If you have a coroutine that dies without being awaited, you've done something wrong. 
> Aside from the insane complexity and lack of understanding on my part of how to best write APIs for it my biggest issue is the complete lack of consideration for context local data.

Write your own contexts. This is not `asyncio`'s job.  
Many libraries pass through a Context-like object to each coroutine in the chain, who can then do with it as they want.

> The worst part is that asyncio is not even particularly fast.

Python isn't fast. How is this a surprise?

This seems like a "I'm unwilling to learn how asyncio works" post, more than a legitimate article.


Is there anything from Python 3 that this guy likes? Honest question.
I don't understand either and the lack of documentation doesn't help at all.

    class A:
        def __init__(self, a, loop=None):
            self.a = a
            self.loop = loop or asyncio.get_event_loop()

I've seen this code on repos but I don't know the reason why people are doing this.

Another thing is:

    class A:
        def __init__(self, a):
             self.a = a
        async def test(self):
            await self.something()

Can I just run `loop.run_until_complete(a.test())` or do I still need to do `loop or asyncio.get_event_loop()` in `__init__`? Should I leave it as is etc. I have many basic questions.
I also find asyncio difficult to grok.  I pretty much hate JavaScript but if you need/want to be async it's much easier to get up and running with node.  That being said, Go.  Go's channels and goroutines just blow Python's various async libraries and node out of the water.

I still find Python more visually appealing than Go, but Go's concurrency model is elegant and easy to understand.  I'm going to keep using Python for years and years but I've already started moving over to Go when I can.
So as far as I understand the logical call context thing it's essentially just a way of storing data on the stack in a way that remains accessible to functions you call. (Along with fancy stuff to carry this across networks or to prevent it from crossing thread boundaries.)

In other words this:

    def set_call_context(name, value):
        calling_frame = sys._getframe(1)
        context_data = calling_frame.f_locals.setdefault('__call_context__', {})
        context_data[name] = value

    def get_call_context(name):
        calling_frame = sys._getframe(1)
        while calling_frame is not None:
            context_data = calling_frame.f_locals.get('__call_context__', {})
            if name in context_data:
                return context_data[name]
            calling_frame = calling_frame.f_back
        raise LookupError(name)

Possibly wrapped up in an object or a dictionary.

Why not just implement this as a library? It's going to mess with PyPy performance-wise but that should be easy enough to address, once it proves to be useful.
You should be using r/learnpython (read the sidebar) but I'll humor you.

1: >> is not the appropriate redirection for /dev/null (even though it may work)
2: use the stdout keyword arg, not a bash redirect
3: use a for loop to iterate over the list
Could you paste the exact error message? 

Seems likely that it's a "List index out of range", on the vid[count]. 

The problem seems multilayered. `subprocess.call` calls the command each time the loop is run. omxplayer, when called more than once, appends the new file to the playlist, in the background. So, this happens while the first video is still playing. The variable `count` keeps increasing. When it reaches 10, there are no more items in the `vid` list. This is what is causing the error. 

Your solution would be changing the while condition to this:

    while (count < len(vid)):

This will prevent the count from increasing beyond the list length and eliminate your error.
* Consider /r/learnpython for asking questions

* Replace os.system() with subprocess.run()

* The first part of your code can be refactored

like so:

    vid = []
    for i in range(10):
        vid.append(str(i).zfill(2))

But we don't need that. Let's just use os.listdir()

    vids = os.listdir("/full/path/to/Video/")

It looks like this is sort of a background thing, so let's make it loop forever.

    import itertools
    vids = itertools.cycle(os.listdir("/full/path/to/Video/")

    while True:
    #we should think of an exit condition
        if gpio.input(11):
            subprocess.run("omxplayer -b --vol 1500" + next(vids))
            time.sleep(0.1)
        else:
            gpio.output(3, 0)
            time.sleep(0.1)

Ok. That was a bit rambly. The only thing that could be out of range on that line is the

    vid[count]

So try putting

    print(vid[count])

before the subprocess.call() to debug the values going in. 
Protecting a scripting language against attackers is hard, and transforming it in another form (such as a binary) won't protect it for long with sufficiently patient and backed attackers.

If you want to sell your program and to protect it, the most efficient idea would be to build it as a web application, with the "interesting code" written server-side. But not all projects can be made this way. An other way would be to rewrite your program in a compiled language (like C++, OCaml, ...). But remember that if someone wants to reverse the code, he will be able to do it. They are softwares who can modify the code to make it "unreadable", but they are expensive or already broken.

The only solution for truly protected software would be to sell a "secure computer" with the software installed on it, with physical protections in it for limited access, but this is beyond (I'm sure) what you want to do.
Make the software free.

Sell support.

Companies that won't pay wouldn't have bought your product anyway. Companies that will pay realize the best support likely comes from the person that wrote it. Offer customization for a fee. 

It's why a lot of projects are MIT/BSD/Apache vs GPL.
> how one successfully copyrights Python.

I guess you mean how one copyrights software written in Python. 

In the US, just merely by creating anything--a poem, a song, a film, a painting, software--it is automatically copyrighted. I mean it. It is copyrighted the moment you write it. Now, if you want to register that copyright at the US Copyright Office, you are free to do that and it will help you defend your copyright better should it come to legal action.

A copyright is a legal defense. If you release your Python program and someone takes the code and sells it as their program, legally you can go after them for infringement of your copyright. But of course, you have to know who they are, and it requires a lawsuit or at least an infringement letter (usually sent by a lawyer).  

Of course, even if you made it a little harder to get at the original code by obfuscating the Python and managing to convert it to C with Nuitka, they could still *pirate* your program by just putting the whole program up for free on some download site, right? 

The way to try to inhibit that is to use some kind of licensing management protection software that "phones home" to some database to prove that *this* copy is installed and running only on *this* machine.

So, are you worried about someone else basically stealing your code to compete with you as a seller of your program, or some kid putting it up on a free download site?


Copyright is as legal matter. Making it hard to copy the functionality/code is an engineering matter. 
Use cython or nuitka to compile to native code.
As a security enthusiast, I will mention that:

1. I can crack your application and find out which password it's going to give next, and thusly the ones before mine that have been given. 

2. I can just say that the more characters you're randomly choosing from, the more secure the program as a whole will be from reverse engineering in general, but **that's not all**.

Random is a fun mathematical concept with nuances, it's great. 

Random doesn't mean random like "as different each time as possible". Random simply means every letter is just as likely to get picked, but this is hard to achieve for computers as they use arithmetic obviously to do anything (inevitably, there will be emergent patterns). So using python's 'rand' is sort of a black box. I'm not going to explain this part because you might already understand it at this point but here is a very valuable topic: http://stackoverflow.com/questions/2145510/random-is-barely-random-at-all

Every random function in every language has *consistency* problems. You want to find out what python's is and fix it in your code to make better passwords over the entire worldwide use of it (make it into a django site!).

Right now, it's useless in the context of security but if you read up and go back, it will not be and it will be much more impressive than even some of the commercial ones our moms and dads are buying. 
Overall it's pretty good! A few minor criticisms, mainly around use of the standard library to do things for you:

* argparse provides quite a lot of help for writing command line interfaces (CLI)
* strings can be treated like arrays in some ways, e.g. 'hello'[1] == 'e', so there's no need to write all the characters out individually. Just write them as a single string.
* Have a look at random.choice(list_like) for picking a random element from a list like object. Effectively the same as what you're doing but you could argue it's a little clearer.
* Instead of calling main() directly at the end of your script put an

        if __name__ == '__main__':

clause in front of it, so that you can safely import your module at a later date, should you so wish.

* Doc strings for your functions are a good habit to get in to. It always seems obvious at the time, but 3 months later...

To get a bit picky...

* As a user, how would I get a password with number, letters and special characters?
* In security stuff, 'secure by default' is a good motto. It'd be nice if the tool has some sensible default options so I dont have to think too much about what options to use.
* Might be nice if you could specify a range of lengths for the password.

To get really, really picky...

* Do random chars really make the best passwords? https://xkcd.com/936/
* random.SystemRandom is probably a better theoretical choice. In reality, if this is actually a problem for you then you've got bigger problems in your life than being able to generate secure passwords.
I would advise using `argparse`. It's the standard way of dealing with cli arguments.
Your implementation of mixing numbers and other characters is not as secure as you probably expect. Right now numbers will be "overrepresented" in generated passwords, since there is a 50% chance of a number getting picked, despite the fact that there are less numbers than letters.

What you probably instead want to do is to concatenate together the lists of possible password characters and then pick a random element from the combined list. This will also enable you to radically simplify your code.
    In [1]: import string, random
    In [2]: "".join(random.choice(string.ascii_uppercase) for _ in range(12))
    Out[2]: 'EKLVLIBJPHYX'

There's also `string.ascii_lowercase`, `string.digits` and `string.punctutation` plus some others.

Check the output against a dictionary (ideally a crackers one). It's random, so it COULD generate 'password' if you are unlucky.
There are a bunch of errors, including `mode` can be any string, and there won't be any output; as well as the program exiting when anything other than an `int` is entered for `pLength` and `number`. Maybe you could handle exceptions too :) 

Aside from that, neat program!
This is probably more suitable for r/learnpython

In any case, it is not a good idea to use `random.randint()` to generate passwords as the [documentation](https://docs.python.org/3/library/random.html) states:

>  However, being completely deterministic, [...] [it] is completely unsuitable for cryptographic purposes.

You probably want to use `random.SystemRandom` instead.


Watch out with automated use of Google. They might block you for some time. No real problem, just speaking from experience.
Have you downloaded and extracted the sdk for instantclient?
Maybe this will help?

http://ba6.us/?q=cx_Oracle_easy_windows_install
> share data between different applications in a bit secure manner 

pickle is not secure. not even a bit. this whole tutorial is useless because it misses a crucial part of pickle, which is at the top of the official docs:

> The pickle module is not secure against erroneous or maliciously constructed data. Never unpickle data received from an untrusted or unauthenticated source.

If you give a tutorial on how to serialize Python objects and you mention pickle, but don't mention that warning, you shouldn't be writing tutorials at all.
This looks promising but you should post the entirety of the game (including assets) to GitHub, so people can easily play it. 
Poster to leanpython.. My bad
Can't you do the same thing in 4 lines of code?

    import hashlib

    m = hashlib.sha512()
    m.update(bytes(input('Some_string'), encoding='utf-8'))
    print(m.hexdigest())

Using base64 encoding is pointless because anyone can recognize it and feed it through a decoder. Couldn't even classify that as security through obscurity because it's not obscure at all.

Multiline comments would clean this up and dem globals tho...
This really belongs in /r/learnpython. You will receive better quality feedback there.

I would have made a tool like this automatable via the command line, so it can also be used by code, and in shell scripts.

e.g.

    $ passgen.py patel 1 2 !!  # can now be called from another program

in addition to the interactive way you have it:

    $ passgen.py
    input 1? patel
    input 2? 1
    ... etc

To do this, `import sys` and then read the value of `sys.argv` to find out the command line arguments. If args are present, just use them instead of the interactive prompt. Keep interactive mode if there are no args.

    # foo.py
    import sys
    print("args are:", sys.argv)
When run:

    $ foo.py patel 1 2
    Args are: ['foo.py', 'patel', '1', '2']

The problem will be of course that you will still have to remember many low security passwords. I'm rolling my own password manager. I'll post about it on reddit soon :)
Why do you have functions? They don't take any arguments or return anything, all use global variables, and all but the first are called only by the function definition that precedes it (and the first is called exactly once).

Every instance of

    else:
        pass

Can just be deleted. `if` doesn't need an `else`.
I bet there are places looking for people to maintain code written in versions of Python earlier than 2.6.
The in-demand python skills are the popular ones.  You can become a twisted expert, or IronPython King, but you're gonna earn half what someone with 3 years' django experience does.
machine learning is about to be huge.  I would like to suggest this is the big thing to put in your toolbag for the future.
This should go to /r/learnpython really.

But, why are you so negative? Python works great on Windows. Also PyCharm is a fantastic IDE that also works just great on Windows, so if you're still looking for one, a free community edition of it is available from their site.

Most often encountered issues on Windows I guess:

- installation issues because Windows is not properly updated and misses some Microsoft runtime components. Easily fixed by having your windows updates be actual.
- some packages can't be installed because of compiler problems. Get precompiled packages instead, for instance by using the Anaconda version of Python that provides them for you.  This is no issue if you only use pure python libraries.
- depending on operating system features that Windows doesn't provide (tty, curses, fork etc). This needs to be rewritten into stuff Windows *does* grok.

Happy Python coding
I've been using Python on Windows for 16 years with no problems at all, except those of my own making :-)  You might be interested in [Python Tools for Visual Studio](https://microsoft.github.io/PTVS/) and [Python for Window Extensions](https://pypi.python.org/pypi/pypiwin32)
Better to head over to /r/learnpython.

But on Windows I would recommend you install anaconda. Basically everything should work.

https://www.continuum.io/downloads#windows

Edit: make sure to get python 3.5 not 2.7
SNMP modules are going to give you fits - if you ever need them!
Relax - everything's gonna be allright. Python works very well on Windows. Pycharm is excellent and will delight you. 
What is this, Java?
I wrote a compiler in Python for a college semester project...I wouldn't do it again that way and can't recommend it.
I mean, it's more so a parser written in Python as if it were C, but still a valuable resource that I'm grateful for, IMO.

It's particularly useful to me because it de-conceptualises the ideas in my mind that I've always known, and gives a nice concrete example of a possible way of representing the concepts.

I need to write a parser in Python for a project I'm working on, so I look forward to taking these ideas on board and writing a nice, Pythonic parser.
Hi, OP's OP here, I'm happy to take discuss this on Reddit, if you have any questions. I've been told professors have been emailing this StackOverflow post to their classes. 

This is based somewhat on a slide for a talk I gave at PyGotham called the Python Datamodel: When and How to Write Objects. (see the slide at about the 7:43 time mark: https://youtu.be/iGfggZqXmB0?t=7m43s .)

Feedback, criticism, and/or any other visceral or intellectual responses are also welcome. 
You mention:

> I need to port forward, and thats not fun

I created [loco](https://github.com/kootenpv/loco) a few days ago, I'll post about it soon here on reddit, but maybe it would be interesting to you as it is about port forwarding.
https://youtu.be/xc9V_5EAPIg 

I learned a lot from this guy. Chris vaden
"In demand" for what type of job?
PyQt5/PySide bindings for Qt5
Check out Kivy
Kivy hands down, check out my latest desktop app with kivy https://youtu.be/GJ3f88ebDqc
While not yet at a level that is usable, Toga is worth a consideration when it is available. It will provide a python binding to the native gui implementations on all major platforms including iOS and Android. 

https://github.com/pybee/toga
Use ttk. 
pyGTK is enought good too...
Not sure why you couldn't find anything--where did you look? 

wxPython is native on all platforms for most widgets, and PyQT is considered nice looking and near native despite not being truly native. (Native here means that stuff looks like what that OS thinks it should look like).
Well that's terrifying. 

Is there a similar db for deaths per day?
Can anyone elaborate on a use case for this tool?
Interesting, so it looks like @Hook registers one method as a hook, and then you add that hook to some other method using a decorator. Could you elaborate how this is any better than simply writing your own closures and decorating other methods with them?

Disclaimer: I haven't had a chance to read through the implementation code, so that might answer some questions. A cool module either way!
I was looking for something like this! Thanks for sharing!
Is my interpretation correct? That without hooks, you'd have something like this:

    class DatabaseEntry(object):
        def save(self):
            pass  # save implementation here


    class VersionedEntry(DatabaseEntry):
        def increment_version(self):
            self.version += 1

        def save(self):
            self.increment_version()
            super().save()
            print("New version number: {}".format(self.version))  # postcall

If so, when would I want to use hooks instead of supers? Maybe like in your heavy computation example? If you have many cases, and want to run the same code before and after each case? Though even then, I can see it working in a different way (context managers, for instance, since supers wouldn't work).

    from contextlib import contextmanager
    import time

    @contextmanager
    def heavy_computation():
        print("The ongoing operation could take some time to complete")
        yield
        print("The running operation has ended")


    class LifeQuestion():
        def compute(self):
            with heavy_computation():
                time.sleep(2)
                return 42


    def brute_force():
        with heavy_computation():
            time.sleep(1)
            return 'aldfjqorqlkjt'


    computer = LifeQuestion()
    print(computer.compute())
    print(brute_force())

Can you have multiple items attached? What order are they run in? What args and kwargs are passed? The same as the method itself?

By the way, you import `logging` in `heavy_computation.py`, call it a logging example in the comments, but the module is not used at all.
Hey, it's awesome that you listened to the feedback from last time, and you were not discouraged at all by my criticisms! :) I wish I can give you gold but it's pretty hard to do that here.

One QoL improvement for the backtesting would be to show the return you would've gotten without the algo--that's your benchmark.

From the numerical perspective, the only thing that's missing is transaction costs. For small purchases, it's the broker fee; for large purchases, it's the market impact of your trades. A lot of quant strategies look good on paper, but fail to generate alpha in practice because of those costs--so make sure to take note of that.

Nice work! I'm glad you're having fun building this.
Cool stuff, I'm actually in the process of making my own trading algorithm from scratch right now!
Assuming that this system works, if it reliably predicts the stock will raise tomorrow, everyone would rush to buy the stock; as a result, the stock will raise immediately, and not a day later. 

If it reliably predicts the stock will fall tomorrow, everyone will sell it, and so it will fall today, not tomorrow.

So this system should be its own undoing.

This is a remarkable feature of second-degree chaotic systems â i.e. systems that are chaotic that also respond to predictions being made about them â that the science is not currently aware if it's possible to predict them.

First-degree chaotic systems â e.g. weather â are predictable because the weather doesn't care what you say about it in the weather reports.

The study of chaotic systems is of a special interest for (and under a funding of) the military, because war is second-degree chaotic system.
Fascinating, but why publish if it works so great?
To see where we are getting our data, look at https://github.com/anfederico/Stocktalk
Ive been wanting to get into machine learning and sentiment analysis for a long time now, but i doubt it is ever something that i would be able to make a career out of. Would you say doing some free courses on the topics and stock trading is worth the time investment to get a rudimental understanding, since building great tools like this require a deep understanding of all of the above and years of experience? Great tool btw, will be checking it out :) 
This is a pretty cool idea and I'd be interested in learning how to do something similar, where is a good place to start / how did you get into it?
Thats a great tool to study ML on finance. thank you for this. 

To the rest, do not treat those tools as a "market superhero"
that will make you suddenly rich.

There is this guy who has TONZ of info and source code, worths checking him out
https://www.quantstart.com/articles/Forecasting-Financial-Time-Series-Part-1

Put your money where your mouth is. 
This is extremely interesting to me. Is there a place where I can learn more about this stuff?
looks really cool!
Does this work for markets other than the U.S, say the Indian Stock market?
    from clairvoyant import Backtest
    from pandas import read_csv

    # Testing performance on a single stock

    variables  = ["SSO", "SSC"]     # Financial indicators of choice
    trainStart = '2013-03-01'       # Start of training period
    trainEnd   = '2015-07-15'       # End of training period
    testStart  = '2015-07-16'       # Start of testing period
    testEnd    = '2016-07-16'       # End of training period
    buyThreshold  = 0.65            # Confidence threshold for predicting buy (default = 0.65) 
    sellThreshold = 0.65            # Confidence threshold for predicting sell (default = 0.65)
    C = 1                           # Penalty parameter (default = 1)
    gamma = 10                      # Kernel coefficient (default = 10)
    continuedTraining = False       # Continue training during testing period? (default = false)

    backtest = Backtest(variables, trainStart, trainEnd, testStart, testEnd)

    data = read_csv(r"H:/Python/ClairVoyantTest/sbux.csv")      # Read in data
    data = data.round(3)                    # Round all values                  
    backtest.stocks.append("SBUX")          # Inform the model which stock is being tested
    for i in range(0,10):                   # Run the model 10-15 times  
        backtest.runModel(data)

    backtest.displayConditions()
    backtest.displayStats()

I have run the above code:
The issue coming was      

*********

  File "<ipython-input-1-9e06f724c5c4>", line 1, in <module>
    runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python')

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 685, in runfile
    execfile(filename, namespace)

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 71, in execfile
    exec(compile(scripttext, filename, 'exec'), glob, loc)

  File "H:/Python/StockPredictionUsingClairVoyant.py", line 30, in <module>
    backtest.runModel(data)

  File "C:\Anaconda2\lib\site-packages\clairvoyant\Backtest.py", line 72, in runModel
    data['Date'] = to_datetime(data['Date'])

  File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 1914, in __getitem__
    return self._getitem_column(key)

  File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 1921, in _getitem_column
    return self._get_item_cache(key)

  File "C:\Anaconda2\lib\site-packages\pandas\core\generic.py", line 1090, in _get_item_cache
    values = self._data.get(item)

  File "C:\Anaconda2\lib\site-packages\pandas\core\internals.py", line 3102, in get
    loc = self.items.get_loc(item)

  File "C:\Anaconda2\lib\site-packages\pandas\core\index.py", line 1692, in get_loc
    return self._engine.get_loc(_values_from_object(key))

  File "pandas\index.pyx", line 137, in pandas.index.IndexEngine.get_loc (pandas\index.c:3979)

  File "pandas\index.pyx", line 157, in pandas.index.IndexEngine.get_loc (pandas\index.c:3843)

  File "pandas\hashtable.pyx", line 668, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:12265)

  File "pandas\hashtable.pyx", line 676, in pandas.hashtable.PyObjectHashTable.get_item (pandas\hashtable.c:12216)

KeyError: 'Date'


runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python')
Traceback (most recent call last):

  File "<ipython-input-2-9e06f724c5c4>", line 1, in <module>
    runfile('H:/Python/StockPredictionUsingClairVoyant.py', wdir='H:/Python')

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 685, in runfile
    execfile(filename, namespace)

  File "C:\Anaconda2\lib\site-packages\spyderlib\widgets\externalshell\sitecustomize.py", line 71, in execfile
    exec(compile(scripttext, filename, 'exec'), glob, loc)

  File "H:/Python/StockPredictionUsingClairVoyant.py", line 27, in <module>
    data = data.round(3)                    # Round all values

  File "C:\Anaconda2\lib\site-packages\pandas\core\frame.py", line 4335, in round
    new_cols = [np.round(self[col], decimals) for col in self]

  File "C:\Anaconda2\lib\site-packages\numpy\core\fromnumeric.py", line 2782, in round_
    return round(decimals, out)

  File "C:\Anaconda2\lib\site-packages\pandas\core\series.py", line 1234, in round
    result = _values_from_object(self).round(decimals, out=out)

TypeError: can't multiply sequence by non-int of type 'float'
*****
What would be the cause of the error.  
None of these comments about how it won't work because of X, Y and Z reasons never mention how fucking genius you are.

K good, I just did.  You sir, make me feel like a Peasant.
If you could predict stock movements, you'd be retired and enjoying the lavish lifestyle instead of peddling silly toy python programs on reddit.
Has anyone outside the OP actually tried this yet? 

What kind of data do you feed it? Is it only sentiment data or does it include other market data? I'm looking at the readme file and just wondering how to run this thing. Do I need to add data first or can I just run the portfolio.py out of Terminal?

 no. that syntax hurts my eyes.
An alternative how, and for what?

Every popular language is used for different reasons. I wouldn't write an android application in Python just like I wouldn't write a web service in Kotlin.

Tools in a toolbox.
In a word, unreadable.
Never heard of Kotlin and just checked it out on GitHub: https://github.com/JetBrains/kotlin

Like I said, i don't know much about it, but a `build failure` of the master branch on GitHub is not really encouraging me to dig further into it at that point. I think it's a nice effort, but I'll stick to Python & Scala for now. Still, it's cool to see that there are efforts in developing alternatives!
Shouldn't the moral of the story be to *always* use a `virtualenv`? 

Especially if you use `virtualenvwrapper` its exactly 1 simple command. 

Edit: Neat hack tho.
This was a fun and helpful story at the same time. Thanks!
Being a newbie, I was a afraid of virtual enviroments. But please, if you are new to Python like me, please learn how to use [virtualenv](http://docs.python-guide.org/en/latest/dev/virtualenvs/). It's pretty easy.


And if you are using Python 3.3+, you can use the built-in venv. You will use the same commands, just replace "virtualenv" with "python3 -m venv" when you create a new enviroment.
I've done exactly this before. That module is dangerous if you don't read
Install python modules as *system* packages, not through PIP. If they're not provided as system packages, make a package, then install that through your system package manager.

Having multiple package mangers per system is stupid. Unless you absolutely *can't* (don't have root), this is a better way since your package manager is probably better tested and has better security.
Nice work, I'll definitely use this for testing network reconnect logic in my programs.
more string formatting methods
I'd like to see a simple and consistent way of declaring which names in a module/class are a part of its public API. Setting `__all__` for modules is far too awkward and people often don't bother. I'm fed up of typing `dir(thing)` and trying to spot the useful functionality amongst all the stuff imported from other modules, uninteresting magic methods inherited from `object`, and private internal variables.

On a more shallow note, they should switch to using i instead of j for complex numbers, because why the fuck would they use j?
Off the top of my head:
- Restarts.
- A defined C ABI (for JITs).

Soooo, you want Javascript?? Perhaps you could take a look at Node.js?
Why would you want a var keyword?
Further improving on the Python 3 changes with proper unicode handling, especially grapheme clusters. 

For example for regex I started using [`regex`](https://pypi.python.org/pypi/regex/2016.10.22) instead of the builtin `re` module in some occasions.

It says

> This new regex implementation is intended eventually to replace Pythonâs current re module implementation.

but I don't know the background and not sure if it'll really eventually replace `re`.

For example supports full unicode case-folding, matching graphemes and by unicode codepoint properties which the builtin `re` module doesn't support yet.
the built in functions and stdlib could use a bit of reorganization; I understand the historical reasons for why there are built-in functions like `reversed` and `enumerate` but it be more consistent with polymorphic OOP principals if they were methods and re-use was achieved through inheritance. This has actually already happened with eg most of the contents of the `string` module, but there are plenty of other areas where it's still a warty and weird.

I would also like a way to declare anonymous functions with statements

Not sure about the value of the var keyword :/
Case statement 
Solution for GIL that does not depend on c-api. Full pure python implementation on all levels with optional compilation to C/LLVM/Webassembly. First-class mobile and web support. Optional JIT compiler. First-class packaging support for deploying binaries or packages. 
I would like:

- a default parameter in get().
- the ability to replace() and split() many things at once.
- a for loop on dict is like looping on dict.items and not dict.keys.
- len as a method.
- slicing on generators (come on, we got dropwhile and takewhile).
- a syntax to extract keys from dict quickly
- a syntax to make a dict quickly from variables (a la f-strings)
- a syntax to alias the result of a calculation in a comprehension to avoid making it twice (in the filtering and result)
- inline try/except.
- improved dedent(), and as a string method.
- http1/2 and websocket with asyncio in the stdlib.
- some features from numpy ported to array.array
- get rid of tkinter and replace it with something actually useful
- remove a load of modules from the stdlib. Do you really need a wave manipulation module to be in the stdlib ?
- most setup.py features moved to setup.cfg
- better error messages for so many things.
- some utility to pack the python interpretter and your lib in a exe/dmg/deb/rpm that works out of the box.
- an way to export things in a module that is better than `__all__`
- detect and avoid circular import.
- integrate linter and mypy.
- integrate sphinx.
- improved sqlite wrapper. We can support WAY more feature.
- and wrapper unqlite.
- a good multiprocessor story. Where is the promised multiinterpretters ?
- a good story on mobile.
- high level asyncio: most people don't want to deal with the loop manually.
- a transpiler than allow you to always write the lastest Python, and that transpile it to work with older Pythons.
- GILECTOMY ?
- a way to capture a blog of code, espacially in with blocks.

Not everything need to happen, though. I'm quite happy the way Python is.

Python 4, aka [Hy](http://docs.hylang.org/en/latest/)?
Hmm, minor changes if any. Relearning print after three years of coding was hard enough and that was just a surface level change.  I fear that if Python continues to introduce major changes it will alienate it's community of supporters. As long as sufficient time is spent discussing the proposed change and getting community feedback, I think I could accept what may come. We all need to think of all those packages we rely on.
Feedback:

* As /u/Flynn58 noted, it's better to use clear variable names.
* The standard is to use spaces instead of tabs. (See [pep8](http://pep8.org/)) If you use a code editor like Atom or an IDE like PyCharm, pressing tab can automatically produce four spaces for you, so you don't have to type four spaces by hitting the spacebar four times.
* The structure of your script is a bit odd. It seems that `prompt` is a function that manages everything. It is also responsible for calling `main`.  Huh? Typically, the `main` name is used for functions that manage everything. So this is unusual.
* You're using many globals, and no function arguments or return statements. Read about arguments, keyword arguments, and return statements [here in the documentation](https://docs.python.org/3.5/tutorial/controlflow.html#defining-functions). You'll find these really useful.
* There are no docstrings in your functions. Please add them! Make this a habit ASAP. This will make it easier for others to understand what your functions do. (The built-in function `help(FUNCTION_NAME)` returns the docstring.)

Just to practice, you could try rewriting your code to incorporate this feedback. Use:

* a `main` function that does all the work, and calls other functions.
* a `prompt` function that takes no arguments, and returns the list of words and the number of times the function should be shuffling. You can use this output in the `main()` function.
* a `print_results` function (`res` is such a short and vague name for what it does) that takes the list of results as its argument.

That doesn't completely correspond to how I would write a program like this, but at least it incorporates more of the best practices.
> `global l`

> `global r`

NEVER USE LETTERS AS VARIABLE NAMES IT IS LITERALLY OF THE CODING DEVIL
Heya,

great work :D
As a next exercise, you could try to devise a deterministic way to find words within words, so that you can find all the possible words without having to do thaaaat many iterations.

So you go through the dictionary, and try to find if every letter of the current word is contained in the right amount (greater or exactly the same amount) in the input. If it is, you can print out the word from the dictionary.


To ensure uniqueness, use a set. 

    >>> a = set()
    >>> a.add(1)
    >>> a.add(1)
    >>> a.add(2)
    >>> print(a)
    {1, 2}   #  a list would be [1, 1, 2]

A list checks membership by checking against every element and is slow for longer lists. A set does the operation in constant time. It also does the unique check for you, which makes the code easier to write and more reliable.

To generate all combinations , use itertools. Read the docs for the itertools module for more info.

    >>> import itertools
    >>> a = [1, 2, 3]
    >>> print(list(itertools.permutations(a, 3))
    [(1, 2, 3), (1, 3, 2), (2, 1, 3), (2, 3, 1), (3, 1, 2), (3, 2, 1)]

    >>> print(list(itertools.product([1, 2], [3, 4])
    [(1, 3), (1, 4), (2, 3), (2, 4)]

We execute people for using global variables. We do it *slowly* if they're all 1 letter.

/r/learnpython may be more appropriate for this content.
New app, "words with words".
/r/learnpython
In the future you'll get a lot more help at /r/learnpython.

It's not equals here, it's setting the return value to a variable so it can be reused on the next line. `=` sets a variable `==` tests for equality. 
Super alpha. Feedback welcome!
Are you sure you wouldn't rather be writing Ruby? :P

I'm all for code generation! You might have used the the [ast](https://docs.python.org/2/library/ast.html) module to do the parsing for you though. (You could have used a no-op decorator instead of inventing your own syntax.)

However, I don't see anything to specify that you're extending the `str` class. As far as I can tell from your tests, it's up to the function itself to ensure that you're working on strings. This effectively weakens Python's strong typing.

Also, in your tests, you specifically test for the `str` class. This will prevent it working on unicode strings, or classes that extend either type of string. In Python 2, you should check `isinstance(x, basestring)`.
What advantage does this have over writing your own class that inherits from `str` and implements the methods you want?

    >>> class MyString(str):
    ...     def my_func(self):
    ...         return self.__class__(self + 'foo')
    ...
    >>> a = MyString('testing')
    >>> a.my_func()
    'testingfoo'
Just for fun, your example could also be written as

    def test_dotted_quad(str_object):
        try:
            items = str_object.split('.')
            return (
                isinstance(str_object, basestring) and
                len(items) == 4 and
                all(0 <= int(i) <= 255 for i in items)
            )
        except Exception:
            return False

Yuk. This is some real beginner code. You need to live, breath and write Python code for a long while. Compare your code with that in the .py files included in your Python installation. Reading such code is a good way to learn how to write better code.

Then you may not consider this extension necessary. And also, by then, you may know enough Python magic to do this in several more transparent (and much shorter) ways.

Please do not write new code in the Python 2 dialect. At the very least, write code that is version agnostic.

Please familiarize yourself with the entire Python ecosystem, including but not limited to PEP8 and distributing code. All the documentation you need is included in your Python installation, and also easily available on the web.
https://github.com/clarete/forbiddenfruit might interest you
`print(thing)` displays `str(thing)`, and printing lists displays `repr(thing)` for every `thing` in the list. `str` is the human-readable representation and `repr` is the technical one, usually, but it's just the same object displayed in two different ways. Also, /r/learnpython is a better place for questions.
Are you fucking kidding me? If this is what people call "data science"... Christ. So basically, blindly apply algorithms without understanding the statistical properties of time series, and overfit like crazy? It's much more dangerous to "teach" people how to do this improperly, rather than not "teach" people at all.
I'm loving the energy, but his entire thing is blind leading the blind.  

It's like hearing a kid say: "YEAH!!  I'm going to jump to the moon!  here I go!! ready!! Watch!  OOF!   OK watch out for the space martians!  beep boop beep!".  

With the physicists be all like: O_o   mmmmm kay.  

How are you dealing with feature reduction, curse of dimensionality, lack of data due to survivorship bias and how are you mitigating the problem of the efficient market hypothesis and back testing on data that's different than what actually happened at the time?  

And the kiddos are like: "LOL what are those things?".  Put down the Caffeine man, it's making you think you're superman and you're not.  A thousand people think they can step into the ring with the prize fighter.  The most exuberant and excited ones like this are the first to fall.  

The developers and Quants who have what it takes in this department are quite dull.  You may have passed one on the train and thought he was a hobo.  You're a great cheerleader though.  Word the wise, don't quit your day job until after the software is proven to work, not before.  

Not to be a downer though.  Keep going, you'll learn.  https://www.udacity.com/course/machine-learning-for-trading--ud501

Save this video and re-watch it in 10 years.  You're going to cringe so hard you're face is going to melt off.
past performance does not predict future performance. Stock prices have not individual patterns. The only value for this sort of model is learning what other securities to link a security to at what weight. 
The guy's YouTube channel is full of videos explaining short tensor flow exercises . The butt hurt triggered in some of you is hilarious. Of course a 10 minute YouTube video won't be as thorough as a semester long course or specialized degree. I'm sure none of you were this triggered when you did the stock predictor problem in your introduction to C programming class freshmen year, which was even worse as far as being remotely accurate. I don't think the point of the video is to create an army of basement dweller wizards that can predict and bend the markets to their will...
what about train/test split lol
Instead of trying to predict the market, learn linear programming and create index funds instead.
TIL about [next(iterator)](https://docs.python.org/3.5/library/functions.html#next) function. Very useful, thanks for that.
/r/algotrading
It seems like a lot of time was spent trying to get the stock price from the csv. Why not use the [pandas-datareader](https://pandas-datareader.readthedocs.io/en/latest/remote_data.html) ?
Put your money where your mouth is. 
If you watched the video and are trading based on your new model's signals, let me know.  I want to trade against you.
Visual Studio can be used as a Python IDE...
1. [Python Tools for Visual Studio](https://microsoft.github.io/PTVS/).

2. [PyCharm](https://www.jetbrains.com/pycharm/)  

Both have Community editions at no cost. 
I've fallen in love with **PyCharm**.  It's easily customizable but it also love the fact that the command line can be used directly from the tool.
Visual Studio Code has some good Python plugins. As long as you're regularly saving your files, it'll give you function hints. Use other plugins to color-code your tab sequences & ensure they're saved as spaces.

https://code.visualstudio.com
Look into Vim. I switched from sublime/atom and am very happy.
What you mean for equivalent? A powerful code editor or a gui designer?
own configured emacs is powerfull... :)
Uh PTVS?

/r/learnypthon
When you say it's not working just right, what do you mean?
"Doesn't work" is ambiguous. Details on what you are doing, and in what way it doesn't correctly (ie what is wrong, what should it be, etc) are helpful.
#Before you ask my to elaborate on what "code doesn't work just right" means:

Sorry for not being clear. Line 52 should only receive 1 or -1. 1 if it is composite and -1 if the number is prime. However I receive 1 when numbers are prime.
Just an FYI, python's built in pow(x, y, [,z]) function takes two arguments with an optional third for x**y mod z.
Consider this piece of code for finding prime numbers within a given range;

x=25
y=75
for n in range(x,y):
    if all(n%i !=0 for i in range (2,n):
           print(n)
What makes you think that Python will be any less vulnerable ? Website security and safety is far more about how you design your website from the ground up, including the server settings etc, as well as the s/w which is being used to provide the actual service.
Install QT for mac. QT Designer is in the bundle. 

Link: https://www.qt.io 
Source: I use it that way.
Nope... on windows you need to also get pyqt5-tools... I haven't found out how to get qt designer on macOS or Linux yet...
Have a look at www.hackerrank.com and www.codewars.com. 
Any Python interview I've had has the classic; reverse a string, sum of even Fibonacci numbers (iterative and recursive) with the optimisation, Binary search trees, linked lists and the number pair that add to a target problem( in O(N) time )
Coding challanges, search for some online judges. I recommend URI, it has a very friendly interface and well divided challanges, remember to always search for the best way to do something, if you just keep making the same mistakes or bad practices (like using for i in range(len(list))), you wont learn as much as you could.
Might as well look at [Project Euler](https://projecteuler.net/) if you haven't already.
  https://www.codingame.com
www.leetcode.com
rosetta code
I've been doing checkio.org for a range of python problems. Start very simple and get more complex. Also offers hints and you can see other people's solutions. 
Did you check the sidebar where is listed programming challenges?
www.rosalind.info 

Especially if you're interested in bioinformatics/computational biology, you'll practice building real world applications in the field.
I personally enjoyed getting data from APIs, parsing it and just manipulating back and forth.
Let's say you love soccer. Find a free API with let's say Mondial stats and start extracting data like who scored the most goals, what team had the most yellow cards, who scored the earliest goal, who scored the latest etc..
It's really fun if you're sports stats fanatic
I usually use this website [http://codingbat.com/python](http://codingbat.com/python)
Check out http://checkio.com. 
Check out https://github.com/mjhea0/programming-exercises
www.codeacademy.com
Well, python as a programming language is just a tool like any other. 

Of course it's possible to use it for backing up a tumblr blog. I suggest you just import your blog to a pelican instance. It's a blog (incidentally written in python) that stores files in clear text files. [Here's the documentation on how to do that](http://docs.getpelican.com/en/3.6.3/importer.html).
Or you could use this :) http://tumblr2json.com/
I think "scraping" would be overkill. Consider using their API to get all sorts of stuff including posts (although it looks like you'll have to generate an oath token which is a pain) https://www.tumblr.com/docs/en/api/v2

Alternatively, if you only care about the post data, consider just pulling the RSS feed. I think it's something like my_blog.tumblr.com/rss. That outputs in easy to parse xml.
Seems a bit complicated considering many routers run Linux or support it aftermarket. Would be less overhead using ssh.

However, this is a neat tutorial/into to Selenium.
This does not have anything to do with data mining? Maybe you're confused with scraping.
http://i.imgur.com/1cadzWC.jpg
I'll be attending. Missed last year. So wish that the Canadian dollar didn't suck so much right now!
How quickly should I register? I have some info I need to figure out before I do, but I don't want to miss out...
I answered your last Post. Your script can't deauth wpa2 unless you are associated with that network. It's called protected management frames
http://selenium-python.readthedocs.io/faq.html#how-to-auto-save-files-using-custom-firefox-profile
12 minutes is a little long just to install django and explain what it's doing but it's always a good thing to have more tutorials since django changes 90% of how everything works in each version. 

If you wanted to do something different, include some jquery in your tutorial when you begin doing the views, templates, and models. There's no reason to treat django like PHP and all of the tutorials currently do that, as if Django is only cool because it ties your db to your structure.

if you show someone how to make quick websites that interpret from the db actively, that would be a very attractive tutorial I would link people to compared to what's on youtube already.
[deleted]
[deleted]
Wow this was really well written and useful and for me timely.  I needed this right now and I appreciate you writing it up!  I'm also impressed by your use of modern online tech (jupyter, and binder in particular).   Thanks!
Nice project, thanks for the post!
[Forked](http://104.197.121.217/user/a55dbfaa3f839a0a5c40b2147c13b629/notebooks/index-Copy1.ipynb), so it's self-contained, i.e. installs the packages if you don't have them.
The main problem is that sentiment analysis sucks :) Yes, there are *many* sentiment analyzers, but no, they are not very good.
I've only dipped my toes into NLP and had never seen the Text Blob library before. Looks super user friendly. Thanks for the heads up 

Edit: wow I'd never seen Binder before either. I use Jupyter all the time but didn't know you could distribute your notebooks in such a friendly way. So cool
This is really cool! I also appreciate the detailed write-up. I'm fairly new to Python (been playing with it for awhile but only recently started really delving into it beyond a basic grasp of the language) and posts like this that clearly lay out process + resources are incredibly useful to me. So thank you! :)  
Definitely going to re-purpose this for my own side-projects. Thanks for doing the write up!
Posts like this are why I enjoy this sub, very informative.
Great notebook w/ explanations!

These results are similar to my experience doing sentiment analysis on comments/articles (e.g. using NLTK):

>Sentiment(polarity=0.07565960941292733, subjectivity=0.52062214346886)

The polarity ranges between -0.1 and +0.1 and the subjectivity is > 0.3 meaning, it's hard to make a strong positive or negative conclusion.  :(

Why no cool charts? I was excited to see the notebook, but wanted to see some cool graphs and stuff!
I'm surprised more people aren't upset about the lack of RAM?

Four years since the last upgrade and they stuck with 16GB of RAM?? Not even a measly 32GB. Shame.
[removed]
There's no reason why you can't do this.
That seems fairly reasonable. My only suggestion would be to add that to the object like so:



     class Foo():
        def __init__(self):
            #some init code
            self.alive = True
            self.daemon = threading.Thread(self.my_method)
            self.daemon.start()
        
        def my_method(self):
            while self.alive:
                #do something
                sleep(1)

        def __del__(self):
            self.alive = False

This should ensure that the thread stops as soon as the object leaves, whether it was intentional or not. 
This is essentially how I always do it, at least in sufficiently complicated programs.
It's not bad, but make sure that it's very obvious that `my_method` is intended to run in its own thread. A comment is the bare minimum. Additionally name it `my_method_threadproc` or something similar. Even better, have a method `Foo.start_my_method` which starts the thread with target `self._my_method`, to clearly mark that `_my_method` shouldn't be called in the current thread.
You should provide more details. 

How would your design work with many instances of the class?
You probably shouldn't. You will have no way of controlling how many threads you get if you have many objects.

A better pattern would be to ask a "thread pool" to schedule your parallel method and maybe pass a callback for the results. This ensures you will limit the number of threads and maybe, if you need, share them with other code that needs parallel behavior.
This is how one would normally use Thread anyway :P (The alternative being to inherit from Thread)
If you believe the method warrants a thread, sure. However, you may want to look into asyncio instead. Same concept, better performance. I did this with a class I'm working on, essentially the __call__() method for the instance calls 2 other instance methods, which are asyncio coroutines (basically a thread). These run side by side and eventually terminate together. If you are not sure why asyncio is good (and the threading module is bad) you should read up on Pythons global interpreter lock 
If it's a "daemon" thread (e.g. goes on forever til program exit) you should set the .daemon flag on the thread before starting it.   ctrl-C will thank you.
This should be all you need. 

http://stackoverflow.com/questions/18625085/how-to-plot-a-wav-file
Hi,
  You need to assemble the parts you need.

Audio libraries -

pysoundcard is a good choice for the raw audio as it's cffi based it will work in pypy.

You can use fft from Numpy to get useful information back.

Aubio can do things like feature extraction.

Essentia looks interesting, I've never tried to get it working though.




Graphics:

There are many choices here, it depends what you want.

If you want to render using Cairo, then Qairah has the best most sane bindings, though lots of Linux don't ship with opengl enabled Cairo, which means things can end up too slow as soon as you want to render something complex.

OpenGL based libraries:

There are loads, it depends on what constraints you choose.
For me, ideally libraries work with virtualenv, "modern" opengl (3.3 and above) and are compatible with pypy for speed.
Your constraints may be different.

Modern GL compatible libraries

Pi3d - comes with loads of examples

Vispy - Looks like A really interesting choice, not yet compatible with the raspberry pi, but can be used with Jupyter which is a plus for prototyping.

Bindings for SDL2

Haven't checked compatibility:

Pygame

Cocos 2d (python) .. A nice looking 2d engine, I haven't checked if it is moderngl compatible.

Panda3d - doesn't work by default with virtualenv



Pre opengl 3.3

Nodebox-gl Great 2d primitives, decent speed

Pyglet - provides text, sprites.


My current stack is pysoundcard, numpy, pi3d on python.
I think that post uses an overbroad definition of self-modifying code and uses scary language describe really standard stuff like factory functions and closures; those are common, standard, everyday functional programming techniques that every good programmer should know. Experienced python devs monkey patch every day when they write test code https://docs.python.org/3/library/unittest.mock.html#the-patchers

Everything in his first list is really just diddling around with objects and identifiers. It's all just one assignment op. That's not "self modifying code" in my book. It's pretty dynamic, but under the hood it's just reassigning a variable, albeit with a potentially major side effect.

He does get into the deep magic later in his post when he talks about manipulating the parse tree and bytecode and stuff. That's REAL self modifying code.

In the old days there was a big deal when Apple came out with the MC68030  Macintosh because it had a cache that would break if a program modified it's own machine code in memory and failed to properly flush the cache. Turned out quite a few mac apps at the time did just that.
Self modifying code was something we did back in the old days in assembler to eek out the last bit of performance of the hardware. You did it by changing the specific binary data in some hardware adresses to different assembler.

You cannot do the same thing in python as you have no way of knowing the hardware adresses of the assembler. It would also be the interprete you would change not python.

You could probably go and change the python bytecode of a running program. I have no idea how to do it. It is not done and would not give any benefits.

So what is left for any meaningfull purpose is dynamic programming where you can change methods on objects on the fly. This is often called monkey patching, and is a bad way of coding for most purposes. If you have a bug in some object that is being monkey patched you it is difficult to know what method actually has the problem.

Monkey patching is like taking a book and putting the pages in random order and removing the page numbers. So also a bad idea. It can be used for specific things, but as a general methodology it is bad.

So i am sorry, but the only thing that is worth the effort is to learn how to "code properly". Object orientation, interfaces, functional programming, patterns etc. etc. There is a lot of clever stuff to learn that will make you a better programmer.
Armin Ronacher wrote a very good blog post about this: http://lucumr.pocoo.org/2011/2/1/exec-in-python/
Checkout Python Cookbook's metaprogramming section & you'll get into all the black-magic you're looking for.
> "monkey patching", "shadowing builtins"

Don't get too tripped up on the fancy terms they used.  It's just saying that you could define a function foo and then do ``print = foo`` and now you have monkey patched a the built-in print function or you could just define the new print statement directly and that would shadow the built-in one.
I actually did my dissertation at university on Self Modifying Code in Python, I will PM you with the relevant parts of my submission - they will give you a good starting point to experiment for yourself
For an interesting (to me, at least!) form of self-modifying code, take a look at Sixty North's Python mutation testing tool [Cosmic Ray](https://github.com/sixty-north/cosmic-ray/). Part of what it does is load Python code from disk, parse it, modify its AST, and "inject" the modified module into the Python runtime. It might give you some ideas of what's possible.
I created a really simple type of self modifying code using the built-in __file__ object to use as a version check/self-updater for my script.

    versioncheck = requests.get('http://remote.host/version').text
    if versioncheck != version:
        from subprocess import call
        newscript = requests.get('http://remote.host/client').text
        with open(__file__, 'w') as f:
            f.write(newscript)
        call(['python3',__file__])
        exit()
     In [1]: exec("_print=print\ndef print(*a):\n\t_print('sssss')")
     In [2]: print(89)
     sssss

only you don't need `exec` for it. Also  you can use `sys.modules` 

     print(sys.modules.keys())
     del sys.modules['os']
     import myos as os


Shoutout to all of you guys who took the time in pointing me to resources. Especially to /u/ali2992 who was kind enough to share with me portions of his dissertation. I learned a lot !
Choosing to enable self-modifying code is not a wise idea. Using exec is terrible unless you can control what is being executed. Allowing exec on a code which user supplies at runtime is a huge security hole.
It's not that hard.

You write a function and you allow access to the user to change said function.  The open source GUI I wrote has a scripting interface.  Go ahead, add security vulnerabilities.  I don't care.  It's an offline program.

Python 3 is more of a pain.  I forget exactly, but something like non-class variables lose scope or something like that.

    class A():
        def __init__():
            self.x = 4

    class B():
        def __init__():
            self.x = 5

    A = B

it's that easy.  You can do it with functions as well.  It's easier to do it with classes and class-functions than pure functions.

Just be careful, the second you allow that capability, the second you allow for arbitrary code execution.  You basically can't stop it.

Might look in to the [code module](https://docs.python.org/3.6/library/code.html), it allows you to execute python code.
I'm researching self modifying code in python as well, but i'd not consider exec or eval a way to go. After doing it in freepascal on x86 and the Nintendo DS i can tell you that exec/eval are poor choices for proper self modifying.

Bytecode- and object manipulation and having code objects at willfully chosen adresses in RAM, though, which is being worked by one core and modified by a different one... there it gets interesting! (and actually worth it if you care about performance)
Take a look at [PyPatt Macro Implementation](http://www.grantjenks.com/docs/pypatt-python-pattern-matching/macro.html) and [MacroPy](https://github.com/lihaoyi/macropy)
are you an unpaid intern, or do yhat pay you to post their spam here every fucking week?
I like what you're doing here. There definitely needs to be some expansion on this kind of thing. At this point, it's a little hard to really grok without an API, and the example isn't entirely self-documenting.

Something I'm wondering is, why not integrate with flask-login or other existing flask tools for authorization? And how does this json thing work? It seems fairly limiting:
    
    {
        "$url_prefix": "http://127.0.0.1:5000",
        "$roles": {
            "guest": {
                "hello": ["get", "post"],
                "docs": ["get"]
            },
            "normal": {
                "hello": ["get", "post", "get_me"],
                "docs": ["get"]
            }
        }
    }

1. Since you're passing the name of the file (with no path??), how is it going to get distributed if you package the API in any way? To me, this is something that should either live in a data store, or live in source code.

2. Since there are no descriptors of any kind, you can't expand this schema. For example, `hello` just maps to a list of methods allowed for that role. What if I also wanted to specify another category of metadata?

Would be nice if there was an explanation provided. 

edit: It's avail in the insecure_full.json file. I looked in the "human version," then the other json, didn't notice the _full one. Sorry I'm incompetent :P
I think the idea here is to catalog known and documented security vulnerabilities (e.g., for penetration testing), rather than to track packages that should be avoided.
I don't really think this belongs on someone's github other than the actual project's.  You're not going to keep it up to date and it makes projects look bad.
Maybe they just need a little confidence boost?
The [curated web database](https://pyupio.github.io/safety-db/) ~~is~~ *was* broken.  ~~It gets stopped at ftw.mail.~~

EDIT: Now working
So the thing to keep in mind: this is not a list of packages with insecure current versions. It is a list per package of changesets containing a security fix, which implies 'don't use versions < X of this package'. Useful to know whether you need to update, but not, AFAICT, to know which packages to avoid.
There is quite a bit of clicking on https://pyupio.github.io/safety-db/ to get to the date. would be nice to see a last updated value on the top-level.
It would be pretty cool to publish in this format: https://stixproject.github.io/
Any plans for proper Cython support in paid version?
Any plans for proper SSH key agent support?  Or MFA support?

https://youtrack.jetbrains.com/issue/PY-6311

https://youtrack.jetbrains.com/issue/PY-21090

Edit:  I'll take this as a "no we still don't care about security"
>Additionally weâve added a special code intention (invoked with Alt+Enter) to automatically convert comment-based type hints to variable annotations syntax

That is a pretty neat feature. Looking forward to using it in community!
To any Linux user running their project in docker with docker-compose, if you're trying to use the Docker Integration, note that the API URL defaults to: `http://127.0.0.1:2376` but you might have to use the socket instead: `unix:///var/run/docker.sock`.
My go-to CLI library these days is [Click](http://click.pocoo.org/6/).

Where do you see your library fitting when compared to raw argparse and more full-featured libraries like Click?
I prefer the class-oriented application style used by [plumbum](http://plumbum.readthedocs.io/en/latest/), along with its many awesome features.
Nice, short and concisely explained. Also, the reporting with HTMLTestRunner looks great bur it doesn't seem to support Python 3.0.
thought you were joking. quite the bummer. you can check out /r/esp8266 in the meantime, cuz there is usually some good micropython talk on there.
I guess word python in micropython could mean something else than programming language. And they want to keep it private.
I have no idea why it's private, but I have found their official forums to be pretty helpful. I've also played with it quite a bit of you have any specific questions. 
Because they want to be a microcommunity? :)
I've used gunicorn  and nginx(static/media files) numerous times and it's really easy to deploy fast or you can take your time and make sure you log adequately. It's pretty awesome.
I found out the most straightforward for me is using gunicorn and whitenoise to serve static files https://github.com/evansd/whitenoise. No apache, no nginx configuration, only python modules. 

Then I looked into supervisord and Honcho (if I have a django app that needs another process running, like reddis). https://github.com/nickstenning/honcho
Have you considered something like Heroku?
Django has documentation on how to set up the server for a project. Its been awhile (2 years) since ive done it, but I believe the only supported method they document is with Apache and mod_wsgi. I saw that someone mentioned docker. While I love docker, please note that you absolutely need to take into account some kind of data retention policy if you go this route. If you're server goes down, and you have not backed up the running container, you -will- lose any data added after the container was started. Docker is not intended as a VM replacement, its meant to containerize processes. That said, the fact that you can set up and test on local machine and deploy without any changes to the docker image is a huge plus. It also makes packaging and moving servers a breeze (usually).
"Throw more hardware at it" is often a valid and pragmatic approach. In this case, however, I'd suggest you look into streaming processing: it's a csv file, so you can probably read it in one line at a time, process that line, and then discard it.

With the "add more RAM" approach, the limit of how large a file you can process in a timely fashion is a hard one: once the file size surpasses the limit, you get swapping and everything slows down to a crawl. Adding more RAM moves the limit up linearly, but doesn't remove it. The streaming approach changes memory requirements from linear to constant, so the hard limit goes away, and performance scales linearly with file size (i.e., 1000 lines take roughly 1000 times as long as 1 line).

Adding more RAM might still improve overall performance, but that has to do with the OS using spare RAM for clever things like caching and buffering.
Now *that's* thinking like a sysadmin.
Re: pandas. 

Make sure you're explicitly setting the dtype of each column. If something is being loaded as object when it could be float32 for example then you'll use up way more memory. 
Spin up a Linux EC2 instance with more RAM? 
If you aren't already, you want to look into using generators. Tldr; only one item at a time is processed, meaning you should save on memory.
Even if you know Python well, it is still requires extra effort to process data in low-memory environments, and not everything can be optimized. More RAM can save you time when you're doing data analysis, it is a good investement in productivity. If you're buying a desktop I suggest to max out RAM (e.g. put 32GB or 64GB instead of 16GB), it is relatively cheap these days. 

Of course, learning is also a good investement in productivity, so please do both :)
If you do heavy work on a laptop make sure your adapter is plugged in and your power settings are on Performance/Best/Max (or equivalent for your OS) or else your OS might throttle performance, clocks and all kinds of things.
Dude, you can probably buy memory sticks to increase the RAM of your notebook. Search your model on Google and check for compatible memory sticks.
I'd probably get a Linode box or other VM and run your stuff there.

Or, you could just use something like Google BigQuery.
Holy hell, my phone has more RAM than your Zenbook.

Either way, if you actually need the entire dataset in memory, you don't have much choice except to have more memory. If you can use mmap to handle the file, it may yield better results for your current setup. If you can process the CSV as a stream, even better and you could still use mmap to improve performance.
If you're on a 32-bit OS (or using a 32-bit python) you might be hitting an address space limit instead of just a ram limit, which would not be solved by adding hardware.

If it were only a memory issue you could add more swap space and endure the extra time it takes.

I haven't used pandas, but if there's any unused columns in your csv, I see there's a "usecols" parameter in its [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function to specify which you want, to save memory omitting the rest, and /u/sleisl mentioned a dtype parameter.
Temporary solution: swap partition on linux
My desktop has 32gb of RAM because I use a lot of virtual machines for a particular task. I still try to optimize my code as much as possible. I like to throw longer running tasks onto a Pi or a Linux server. I don't want them to get bogged down by running multi scripts simultaneously. Even with multiple machines to use, I still try to optimize a lot.
So, many people in the thread have posted the value of both optimization and more memory. But there has been no discussion about what you are trying to do. Trying to do "data analysis" can mean very different things to different people and different datasets. If you explain, in general terms, what your dataset looks like and what you are trying to do with it maybe recommendations could be made for ways to optimize rather than just throwing theoreticals around. 
If you go to a university or work for a business you should inquire to see if you can get access to a remote machine. My university gives everyone (in CSC at least) an account on a machine with just shy of 20 GB of ram that is normally mostly free. 
You have a 5lb bag and 20lbs of data.  If you get a 30lb bag and try to put 20lbs of data into it, it would work better.

Unless you NEED all the data in memory, would it make more sense to take bites out of the data and work with smaller pieces??

https://github.com/jflaker/Useful-Python-Stuff/blob/master/ChunkyRead.py

This is python chunking.  It takes bites out of the data instead of the whole file.
Oh, gods yes.  The last time I had 2GB ram in my laptop, I sported a mullet and Lehman brothers was a great bank.  

A side effect of programmers only buying pre-configured laptops and cloud VM's rather than building their own hardware rigs, is that they forget how huge a difference a hardware upgrade can make.  

[You can get a laptop with 32GB or RAM for less than $1400](https://www.amazon.com/gp/search/ref=sr_nr_p_n_feature_five_bro_1?fst=as%3Aoff&rh=n%3A172282%2Cn%3A%21493964%2Cn%3A541966%2Cn%3A13896617011%2Cn%3A565108%2Cp_n_operating_system_browse-bin%3A12035945011%2Cp_n_feature_twelve_browse-bin%3A9521908011%2Cp_n_feature_five_browse-bin%3A13580788011&bbn=565108&sort=featured-rank&ie=UTF8&qid=1477632880&rnid=2257851011&lo=computers).  If you measure a programmers' time at $100/hr, your new laptop will pay for itself in a couple of weeks.  

If you build a workstation, $4k buys you:
[256GB RAM](http://www.newegg.com/Product/Product.aspx?Item=N82E16820239276)
[2 x 8 Core CPU](http://www.newegg.com/Product/Product.aspx?Item=9SIAAEE40T5826)
[4TB of SSD](http://www.newegg.com/Product/Product.aspx?Item=N82E16820147374)
[Kickass MB](http://www.newegg.com/Product/Product.aspx?Item=N82E16813182348)

That's not a lot of money to easily work with 100x the data you're currently managing.  

[deleted]
Good read, thanks. 

Some words on performance?

If I got this https://www.techempower.com/benchmarks/#section=data-r12&hw=peak&test=fortune&b=2&s=1&l=27wphb correctly, in each tested framework, what seems to be the most penalizing factor is SQL alchemy.

Filtering only for Flask for instance (https://www.techempower.com/benchmarks/#section=data-r12&hw=peak&test=fortune&b=2&s=1&l=27wphb&f=zhb2tb-zik0zj-zik0zj-zik0zj-zik0zj-1ekf) you can see that it's twice faster at least without the ORM.

Sorry for the big links, on ð± ;) 
Does SQL alchemy have a migrate function like djangos orm. That's such a good feature for developing at least. Change the class, generate the migrate scripts, and migrate them in.
I've been using sqlalchemy pretty heavily for the last couple of years, and I'd like to offer a couple observations/some thinking about how we build things.

First, having used 3-4 ORMs over the last 5 years (Eloquent mostly), SQLAlchemy is top tier. Really great, and produces very readable code in controllers. So, in some sense I'm a fan of it.

On the flip side though, many joins/things we want out of our databases are not very simple, and whenever I try to get SQLAlchemy to handle those situations, I feel like i have to write it in sql in my head (or pgadmin), and then figure out how to translate that to sqlalchemy. This is generally a slow / buggy process that involves lots of looking at the query log and figuring out if the sql that sqlalchemy generated is equivalent to what I *think* it should be, but maybe that's just me not having enough experience with it.

So the amount of time I've spent debugging complex sqlalchemy queries has led me to think about things this way:

If the query I want to do is simple (a primary key / foreign key join, maybe a sum), do it via sqlalchemy. *Anything* more complex than that, I simply make a view in the db, and then add a sqlalchemy model. That way, I'm doing all the complex stuff in sql (which I had to do anyway). 

Thinking about things that way has also led to me wonder if I should be looking at a simpler ORM. If all I'm doing now is simple joins, do I really need SQLAlchemy? If I was starting a project from scratch today, I think I'd be leaning towards the simplest/stupidest ORM possible, but I haven't really solidified my thinking on this.

What are everyone's thoughts on this?
> No SQL is required to create, maintain and query the database.

I don't think this is entirely true. Technically, yes. But once you start moving beyond basic queries into even just joining across three or more tables, a healthy understanding of SQL makes using SQLAlchemy much more intuitive. 

If I'm having trouble with retrieving data, I'll  often think out how I'd approach the query in raw SQL and derived my SQLAlchemy expression from that.
SQLAlchemy may be the single best library ever made. 
How does it handle complex queries?  

Like I had an application at an old job that I made that had some pretty complex queries across a lot of tables that returned a lot of data.  I can't see how that could be done with this. 
the only thing I dont like about sqlalchemy is the use of expressions AND orm.

It makes flask admin maintenance very hard/complex filters/queries than django orm.
I've never used the SQLAlchemy orm, just the SQLAlchemy  core.

It's fast! ,safe, and writing wrapper code is simple enough.
Serious question: Does relying on SQLAlchemy make your skills less versatile? I am not arguing one way or the other; just asking.

I know next-to-nothing about databases but my wife works in them all the time. I was telling her about this post and she pointed out that she can write the same (or close to it) SQL queries in .Net as she does in Java, etc (she doesn't use Python). The skill translates well. Is that an issue with relying on something like SQLAlchemy?
One of the things I like about SQLAlchemy is how it separates the db interaction layer from the ORM layer. You can still get a lot of benefits out of SQLAlchemy while completely ignoring all the ORM stuff and just write plain text SQL.
It all comes down to the particular software license that the author of the library decided to use. There are so many different options, here's a good spot to get started.

https://its.uncg.edu/Software/Licensing/
Basically, you can use any library that has a license that is compatible with the way you intend to license your application.

Generally speaking, if you don't want to make your application Open Source/Free Software  source-code, you need to avoid libraries with copyleft licenses like the GPL, because by using them in certain ways, you will end up having to provide your source code under the same license (always read the label). You can find MIT or BSD licensed libraries that allow you to use them in closed-source applications.

I would, however, encourage you to make your program source code freely available under a liberal or copyleft license, because then you are not abusing the software freedoms of your users  - you can still sell it, of course.
Other people have given you more technical answers around licensing. I'll try to give a broader overview.

Firstly, it's totally normal in programming to use libraries other people have written. Most of the interesting stuff we do would be impossible if every programmer had to write their own libraries from scratch. But there's a few different ways this works.

Some libraries are commercial: if you want to use them, you pay the creators (or the copyright owners, to be precise). This may be a one off payment or based on how many users you have.

There's also a large ecosystem of open source libraries, which you don't have to pay for (it is possible to charge for an open source library, but it's unusual). However, you usually need to credit the creators of open source libraries you use by including their copyright notice somewhere in your program. E.g. if you use Firefox, go to `about:license` to see a big list of code it uses under different licenses.

Some open source libraries can only be used if your code is open source as well. This idea is called 'copyleft', and the main license for code like this is the GPL. But don't worry too much about the details of different licenses while you're messing around.
The shortest answer to just the title is:

It's close to unethical NOT to :P
In cases where all I need is a simple GUI on top of a command line program, I have had good luck with [gooey](https://github.com/chriskiehl/Gooey)

I wrote an [article](http://pbpython.com/pandas-gui.html) about it as well.
This is a problem that is already solved by several applications. Splunk, elasticsearch, MS power BI, Tableau, etc.... I would use an off-the-shelf product. Supporting an end-user reporting/analysis program seems very messy, particularly when there are products that do it already. 
Tips:

1. Don't use `cat` to read files at the terminal. Use a pager like `less`. You get nice additional features like search. 
2. If you need to remove entries from `known_hosts` use `ssh-keygen -R <host>`, that removes the provided host from `known_hosts` while saving a backup. 
3. If you're working with VMs or machines that get wiped out often (RPis), often enough for host key checking to be an annoyance, use `ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no ` to use a blank `known_hosts` file and don't perform strict host key checking. This would not be secure connecting to production machines but it's probably ok in a lab environment. 

Don't stop writing utilities but it also helps to learn your existing tools. You can use existing tools to write more robust or useful utilities or save the effort. Learning the tools that are on the system by default also means you don't need an extra dependency to make your workflow actually work. 
It would be nice to add some sample output (both the source file and output) in the README so we can see what you mean by "parse out" without having to read the code. 
Was there a reason you used Python instead of PowerShell? I see you're at MSFT, so I presume you're using Windows, but maybe I'm mistaken.
Very useful for newbies, thanks!
Did you already use supervisor? Just discovered PM2 with your post, and it seems a little bit more advanced. Any thoughts?
If you fully execute your reference Notebook and then commit it into your repository, it'll render with all your output and plots when people view it on GitHub. You do this for the ROC curve and multi-level modeling notebook, but not your example/template one, which you link to in the README. Come to think of it... those aren't your notebooks, are they? At least, the multi-level modeling one isn't. It looks like one of the PyMC3 tutorial notebooks, although I could be wrong. If it is, you really need to provide a citation or reference to the original author.

That being said, what problem, in particular, does your package solve? Most of the tasks in my data science workflow are easily satisfied already with the very high-level interfaces of statsmodels, sklearn, pandas, and seaborn. Even my intermediate complexity tasks are usually just a few lines of code, and it's easier to craft that extra function when I need it, tailoring it to the specific application I'm working on.
I coded html sites in '90's. I want to code full feature site in python. Can anyone advise on this initially free setup.
This looks like an ad.
Atom isn't really ever going to be as complete as Eclipse/PyDev in terms of being a complete IDE. It's really a text editor with syntax highlighting and a basic plugin system.

The packages I use with it for Python dev:

* magicpython -- better python syntax highlighting, supports async & parameter annotations in particular
* linter-pylint -- run pylint continuously on your code and add a red squiggly underline to parts which don't conform
Hydrogen: integrates Atom with Jupyter. You get the interactivity of ipython and the literate programming of the notebook, in your editor.
Python stuff

* MagicPython for syntax (especially if using python3 with mypy/type hinting)
* linter (general linter with plugins available for many languages)
* linter-flake8 (flake8 plugin for linter, combines pep8 and flake)
* python-indent
* python-tools

General dev stuff

* project-manager (for saving projects)
* git-plus


Other visual stuff I like:

* minimap (for that sublime like file minimap)
* fonts (more monospace fonts, including Meslo)
* file-icons (show icons in treeview based on file type)
I know this isn't what you asked. 

But... Have you tried PyCharm?
This isn't really what you asked but in case you haven't found it. I really like the autocomplete-python plugin for Atom.

Also to setup projects you could always use a tool like cookie cutter, but that  wouldn't be integrated with your editor.
https://github.com/audreyr/cookiecutter
Classic one, Emet.
Auto-complete plugin.
Spyder also has cells that allow you to do that.
What you're looking for is how to define a *code cell* in an IDE.

For example, in the Spyder editor, you can separate code cells by lines starting with **#%%** (standard cell separator).

**Ctrl+Enter** within a cell runs that current cell only.
**Shift+Enter** within a cell runs that current cell and goes to the next cell.

Hope this helps!
If you use Atom, you might want to check out the [Hydrogen](https://atom.io/packages/hydrogen) package, which lets you do stuff that's similar to Jupyter inside an editor.

The Sublime Text plugin API has also been improved in the last year, so someone might make something equivalent here too.
I use Jupyter notebooks are mainly for exploration, and PyCharm or vim for writing files. I also usually have a Jupyter qtconsole open as well, attached to the same kernel.

When I want to finally clean something up, I either export it into a python file or copy paste it into my IDE, and save it for future use.

At least Jupyter has tab completion and docstrings etc, I guess? And you can reload (automatically is possible too, I think) python files whenever they are saved. So explore, write final version of function, use it in the notebook for further exploration.
Who uses Jupyter files for dev? They're fantastic for documentation but I see no way in which they're meant to superseed a proper IDE or even VIM/emacs for that matter. 
I use Microsoft VS and it will let you select whatever code you want, right click it, and send it to interactive mode where you can see it work. 

Alternatively you can debug the code line by line stepping through the code.  You can add watches to whatever variables you want.  You can visually see your data structures by hovering your mouse over them and selecting the lists and dicts.  These obviously change as you step through your code and it is nice being able to see how the data structures react to each line of code.  You can add stops at certain points in your code to speed the process up and not have to go line by line. 
You can work with Jupyter notebooks in ways other than via the browser interface. The Jupyter notebook server exposes a client API, so you can have the best of both worlds if youâd like. Iâm afraid I canât provide an exhaustive list of clients implementations, though; I have used notebooks from within Emacs at the time however.
> Am I missing an obvious development method the productivity beasts use daily?

PyCharm has support for Jupyter notebooks. You can have your cake and eat it too.
you can configure pycharm to run ipython, which allows you to run just blocks of code interactively. when i work in pycharm i typically highlight whatever batch of code i'm working on and push the 'execute selection in console' hot key (ALT+SHIFT+E).
[JupyterLab](http://blog.jupyter.org/2016/07/14/jupyter-lab-alpha/) is looking to fill that gap, though it's still in development.

There are also ways, in other editors, to highlight lines and send them to a REPL.  In PyCharm you can configure a hotkey for this, though Spyder is probably a better fit for data analysis work.
Many interesting tips in this topic, but only a few mentions of Rodeo. I personally stick with notebooks, but RStudio is great and Rodeo looks like a good alternative for Python.
You're not really missing anything - what you've described is exactly the reason the Jupyter Notebook exists. Traditional IDEs aren't suitable for scientific work.
It reminds me a recent thread about [workflows in python](https://www.reddit.com/r/Python/comments/50t9hz/fellow_scientists_what_is_your_workflow_in_python/). You may find it interesting.
You can run block of code in ipython console using %paste ipython magic command.  I use jupyter notebook to explore data or documentation , otherwise, I use sublime text + ipython %paste
That is what jupyterlab and nteract are addressing! But have you tried ptipython which comes with autocompletion and error checking? It is slowly integrating into ipython project.

So simply jump between pycharm, jupyter, Spyder, rodeo, and ptipython :)
I do mostly data science type work and spend the majority of my time working in notebooks. Once I'm happy with my development solution I clean up the notebook and export to .py file. Then I load up my editor and clean it up to remove any jupyter artifacts.

I work in data science as well, and (at the moment) I don't use Jupyter at all.

What I do is spend a great amount of time in Pycharm's debugger-I usually build out the basics of the script that gets my data into the right form, then I set breakpoint and get stuck in with the debugger.

I prefer the debugger approach because I tend to feel like the notebook approach (be it R or Jupyter) tend to let me do too much and I lose the thread of what operations and methods I attempted on the data to get that result/structure/etc-that is, I find I lose repeatability with them.

The debugger setup helps me ensure that whatever I start from the same place and that my data structures and types all remain consistent and repeatable.
Post your code and post the error(s) you are getting.
code:

import os.path
import ConfigParser
from ftplib import FTP_TLS

class IMPLICIT_FTP_TLS(FTP_TLS):
    def __init__(self, host='', user='', passwd='', acct='', keyfile=None,
        certfile=None, timeout=60):
        FTP_TLS.__init__(self, host, user, passwd, acct, keyfile, certfile, timeout)

    def connect(self, host='', port=0, timeout=-1):
        if host != '':
            self.host = host
        if port > 0:
            self.port = port
        if timeout != -1:
            self.timeout = timeout
        try:
            self.sock = socket.create_connection((self.host, self.port), self.timeout)
            self.sock = ssl.wrap_socket(self.sock, self.keyfile, self.certfile)
            self.file = self.sock.makefile('rb')
            self.welcome = self.file.readline()
        except ftplib.all_errors as e:
            print str(e)
        return self.welcome
def check_login(ftp_server, ftp_port, fname):
    try:
        ftps = IMPLICIT_FTP_TLS()
        ftps.set_debuglevel(2)
        ftps.connect(host=ftp_server, port=ftp_port)
        ftps.login(user=user, passwd=password)
        ftps.prot_p()
        ftps.cwd('/')
        #ftps.storbinary("STOR " + fname, open(fname, "rb"), 1024)        
        ftps.storlines("STOR " + fname, open(fname))
        ftps.quit()
        return 1
    except ftplib.error_perm, e:
        return 0

error:
Traceback (most recent call last):
  File "new_ftp_check.py", line 89, in <module>
    write_status(ip,port)
  File "new_ftp_check.py", line 70, in write_status
    result = check_login(ftp_server, ftp_port, fname)
  File "new_ftp_check.py", line 63, in check_login
    ftps.storlines("STOR " + fname, open(fname))
  File "/usr/local/lib/python2.7/ftplib.py", line 759, in storlines
    conn = self.transfercmd(cmd)
  File "/usr/local/lib/python2.7/ftplib.py", line 376, in transfercmd
    return self.ntransfercmd(cmd, rest)[0]
  File "/usr/local/lib/python2.7/ftplib.py", line 693, in ntransfercmd
    conn, size = FTP.ntransfercmd(self, cmd, rest)
  File "/usr/local/lib/python2.7/ftplib.py", line 334, in ntransfercmd
    host, port = self.makepasv()
  File "/usr/local/lib/python2.7/ftplib.py", line 311, in makepasv
    if self.af == socket.AF_INET:
AttributeError: IMPLICIT_FTP_TLS instance has no attribute 'af'

As someone who just got a Mac, this is super useful. Thank you :)
So you have to take your hand off the keyboard and grab a mouse? No thanks
I've used repl.it a few times to quickly test Python code and I found that it's a very good tool. It's more practical than using the Python console, especially if you work with several source files. Nice to see that they added all packages!
Seems interesting, but matplotlib and ratcave didn't import.  Is there something that needs to be activated or set for these packages?
Huh. My package is on there.

Now I just need to update the version on pip.
That's fantastic, wow. Definitely going to use it to check out libraries before installing them.

But at the moment`import requests` doesn't work at all, no response in the repl.
It's really neat to see my package in here (pysparklines, `import sparkline`). 

How are you resolving module namespace issues?  I'm sure there must be overlap in pypi.
`import cv2` fails
On the gif it shows it importing pygame but if you try to run a pygame script it says no availabe video device. I understand why it might not be practical to run pygame scripts but I just want to know if I'm missing something.
How does this work?
I wasnt able to import NLTK. Possibly another bug?
The following fails on python 2:

    import scipy
I just tried a scipy sample snippet because it's something I've never successfully installed on my PC. Got an error though:
ImportError: libtk8.6.so: cannot open shared object file: No such file or directory

Code:

    """example.py
    
    Compute the maximum of a Bessel function and plot it.
    
    """
    import argparse
    
    import numpy as np
    from scipy import special, optimize
    import matplotlib.pyplot as plt
    
    def main():
        # Parse command-line arguments
        parser = argparse.ArgumentParser(usage=__doc__)
        parser.add_argument("--order", type=int, default=3, help="order of Bessel function")
        parser.add_argument("--output", default="plot.png", help="output image file")
        args = parser.parse_args()
    
        # Compute maximum
        f = lambda x: -special.jv(args.order, x)
        sol = optimize.minimize(f, 1.0)
    
        # Plot
        x = np.linspace(0, 10, 5000)
        plt.plot(x, special.jv(args.order, x), '-', sol.x, -sol.fun, 'o')
    
        # Produce output
        plt.savefig(args.output, dpi=96)
    
    if __name__ == "__main__":
        main()

I could easily be doing something wrong though. Cool concept still.
Holy cow this is amazing.
Sweet, someone else has finally installed my svg select widget for Django!
If you take into account that many package behavior are changed by entrypoints (eg all nose plugins, pytest, IPython), then this is a strange choice. Keep in mind that several packages can be behind the same import. For example, PIL and Pillow are both `import PIL`. Installing both make no sens. Have you considered using something like what conda does, where all packages are on the filesystem but can just be quickly "hardlinked" to the correct location to make installation a quasi-instantaneous step ?
import arcade fails.
[deleted]
Tried `import keras` and the prompt hanged.
What is the difference between REPL and Anaconda? 
Very cool! Well done!
scrapy isn't on there.
Are you guys planning on including Kivy? 
`import skbio` fails with [scikit-bio](https://pypi.python.org/pypi/scikit-bio) being a pypi hosted package.
Clearly, I missed something.  It doesn't work, even on numpy.  It works exactly like their gif does.  It returns None...
Is it possible to disable some packages ? Because right now, i can't use Pillow because it's namespace is overwritten by PIL :/
I have a library dealing with I/O (namely command-line argument parsing). It sometimes prints to stderr, and always exits. On repl.it, stderr is swallowed and exit breaks the connection (unlike the Python REPL which just catches the SystemExit exceptions). I could detect whether we're in repl.it and adjust accordingly, but I think it might be cleaner if you addressed these issues :)

Finally, is repl.it suitable for embedding in generated documentation?
What Linux distro is installed on repl.it? Looks like this is neither Debian/Ubuntu, as my package works fine on these, but fails on repl.it. On Python 3 throws error about freetype library missing, and on Python 2.7 error about glib/gmodule library missing.
Nice that works very well! I can include running examples in my projects as in: https://repl.it/EGcO/0

Should be nice if I can embed this, can I?
Is there any way to get [Hy](http://docs.hylang.org/en/stable/index.html) ?
Is repl.it open source? Can I run it on my own server?
It's pretty amazing what happens to your code once you open source it. Without spending a cent, some kind individual makes it accessible to anyone over the web!
    Python 3.5.2 (default, Dec 2015, 13:05:11)
    [GCC 4.8.2] on linux
    > import nistbeacon
    Traceback (most recent call last):
      File "python", line 1, in <module>
    ImportError: No module named 'nistbeacon'

So it's not every package because [mine isn't working](https://pypi.python.org/pypi/nistbeacon). Mind clarifying /u/amasad ?
If you're getting things off of Pypi, why is the version of my [Pyro4](https://pypi.python.org/pypi/Pyro4) that is installed so ancient?  It has 4.18 from 3.5 years ago. Current is 4.49
So... of those of us who have packages on pypi, many have now updated those packages. What is your update schedule for packages, or is that not yet one of your concerns?
I would have prefered the inline except to be accepted:

foo = bar.attr except AttributeError: "default"

It easier to read, feels more like Python and has a bigger list of use cases.

Espacially, we rejected the classical foo ? bar : else ternary syntaxe in favor of keyword. I really dislake the whole '?' invasion.
Python stands out for having such clear, readable syntax. I think the syntax this PEP introduces would be a disservice to the language.

I would prefer to see something similar to `getattr` which accepts an iterable of attrs and recursively looks them up. I would not be surprised to see something like this already in the "util.py" that all developers collect over time, and I'm aware of at least one project out there that does something similar.
`?=`, while not the main focus, is really nice, however I can't see that making it in (not really obvious which side it tweaks on, but still cool!)

It'll be nice to finally join a bunch of other languages in having this feature.

I kinda wish that "existence" would also mean actual existence is considered, but it doesn't seem to be the case

It would be nice to go from

    try:
        a_variable
    except NameError:
        a_variable = {}

to

    a_variable ?= {}

so for every persistent variable, that is going to be 3 extra lines :(

(why? for module reloads of course)
For those working on data pipelines, which often include sparse data or even missing data, this PEP would be a great improvement.

I'm 100% convinced about the syntax, because it consists of a single character, there's a risk of missing it when reading 
This PEP introduces what python tries to avoid - syntax full of magical symbols. It is not a good thing...
Cool feature, ugly syntax.
> Status:	Draft

Nothing to see here.
The problem with this is:

    Explicit is better than implicit.
    Sparse is better than dense.
    Readability counts.
    There should be oneâand preferably only oneâobvious way to do it.

Accepting this PEP would serve to make python more like perl and less like python. 

But I guess the multiple methods of string formatting all got accepted, so I might be in a minority.
Reasonable idea, but I don't like the syntax.  If we get something like this, it should be _better_ than `if hasattr(x, y): y`, not worse.
Surprised at the negative reactions, this looks incredible to me! It's the maybe monad in a single character!
Can someone explain what the challenges are with overriding `__getattr__()` on a class where this is a common use case? Obviously you have to create the class representation of the object, but that doesn't seem like much overhead.
Do want.
I love the idea, but ?else is sooo ugly. Having said that, I don't think any language has a good operator string for this feature.
I'm not a big fan of the whole existence thing and the fact that we would have operators that support the use of None instead of exceptions for indicating errors.  It seems to me that exceptions already work very well for this â for example, doing `return foo?.bar?.baz` is really just a way of propagating a None.

`?=` might be nice for dealing with function defaults of None, but I'm not convinced it is really worth it.
I really like this. It seems very similar to the null propagation and null coalescing features of C#, which are some of my favorite parts of that language. Just the (?.) operator in particular would be great to have. 
It'll be an improvement, but we'll have to live with the consequence of being able to less often say "python is readable".
Why not just expand the existing null-coalescing operator to do this.

`var1 = var2 or 5`

Or just add the ? decorator to it to make it check suppress non-existence.

`var1 = var2 or? 5`

I personally like the look of the first but don't like how it can suppress flaws in the logic of the program.

In the end, it seems like a ham-fisted way to glaze over inconsistencies in the logic of a program.

If this is what you need to do you should have to write a bigger construct.

<code>
from contextlib import suppress

var1 = 5
with suppress(NameError):
    var1 = var2
</code>
The first thing that came to my mind was the Forrest Gump quote, "Run, Forrest, run!", but that's just a guess.
I think it's a Metal Gear Solid reference
The joke is their 3.x compatilbility. The last update of this project in pypi is 2013-10.
I always thought it was a reference to comic book guys C:\DOS\RUN run DOS run T-shirt in The Simpsons

https://m.youtube.com/watch?v=DID8B2yk5lY
Sounds like a scary movie, or forrest gump reference.

What would have been  your last words to the murdervictim?

RUN BITCH RUN!

Or maybe it's a joke about the classic Snake games?
I feel like you'll enjoy mixins in Ruby or scoped traits in Scala/Rust. Monkey-patching builtin classes really isn't something you should be doing in Python.
We can already extend built-in types like string:

    class MyString(str):
        def mymethod(self): ...



There. MyString extends str, as requested.

What you're doing is writing a pre-processor that lets you pretend to have monkey-patched built-in types but without actually monkey-patching them. Why bother? Just write a function and be done with it, rather than pretending to be writing Python-with-monkey-patching.
any plans for adding automatic javascript form validation?
awesome :)
Nice, but...

I use Pyramid quite a lot and the same thing goes for at work, but we never really went with Deform because it seemed it was very tightly integrated with Colander.

I ended up going with Pyramid + wtforms + jinja2, which gives a very Django-like feel and I've come to quite like this stack.

One of the reasons our team at work ended up really disliking Colander, is because (at least if you use it for API schemas) it serializes fields very badly to JSON and everything just becomes a string which is not really what you want for ints and bools for example.  I also found Colander schema classes to be a bit more verbose than Marshmallow because every field is wrapped in a SchemaNode() type, while Marshmallow doesn't really need this.

Once again, I do not know much about Deform and if you can even use it with Marshmallow instead of Colander, or if that even makes sense.

Colander can be "fixed" by subclassing every field, but this is a bit annoying and I really hope they "fix" serialization to JSON.

https://github.com/Pylons/colander/issues/80
How do you dynamically show/hide a form input?
If you're still not sure how to develop the actual gui application why complicate it even further by wanting to create a client-server system right from the start already?
I suggest creating something that at first stores stuff inside a local sqlite database (for instance). If you make sure your data access is done in code that is clearly separated from the rest of the application, it shouldn't be that hard to modify it later on to store it somewhere on a server. 
You'll get a lot more help at /r/learnpython. 
Isn't it more fun to write it all yourself?
I second it.
In fact, one of my MSc students took this course last year and it turned out to be a very good one.
Very good course, covers a good range of subjects. Took this course would highly recommend.
It's one of the few courses I took before going to college and I will say it's also one of the best out there.

Just complete week 4, thanks for the heads up! Amazing course. 
[Automate the boring stuff with Python](https://automatetheboringstuff.com/) is a great beginner's resource. Depending on how much you know about Python, you might want to read through the first chapters or skip straight to Chapter 11 for web scraping, downloading files and so on.
[The Hitchhikerâs Guide to Python!](http://docs.python-guide.org/en/latest/scenarios/scrape/)
[splinter](https://splinter.readthedocs.io/en/latest/) could be something you are looking for
Take a look at selenium, which will help you open a browser you  desire and login to website you want to download from. There is already build script that will help you achieve that. 
Either look at requests module, or if you're feeling saucy use the urllib module. Extra points for just using sockets.
Check out mechanize

Windows?
Fantastic :)
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/kivy] [Pyonic interpreter: A Python interpreter GUI for Android, written in Python (cross-post \/r\/python)](https://np.reddit.com/r/kivy/comments/59dy6z/pyonic_interpreter_a_python_interpreter_gui_for/)

[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*

[](#bot)
I thought I would never see the day. Way to go Mayavi team, it must have been quite an effort to port to python 3!
I've never seen this before so I got confused for a moment when trying to see how this was related to Autodesk Maya and vim....

Anyway, looks like a cool project.
For all non Hindi speaking fellas out there, Mayavi means magical in Hindi.
I wonder how this compares to [plotly](https://plot.ly/python/).  The time series stuff looks super helpful though.
For 3D visualization, I use VTK and Paraview.  As the blog says, Mayavi "provides a convenient Pythonic wrapper for the powerful VTK (Visualization Toolkit) library."  What are the advantages of using Mayavi over the VTK library itself?
There are also plotly, pythreejs, sage 3d plots, and vispy worth mentioning. But matplotlib with mplot3d was good enough for my 3d plots, especially since I do matplotlib + pandas mostly.

We need altair for 3d plots!

https://github.com/altair-viz/altair
For 3D visualization, I used VTK and Paraview in the past, but I think I am going to use Mayavi 3D from now on. It seems much more straightforward.
It says it requires authentication. I can't access the website as it's blocked by my ISP, but look into how their authentication works. Also, please post your other questions in /r/learnpython.
You are sending api_key in POST data, but you need to pass it as GET argument.

    post_data = {'amount':'0.00001000', 'target':'50', 'condition':'<'}

    post_response = requests.post(url='https://api.primedice.com/api/bet?api_key=<API KEY>', data=post_data)
Awesome! I have been planning on doing a series on building a self driving toy car as a combination of a bunch of my tutorial series.

Are you the creator of this? 

If so, why did you use the paper, as opposed to building a model in unity, or even pygame...or even just in pure data for that matter? Would be a whole hell of a lot faster to train it to do things. That's what I was planning to do anyway.
Here is the [git repo..](https://github.com/RyanZotti/Self-Driving-Car)


I was just thinking about how to do such a thing. Thanks
Watched it all the way through, and learnt some new stuff. Cheers.
As a second year student in computer engineering, how might I go about recreating something similar? I've wanted to play around with a Raspberry Pi for a while, and I want to learn OpenCV, so this sounds so cool. 
Is there a live demo anywhere?
Brain skipped the word "toy".. I was about to start raging about how irresponsible a DIY autonomous car would be.
Why do you want to transition to Visual Studio? In my experience, PyCharm is way better for Python.
Well, most of the reasons why Python is a good choice for data science are about the same as why Python is a good choice in general: simple, easy to learn, highly readable, good libraries.

But for data science in particular, you have good Hadoop interfaces (most data scientists rely on Hadoop), you can easily do map/reduce type operations in Python (though not as easily as in, say, Go), and you get Numpy, Scipy, and other mathtastic libraries.
Network effect. The main reason it is used for data science is because everyone uses it for data science. As such it has a massive ecosystem for data science, with the most complete libraries, training and documentation for this use case. The language itself is pretty no nonsense and easy to pick up, which is probably why took a hold to start with.
In addition to all the other answers, I'd also like to add straightforward integration with old C and Fortran code. If I recall correctly, a lot of the early scientific Python (like SciPy) were effectively just wrappers around old Fortran libraries.

Even today, I think Python still has one of the best stories for C integration because of Cython. I've don't think I've ever heard of a Cython equivalent for any other mainstream language.
Python syntax is easy/clear.  I cannot stress enough how nice it is for all Python code to look pretty close to the same.  

There are a ton of libraries.  Libraries are free (unlike Matlab).  They're well developed and highly integrated (unlike R).  Many libraries support HDF5, which allows for huge data arrays to be processed.  Despite what you may have heard, libraries are easy to install (unlike C++) because rarely do you have to build them.  

Not sure why anybody would use PHP or Ruby or Javascript for numerical computations.  That sounds like a disaster.  Still, that's probably better than Perl (without `no strict`, which is what I used to use...
i would say R is better for data science. but python is in addition really good at general purpose programming. so python wins overall.
Libraries (scipy and numpy paved the way, scikit-learn and pandas and whatever else built from that). Nice repl (esp with interactive notebooks). Easy syntax (compared to say java that requires a fair amount of comp sci knowledge, or r that tends to be difficult for non maths people). Fast enough generally. All that led to a strong network effect.
A few reasons:

* As others mentioned, the suite of available scientific libraries is fantastic.
* Performance is generally quite good (especially since it's pretty easy to write fast C libraries with Python interfaces).
* It's easy to scale. A lot of data science problems are embarrassingly parallel. It's really easy to do multiprocessing in Python or use GNU parallel or whatever.
* The most important bit: dealing with data is *really easy*. Reading/writing text data is incredibly easy with Python. SQL is easy. 80% of the time spent doing data science is just spent munging data, and if you can dramatically lower the barrier there, like Python has, then you've got a winner.
there's nothing about python itself that makes it well suited to data science. it's the libraries like numpy, scipy, pandas, etc. which are very nice. the reason the authors of those libraries chose to use python as the scripting interface is because python is a very nice scripting language. clean, expressive syntax and a good community. 
It has really great libraries for data science and good community support. You get:

* Juptyer Notebooks
* SciPy
* Pandas
* NumPy
* SciKit Learn for Machine Learning
* Data Viz: Matplotlib,Seaborn,Bokeh,Plotly, etc..

And most major Big Data libraries have a Python API, such as Spark.

A lot of times people prefer or suggest R, which is also a great language, but Python is also a great choice because it is a general language and you can apply your skills in Python to multiple fields using other libraries.
As everyone else has mentioned, Python has great libraries, easy to learn syntax, and interops with just about everything.  What makes all this possible, in my opinion anyway, is that Python has duck typing.  Not having to specify complex data types makes it incredibly easy to work with.  If you have a function that can work on a certain subset of `pandas.DataFrame` instances, but it doesn't matter if it's a MultiIndex or just a normal Index, or if some columns are booleans or integers, then writing that function is a lot easier.  Having to work with incredibly complex types becomes a huge chore in languages that choose to go that route.  I'm not saying it's bad, but it's not conducive to fast iteration.  The types make it more correct, but very frequently in the data science and data processing world you don't need absolute correctness, you need flexibility.  Duck typing means that 3rd party libraries can accept your objects, and your APIs can accept objects from your code or 3rd party libraries without much effort.  This makes libraries much more "plug-n-play".
The syntax is simple, it's easy to learn and there are plenty of libraries.
The answer is different for different use cases. In mine, I control my physical electronic hardware with Python and it just makes sense to analyze the data real-time in the same language without having to package, unpack, manipulate, and whatnot multiple times. I generate less data this way, but the data I store is entirely meaningful.
Whatever the reason, the interest in Python for these uses is VERY old:

https://mail.python.org/pipermail/matrix-sig/1995-August/000001.html

My guess is this: people were looking for alternatives to commercial solutions (particularly Matlab). Python was an elegant language with an interactive interpreter. They "only" needed to add a proper array data type. Guido was an early supporter of this use case and added the multidimensional slicing syntax and ellipsis.

The rest is history.
Why would one want to use a closure rather than a class?
Saying Python 3 implies that it came out in Python 3. :(
I don't know about others, but personally I don't love Jupyter, it obviously depends on what you do, and for visualization it's pretty good, but I'd leave it most of the time.
Data Analyst here. I use Jupyter Notebooks most days, because a lot of the work I do is in preparing reports or analyses, for which they're a natural choice. It's absolutely fine to do any reporting work, or even more exploratory stuff in Notebooks. 

What I tend to do when studying something new (software or data-wise), is make a few Notebooks as I fuck about and get closer to what I'm trying to do, then eventually move the bigger moving parts of that out into modules which I call from the Notebooks. 


When you need to write a program consisting of more than just one linear flow, there's no real need for Notebooks. Working in a plain old IDE/text editor is fine, and maybe it'll even help you organise stuff better.
It fills a niche in the same way i use python tutor for code visualisation but some features i fall back into pycharm. 


Jupyter Notebooks are great to tell a story or explore data ad visualize it, but when it comes to production, you'll need to eventually have a .py file and most likely your own modules, in which case you'll want to go to a text editor like Sublime/Atom or a full IDE like PyCharm
At work, I find the only people using Spyder/IPython/Jupyter/etc. are people coming from a MATLAB background. They use it because it feels more familiar.

People without a MATLAB background tend to use a text editor or IDE, running the programs from the command prompt. I also tend to keep an interpreter up and running just to test lines of code.

Great for analysis. But I use vscode for application development.
I like a mix. Real development happens in sublime text, visualizations, tutorials, and the like happen in notebooks, often supported by libraries. Not too long ago I wrote a fairly large data processing pipeline that ran through several gigs of data, produced some excel reports, and generated some notebooks for interactive analysis. I leveraged ipywidgets to make the usability much better, and ran everything on a central server so I could share it easily. Turned out great, but the couple thousand lines of code written to make it possible were primarily written in sublime and tested from the command line.
I generally explore code and poke around API's using ipython and jupyter.  Once I figure out what I want to write, I move my code to the text editor.  
I would rather use a text editor like Sublime, but that's just me.
I personally use it for any data analysis which is more than a few steps. It's just so convenient to have the data right in front of you as you work with it, rather than reloading the data to memory every time you run another iteration of the script.

I also use Jupyter Notebooks when I'm unfamiliar with an API and want to learn more about it. I definitely feel more comfortable investigating with notebooks. I will say my output is probably a little faster with standard code editors when I'm familiar with an API though.
[Bokeh?](http://bokeh.pydata.org/en/latest/)
Plot.ly perhaps?
[MDBtools](http://mdbtools.sourceforge.net/) can parse at least some MDB files - I've used it to extract data in the past. I don't know of a Python wrapper, though, and I don't know if it compiles on Windows.
Look for something called ADODB for python

http://adodbapi.sourceforge.net/

http://mayukhbose.com/python/ado/
I just booted up an XP Pro VM that has very little installed on it and it has the Access MDB ODBC driver so it looks like it's installed by default.

Unless you're running XP Home on these machines and that doesn't have them installed, I don't think you need to look for another solution.
Look at the multiprocessing module
You may want to use `subprocessing` in order to spawn a child process. If the scripts are executable, they ought to spawn their own python process as a child of your GUI.
You may be able to use the `code` module. It will let you drop into an interactive prompt after running or importing a module.

https://docs.python.org/3/library/code.html
If you see something that belongs in /r/LearnPython on /r/Python then hit that report button and select "belongs in /r/learnpython". It'll get removed whenever I get to the modqueue (I try to do this daily). Removing things that are learning questions is not the highest priority in my life, and it shouldn't be yours either. If a post languishes at -3 votes and is answered and then removed 8 hours later, who does it hurt?

If you think something isn't appropriate for /r/python then downvote it. If you don't want to see it, then set reddit to hide posts that you have downvoted.

The moderation policy here is "the minimum amount of moderation possible". We should all be reasonable adults and vote up the things that are good and vote down the things that are bad. If something with only a few votes is on the front of /r/Python then that means that we don't have very much content, and maybe instead of complaining, you should submit something amazing.

News does not flow very fast in the Python world. We don't get thousands of amazing submissions every day. Learning posts are not preventing great content from reaching the hot section. We just don't have lots of content, which is the problem.
Yes moderation must be bad with useless posts like this getting through. 
1) The mobile site or app does not show the sidebar.

2) Mobiles now represent the majority of internet usage.

3) School term timetables
If I see a post that should not be here, I just down vote it. What the current trend tells me is that we now have more beginners coming to /r/python.
Maybe I don't notice it as much since I also read /r/matlab  and that is truly painful with the questions that 5 minutes of thought or 2 of Googling would help fix.

Or, maybe it is a sign of Python becoming a taught-to-beginners language and more and more people are using it 
r/python is intentionally catch-all to a degree, sans learning questions

moderation only works when people are awake and not busy usually

r/learnpython is obvious

r/pythoncoding (which I now run) is for content but without the beginner stuff, but lacks content
Flask
Autobahn is another option built on top of Twisted. I have started using it, but haven't fully explored the features or performance so I have no comparison information for you, but it was dead simple to use with Twisted.
I like Socket.IO personally, and we use [flask-socketio](https://github.com/miguelgrinberg/flask-socketio).

That being said... If you just want to do something simple, you can just do [server-sent-events](https://flask-sse.readthedocs.io/en/latest/quickstart.html) to send from server->client and then use normal ajax calls from client->server.

*edit* Socket.IO is nice because it works also as a fallback if websockets aren't possible, via polling, and also it re-connects on disconnection if there's a network hiccup.
If you want ease of use, I'd probably go with flask-socketio. You don't mention anything about your scale, but it supports a broker (amqp or redis) so if you need multiple instances of your application to support your users, they'll all get the event.

There are a few other options, primarily in the async world - aiohttp has raw [websockets](http://aiohttp.readthedocs.io/en/stable/web.html#websockets) or a [sockjs](https://github.com/aio-libs/sockjs) extension, there is also just the [websockets](https://websockets.readthedocs.io/en/stable/) module, but if you have the need for multiple instances running you'll end up writing most of what flask-socketio already gives you.
TL;DR straight from the Pytho docs: "The marshal module is not intended to be secure against erroneous or maliciously constructed data. Never unmarshal data received from an untrusted or unauthenticated source."


Try /r/forhire or maybe /r/learnpython.
Do kindly read the side bar info / FAQ for both r/python & r/learnpython.
codecademy.com really helped me learn Python, it teaches you parts of Python and then makes you do challenges using that knowledge. 
I suppose you are coming from a language like Ruby or C# which allows you to "open" the built-in classes and extend them. As a person who writes most of his code in Python, I can see the novelty of the idea but ultimately think it would be more trouble than it's worth. I would much rather see an `IPAddress` class inheriting `str` than all of the sudden have all strings act like IP addresses.

> some assumptions about writing strings that are pretty basic and an inherited class won't "do the right thing" in such a circumstance the way string would

I suspect that in these cases there might be simple, Pythonic solutions. Could you provide a specific example? 

The question you need to ask yourself is "Does this change make sense to *every* string in my program?" That includes ones coming from other libraries and going into other libraries. 

For your IP example, the answer is a resounding no. If someone asked this with `'$5.56'.toMoney()` the answer would also be no. 

I suppose your question could also be phrased: can Python auto convert types ala scala or javascript. The answer is also no, and nor should it as it goes against everything in Python -  explicit is better than implicit, but there's also the fact that types are ducks rather than an actual enforcement like Scala and there's no special primitives like in Javascript -  you could argue that have literals makes then special but they produce the same thing as calling the constructor unlike javascript which does (temporary) auto-promotion on boolean, number and string. 

Rather what you should be asking yourself is "What do I want to accomplish here?" If the answer is parsing an ip address, there's `ipaddress` in 3.3+ (and it looks like there's a backport as well, but I've not used it).

As for *why* you can't just monkeypatch builtin types, it's because they're built in C and have special limitations placed on them. There needs to be special for written to allow them to be subclassed in Python even (afair, `function` and `bool` never had this written, so I can't implement `FileNotFound` as a member of bool -- boo). But you can monkeypatch these types by going through the C api and touching them directly. 
I really don't think you are going to find a *reliable* library or alternative python implementation that lets you do this. It would be an awful lot of work to provide some functionality that is potentially dangerous and barely useful. You can already monkey-patch all manner of classes in the standard library that are implemented in python, but people rarely do it, because it causes confusion and might create incompatibilities with other people's code or future python versions.

Having said that, I found [this](https://gist.github.com/mahmoudimus/295200), but it's a mess and clearly relies on CPython implementation details. I don't know my way around the C API, so I don't know if it has any warts or is likely to work in future versions (it seems to work in python 3.5 if you fix the print statement and replace `DictProxyType` with `MappingProxyType`).

> `"127.0.0.1".doThingToDottedQuad()`

I really don't understand why this is better than `doThingToDottedQuad("127.0.0.1"). I know ruby lets you do this kind of thing, but I don't understand the value of it. Most articles I can find about monkey patching in ruby advise you to try and avoid it if at all possible.

> `doOtherThingThatExpectsString(str(thing))`

Most functions that expect a `str` are going to be able to cope with a subclass of `str` that merely adds a new method, so coercing back to `str` is probably unnecessary in most cases.
Sorry, I'm just another jerk who thinks you should inherit from `str` and doesn't understand what the problem with that is. For a good example of a project that does this, check out [plumbum](https://github.com/tomerfiliba/plumbum)'s `Path` (or `LocalPath`) class.

    from awesome import DottedQuad as DQ

    thing = DQ('127.0.0.1')
    thing = thing.doThingToOrWithDottedQuad()
    doOtherThingThatExpectsString(thing)

What's wrong with this?

Rereading, I see

>  an inherited class won't "do the right thing" in such a circumstance the way string would

and I think this is a problem. If you want it to be a `str`, don't write it in a way that breaks `str`s.
Question: Does your class provide a `__str__` method for reproducing as a string?
Take a look at a free online book, How To Think Like A Computer Scientist".  This is an excellent first programming and Python tutorial. 
programarcadegames.com. It's an excellent tutorial in its own right, and right up your alley for your preferred career path.

Note: this type of thing is best submitted to r/learnpython. It's extremely active. This sub is more for people who work with Python already.
Automatetheboringstuff.com 

Work your way thru this; it should get you to the point where you can read/write values to/from csv & excel files no problem 
I think you need to know some data scraping to scrape data off the database, suggested modules: **Scrapy, Beautiful Soup**

Then you need another module to write the data to Excel files, suggested modules: **Xlwings**
It best approach depends on the specifics of the database. If it is an LDAP database, you can probably dump the database directly. Since it is a local database and you are presumably authorized to access the information, you could also ask the appropriate administrator to dump a few columns from the master database and give it to you in a file. Automating database lookups will get you a little farther, but it seems like you are trying to make a copy of a database row by row via an API and there are many faster approaches to copy a database. 
I had to leave early and missed the lightning talks, so I was hoping they would be posted as well -- but I don't see them. Any chance they'll be showing up at some point?
God I wish I could make nice charts and graphs from my spreadsheet data...ugh always turns out crappy for me.
Look at this https://github.com/dddomodossola/remi
It is a gui library in pure python, suitable for local network webapp.
I'd recommend not doing this unless you want to spend a lot of your time puzzling over a non-standard web framework. JavaScript is an easy language to learn and the popular frameworks are well documented and widely used. 
On [GAEStarterKit](https://github.com/kkinder/GAEStarterKit), which is Flask+AppEngine, I had relatively good luck with [uikit](https://getuikit.com/). Since you are writing a web app, you do need *some* JavaScript ([CoffeeScript](http://coffeescript.org/) or [TypeScript](https://www.typescriptlang.org/) can help keep you sane), but UiKit takes care of most of the basics of a web interface: date/time pickers, panels, all that.

I would also favorably mention [KendoUI](http://www.telerik.com/kendo-ui) as a jquery-focused option.
[flexx](https://github.com/zoofIO/flexx) is one I'm aware of, though I haven't tried to use it.
In the end, you're just going to get a library that writes out to html/javascript. 

You might as well as just use bootstrap and something like flask/django/jinja to generate the html. 

It'll scale much better than any python library that currently exists
I would rather use javascript for these type of things.
Watch someone run games on Wine on WSL and get better performance... xD
Can you do me a favour? Pip install affinity, at the top of the script set the process to one core only and time it again. It's just one line of code excluding the import. Curious.

I've also noticed 'conda working much faster in a *VM* on Windows than from the cmd/Powershell. 
Noob question : Why not use datetime? What is th epoint of these tools? 
Another reason: Arrow is really slow. Although [this article](https://aboutsimon.com/blog/2016/08/04/datetime-vs-Arrow-vs-Pendulum-vs-Delorean-vs-udatetime.html) implies Pendulum's even slower.
I ve stopped using arrow too, and am back to datetime.
The way the replace method workd in arrow is very dangerous (as explained in the article). The fact that a single letter (changing an argument from 'hour' to 'hours') has completely different results  (replacing the hour component or shifting it) has the potential to create really hard to find bugs. It s completely unacceptable for anything else than very quick explorations.

Currently i'm removing arrow from all my projects. Haven't tried pendulum yet.

It's starting to feel like a crusade, Pendulum author on a quest to banish Arrow.
I've been using arrow for a long time, and reacted with skeptisism when pendulum was announced. Then the author started to almost attack arrow and I quite disliked the tone of it.

But in the end, and after doing some side by site comparison, I must admin, I will now use pendulum. The API is better (the omnipotent get() and non standard format language are my pet peaves) and the results are more accurate. I don't mind the performance.

And why am I not using:

- datetime ? Because it lacks feature I want such as easier time shifting, human formating, better text parsing and timezone handling.
- pytz ? it's installed with pendulum anyway, and the later bring more things to the table.
You may be right but the way this article is written is quite off putting
Keep up the good work
https://backchannel.com/how-the-web-became-unreadable-a781ddc711b6?gi=e90ab0fdc44d#.27php9jqi
I would like to have timestamps that are sortable and unambiguous and to have that, I would need something like [TAI](https://en.wikipedia.org/wiki/International_Atomic_Time), [GPS](https://en.wikipedia.org/wiki/Global_Positioning_System#Timekeeping) or [Loran-C](https://en.wikipedia.org/wiki/Loran-C) time, because they aren't affected by leap seconds like every UTC based timezone or the Unix time.

Is that currently possible with Pendulum or some other time library?
I couldn't help wonder why it named Arrow, Pendulum makes senses for a time library at least.
This is an example of nasa apod using python-telegram-bot.
In general, Python threads only stop when they choose to stop. If you mark them as "daemon" threads before starting them they'll stop when the main thread stops, but otherwise you need to design it into them. Including some sort of "time to stop now" event is probably a good idea if they're long-running threads.
You have double quotes inside double quotes. Try `'download_url'` instead. Also, [jq](https://stedolan.github.io/jq/) is a great tool for this purpose (and JSON processing in general). With it, you can just do `curl https://whatever/... | jq .download_url -r` to get the same result (and the query syntax is very flexible - you can do stuff like `.result.data.download_url` and a lot more). Also, /r/learnpython is a better place for questions.
A great goal as we as a community do need to let python2 go at some point in the near future, as maintaining python2 compatability hinders the future development of the python ecosystem.

Now if Pandas and Matplotlib are dropping python2, I think other projects will surely follow, as these two are quite foundational. If only Django, Flask and numpy would make the same commitment, it would move things along even faster.
Many of the large scientific libs (scipy, numpy, etc) are notably missing from the projects listing.
Can't come quick enough!
Format your code properly if you want help
If all you need to do is basic interactions with the shell, I'd recommend pexpect's pxssh. It is much simpler to use than paramiko. http://pexpect.readthedocs.io/en/stable/_modules/pexpect/pxssh.html
You need /r/learnpython

r/python is the subreddit for news (and arguing about interpreter internals).
Also ask on the python for Maya Google group
If there are exact duplicates, try using set()
Hey there, use set()

And you could shorten that code to 1/3 if you switch to pymel
[`puresnmp` on Github](https://github.com/exhuma/puresnmp)
Brushing up on math. I have to take a math placement test. I have to pass into at least pre-cal to switch into a CSE major. Python projects are put aside while I study. Ive been working through some Project Euler problems since it's applicable to math as well.
I'm building a timetabling API and I'm trying to make it the best out there. I'm doing it all alone, so if anyone's interested in helping out or suggesting, I'm open for it. I'm using Flask!
I'm trying to figure out how to turn a signal from an adc into audio
Figuring out Pandas :) 
Building a heatmap of the plant I work at to show which depts have the most WorkOrders. Using Flask/Matplotlib/pyodbc/numpy
Hey folks,

I keep working on my pet project - it's a dependency injection microframework for Python - Dependency Injector.

https://github.com/ets-labs/python-dependency-injector

Now I'm working on making optimizations using Cython and plan to finish this week.
Building a data factory that deduplicates and normalizes data from disparate sources (various database/flat files). Performs ETL based on rules stores in a 'rules' schema on the main database dynamically. Automatically audits each step. etc etc.
An Al Gore Rhythm for recognizing ebony porn with black girls fucking white guys. It's the only thing that turns me on
At home - I've just started mapping out a text adventure game. Also will download [Anaconda](https://www.continuum.io/) this week to start exploring that.

At work - Tweaking my text analysis script for a new project.
Trying to find out the future of Python at work. ð¢ 

Other than that, starting more pet projects and experiments than I'll have time to focus the attention to finish - "magic mirror", a calendar system (for shiggles), some blogging software, playing with rich domain stuff (hard to do proper DDD when it's just me, myself and I). Should probably give my money lib some love. 

There's a dateutils-ish lib that could probably use some expansion or just be a PR to that project - relative dates (pass it a thing that makes date/datetime objects and an optional timedelta, e.g. `RelativeDateTime(datetime.now)` and then you can treat it as a datetime but it just produces the current datetime when interacted with) and a daterange object that uses timedelta as a step rather than the weird stuff I've seen other libs do. 
[deleted]
Am working on a script that update users signatures in Google apps using oauth 2.0 and have been having trouble getting it work . Please let me know if there is anyone here who can help. 
I am working on creating some users in [Dell DRAC](https://en.wikipedia.org/wiki/Dell_DRAC) console.
Though this is more of bash shell script work but I find text processing in Python very clean.
Working on learning data science and video game development.

**numpy**

**pandas**

**tkinter**

**pygame**
I'll continue working on my Telegram bot app based off the Telepot framework. It's basically a bot that can help you identify songs, retrieve lyrics and videos of the song. I definitely recommend creating a bot as a fun beginner project to work on :)

You can check it out on Telegram at: https://telegram.me/MusicLyricsVideoBot. 

A simplified version of my source code is at: https://github.com/davidkohcw/MusicLyricsVideoBot-Public

I love reading these threads. I'm a complete noob with a big project swimming in head and a ton of reservations. I love seeing all the ideas and ambitions of people! Keep up all the good work!!!!

RemindMe! 23 hours
Working on my [linux control panel.](https://github.com/CodingForCookies/Prism)


I am developing a vim plugin for django now. Here it is: https://github.com/umutcoskun/vim-mule
Working on a audio downloader with proper ID3 tags, album art scraping, and a GUI. Going to support most sources as I'm already familiar with downloading audio from placing like youtube and coub as I've written individual downloaders in the past.  
  
So far youtube playlist downloading is making progress, I can fetch all the videos in a playlist in its highest quality, convert to mp3, and add its ID3 tags (Artist, title).

Just need to mess with the video titles a bit and see if I can wring a searchable artist and track title out of them to make getting the metadata easier from an external source like MusicBrainz, FreeDB, or Discogs as many uploaders like to do stuff like:  
`Gakusen Toshi Asterisk ED å­¦æ¦é½å¸ã¢ã¹ã¿ãªã¹ã¯ ED - Waiting for the Rain by Maaya Sakamoto Piano Cover FULL`

I can't decide what to use for the UI though. Doing GUIs in python is the one thing I just haven't gotten to as nearly everything I've done so far has been CLI. I want something that will look consistent across platforms and allow me to design my own UI elements. So far Pyglet + Pyglet-gui can allow me to do that but its a pain to work with.

Anyway, sorry for the wall of text \^_^
Python wrapper for a large number of pentesting tools.
Modeling SSD internals with Python\Cython\numpy\scipy
Brainstorming new ideas mostly. I've recently become interested in neural networks and evolution. I want to create a game/simulator of sorts that a person would run on their smart phone. 

The idea is really abstract, but I want it to be something you check up on every once and awhile, and it would somehow "learn" based on outside variables gathered by your phone. Nowadays phones have sensors of all sorts, so it'd be cool to have something "evolve" based on the environment where you spend your time. Kind of like a virtual pet, but it evolves and changes based on your environment. 

I've done very little coding for this project in particular, but I did do some fun tests with neural nets and evolution simulators previously. 
found out the great tutorial https://www.youtube.com/watch?v=c0tw9CPxU-A&list=PLt8AISrPVpEXgm4fYtYY0UXZiVq5ygVS7&index=25 for sound processing. Will be writing some sound processing modules of my own for my podcast flawcode.com
I am working on writing a Cython binding to [libqmlbind](https://github.com/seanchas116/libqmlbind). This would allow people to write cross platform apps in QML and Python! Basically just started, but I will of course post here when I have something usable.

edit: and [here](http://i.imgur.com/P4WIX38.png) is a screenshot of the Qt Lab's Example program running on it.
Well guys I'm out of ideas can anybody recommend or suggest something. 

Thanks
Recently released [Pyvisgraph](https://github.com/TaipanRex/pyvisgraph), now I am going to use it to implement a website with Flask/Google maps API where you can find the shortest path from any point to any point on the ocean. Will use this for work.
Working on my WordPress-like blogging system:

https://github.com/syegulalp/mercury

It's at the point where I'm running a site with it full-time, but not quite ready to be packaged up for other people to use. (I'd eventually like to create a Softaculous installer for it to make it as easy as possible to get up and running.)
I've been working on a chatbot that can teach you stuff about hacking.. Made a prototype..
http://fsecurify.com/fbot-a-chat-bot-that-teaches-hacking-and-security/
Writing code for Sanic, a super fast Python 3 web framework
At work: making a meteorological cms with django

At home: improving a translation server and client to work with django. They can be on separated django projects, or together. The aim is to manage all the project translations with one database, and using the django admin.
Working on a game framework with pygame as the base.

More accurately: getting ready to release a framework that I have been dabbling with for a few months

Edit: pygame*
As GUI Automation enthusiasts we're preparing [pywinauto](https://github.com/pywinauto/pywinauto) 0.6.0 release with initial MS UI Automation support. It's a result of more than one year's work of 4+ contributors. Now working on documentation and last minute clean-ups for usability and consistency.

pywinauto 0.6.0 will support both legacy "win32" backend and "uia" accessibility under the hood. The high level interface will remain almost the same (just aligned with PEP8).
I have some time of this week, so I'm making QT/PyQt css/qrc style sheet automation tool. 
I'm gonna post later this week at my github 
https://github.com/techbliss
A MIME message parser.

Python's standard email package gets some multipart edge cases wrong, doesn't handle bytes very well, is unable to serialize parsed messages back to their original form (it mangles them), and pulls entire messages (including all attachments) into memory at once. All of the third-party parsers I've found have significant flaws as well.

I need a better email parser, so I'm writing my own.
I'm making an async API wrapper for a service I'm not going to mention so no one can make it before me since I'm slow :)
mastering github with code analysis tools :)
Testing happypanda (manga archive library) and Melissa (virtual assistant) 
I'm writing a thingey that maybe one day could replace the tournament software used in MTG, because that's a total trainwreck.  It's been an off-and-on project for years though.
Having fun with Asyncio, I'm trying to write a library to interconnect asynchronous task pipelines.
Trying to automate the updating of my company's directory info using Selenium... No idea why uploading a CSV or excel isn't supported. Upside is I get to use python to solve my first "real" problem. Hopefully.
Still trapped in C++ land because I'm writing a numerical simulation. I escape every so often when I fiddle with the test script for its extension module.

I've never been more thankful for Python's expressive syntax.
A asynchronous web frameworks with a different taste. Not "async flask" or "async django". Something providing a bit of a different paradigm. Getting the HTTP req/res cycle right is actually the easy part, the hard part is actually ironing API so that async is easy to code and debug. 
I've been playing around with the Groupy module for Groupme and just making random bots. For example, [one bot I made](https://github.com/Hermje/Groupme-Bots/blob/master/groupmeBot/memer_of_the_day.py) takes all the messages from the day and tallies up the likes per each member of the chat. At the end of the day, the member who acquired the most likes is known as the "Memer of the day"

I got a little lazy as I was excited to show this off to my friends, and made it so scores are assigned based on a name stored locally and not retrieved from groupme. So if a member makes even the most minute change, it will mess up the bot. So I guess it has a little work left. 

However, I'm super excited I found out about groupme supporting bots, and this specific module. As originally, i wanted to use beautifulsoup and scan through the source somehow???
Machine Learning and BigData :metal:
I fixed an easy issue in AIOHTTP and am building a Django app. 

Anyone have a cookbook recipe for building a selenium functional test to test user login on Django? I am having trouble getting it to work. 
I am working on populating my github with projects i made to get a job. Some simple algorithms inplementations in Python, a few Project Euler solving scripts, two Django+JS apps and i must do something with AngularJS & Django REST.
I'm working on [aiocache](https://github.com/argaen/aiocache). An asynchronous cache for asyncio thats aims to support multiple backends with different serializers and policies :).

Feedback is always welcome! :P
trying to implement the visitor pattern in python. the results i see online i'm not too happy with the implementation.
As usual, I'm just working on BitMon. I've almost got a system for assigning wild encounters to the database, but I'm struggling on how to actually build a battle function. It needs to be something that runs on both the client and the server simultaneously. My other hurdle is going to be assigning these wild encounters different stats based on player level. I'll have to develop some type of standard database of monster stats at certain levels to pull the stats from. It'll take some work, but I'm confident that I can get a complete product together by around this time next year.
Assuming the expressions can be statically evaluated (ie: doesn't depend on run-time state), you could probably use the [ast](https://docs.python.org/3.5/library/ast.html) module to parse the code into an Abstract Syntax Tree, do transformations on the tree to condense the obfuscations into their results, and then spit the code back out as text with the [codegen](https://pypi.python.org/pypi/codegen) module.
You need to have an X11 server running on the Windows side.

Do these two things:

1. Install VcXsrv.  Set it to just run on startup in the background.

2. In your ~/.bashrc file, add the line:

    export DISPLAY=localhost:0.0

Then you should be able to plot.
Try using different backends until you find one that works. If you're getting a QXcbConnnection error it sounds like it's trying to use one of the Qt backends. I don't know if you have Qt even available, but try something less sophisticated first perhaps.
Python support is not as prolific as PHP support for web hosting. You can learn how to set up your own Python web server and then serve up plain old Python scripts.

http://www.devdungeon.com/content/installing-apache-modwsgi-arch-linux
[pythonanywhere.com](https://www.pythonanywhere.com/) offers free hosting and an integrated ide...
Many web hosts that support CGI support Python. With CGI the web server launches your Python script and sends anything written to `stdout` to the client. When the Python script exits that web server process/thread goes away and the server waits for another request. To get data from the client the web server will launch the Python script with a standard set of environment variables. The easiest way to work in a CGI environment is to use the [cgi](https://docs.python.org/2/library/cgi.html) module.
Yes. pythonanywhere comes to mind. If you really, really want the simplest web tool, try bottle. It's single py file you put next to your code and start creating web page.
I see a lot of votes for pythonanywhere, and cloud hosted VPSs. You may also want to look at PaaS (platform as a service) offerings, of which pythonanywhere is a member of. But there are many others, like [OpenShift](https://www.openshift.com/). The essential premise is you just provide code, and the as-a-service kicks in for handling your webserver and machine administration. pythonanywhere is great for python, but more generalized PaaS's like OpenShift can open the doors to running a lot more than just python if and when you get into it (caching layers, etc)
Well what do your scripts do?  Generally if you want them on the web you want an endpoint, so you may as well use Flask.  Once you're using Flask you can use pythonanywhere without even thinking about anything.
I think nearly any cloud platform such as with a linux server will meet your needs. This is because you can ssh into the server and use python just as it were on your computer, only in this case it is running 24/7 in the cloud.

I have used Google Cloud, Amazon Web Services and Digital Ocean. Out of all of them I recommend Digital Ocean for its ease of use, and also because most of its servers come with python 3 installed. Its the main server I'm using for my own python scripts.

 If you sign up through https://m.do.co/c/af4174c070fb, you can get you 10 dollars credit to try out - around 2 months of server time :)


9cloud  is free.
This isn't a homework help forum, but you may be able to find some help on /r/learnpython if you're willing to provide a code example you can't get to work.

More generally, you should check if your professor or TAs offer office hours. They would be better able to help you think through a problem in a way that touches on the topics they want you to learn about.
Change to liberal arts major
I wish there was a language-defined way that you could mark a function as returning a generator, like `async def`, because they act a lot like lists, until they don't. So I don't tend to design APIs with them, in case the user gets burned. 

p.s. hope you're enjoying your Tingbot :)
Your example can actually be simpler:

    (line for line in lines if not line.startswith('#')) 

Which is a generator ~~comprehension~~ expression and works in Python 2 and 3.
The problem with iterators/generators is that they add state into what used to be a purely functional function. Thus making the whole thing a lot harder to understand and reason about. They obviously have some huge advantages when it comes to memory consumption, but I find that I almost always run into issues when I try to use them (e.g. can't use them twice, can't know the length, not obvious if an API returns a list of iterator, etc.).

They might save you a few lines of code, but they require a lot more mental power to get right. Just look at the example, without generator it's clean and easy:

    lines = get_lines(f)

with generators the user has to take special care:

    lines = list(get_lines(f))

It's very easy to type the first when you really needed the second. The worst part is that your code will continue to work just fine for a while, but at some later point you might find out that you have a generator in place where you expected a list and then have to figure out where the hell that came from.

literally was just thinking the other day "i wish there was a prettier way beyond creating faux-lists" to achieve the yield thing - thanks for this!
Correct me if I'm wrong, but the memory usage of both the iterator / non-iterator examples will be the same. The iterator example also won't work with an infinite stream.  This is because you turn the iterator into a list.  

*edit: A more apt example might be to print the lines that don't start with '#' instead of putting them into a list. If you did this then the 'Benefits' section would be correct.
Sequences like the following are horrible to debug if working with iterators:

    data = get_data()
    data = decrypt(data)
    data = decompress(data)
    data = decode(data)

During Debugging, i sometimes use a decorator like

    def degenerate(f):
         def deg(*args, **kwargs):
            l = list(f(*args, **kwargs))
            return iter(l)
         return deg if DEBUG else f

Then all steps happen sequentially and you can look at the stuff with PDB, but you don't accidentally do `len()` on a generator.
Speaking of generators, I little while ago I noticed the fibonacci implementation in the sidebar. I was instantly impressed by its elegance and simplicity. It uses two of Python's strong features (generators and tuple assignment) to showcase the language's expressiveness in very few lines.
You can also make stateful iterators from older functions as well.  Say you have a non-iterator based function that reads a record from a file and returns it and returns None when there are no more. 

    rec = red_rec(file)
    while rec:
        do_work(rec)
        rec = read_rec(file)

or

    for rec in read_rec(file):
        if not rec: break
        do_work(rec)

But you could turn that into a lambda generator that automatically stopped on a particular return value.

    for rec in iter( lambda: read_rec(file), None ):
        do_work(rec)
The title should be "use more generators", not "use more iterators". 
> Here's an example of a pattern commonly seen:


> Now look at the equivalent thing as a generator:

both seem fine to me

is the second one really that faster?
Iterators and generators are great! And even more so if they are not strictly confined to running them inside the same program on the same machine....:

The latest [Pyro4](http://pythonhosted.org/Pyro4) library allows you to loop over remote iterators/generators. What this means is that in your program you can loop over an iterator/generator that is actually running in a server on a different machine, transparantly.
Thank you, this solved a really annoying problem for me. I was trying to pour a text file with 9 million lines to a django mysql database, but I kept running out of memory in my online hosting environment. This solved it nicely.
Well said!
Great! Short and to the point
> Want a set instead of a list?
>
    uniq_lines = set(get_lines(f))

This example is a bit useless, you can do exactly the same with a function returning a list, in fact the author made this very point a couple paragraphs above.

EDIT: I understand that is is less performant, just pointing out the fact that the syntax is identical, so makes for a unhelpful example of ways to "use iterators to make your code nice".
The relevant error message is: zlib is required unless explicitly disabled using

So you need to have zlib in you environment. 

I always found installing stuff with pip on Windows to be very frustrating and I would suggest to use something like anaconda since these package managers take care of such dependencies.
It is a Monty Python reference. https://www.youtube.com/watch?v=anwy2MPT5RE

Monty Python references are heavily encouraged in Python documentation :)
I always hated all placeholders.  It's worth coming up with a real situation when writing examples, so the reader has something real to grow their knowledge from.

Saying that `foo.bar()` produces a `qux` is all very well and good, but the reader basically has to trust that this is a useful thing that they want to happen.
Metasyntactic variables
Nice article, Michael!
The differences are minor, and for a beginner not so important. I have a bunch of code that works in both, with no changes. The takeaway: sign up and enjoy learning Python!
I can also recomment Udacity, there is a nice Intro to Computer Science course there that also teaches Python, check it out!
> Username: GovSchwarzenegger

>Green 40.25%

>Conservative 25.48%

 >Liberal 18.22%

 >Libertarian 16.05%


Sorry for title gore. This is my first python module, so if anyone has feedback (+ or -) I would love to hear it. 
This is awesome.
Holy hell h2non, from the looks of your github, you are one of the most productive and multi-talented human beings on the planet.

Also, this looks like a fantastic library!
It's actually more of a `dictdiff` :-)
What about loading them into dicts and then comparing the dicts. 
If your JSON is a dictionary, you could use [this code](http://stackoverflow.com/questions/1165352/calculate-difference-in-keys-contained-in-two-python-dictionaries) on StackOverflow.

It won't deal with nested data structures or lists (though lists are trivially simple to diff), but it will show what's missing/added from dictionaries. Deeper than that, it's going to get complicated.
How is this different from https://pypi.python.org/pypi/dictdiffer ?
Can I get the macbook prize with Debian already installed?
Did you mean to post this to /r/scala? 
+1, I guess people missed the joke.
it's unpacking an array-like object (list, tuple, set) into individual variables. `a, b, c = [1,2,3]` also works
`val,` is a tuple of one element.  If you put a tuple of names on the left hand side of an assignment statement, you activate tuple unpacking.  The right hand side is treated as an iterable, and unpacked into the names on the left hand side.  The RHS in your case is an iterable of length one, and the LHS is a tuple of one name, so everything works out as expected.

It is hard to see that comma in `val, = li` . I prefer `[val] = li` because it catches the eye. It's a useful little trick because in cases where you expect a list containing only one element, `li[0]` will work even if the list has more than one element, while `[val] = li` will raise an exception, giving some extra error-checking for free.
The punch line I was expecting when I started to read this was 

    li[-1]
I could see a use for it with regards to a simple script that I have released. The script scans a text file for info, and then uses that info to scrape a website and download some stuff. At the moment if someone wants to use my script, they need to install python and the required modules (only requests), and then launch the script on a CLI. A small stand-alone exe would be ideal.

I'm sure the alternatives you mention can do the same, but I only had the briefest look into them and it seemed too hard. If you go ahead with this, please make it is extremely simple to use. I imagine it should be possible to point such a tool at my virtualenv and custom packages/scripts, then give it a start/entry point, and then click create.
I don't see the big benefit (other than in the heavily constrained environments that ÂµPy already seems to be tailored for) in reducing binary size while sacrificing compatibility, security, resilience and speed.

If in general Python binaries were several GB in size or required large VMs (e.g. like Java), there might be a better argument; 1 single order of magnitude (500 kB vs. 5 MB) with several limitations on top does not really sound like a great deal to me.

If you personally need this, I'm all for it and good luck, however I personally can't really imagine a large need for this on desktop platforms.
The ability to distribute small(<1MB) fast standalone executables for basic python scripts would be amazing even with some limitations. My main use case would be distributing cli programs. Seems like there could be [plenty of functionality](https://github.com/micropython/micropython-lib) coming with MicroPython.


PyInstaller works for a single file but the executables are large(5-6MB) and very slow to start. I can live with the size but the startup speed can be problematic.


So far the best I've found is Nuitka + UPX packing the executable. That gets the file size around 3MB while still being very fast. 


Yeah, why not?
I'm in the scientific research field and use pyinstaller to distribute a PyQt4 GUI that uses numpy, matplotlib, gdal, and pyopengl. So no.
I would be interested, but only if one of the things addressed was adding C extension support. That right there would open up a lot of possibilities.
I don't think MicroPython supports filesystem access? Without that, and without C extensions, you're restricted to pretty niche applications on the desktop.

5 MB is not that much in today's environment. Smaller is always nicer, and there are situations where every byte counts, but games and movie downloads can easily be multiple GB.
/r/learnpython 

python3 / BS4:
    
    from bs4 import BeautifulSoup 
    s = BeautifulSoup(YOUR_HTML_DOCUMENTE_HERE)
    # s = BeautifulSoup(YOUR_HTML_DOCUMENTE_HERE, 'lxml')
    all_divs = s.find_all(id="containers")
    for div in all_divs:
        print(div.string)

For for all intents and purposes that's malformed html. You mustn't have more than 1 element with the same id - I'm using lxml as the parser, not sure if others won't bail on you.
Great post. I love the color rotation animation!
Wow! That's a Saver!
That dog is such a wicked example image haha
Go to /r/learnpython and check out the sidebar
Try building a website for your club together! Treat it like a business project.

* Discuss a design
* Choose your framework (flask, django, bottle, etc)
* Split into work units
* Create a github account for your collaboration
* Write it together!

If jumping into this is a bit too challenging to do at first, pick one of the numerous resources in the sidebar and go through it together. I learned from Learn Python the Hard Way, but it really helped to have a project to dive into, which is why I suggest something that your club will find useful. Hacker Rank is also a good start for a long list of small projects.
Great work.  Psutil is almost too useful.
For Django, I really recommend going through [official tutorial]( https://docs.djangoproject.com/en/1.10/intro/tutorial01/)

Also the book [2 Scoops of Django](https://www.twoscoopspress.com/products/two-scoops-of-django-1-8) was really helpful for me.

For Flask, I recommend [Miguel Grinberg's mega-tutorial](https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world)
If you're new to web development and django, I would absolutely not recommend STARTING with the official tutorial. I would go through [Tango with Django](http://www.tangowithdjango.com/) first. It assumes that you know less and really helped me early on when I was confused by the official tutorials.

Of course, if you're an experienced programmer/developer go straight to the official site.
Disclaimer: Iâve done work for Real Python

[Real Python](https://realpython.com/) has three really well written books on Python fullstack development. $60 bucks, solid deal. I am working my way through book 2, building a Flask application with SQL and server side templating. These are well put together thoughtful exercises and explanations. Book one is python fundamentals and works through some libraries (that one is a foundation for adding more web dev that comes in book 2). Book three covers Django and Angular among other frameworks concepts. Highly recommended.
TDD with Python by Harry Percival. Also, even though it's really out of date, the Django Book (online) really helped me get the basic concepts of Django. 
You can take a look at http://www.fullstackpython.com/
It's pretty good as a source of reference but might also be excelent for a beginner.
are you planing on doing some frontend too?. I recommend for that the free code camp courses.
[Lightweight Django](http://shop.oreilly.com/product/0636920032502.do)
Udacity Web Development is by far the best course I've taken. It's free.

https://www.udacity.com/course/web-development--cs253
All great resources. /r/learnpython...
I just recorded a video that shows how to setup Nginx and uwsgi to serve Django projects on CentOS minimal. I haven't posted it to YouTube yet, but am planning to. It will be my first video and I am aware the quality isn't what you would get from Lynda, I do run into errors and figure them out "live"(I am not editing them out you will see me troubleshoot through them). I will let you know when it is up if you are interested. I plan on posting it sometime later this week.
Well over the weekend Github was affected by the DynDNS DDoS attack so it may be related to that, otherwise I think we'll need more details.
What is the result when you run the unit tests?
Any chance you could give this poor guy the course for free? Will complete the course in a month or 15days.(college student) 
Does OpenCV play nice with Python 3 yet?
Just wanna talk the few people who purchased this course! 

If you have any issues please contact me on Udemy or right here on reddit. C
Depends on what you want to do, really. It's relatively easy to program a basic neural network and train it on something like character recognition or a simple game. It's a fun project and IMO quite good to learn the language or programming in general.

That said, for "large scale" simulations you might be better of using existing libaries like pybrain or something, skipping most of the programming side of things.

In the end, your biggest challenge will not be the implementation of a neutal network in general, but decisions like choosing the right network topology, training method, number of nodes, and inputs/outputs.

This will require some reading, but it's fun and ultimately very rewarding. Good luck!
Neat! I don't end up reading a lot of python functions in vim. 

I'm curious if the settings.py finder is slow on your projects. I haven't installed this yet. Some other ideas are searching for `manage.py` first, trying `DJANGO_SETTINGS_MODULE`, maybe using `scandir` instead of `listdir` since you'll grab the `is_dir` information in the same call, or storing it in a local variable (can `b:` be used like that?)

    last_searched = None
    for node in os.scandir(directory):
        if node.is_dir() and node.name not in ignored and node.name != last_searched:
            settings = os.path.join(node.path, 'settings.py')
            if os.path.isfile(settings):
                vim.command('edit {}'.format(settings))
                found = True
                break
       last_searched = node.name

might work for the scandir idea. I'll give it a run tomorrow.
Now I added manage.py support with tab completion. You can run manage.py commands anywhere in the project.
Now I wrote all the plugin with VimScript again and used findfile function to find manage.py. The plugin is faster a bit now.
Now I added virtual environment support for manage.py (:DjangoManage) commands. Also added quick jump commands, between apps/files.
Maybe it should have some facility for branches, tags and such?
I personally install latest python, then as the relevant user, `--user` install pip via get-pip.py, and then user install all packages after that
Modern releases of Python on any platform come with the ensurepip module. (I believe this is true for Ubuntu 15.10+). I generally do `python -m ensurepip`, (may need sudo) which installs pip, then you can install packages via pip. If ensurepip doesnt exist, I try `easy_install pip`, and if that doesn't work, I use get-pip.py.
I would suggest Anaconda just because of the distro hopping.
Use Conda ... it will save you a lot of headache. Especially with scientific packages like numpy, scipy, etc. Just go through the Conda Test Drive tutorial, its super easy to get started with, and has a much better user experience than virtualenv and pip.
I didn't have a chance to read through all of the link you posted, but I was able to find a few things that might help in debugging this.

The same issue pops up with Qt on windows in several places. They all link to this [bug report](https://bugreports.qt.io/browse/QTBUG-50191) and fix. I might not start with building a patch, but at least it should get you headed int eh right direction. I also saw that a few people complained about the same thing in the [microsoft forums](https://social.msdn.microsoft.com/Forums/vstudio/en-US/86bc577b-528c-469c-a506-15383a44c111/missing-corecrth-from-the-default-include-folder-for-vs215?forum=vcgeneral_).

Another thing you might look into is third party conda packages. That article is a year old, there is a chance that by now someone else has compiled a different version that doesn't have this issue.

Hopefully that was helpful. If not, like I said in my other comment, you'll probably get a lot more help at /r/learnpython.
You'll get a lot more help at /r/learnpython, especially if you format your code correctly (4 spaces. Example in the sidebar.). 
Could always normalize the string before searching.

    >>> s = "SpaM HAM eG Gs"
    >>> s.lower().replace(" ", "")
    'spamhameggs'
    >>> "eggs" in s.lower().replace(" ", "")
    True
    if needle.lower() in haystack.lower().replace(' ', '')
fuzzywuzzy or at least read about how they did it.
I agree the string version is better, this is a way to do it using regex, in the case your requirement is not  only spaces, but any whitespace:

`#` comment lines showing output of the previous expression:

    import re
    needle = "eggs"
    haystack = "SpaM HAM eG Gs"
    pattern = "\s*".join(needle)
    pattern
    # 'e\\s*g\\s*g\\s*s'
    re.search(pattern, haystack, re.IGNORECASE)
    # <_sre.SRE_Match object; span=(9, 14), match='eG Gs'>

The reasoning is that we're iterating over the string "eggs" and putting `\s*` (zero or more whitespace) in between.

You can make it a function to play around with different regex wrapping (only spaces, character "-" or whatever):

    def find_needle_in_haystack(needle, haystack, wrapper="\s*", ignore_case=True):
        return re.search(wrapper.join(needle), haystack, re.IGNORECASE * ignore_case)

    # OP example
    find_needle_in_haystack("eggs", "SpaM HAM eG Gs")

    # between each letter there has to be a single "-"
    find_needle_in_haystack("eggs", "SpaM HAM e-G-G-s", wrapper="-")

    # only whitespaces, case sensitive
    find_needle_in_haystack("eggs", "SpaM HAM eg gs", wrapper=" *", ignore_case=False)

But this might be overdoing it a bit....
heh, what difference does it make if its homework. :)  
There might be something here to help you get started.
http://zulko.github.io/blog/2014/03/29/soundstretching-and-pitch-shifting-in-python/
We need more info to help.

Is the network WPA2 ? If so, you can no longer send unauthenticated deauth packets to an access point due to 802.11w.

Secondly, if your router is new, the two channels probably represent wireless AC. One operating on 2.4ghz and the other on 5ghz.
Sure, but [flake8](http://flake8.pycqa.org/en/latest/) is better. Just install it and run it against your script from the command line. Better yet, get an editor that supports plugins for Python linting and see linter errors as you are writing the code.
Parse it with a datetime pattern (strptime), then format the datetime object with with a different pattern (strftime). Easy peasy. (After you consult the table for the magic pattern strings).
What is a non-military time?
I use ``dateutil`` at work. It's a good way if you're going to be dealing with various time formats and you don't want to explicitly state the string format every time.
I'm using a Community Edition for about a year and very happy with it so far. At first I was disappointed with performance (like with any other JetBrains IDE), but SSD solved the problem.
[deleted]
What does it have over PTVS or VS15?
One reason of not using it .... It's slow and memory hog
That SQL preview looks really cool, I'll need to look into that
This is probably a paid ad, so skepticism is prudent.
I use pycharm, the windows version makes installing most packages easy on that OS.  It's also easy to use different versions of Python.  Then I have a third install separate from the IDE for Panda3d which I never got working with Pycharm.
I recently switched from Notepad++ (I know, the dark ages) to VS Code, it has most of the features in the article and totally free.
With vim I have all that AND a text editor. 
The only reason I know of to use it over WingIDE is it has error checking in realtime.  Interestingly, so does Eclipse.  WingIDE has a debugger that is 100x better than PyCharm and Eclipse's is unusable as far as I'm concerned.

Code completion is standard in every Python IDE.  

Type hinting would be nice in WingIDE, but I mainly use Python 2.7; stubs would be fine, but there is terrible documentation on those.  

SQL would be nice if I cared about that.  

The git thing is neat, but I'm on the commit early commit often mindset.  I know-ish what changed.  I'd rather have a quick git blame.  That would be useful.

Code coverage, having a package manager, and refactoring is also standard.
I really dislike the subscription model for dev tools. I've paid for sublime as my default text editor but I'm not prepared to pay hundreds/thousands of pounds during my career for any one ide. So pycharm CE only for me.
Can anybody elaborate on how pycharm code completion is better than Sublime Text + Anaconda, or any other editor + auto-completion plugin.
Pycharm is like.... A Bacon that does good to your health. 

Once you go pycharm professional you never go back. 
The only reason I need not to use it. It isn't `open source`.
I use PyCharm, CLion, and IntelliJ. I frickin' love JetBrains.
I prefer Emacs.
I don't see a killer argument here; these things also work in most text editors via plugins as well. Sure, it saves you the setup time, on the other hand, it saves you from learning yet another tool IDE/editor. 

"9 reasons you ~~should be using~~ [may want to look into] PyCharm"
I really like Pycharm but I wish it was a little more pretty looking. Their logo is very neat but the GUI is not as sexy as Sublime or Atom. 
Pycharm is made of rainbows and unicorns. 
This seems like a good list of reasons to use a decent IDE, and PyCharm is a decent IDE but hardly the only one.  I've been through several over the last decade before finally settling on Eclipse+PyDev, which I believe is capable of all 9 of these items while being free and open source.  I'm not positive about a couple items but don't need those to be part of my IDE.

Are there other killer features PyCharm has that Eclipse+PyDev does not?  I give PyCharm a try every couple of years but am so accustomed to Eclipse that I don't have enough motivation to adjust even if my employer would foot the bill for the license.  So I'm genuinely curious if anybody else has made that switch for a feature I'm not even aware of.

(If I were just switch from a text editor to an IDE today, I'd probably go with PyCharm or Wing.  Both have much better UX; Eclipse is extremely powerful but has the UX typical of most FOSS projects...)
I'm all but convinced
PyCharm + emacs key bindings (available in PyCharm) == A+
I am a fan but not a big fan of PyCharms. I use it for bigger projects now and then, but honestly, I find that it is a bit cluttered and also relatively slow performance-wise. To edit/write a quick script, it's really not worth the effort, but I appreciate it sometimes depending on the task -- I use it about 10% of my coding time (about 70% of the time I use Atom, and 20% of the time I use VIM).
Has anyone used it that's also familiar with Wing IDE? I'm curious how it compares.
Been using it for awhile now in the student professional license. It's great!!
Ran out of header integers after #1?
Vscode (open source editor by Microsoft) has intellisense that works like the one in PyCharm. I think it can make a decent development platform with some plugins. I still use PyCharm when working on Python projects.
How do I set up the git visualization?  That looks amazing. 
How do you get the code coverage thing working. 
I like pycharm, having built in git support is great. However I've yet to see an IDE display docs as well as Spyder can. With pycharm I'll usually just pull up a local rendered version of numpy docs. Spyder is able to use Sphinx and get nice readable docs with just a ctrl+i
Had been using Python Tools for Visual Studio with Visual Studio Community Edition for a while and started using PyCharm recently to re-teach myself Python on and it's been amazing.
Been using Pycharm for almost all of my Python based projects. It works ridiculously well. It even works pretty well with Javascript.
Jetbrains develop 2 products: r# and pycharm.
and pycharm doesnt have too much interesting r# features.

And it so sad.
Eh, I can get +95% of those features on emacs/spacemacs and it doesn't kill the performance on my laptop, it has far better customizability and it works with ALL the languages and use cases I could imagine.
Meh, I'll stick with PyDev.  It's free.
But...its not free... :(
This sounds too much like an advertisement. There are plugins to assist you with Python most likely already available for your editor of choice, they are free, no learning curve, and they are guaranteed to not go out of business a few years down the road. 
mhm... interesting... Does it have CTRL-D ? No?

Ok, moving on.
There are always free resources online he can check out. 

If he is really struggling, he should post some notices at his nearest university asking for a tutor. I was paid about 40/hr for helping some students with python.
Codecademy has an interactive web course for learning Python that was helpful for me learning Python, given I had prior programming experience though. He might find that helpful!

I believe their content is still free but they may have some quizzes or exams or programming assignments behind a paywall, not quite sure. If they do, don't sweat them - the free instructional problems were very helpful for me in learning Python!

You can check it out here https://www.codecademy.com

Edit: also, /r/learnpython might have some more links and pointers for you and your friend to look at
Sure I'll help out.  Add "asday_" on Skype, (listed as living in Al-Samiyah, Syria), and we can discuss scheduling.
I feel like I'd need to see the code, but asyncio does support locks (same names as threading primitives), so you could say create an event (that's a type of lock), and have write wait on it, then have open_connection trigger the event (by setting it to True).

Edit: It might actually be easier to use a asyncio.Future, since only one thing waits on it.
Just call writer before open_connection:

    import asyncio
    loop = asyncio.get_event_loop()

    async def client():
        reader, writer = await asyncio.open_connection('localhost', 25000)
        writer.write(b'data\n')
        response = await reader.readline()
        print(response)

    loop.run_until_complete(client())


The event loop "lock" the client coroutine until open_connection completes.

Inside a coroutine, everything is executed in the order that was defined.
call and (a)wait open_connection() before you call write()?
How does it relate to dogpile.cache ? https://dogpilecache.readthedocs.io/en/latest/
[moviepy](http://zulko.github.io/moviepy/) might be useful to you.
I tried this once a little while back. I wrote a script that increases video brightness. I used opencv and pil for the image capturing and editing, stored each modified frame as a png and used ffmpeg to stitch the png frames back together as a new file.

I have no idea if this is the best way to do this. It probably isn't. [Here's my script anyway](https://github.com/joshnewlan/cool-scripts/blob/master/brighter.py). Maybe it will point you in the right direction.
Try also SimpleCV. You may not have a way around digging into NumPy. With DSP you'll always have a latency... Pure Python will not be quick enough for 25fps 1280x720 ... Maybe 640x480? Anyway, you'll want to start using something that uses less clock cycles per calculation and that's stuff like these libraries. 

Another tip is to not stay too fixed on the idea of "live". For instance, in Apple's HTTP stream spec, it is just a text file list of MPEG files swapped in as playback proceeds.   So, if you can at least make a new file on disk or in memory faster than the 1x playback speed, then that is for lack of a better definition live. 
Opencv is the way to go. Check this for example:

http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_gui/py_video_display/py_video_display.html

(first google result for "opencv python camera")
Looks good. Are you looking for any contributors? I'd love to do the closest-match string searching part.
Hey, if you want to couple that with a book searching lib (to search from keywords or isbn): https://gitlab.com/vindarel/bookshops (there's also pyisbn). Just pointing at it :] (I'm the author)
You may get more help at /r/learnpython. 
Do people here even read the article? This is not about argument parsing, but rather packing the cli into a native app.
[deleted]
Author here... When trying to wrestle through the many options I was extremely surprised that a straightforward (and modern) approach to CLI development wasn't readily available.

Having previously done most of my CLI development with node.js, I'm finding that the 99% solution for CLI apps is Python. I couldn't seem to find a great "top find" article on this, so I wrote my own when I worked through the process.

I hope you enjoy, and thoughts/suggestions/advice are much welcome!
okay so, a big problem is the "recycling" you got going there, which isn't the best way of doing what you want

    python setup.py develop

will symlink your package into site-packages, so you won't need to constantly delete/reinstall it
A great library that I use for writing CLI apps in Python is [plac](https://github.com/micheles/plac/blob/master/README.rst). It's an argument parser built on `argparse` but a couple hundred times simpler. It's almost so simple it makes my head hurt.
This is excellent. I finally converted one of my company's core python scripts to a CLI program.

Thanks!
Good stuff here I like it
Question to the author:

What's the difference between defining an entry point in the setup file and putting a static file in the bin/ directory and listing it under installed scripts in the setup file? I've always done the latter for my CLI apps, have I been doing it incorrectly?
For the love of God, *please* stop writing CLI packages for Python. We don't need any more. If argparse, docopt, click, argh, or any of the dozen other options out there don't work for you, then the problem in your code isn't a missing library, it's your approach to the problem. 
Nice.
I'd suggest doing the getattr before the try, so that failure (called closing on something without a close method?) prevents the with body from running. 
Why strings and not function references? `seek0ing = blanking(file.seek, 0)` is just as readable, and somewhat stronger typed.
Why the fuck are you hammering public websites with thousands of high-speed requests? Bullshit like this is why scraping has a bad name.

Instead show us how to do this properly. For starters try not to rapid-fire requests in as short time as possible. Also I see nothing about optimising using cache headers (etag, expires), HEAD requests, update feeds etc.
Is "diggernaut" something I can download and actually use without running proprietary software or relying on your cloud infrastructure?

I know the answer to this question. I'm hoping it will point out the fact this comparison is utterly useless and only exists to serve your own purposes.


>Is python development in windows environment bearable?

Sure, with anaconda python development on windows is just fine.

But why not linux?  If your primary requirement is python development, then why go for second or third best?
I like my macbook quite a bit, mostly because it's so easy to take with me, the SSD/camera/microphone/sound always just work, and etc. I'm considering using a hackintosh next with ubuntu or arch.

Sort of related, is anyone actually using the new Bash that's included in Windows 10 for real development work? Is it usable?
I use windows on my laptop (surface book) and linux on my desktop. Developing on windows has been fine and I got emacs + tons of utilities all working. Hasn't always been straightforward though, linux is a much smoother experience. You are unlikely to run into issues you can't get past with windows unless you are doing something specialized (some emacs packages aren't ported, compiling some scientific computing packages beyond conda is hard, deploying...)

People hate on windows too much, you can get very far with it.
For python stick with Linux. No need to switch to OSX for *that* reason. 

I use Macs for OSX, not for their hardware. If you don't like or need OSX you don't need a Mac. Python development on Windows is perfectly fine, and you'll get the benefit of a cheaper system with far more configuration options and accessories (docks, detachable batteries, detachable tablets, etc). My personal laptops are nearly always Thinkpad X's with Linux on them and the only reason I use OSX for work is for tooling that we've designed specifically for OSX.

It's all about what you prefer and are most comfortable using.

With that said, not sure where you're at in your career but there are a huge number of development groups that only build developer tools for OSX/*nix, and some that only build tooling for Windows. That might be something to consider if you're job hunting. I've worked at plenty of places where if you didn't use the OS that most/all of the other developers used you'd likely not be hired as onboarding you and keeping you as productive with all the latest and greatest internally made systems/tools could be a huge task when that 1 person starts with OtherOS. 

Example; if I hired a person who developed on Windows today I'd have to dedicate at least a week getting our staging/testing (Kubernetes/Docker) instruments to work on his system. I'm not bashing Windows at all. I just don't have any tools for it to mesh into our current development workflow. If it's a dev shop where you just pull from a repo and write code it's a different story.

Just food for thought.
I've had a Mac for work for the last 8 years. Next laptop I've told myself I'll switch to linux. As someone who was educated on developing on linux, I can't imagine switching to Windows as my main dev machine. Writing quick single purpose scripts on linux just feels right, on Windows it feels like a chore and a hack and I imagine I would have a tough time (maybe that's my fault and not the OS).
You _should_ be developing on a machine that is as close as possible to production.  Of course, given that Apple stopped producing Xserves five years ago, I'm pretty sure OS X isn't anybody's production OS anymore.

So that's why Vagrant and Docker/VirtualBox have become fairly standard, and once those are an option the host OS doesn't really matter.  You can run Vagrant and whichever virtualization layer and an IDE on Windows, so good enough, right?

But if you really feel the need to develop on "bare metal" it's generally a bit easier to get OS X to run all of the things a production machine (probably Linux) would run; databases, caches, webservers, etc.  You can probably run all of these on Windows, too (and see Cygwin for help with that, plus a bash shell), but all of the docs are going to be for Linux and maybe OS X.  

And if you do go "bare metal" on Windows, there are some small benefits; you'll find all of the lazy assumptions your fellow developers have made about OS that result in less portable code than you'd want, from things like writing to '/tmp' instead of using tempfile, to hardcoding paths instead of using os.path.join(), to even assuming the filesystem is case-sensitive.  If your target production environment is actually multiple platforms, this is a huge benefit.
I made a full switch back to PC/Windows laptops because the Macbooks price tag kept going up for the spec I wanted.  Just recently picked up an HP Spectre x360, i7, 500GB SD, 8GB RAM, and ample USB ports.  with 2 years support was still about $500 cheaper than the Macbook Pro with close to equivalent.  Add the convertible tablet mode and I am much happier with this.  I just run the regular IDLE on it for now but if you want to go nuts you can grab Visual Studio Community which also supports Python.  It should also run any other windows supported IDE for it.  Oh and you can turn on Dev mode and install the Ubuntu shell so there is your linux Python environment.  

For all stuff Maker I use a fully loaded Probook 430, much lower price point but you can swap our RAM and HDD so great for a lab system.  Max RAM is 16GB on it I believe.  But this model is almost 2 years old so you can probably get something better for roughly the same price.
I used Python on Windows before a Mac and found it worked fine. Windows is a first class citizen in the Python world (unlike Ruby) although I did experience some issues with third party libraries as a lot of Pythonistas will develop on POSIX and not care about Windows which can be a problem.
I've been doing professional python development on Linux Mint for years and I ran Ubuntu before that and Fedora before that. 10 years of mostly Python on Linux development. On a laptop. With a docking station. If you can find one with good Linux compatibility it's pretty sweet. I like Dell's that have the Intel graphics; I've never had good luck using nvidia or ati devices with a docking station, which I can't live without.

I run windows in a VM when pressed.
Choose the platform that you will be most productive on. At the end of the day, Python will work on any major OS.

I love my MacBook personally, but Linux is great as well, and even the Windows experience has greatly improved IMO.
IronPython comes to mind, but I have never used it and I have no idea how it works.
You might get more help at /r/learnpython. 
A quick look... 

    msg ** e 

I don't believe will work.  You'd need to convert each letter in the string to ascii first (?) then do the pow()

Also, the input fields are text, so they need to be converted to int before doing math with them e.g. 

    int(p.get())
Can you edit that to indent the block of code by an additional 4 spaces? This will fix the formatting issue, and greatly improve your chances of getting help.
Finally it worked! https://github.com/patidarayush11/RSA-Calculator
You should always post the error with full stack trace when asking for help. 
> I hope to get a good data analysis or other related job

You're probably going to be coding for a living then.
You're going to get a pretty biased response in /r/python.

If I were you I'd concentrate on learning SQL as it'll likely come up in your day to day job at some point.
You need SQL and Excel for such a job but Python would be an excellent choice to be much more productive than without. 

Could also look at R or something. 
Don't know how this would be helpful, but for me great resource was David Beazley talks on youtube. 

As for books, http://shop.oreilly.com/product/0636920032519.do (Fluent Python) gave some great intro
The core of [Home Assistant](https://home-assistant.io/) is based on async. As we're still in the process of migrating, most components are still using the old threaded API (which now hooks into asyncio).

[Core source](https://github.com/home-assistant/home-assistant/blob/dev/homeassistant/core.py)

[Home Assistant Async Docs](https://home-assistant.io/developers/asyncio/)
It's a long read but maybe worth it because its co-authored by the BDFL, and you can get the code on github. I guess one advantage is that it's intended to be an example.

[http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html](http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html)


You could also look at [tornado](http://www.tornadoweb.org/en/stable/). I find it a little more accessible than the docs for the new stuff in the standard library.
There's many frameworks you can learn. Pick one to know well and be familiar with the rest.

**asyncio**

* http://www.blog.pythonlibrary.org/2016/07/26/python-3-an-intro-to-asyncio/


**Twisted**

* https://twistedmatrix.com/documents/current/core/howto/index.html
* https://doc.scrapy.org/en/latest/


**Tornado**

* http://www.tornadoweb.org/en/stable/index.html


**Gevent**

* https://www.youtube.com/watch?v=GunMToxbE0E
[deleted]
It looks like you're using slanted quotes rather than upright. Compare the quote in the line throwing the error to the ones a few lines down. Hopefully that helps! 
Very cool.  I know einsum is useful, but it could use better examples.  So my suggestion, show examples.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/scipy] [A parallel einsum (x-post from \/r\/Python)](https://np.reddit.com/r/scipy/comments/58pab5/a_parallel_einsum_xpost_from_rpython/)

[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*

[](#bot)
Looks handy!

I would encourage you to look into integrating this into numpy proper. We recently merged some significant improvements to einsum that will make it into the 1.12 release. Your work has a similar flavor: https://github.com/numpy/numpy/pull/5488
You only need to create one instance of your class - `RUN = C()`.

What is happening is that you are creating a new, blank object each time, so when you run the "a" branch, then the "b" branch, the value you put into RUN is "gone". 

Put the `RUN = C()` bit above the `if`, and remove both of the other ones. You can then refer to your object as many times as you like.

Hope that helps.
PyCharm is popular, full-featured, actively developed, and the community edition is free.

https://www.jetbrains.com/pycharm/
There's a difference between the question of which IDE is best, and which IDE is best if you already know some other IDE. 

If you are already familiar with Visual Studio, look into [Python Tools for Visual Studio \(PTVS\)](https://microsoft.github.io/PTVS/). 

I personally use Pycharm Pro over it because I am more familiar with it, though for some projects that are mostly c/c++ with some python, I will use VS+PTVS.
PyCharm always and forever^*

^^^^^*Until ^^^^^something ^^^^^better ^^^^^comes ^^^^^along.
The best IDE is the one you're most productive in. Doesn't matter if that's edlin on MSDOS 3. Very popular ones are Pycharm (my personal go-to, and I pay for the Professional version, Community is great too), VIM with some python plugins to give you IDE-like things (what I use if I'm not on my own laptop), Sublime Text with something like the Anaconda plugin (what I used before Pycharm), and PyDev. There are quite a few others.

Visual Studio Code + the Python plugin are really nice, as is Atom + Python plugin.

Really, it's whatever floats your boat. Find the one you're comfortable in and gives you the things you need. There's no "right" IDE.
Depends on what features you're after.

Pycharm is great if you want the kitchen sink approach. Everything built in. Git support, debugging, almost auto-evrrything, etc. You need a decent processor and RAM though.

My older laptop didn't cope with pycharm too well so I went with Liclipse. It's a great little eclipse based editor with great default settings and add-ons which "just work". I know eclipse gets a lot of flack for being "slow" but in my case it worked much better on a slower computer than pycharm. Did almost everything I needed from pycharm anyway (I personally don't like git integrated into the IDE)

Sublime Text also works very nicely with almost every language I've thrown at it. Mind you it's a text editor with syntax highlighing rather than an IDE. you can install plugins for it but great for quick edits and navigating code. You lose out on a bit of the automated stuff which comes with an IDE and virtualenv awareness.

A few people at work use Atom but I haven't used it enough to give it a fair comparison.
I'm primarily using vim with Jedi. But whatever floats your boat! 
Can't go wrong with pycharm.
PyCharm Community Edition - totally free. 

You can thank me later when your productivity goes through the roof. 
I went on a Python IDE hunt last night myself, ended up with Pycharm (The full version is free if you are a student) and so far it looks pretty amazing.
Sublime text with anaconda plus other useful plugins is an excellent lightweight option!

[interesting document on how to turn sublime text into a python ide](https://realpython.com/blog/python/setting-up-sublime-text-3-for-full-stack-python-development/) 


If you are used to Visual Studio, consider checking out the official [Python plugin](https://www.visualstudio.com/vs/python/) for it. It's open source and has a lot of the Visual Studio features you are probably already familiar with. 
Ya know there's a python extension to Visual studio that works perfectly. 
Not an IDE, but I love Atom with some extra plugins - in particular autocomplete-python (helps you finish code as you type), linter-pep8 (helps to clean code and correct things) and script (run scripts from Atom, like an IDE).
A lot of people may disagree with me, but I'm in the school of thought that using a text editor rather than a full IDE is preferable. Why you may ask?in my opinion, it forces you to understand the code and file structure of a project because of the absence of features that IDEs have, and when something goes wrong, you're more likely to be familiar with all the interactions and find the bug quickly (again, this is just _my opinion_). Once you encounter the things that you do frequently and fully understand, you'll likely find a plugin or macro that will help you be more efficient with it, and can build up your skillset using it to your own requirements, rather than trying to learn "the way" of whatever IDE you may use. Best of all, you'll learn to use the standalone tools you work with so its a lot easier to modify your workflow and add or remove tooling as needed (again, just my opinion). It's like comparing a framework to a bunch of small libraries. You can go either way, the trade-off is usually just long term vs short term efficiency and upgrade/maintainability. 

Sublime text is the best/lowest mental cost choice , or if you want to make a great investment with regards to long-term efficiency, vim. Or Emacs if you're weird and into that kind of thing. 

If you don't wanna go that route, pycharm is probably the one but I'm not a python dev so don't listen to me. 
I personally like WingIDE the best. I think its debugging ability beats PyCharm. However I use PyCharm at work as that's what it provided. I like that PyCharm has a lot of static analysis running all the time to help you see what imports aren't in use. it highlights function names that don't exist and it has a decent PEP8 tool. 

But if I need to debug code, Wing still makes it much easier.
Atom

I used to use the pycharm enterprise (or whatever the paid version is called), and I found atom to have more features, a rich plugin API, and easier to use than pycharm.
PyCharm introduced me to idea, now I use it for everything; web, java, sql, etc. 
I'm partial to [Spyder](https://github.com/spyder-ide/spyder). They just released a major update too.

I've been meaning to look into PTVS because I'm also doing a lot of C#, but haven't gone in-depth yet.
Linux Command-line + vim.

Available "everywhere" that matters.
Kdevelop has first class Python support and is now available on Windows if that matters.
I use Pyzo and I'm quite happy with it. It uses a 'Matlab-like' approach, as Spyder does, but it gives me less problems as I often switch between Python versions. It's designed for scientific development but I found no drawback using it for general programming. Also, they often refer to conda, but it's not mandatory; you can install it from pip.
Neovim with a lot of plugins!

* **File navigating**
 * ctrlp.vim 
 * nerdtree
* **Auto completion**
 * neomake
 * deoplete.vim
 * deoplete-jedi
* **Better syntax highlighting**
 * vim-python-combined
* **Handy tools**
 * vim-airline
 * vim-airline-themes
 * vim-fugitive

These are not all the plugins I use, but these are the ones for Python development. I was considering maybe using utlisnips.

For debugging I use pdb or pudb, depending on what want to do.
[VS15](https://www.visualstudio.com/visual-studio-pre-release-downloads/?wt.mc_id=blogs_msdn_python#vs-preview) is pretty good so far.
VS code, works like a charm
I like Anaconda Spyder. I will see myself out. 
Komodo Edit - easy to customize, lightweight, fast (~150M RAM normally consuming)
Sublime Text, if you prefer lightweight tools. There are a bunch of helpful plugins if you need them.
"I want the code well documented."

No, what you want is to be able to hire another developer to work on the project six months or a year from now when your target website changes and everything stops working.  This isn't about documentation (in this code), this is about building a flexible scraping pipeline using off-the-shelf packages that have established communities of users and excellent documentation.

I'm sorry to break it to you, but if you are going to become a de facto software engineer manager, you're going to have to learn more about software engineering.
How much does a car cost? It really depends on the web page being scrapped, and the depth and complexity of the statistics. Also your demographic could play a major roll, are you in the United States, India, South America? You could ask 100 programmers and have 100 different quotes. $500, $1000, $10000, it all depends, you should get a detailed quote from individuals and agency's
.
>I want the code well documented.

This is a strange stipulation to make while asking that question. You might consider including a bit more information. How is the data structured? Will the data you want need to be weeded out of other data? Will it need to be altered? Is the source website reliable? Does it allow scraping? What is the source website?

I understand you may not be well versed in the specifics, but I know you can provide more information than you have. You know your question is too vague for an answer, so I'm not really sure why you bothered posting it.
Is the dev just doing the scraping and uploading, as your title suggests, or are they also running statistics on the data and doing the output to a website?

A dev that does this will be paid anywhere between $20 and $200+ an hour, and the job itself can take anywhere between 5 and 100+ hours, since you've been very vague about the "statistics" and how the data is output on a website, and if said website even exists yet, or if thats's something for the dev. The scraping is likely remedial, but, if it's millions of rows, may need to distribute processing.

Thus, you will pay anywhere between $100 and $20,000+ for the job.

...your post should have been well documented :P
These games usually have a lot of recipes so you probably want sqlite.

There's a number of ways to do it. 

You probably want one table of (recipie/itemID, recipeName, craftingTime etc). Just header info and no components.

    01, sword
    02, axe
    03, metal bar
    04, wood block

Then you probably want another table, with the rows being a tuple of (recipe id number, component, quantity).

    01, 03, 10  # item 01 sword needs 10x item3 (metal) and 1x item 4 (wood)
    01, 04,  1
    02, 03, 5 # item 02 axe needs 5x item 3 and (metal) and 6x item 4 (wood)
    02, 04, 6


Pretty standard RDMS layout.

There's many other ways that'll work.
Don't store it recursively. Have the recursion happen in your calculation code.

    recipes = {
        'NobleSuit': {
            'Fabric': 5,
            'FancyFeather': 1,
        },
        'TradingClothes': {
            'Fabric': 5,
            'RedPowder': 10,
            'BlackPowder': 10,
        },
        'Fabric': {'Thread': 10},
        'Thread': {'Cotton': 10},
        'FancyFeather': {'RegularFeather': 10},
    }
Why specifically 3.5.2? Your script doesn't run on 3.4? Also, try /r/learnpython next time.
Why not run it from terminal? 


Edit: I see that you coded in windows and are trying to run on rpy. 

Google about running python programs on Linux or on rpy. It works, in a way, very differently from Windows but it's very easy once you get the hang of it. 

And you definitely don't need idle to run it



Those are usually referred to as old-style string formatting and new-style string formatting.  You should use the new style not because the old style is outdated, but because the new style is superior.  Many years ago the idea was the deprecate and eventually remove old-style string formatting, but that has been long abandoned due to complaints.  In fact, [in 3.6 there is a new new style](https://www.python.org/dev/peps/pep-0498/), which largely uses the same syntax the new style but in a more compact format.

And if someone told you that you have to explicitly number the placeholders, then you shouldn't listen to them as they're espousing ancient information.  The need to do that was long ago removed (in 2.7 and 3.1), e.g.

    >>> 'go the {} to get {} copies of {}'.format('bookstore', 12, 'Lord of the Rings')
    'go the bookstore to get 12 copies of Lord of the Rings'

The new style is superior because it's more consistent, and more powerful.  One of the things I always hated about old-style formatting was the following inconsistency:

    >>> '%d Angry Men' % 12
    '12 Angry Men'
    >>> '%d Angry %s' % (12, 'Women')
    '12 Angry Women'

That is, sometimes the right hand side is a tuple, other times it's not.  And then what happens if the thing you're actually trying to print is itself a tuple?

    >>> values = 1, 2, 3
    >>> 'debug: values=%s' % values
    [...]    
    TypeError: not all arguments converted during string formatting

It's just hideous.  (Edit: yes, I'm aware you can avoid this by always specifying a tuple, e.g. `'debug: values=%s' % (values,)` but that's so hideous.)  And that's not even getting to all the things the new-style supports that the old-style does not.  Check out [pyformat.info](https://pyformat.info/) for a side-by-side summary of both, and notice that if you ctrl-f for "not available with old-style formatting" there are 16 hits.

ah man, this has been one of those really cool threads. Everyday you learn something; 

Thanks all contributors.
The new style is nicer, I find. 

You should still use old style for logging, however:

    logger.debug('%d results', len(res))

The reason is that they're lazily evaluated. If log level is INFO, the string formatting for DEBUG messages isn't performed.
It's not true. In the documentation of python 3.0, 3.1 and 3.2 was a note that the % operator will eventually get removed und str.format() should be used instead.
This note was removed in the docs with version 3.3

http://stackoverflow.com/a/23381153/224656

With python 3.5 the % operator even got new functionality. http://legacy.python.org/dev/peps/pep-0461/
One of Python's core principles is that "there should be one-- and preferably only one --obvious way to do it." And keeping % in the language after the switch to Python 3 is *the worst* compromise of this idea. They *were* going to take it out, but they backed out at the last minute.

You know what this leads to? Nitpicky, holy war-style rifts in the community over whether or not the brevity of `%` in edge cases makes it worth using...in a world where 9 times outta 10 they're using  autocomplete anyway.

And, on top of that, they *also* left in a built-in `format` function on top of `%`, so there are actually three somewhat equatable ways to do this.

It's bizarre.
One thing that hasn't been mentioned is that the old `%` style formatting does have one big advantage, it's faster.  If you have a specialized use case for doing a lot of formatting, it can be faster to use `%` instead.  NumPy does this with `savetxt` when saving out delimited files like tsv or csv.  If you have the use case for speed over flexibility and readability, then you might want to consider using `%`.  Keep in mind that this really only matters when you're doing a _lot_ of formatting, on the scale of thousands of individual values, but it can squeeze out a few extra milliseconds.
For simple string formats I use %.

Generally if I need to print more than two variables I use .format with a dictionary.  See here http://stackoverflow.com/questions/5952344/how-do-i-format-a-string-using-a-dictionary-in-python-3-x

If it's something quick, dirty, and temporary, sometimes I even use 'Hello ' + name.

I used % for a long time as well, but know that I know how format works, it's way easier and more confortable to use:

    >> x, y, z = 4, "foo", 8.90
    >> print("{1}, {0}! {2}?".format(x, y, z))
    foo, 4! 8.9?
    >> print("{a}, {b}! {c}".format(a=x, b=z, c="bar"))
    4, 8.9! bar?


It's very intuitive and easy to use - you don't have to worry about type, order etc. anymore!
Mandatory plug for https://pyformat.info
Nope. I use it and plan on keep using it. It is just much shorter and the .format... and curly braces don't seem to offer me any advantage.

Besides I use C as well once in a while, so only have to keep in mind one formatting syntax.
It is supposed to be outdated, since the new style is supposed to replace it. As about a dozen people have shown, the new style is a lot more readable in complex esoteric cases. The drawback is of course that it's also a lot wordier in the much more common simple cases, e.g.

    "a %s c" % str

vs

    "a {} c".format(str)

Not everyone thinks that making the common simple cases wordier is such a great design, so the old style has remained.
Basically it looks like this:

    a, b, c = 'jim', 'bob', 'joe'
    print "hello {0}, {2}, {1}".format(a, b, c)
    >>> hello jim, joe, bob

It's not really 'better' than % formatting. In theory there are some flags and nifty tricks to display data in different formats, but I don't think anyone can do it without looking it up. Personally I prefer it, but it's just preference. 3.x has some formatting like below, but it's sadly not in 2.7.

     print f"hello {a}"

% is considered the "old" style now. 

See [PEP 3101](https://www.python.org/dev/peps/pep-3101/) and the [string formatter options](https://docs.python.org/2/library/string.html#custom-string-formatting).
[deleted]
Yes.
Isn't {0} from c#?
Also, with format you forget about data types (%d, %s etc)
You can either use it like this:
'Hello {}!'.format( name )
Or:
'Hello {NAME}!'.format(NAME=name) to make it more readable 
I'm just putting this out there in case it is useful to someone:

If you are using format strings to insert information into a regular expression, you will need to use double curly brackets {{}} for the placeholder inside the regular expression since they use curly brackets for repetition (ex: '\d{5}' is the same as '\d\d\d\d\d'). Had I known this, I'd be about a day and a half younger.
Not only is `%` outdated, but `format` is outdated (*edit for string literals).  When Python 3.6 comes out, you should use `f'{variable} {array[3]} {dictionary[key]}'` instead of `'%s %s %s' % (variable, array[3], dictionary[key])`
I prefer the old style for a number of reasons:

* new style is python-only but my life is not python-only
* you _should_ use it in logging
* it's slightly faster
* the common use case conveys more type information

Via my exposure to other languages I've been convinced that "you shouldn't have to care about types" doesn't lead to writing good software _for me_.

What I _don't_ like about old style is that it has built in syntax support with nasty edges.  If that was removed in favour of `"%s".format(...)` then I'd have been fine with that.  I will also admit that, for beginners, the new style has less cognitive load and is less confusing.
It depends on your use case, but considering Continuum (the company behind conda) is primarily a Scientific Python consulting company that has multiple packages offering various levels of support and services, it's pretty safe to use in production.  If you really need a lot out of conda it may be worth looking in to a support package with them.
At my company we use conda to manage our entire python stack across multiple platforms (OSX, Windows and Linux) and we haven't had any issues. Typically we have a metapackage that defines the specific requirements of a project. You could also use an environment.yml file, but these aren't always cross-platform compatible. The nice thing about a metapackage is that it has a formal recipe so you can use all of the standard conda meta information to control what happens on what platform. I guess you could also use 1 environment.yml file per-platform as well. 

Also, depending on what you need to get from pip, you might consider looking at what is available via conda-forge since this fills in a lot of the gaps between what Continuum makes available through the default anaconda channel and what is on pypi. 
We distribute a Python 3 GUI application on Mac, Windows, and Linux that uses PyQt4, gdal, matplotlib, pyopengl, etc. We use conda for all of our developers and beta testers and use pyinstaller to create an installer for each OS that we support. The biggest issue we've had is with version incompatibilities between various packages or packages not being fully tested before going out. The biggest problem was (and still is) gdal and to a lesser extent PyQt. I've had multiple cases where gdal doesn't have it's dependencies proper specified (no minimum version, missing dep, etc). So when I prepare for distribution and have the crazy idea to update the packages being used I go through a cycle of update, error, google error, force older version, error, google error, and so on.

But once you find a version that works for you you are mostly OK...that is until someone comes out with a new build number with the same version and that build doesn't work for your application.
We use conda in production. The twist is, the production has no access to Internet, so I have a shell script that installs Anaconda + everything from scratch using both conda and pip to a directory inside Docker or VM which do have Internet access, then pack it in a tarball which gets copied + extracted to production environment.
I hear Conda is pretty good at your use case - you're on a somewhat old OS, and you have both Python and non-Python compiled dependencies that you want someone other than your OS to provide for you.

It is less good at integrating with the rest of the system / with anything non-Conda. Whether that's okay for a production service (or, for that matter, for a development machine) is somewhat a matter of deployment philosophy  pip is fairly good at integrating with the rest of the system, but it's definitely not going to get you a newer LLVM.
We use conda in production and we use numba as well. I actually haven't figured out how to upgrade packages reliably using an environment.yml file. That is, if we bump a dependency version in there (usually in the 'pip' section), I don't know how to upgrade that package in an already-created environment. 

Does anyone here know how to do that?
I'd like to thank everyone for taking the time to reply. Great comments, very helpful. Cheers!!!
I've built llvm on rhel7 and it's quite doable. 
IIRC you need to first build cmake, then llvm.

"download, configure, make & make install" work well.
Oh I don't know. I googled python and license and took the second hit. https://docs.python.org/3/license.html
It had to be harder to submit this post than to just google "python", and see that there is a [download](https://www.python.org/downloads/) page with no mention of any price.
Yes it is free.
There are (at least) 12 different meanings of just the adjective form of the word 'free' so you may need to be more specific.
Try /r/learnpython. Also, do you have any code examples that illustrate what you're trying to ask?
I have absolutely no idea what you're asking about. What do you mean by "passing an object as an argument to call a method"? Why do you think it's different than "using an object to call a method"? The difference isn't obvious from your language. If you don't know the right terms to use, it might help to give an example as code.
I have to accept your licence agreement amd waive my right to withdrawal to even see your site?

No thanks.
This site is utterly broken on mobile (Chrome).
That license - no chance. Sorry guys, my interest stops at the point you accost me with legalese just to see your site and find out about your program.
Yeah, site is down.  How does this compare to panda3d?
This was born out of having too many tweets to go through by hand and I thought it'd be a fun, quick project.

It works by using the Twitter API along with your Twitter archive. The script parses the CSV and if the tweet falls within the given date range (optional) and matches any one of the provided regular expressions, the tweet is deleted.

Example usage:

```
$ ./detweet.py --csv ~/Downloads/tweeter_archive/tweets.csv --before '2014-06-01' 'some(thing)?' 'maybe a swear here'
```
Pretty clean, I like it. Nice work.

Whip up a post about running this as a scheduled AWS Lambda task and you've got a some great blog material. :)
I made something similar a few months ago but without the regex feature (thats a pretty good idea). 
Nice work yo.
Dump your code into a [gist](https://gist.github.com/) and it'll make it a lot easier for us to see what is going on, especially with regards to indentation.
The most sought out skills in python are people with personalities that don't make you want to stab them (or yourself) in the neck with a fork.


Data analysis, scipy, numpy, web
Everyone is naming framework and libraries; but i think that misses the point.

I would argue the most important skill of python is understanding it's core philosophy and learning to use the language features to write clean idiomatic code. 

Raymond Hettinger puts out a lot of very high quality content on this subject and definitely worth checking out.
Flask, Django
Knowing when not to use python. People try to make it do everything. This is a problem in every language but I notice it most in Python. Know when to chose another language. 
Readable code, Maintainable code, Unit tests
Although not limited to python, 
Watch https://www.destroyallsoftware.com/talks/boundaries
and read "The Pragmatic Programmer"

For me, that leads to writing way more classes, with way more well defined functionality (No egg laying wool hogs). I also drop asserts all over the place as a form of executable documentation.

dSpace, CANape, Controls.

But that's my industry.
Platform automation. SaltStack, Ansible, Fabric... Anything that bash can't do better.
I don't know about other countries, but in NZ I'd say it's GIS and web
Proficiency and versatility. Being good at using it and being able to creatively think of new ways to apply it to common problems. There's no real skill set as most programming languages can do what others can, for the most part. I can use python to help me do black box pentesting, as well as use one of the various C languages to assist me in all the same tasks I completed with Python 2.7/3.x. Its really up to you, and how good you are. 
I think regex and webscraping is assumed tbh... 

With Python I would say generally Django and python with postgreSQL would be what gets listed on job posts.

As with all of these types of quesitons, Python is just such a general language that it really depends what you want to do with it that will determine what's in demand.  
Writing Pythonic code.

I'm having to rewrite my product because a couple Java programmers wrote Python code as if it were Java code. It's very frustrating.
I think that being able to do *actual* software development in Python (beyond basic scripting) is a sought-after skill.
I wanted to say that I'm very happy I found a colleague who appreciates writing good code and adheres to PEP8! I love the discussions, great experience to have a good peer!
text
That seems like a job for a batch file, not Python. 
Check out the 'subprocess' library. 
> From there, it looks like 'os.system(cmd)' is on the right path of what i want, but i can't seem to get it to run any commands after i open the cmd window.

os.system() is used to issue commands directly, not to interact with a command prompt window. You seem to be confusing/combining two entirely different ways of tackling the problem. One way is to execute commands directly through code, while the other way is more like a macro where you're replaying keystrokes and mouse movements to repeat a process you've recorded (or programmed) previously. I would strongly suggest using the former method rather than the latter whenever it is feasible.

Really, the script you're trying to write doesn't need to touch the command prompt at all. You can get a timestamp and ping a host easily from within Python, so it wouldn't make much sense to go outside of your script to run these commands and then bring the data they generate back into the program.

I would also advise just printing the data out to a log file instead of taking a screenshot. All of this is fairly simple (as far as programming goes) and very doable for a beginner with some dedication and reading.
I think I would use a batch file for this, with logging. But, with the requirements of a screenshot, I would imagine there is a program out there that can be called from a command line and screenshot based on hwnd, window title, or similar. This post lists at least a few that should do what you want: http://superuser.com/questions/75614/take-a-screen-shot-from-command-line-in-windows
why flask?
The language is named after Monty Python, so you're have way there. 
Know what I mean? Croydon. 
actually, there is an online Python book that uses Monty Python stuff as examples
I'm sorry, this is abuse!
Dask dataframes provide a parallel version of pandas apply.  
 http://dask.pydata.org/en/latest/dataframe-api.html
On mobile, so bear with me.

For starters, I would separate any long running, prone to fail task (web queries) from a local fast operation (dataframe creation). Easier to catch errors, multiprocessing, or other changes.

Can't see the code, but I'm guessing you have something like a source_list and result_list. You can just zip then together ( zip(source, result) ) and turn that into a dataframe that you merge with master using the source variable as your key. If the result list is in random order, the quick and dirty solution could be to return the result with the function argument.
What ever machine you're using it on now doesn't have ```requests```.
I would bet you are on a Mac and actually running Python 2. If you're in an ide, make sure to select Python 3. If you're using terminal, "python3 my script.py"
MicroPython is lean and efficient Python implementation for microcontrollers and constrained systems.

In this version:

"New port to Zephyr RTOS, initial support for running upip (package manager) runs on baremetal systems like ESP8266, and reduction in code size."

More detailed changelog is available by the link in the title.

MicroPython seems like it could be used to make standalone executables for distributing simple python programs. It should be significantly smaller than what Pyinstaller can do for a single file.

Is that a future possibility or are there reasons why that's a terrible idea?
Just flashed another ESP8266 a few days ago. 

It's nice developing in a single language for quick and dirty prototypes.
How many have used this and how is it coming along?

I've used some microntrollers years ago, but currently don't have much knowledge. I was considering picking up an arduino just to get some projects done quickly, but do you think this would be a better alternative in that I can accomplish things quickly and effectively while also learning something somewhat useful. 

I have no problems with Arduinos for hobbiest projects, but it is never really getting to the nitty gritty of it. 

I'm sure both are effective for my needs, but was just curious what yall thought. Thanks
What made the author of this library to give up his job as a physicist to make an Arduino thing?
I've been using micropython on my adafruit huzzah esp8266 and 1 thing has caused me to sadly switch back to c 

**There's no easy way to get your code onto the device!** 

I ended up using this very nice helper program by adafruit, but you can't move entire folders which makes it a massive pain for moving a library: 

https://github.com/adafruit/ampy

I don't see this ever really getting traction on the esp8266 until you can use it like the main micropython board and mount it as a USB device. The main micropython board is awesome btw. 

As an alternative, once `upip` is implemented (it's listed in the kickstarter) I'll at least be able to get the libraries I need. 
There's been a [DDOS on the DynDNS managed infra](https://www.dynstatus.com/incidents/nlr4yrr162t8). This might explain it.
I just got to it with out issues.
I think you forgot to add a link. 

But I dunno if saying natural language processing or SA isnt hard is helpful. Sure, its easy to gain an introduction and learn a model or two or have slivers of knowledge but to say these fields that are vast and complex 'arent hard at all' just doesnt feel honest, you know. I mean people are still publishing their doctoral thesis in these fields, they are active areas of research. Theres gotta be a better way to motivate people to look into these fields then by telling them its not hard at all. I mean they are extremely interesting partly because of how complex they can be.
RemindMe!
also: http://www.kdnuggets.com/
Really cool, thanks!

I've taken all of five seconds to look into this, so don't think I know what I'm talking about, but it looks like you could use Selenium.  It's basically a headless web browser that you can use to interact with the page more like a user.  Which lets you wait for it to load content before you get to your scrapin'.  
If all you want is the data from the ajax call, just use the `requests` library to make the http call on your own and use the data it returns.
This:  https://pypi.python.org/pypi/selenium
+1 for Python Requests. Sample code for a POST request that returns JSON:

    import requests  
    url = 'https://example.com/liveodds.php'  
    payload = {'event':'122849212', 'token':'aff3b34443cbd12134b294'}
    
    r = requests.post(url, data=payload)  
    json = r.json()
> I am new to Python

For such tasks the shortest way to the solution is the best

It should be the other way around - understand the task then choose tool. (ajax is not relevant here, it just a way browser makes request)

1) You have one site - you maybe don't need tool that knows to scrap any site

2) first you understand how data pulled - open browser F12 -> network,  browse the site. Copy in cURL format requests (or use some tool like Fiddler)

3) Do you need login to see the data? You need a tool which can keep the session, command line `curl`can do it, also pycurl or httplib (maybe simpler) 

next step is to choose a tool and that depends on what you found. maybe all you need 

    import time, os
    while True:
        os.system("curl http://site.com/api?q=value >> data ")
        sleep(1)

separate the tasks (common beginner's mistake)

task 1 - get data

task 2 - parse data

task 3 - do something with it

**don't** do it 

    for raw_data in request():
        data = json.loads(raw_data)
        parsed_data = parse_data(data)
        for a, b, c in parsed_data:
             process(a, b, c)

do

    import csv
    with open('raw.data', 'w') as rf:
        try:
            for raw_data in request():
                rf.write(raw_data + os.linesep)
            except:
                traceback.print_exc()


    with open('raw.data', 'r') as rf:
        with csv.writer(open('parsed.data.csv', 'w')) as pf:
            for line in rf:
                data = json.loads(line)
                for a, b, c in parsed_data:# 
                    pf.write([a, b, c])

    # or just use Excel
    with csv.writer(open('parsed.data.csv', 'r')) as pf:
        for a, b, c in pf:
            process(a, b, c)
             
Wow!

A suggestion.

Put your data in a text file, then just read it in.

    file: data.txt
    Hello.
    It's me!
    I'm going now.

And the code:

    file: incomplete-story-program-thing.py
    with open('data.txt', 'r') as fp:  # open text file in read (r) mode
        lines = fp.readlines()  # create iterator of lines in file
    for line in lines:  # for each line ...
        print(insta_print(character_names[3]) + delay_print(line))  # print the line

If you need a quick way to distinguish between 2 types of line (for your delay effect) put a '@' as the lead character, and test with:

    if line.startswith('@'):
        delayprint(line[1:])
    else:
        instaprint(line)

You might also stick another code in the text file strings like `#name#` to mean player name. Then you can search and replace it like this:

    if '#name#' in line:
        line = line.replace('#name#', character_names[3])
Pardon my question but why post it here, it's a Java project, surely it would be better off in /r/Java, in my opinion even if you are trying to copy Python it doesn't make for a good reason to post it, it's not a project we as python users can make use of.
https://developers.nest.com/documentation/cloud/data-rate-limits/
This is a thread someone started on Stack a while back trying to achieve the same thing. The OP never said if they were able to get it working though. 

http://stackoverflow.com/questions/25872562/what-is-the-link-between-your-firebase-firebaseio-com-and-home-nest-com
Here is my Python code for GET from the normal, but **Rate Limited** API. I'm sure the code is pretty sub-par but even though its messy, it works for a limited number of requests That is why I would like to go with the Firebase alternative. Maybe by seeing this code, someone could help me adapt it to using it with the Python Firebase wrapper

    import requests
	import json
	import time 
	counter = 0

	# Loop will run whenever a nested While loop breaks
	while True: 
		
		# Address where API is request with authroization 
		response = requests.get("https://developer-api.nest.com/devices/thermostats?auth=c.zWUFYLl.......cLP3") 

		data = response.json()

		hvacState = data["Z9S1....aBu_Xk"]["hvac_state"]

		#Loop will run when Thermostat State is Off
		while hvacState == 'off' : 

			# Address where API is request with authroization 
			response = requests.get("https://developer-api.nest.com/devices/thermostats?auth=c.zWUFYLl.......cLP3") 

			data = response.json()

			# Device ID and Thermostat State. Used to pull API data, must use Device ID.
			hvacState = data["Z9S1....aBu_Xk"]["hvac_state"] 

			if hvacState == 'off': 
			
				print "HVAC State: %s" % hvacState 

				# Counter to watch while script is running, mainly for API Rate Limits
				counter = counter + 1 

				print "Count: %s" % counter
				
				print'30 Second Delay'

				time.sleep(30) # No requests for 30 seconds
			
			# If the state does not equal "off", end loop and jump to beginning of first Loop
			if hvacState != 'off' : 
			 	break

		#Loop will run when Thermostat State is Heating	
		while hvacState == 'heating' : 

			
			response = requests.get("https://developer-api.nest.com/devices/thermostats?auth=c.zWUFYLl.......cLP3") # Address where API is request with authroization 

			data = response.json() 

			# Device ID and Thermostat State. Used to pull API data, must use Device ID.
			hvacState = data["Z9S1....aBu_Xk"]["hvac_state"] 
			
			if hvacState == 'heating':

				print "HVAC State: %s" % hvacState
				
				print'30 Second Delay'

				counter = counter + 1

				# Counter to watch while script is running, mainly for API Rate Limits
				print "Count: %s" % counter  
				
				# No requests for 30 seconds
				time.sleep(30) 

			# If the state does not equal "heating", end loop and jump to beginning of first Loop
			if hvacState != 'heating' :
			 	break

		
		
I have read most of Dan's blogs from the time I just started working with django and needed to deploy static files to S3 to this one. Every single time I learn something new and it's pretty awesome
Hey, thanks a bunch for sharing! <3
/u/sentdex has launched the campaign which he talks about on his youtube channel [here](https://www.youtube.com/watch?v=qO-V5ctO-vU).

He makes quality videos and supports the community well so consider supporting him if you can.
A 24 day old account with nothing but codequs.com spam.

Nice...
You should post this type of question on [r/learnpython!](http://www.reddit.com/r/learnpython).

In the meantime try just python3 or python (not python3.4) and see what version you get.
http://selenium-python.readthedocs.io/

This may be what you're looking for. I refer to it frequently.
http://selenium-python.readthedocs.io/py-modindex.html
thank you very much both of you!
On the topic, you might want to use [Splinter](https://splinter.readthedocs.io/en/latest/) rather than the low level driver. 
Very brief look through: it's a good tutorial for Python in French.
`import sys; print(sys.version_info)`. Also, try /r/learnpython next time.
How much you paying for this
Or you can just look at the api , doesn't look to hard.
https://github.com/plamere/spotipy/tree/master/examples
You can start here :)
https://automatetheboringstuff.com/
This is interesting, I might actually do this but if you're only paying in exposure dollars it might take awhile!
The Javascript one is horrible to write on non US keyboards.
Because in  Python2, backticks are like `repr`, so it would've caused confusion.
this was considered in https://www.python.org/dev/peps/pep-0502/#id85

imo, using the same syntax to mimick consistency is undesirable when the two things don't behave in the same way; python has no tags, and javascript has no string formatters.
f"test: {a} {b} {c} {d}"
vs
`test: ${a} ${b} ${c} ${d}`

js version is just ugly
An aversion to dollar-variable syntax - Too much like Perl!
Hey there, bit of an odd question but I'll bite. I work on question answering in NLP. I use python all day with a TensorFlow back end to write neural networks which are meant to be able to read documents and answer questions about them in natural language.

So I come quite close to being qualified to answer the question in your title: massive progress is being made in AI now, we are starting to see models which show signs of being able to do complicated reasoning on unstructured data. DeepMind's recent DNCs are an exciting example.

Alas, we are still a long way from a general 'what if' machine, I think such a thing is probably AI-Complete.

This is easily for me the most exciting thing you can do with python today. The way things are going the first AGI might very well be written in it!!
Why not make the Traversable object callable instead? Then you can avoid needing a reserved key name and you make it a little shorter to use.
This is moving in the wrong direction, IMO.

There was [a good post a month ago](https://www.reddit.com/r/Python/comments/4zhyzu/arguments_against_jsondriven_development/) about how "JSON-driven development" is unmaintainable. There's nothing wrong with using JSON as a wire format to talk to browsers, but once you get the JSON into your system _convert it into real Python class objects_. Messing around with a bunch of dictionaries and lists when using a class would be more appropriate is an anti-pattern. Use dictionaries as dictionaries, not as classes.
An alternative approach could be to validate your input?
this is pretty much bad monads that loose metadata as replacement for actual input validation :)
Everyone better read that first readme paragraph--- thats a pretty dicey situation
Here's an alternative approach, although not specific to JSON. 

    from moya.context import Context
    >>> c = Context({"foo": {"bar": {"baz": ["well", "hello", "there"]}}})
    >>> c['foo.bar.baz.1']
    'hello'

And bonus expressions:

    >>> c.eval('foo.bar.baz.1 + " " + title:foo.bar.baz.2')
    u'hello There'
Looks kinda like [dictdigger](https://github.com/jtushman/dict_digger) 
Another solution, also not limited to json: [TreeDict](http://www.stat.washington.edu/~hoytak/code/treedict/)
What a great write! Not only is the author quite a brave programmer, but a gifted writer.
I feel this construct is under-utilised:

    foo.get('bar', {}).get('baz', {}).get('boz', None)

However: Nice library. I'll try it out next time someone sends me a mess of JOSN.
Well the motivation sold me :D

edit: https://github.com/skorokithakis/jsane#motivation
1. Install pypy
2. Make virtualenv using it (virtualenv -p ...)
3. Enter virtualenv
4. Install gunicorn

Or perhaps just pypy gunicorn ... will work
I think its important to run everything in a virtualenv. I'd try to not touch, or install anything using the systems python.
Just knew this would be Armin just from the title and source. 

Looks interesting. I haven't used cffi much, so I'm not sure if the trade off of using that vs being building native bindings. 

I suppose the most tangible takeaway for me is returning multiple values from a context manager which isn't something I hadn't considered before. 
What is a "source map"?? The article uses the term as if it's common knowledge...
Or you could just use PyPy :) 
I'm sure the answer is no, but would using slots have reduced the memory usage enough to stay pure python? 

At some point for performance reasons, it's always going to make sense to go to a complied module, I'm just curious :)
You'll get a lot more help at /r/learnpython. 
> https://github.com/khamidou/lptrace#technical-details

Wow. You have buried the lede here, I think.

There's a huge problem in Python land: my script has hanged, how do I debug it, just figure what's going on, without adding the call to start the pdb server and whatnot and restarting it? 

There were two posts by /u/mbenbernard about using Python support in gdb to do that ([1](https://benbernardblog.com/my-startling-encounter-with-python-debuggers/), [2](https://benbernardblog.com/my-startling-encounter-with-python-debuggers-part-2/)), but yeah, it's complicated and you'd be dealing with gdb directly.

What you did there is a game changer I think. But if I may very humbly suggest, you should emphasize it in the README that what your thing can do is to inject and run _arbitrary_ Python code in a running process, including STARTING THE FREAKING PDB with that `-d/--debugger` switch, and maybe add an option for running really arbitrary code.

While tracing Python calls is just what it does by default because that's what you usually want, but it's nowhere near the limit of what it can be used for.

Because, and I speak only for myself, the title of your post and the first page of the readme left me somewhat lukewarm about your thing. Oh, some weird trick to trace Python code. It was when I realized that it solves the general problem of attaching to a running Python process and running arbitrary code in it that I became excited as fuck! Don't bury the lede, say that that's what it does first of all, mention the starting pdb use case, mention the tracing use case.

-------------

Also, why do you manually check if you run as root, I'm entirely sure that you can attach to any process started by the same user with gdb. If it's not true in some weird edge case, let the gdb fail and complain about it.

Also, please don't suppress output from `subprocess.Popen`. Either just remove all those `... = subprocess.PIPE` or check if running the commands was successful and print the errors if not. The last thing I want from my debugging tool is to silently pretend that everything is OK, when I'm using it in the precise situations when things are not OK.
Nice tool. But I wonder what happens if the Python interpreter becomes inactive (e.g. the Python program is stuck in a C module function)? Will lptrace freeze?
>  vagrant@precise32:/vagrant$ sudo python ttrace.py -p 1818

I'm unsure of why you're running `ttrace.py` in the README, shouldn't it be `lptrace.py`?

Edit: Glad you fixed it =)
Very cool. Also nice to know we can inject python code so easily.
This is something that I was hoping to [add in Hunter some day](https://github.com/ionelmc/python-hunter/issues/27). Interested in helping? Even if just giving feedback.
This looks pretty awesome; not to say that the use case is identical, but for those of you who run into similar needs might also want to check out [pyrasite](http://pyrasite.com/).  It lets you inspect (and inject code into) a running python process from a python shell.
Any ideas for a Windows version? I have a fairly large Windows python project with a few bugs that need solving, and this is exactly what I need! Great job by the way!!!
[deleted]
[deleted]
You could use a DigitalOcean server - it's what I do. It charges by the hour and is pretty cheap. Its running the LAMP stack, so it acts as a webserver and can also do everything a Ubuntu server can do, like run Python scripts. It currently runs a bot I made perfectly.
I recommend PythonAnywhere. Deploying is pretty easy and they have an integrated IDE which is nice. 
If you want a Python-supporting host to run websites off I strongly recommend [Webfaction](https://www.webfaction.com/). They allow you to install whatever you want on their shared servers (any Python module), you can even compile/run your own http server instance if you want. It's $10/mo.

It's got easy installers for Django and supports MySql.
Heroku is a good place for a small dev database. I have a small django app hosted on pythonanywhere which communicates with a postgres db on Heroku. All free!
Get some cheap VPS and manage it yourself. It's not difficult, and given that your main goal is learning, it's an opportunity to learn some simple sysadmin stuff too. A nice list of cheap VPSes is on [lowendbox.com](https://lowendbox.com/).
You can do all of that on the aws free tier
/r/learnpython is a better place for such questions. Also, that question is ... weird. An IDE is not an interpreter, it doesn't execute code.
I suppose there was something question author had in mind, but for me it makes no sense:

1. IDE's are not executing anything, interpreter does it.
2. IDE read file as a whole or in chunks, not in lines.

So the answer could be "when it loads it" or "never".
Omitting the fact that IDEs don't execute code (the interpreter does), code may be unreachable. For example when you have code inside a function behind a return statement.

    def fn():
        return 1
        doesntHappen() # never executed
That;s the sort of question I'd ask when teaching `if __name__ == '__main__':`. Of course I know the difference between an IDE and an interpreter, so I would not phrase it like that.
Sorry for being the nit-picky mechanical engineer hereâ¦ But using three interlocking gears as a logo wouldn't have been my choice for logo design.
What do you mean by "make a function a variable"? Define a variable with the same name as function? It just overrides the function. Also, next time please post questions in /r/learnpython.
This is not the subreddit for questions. You've already posted this in /r/learnpython, someone should respond there.
I must say I'm -1 on all of the suggestions (related to the for constructs, there should be only one way to do things).

As for the generator, you can actually create your own generator to have the API you want to some odd case if you really want it (take a look at https://wiki.python.org/moin/Generators for examples). 

It doesn't seem like the default generators should be more complicated or even worse need special syntax for that.

Please note that you shouldn't take that I'm -1 on the idea personally, if you really think it's nice, go on and hack the Python code to add it nevertheless (it's Open source after all). 

Still, if you really want to land it in Python, the proper way to add something to would be first to first discuss it on the python-ideas list and if others agree, write a PEP and proof of concept (e-mailing psf about that is definitely not the right place for it).
There are mailing lists in which they discuss these things ([Python Ideas](https://mail.python.org/mailman/listinfo/python-ideas)), but note that is a wide distribution list with pretty much all the major names you'd know in Python. I'd tend to agree with the other comments thinking there may be better syntax.

Instead you could likely just make your use case a library or compose some pieces from itertools in there. There are a lot of nuances in your proposals, for example what if your two generators aren't the same length? What if a generator raises? Etc.
I honestly like `for x in generator1 and y in generator2 `. Not really sure if it helps since we can do `for x,y in zip` already, and it doesnt make much sense to add it for just the reason that we might like this. It really is not enough reason. Plus, this is cute for 2 generators, but what about when you do for `x,y,z` (or more) which also happens.... your method won't "scale" :)
What are you trying to achieve with your first example that could not be done with:-

    for a in some_generator:
        b = a

Am I misunderstanding something?

I very much doubt that you'd get much agreement over your other suggestions as they look to me like far too much work for far too little gain.
eh...  no? these suggestions are ill-conceived

for instance "for a and b in... " is poor notation for what you want to do  . such suggestions should be left to people with a sense of structure and mathematics .  they'll come up with a notation that makes sense. 
Your "suggestions" are unjustified and I'm sure cold mailing the PSF is not the appropriate way to try contributing to the language.
Currently working on a medium sized project with MongoDB. My advice: don't do it. Postgres is a better choice in every way that matters.
Why not use Solr? It will do the shardijg, ngrams, stopwords, etc for you. It scales very well in its cloud mode. 
I already posted this like a month ago mentioning the better performances of pendulum compared to pytz.

I updated the article mentioning some cases where pytz does not behave properly whereas pendulum does.

This is not an article that tells you to ditch completely pytz but that you should also consider pendulum when working with timezones.
I've been using pendulum on my latest project, and have enjoyed working with it. I did find a bug though.  

If you create an object using pendulum.today(0), the object seems ok, but then if you pickle it, it will fail when you unpickle the object.  

So if you are wanting to default to the +00:00 Time zone as I am in the program, use today(tz='UTC').
This library has made my life so much easier. I've stripped datetime out of almost all of my projects in favor of pendulum.
This looks great. I always forget when I need to use `normalize` and `localize` and in which order. `convert` is easier.
This is nice, but 90% of my timezone-related operations are in pandas...
This really fits better in /r/learnpython. 

Also, pleeeeeeeeeeease do tutorials in Python 3, not 2. Make those two changes, and I suspect you'll do better in terms of votes at least.

Text in IDLE is also too small. You should make the font-size more like 20 so it's easier for people to follow along.
Great write-up. Personally, I started with Python 3 and never looked back. And as he points out in his post, Python 3 is clearly the future.
Welcome to 2009. 
Is switching this big of a deal for most people? You'd think you were asking them to switch to assembly.




The fact some people continue to write py2 code baffles me, I understand existing codebases being still in py2, migration is a huge pain in the back, but I don't get why so many places still teach py2, it's gonna be dead like next year (assuming Guido pulls the plug for real) and there's plenty of libraries fully on py3.
+1 for writing Python 3 now. It's much more fun and the ecosystem has reached a nice point now.

Unless you can't move away from Python 2, just don't use it anylonger.
It shows they are feeling threatened by Python.
A lot of their points are valid (better/complete libraries, documentation, support, etc.) but there's no getting around MATLAB being a terrible programming language and way too expensive. 

Their first example is also misleading since the matrix NumPy class or the new @ operator make both pieces of code on par in terms of readability. 

Mathworks needs to just adopt the Python language and officially support it as an alternative way of using their libraries. 
TL;DR:


"Matlab is better than Python, get it now!"

- Mathworks
Let's recognize that this was posted by the company that makes MATLAB, and is really an advertisement for MATLAB rather than a legitimate comparison. Anyone who has used both Python and MATLAB will understand how painful MATLAB is for anything of more than minimal complexity.
Oh that is just hilarious.  And it is a sign they are feeling very threatened by python.  
Here is more realistic comparison:

http://sebastianraschka.com/blog/2014/matrix_cheatsheet_table.html

And one more:

https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html
Biggest advantages mathworks has at least in Controls engineering is Simulink and auto code to C. I can prototype a design or tune some gains and have it ready to go on a microcontroller in a day or so
It should be either downvoted into oblivion because it's blatant spam or posted in /r/humor
This comparison would have really bothered me a few years ago, but it almost doesn't matter now. See this quote from 2009:

"Something important happened in the Scientific Python world during the last year: we are no longer constantly comparing our software with commercial packages, nor justifying the need for Python in Science. Python has now reached the level of adoption where this sort of justification is no longer necessary. The exact moment when this shift in focus occurred is difficult to identify, but that it happened was apparent during the conference."

Gael Varoquaux, StÃ©fan van der Walt, and Jarrod Millman, [Editorial](http://conference.scipy.org/proceedings/scipy2009/paper_0/full_text.pdf), Proceedings of the 8th Python in Science Conference (SciPy 2009). Note: link is a PDF.
There are some nasty things in the MATLAB language that Python does much, much more cleanly.

MATLAB is still way ahead in terms of plotting capabilities, advanced scientific libraries, and to some extent the IDE in my opinion (although I usually use Vim everywhere else, I deal with MATLAB's editor because the linting feedback is very useful).

In the end I've been absolutely struggling to do any new development in Python because I'm stick of the horrible MATLAB language and the cost, but there are definitely use cases where I still turn to MATLAB. Different tools for different applications.
You've come to the right place.
Does anyone ever count? 
I just see what it prints, and the adjust accordingly. 
Don't forget /r/learnpython as well.
This is a subreddit for snakes ððð
It must have been written back when reddit wasn't https all over.
Shame! They didn't use https
Thanks Zybooks! Now I have knowledge and karma! What a phenomenal publication.
The answer is '/r/python', yeah? The colon is a new thing for me. 
    from urllib.parse import urlparse
    parse_result = urlparse(my_str)
    path = parse_result.path
> http://

> Not https://

Shame on you, textbook.
Alright, who did this?
prints 'reddit' or something, idk, do I look like I know string manipulation? 
And now you are stuck here for the rest of your life!
Just for fun:

    >>> s = 'https://www.reddit.com/r/Python'
    >>> "/".join([""] + s.split("/")[-2:])
    '/r/Python'
Hey I used the same online textbook for my python class.  To cool.  
What a terrible exercise... 
Shame the URL is http, not https.
[deleted]
[removed]
Your code seems to be written under the assumption that this is a text file, but the error you're getting indicates that it isn't.  Which is it?  Are these values represented as raw binary or as ASCII text?

(And saying that you have a .data file doesn't help.  That doesn't mean anything.  You need to describe the actual format.)

What's a .data file?  That's the most generic sounding file ever, but it's probably super specific.  

What's the file look like?
You'll get a lot more help at /r/learnpython. I am on mobile so it hard for me see the exact same problem here, but I wikk suggest breaking the long function up into a few smaller ones. It will make troubleshooting much more simple and your code much easier to maintain. You might also look into using a dictionary to call the separate functions for the different inputs. 
BTW,

    if newname in lista:
       ...
    if newname not in lista:

is a waste of computation since Python has to iterate over `lista` twice!

Anyway, to your question, You can't directly change the key in a dictionary. However, you can do something like:

     >>> lista = {'joe':'555-555-5555'}
     >>> lista['bob'] = lista.pop('joe')

May I make another suggestion? Donât back yourself into a corner with a dictionary of name as the key and the number as the val. What if you decide to store addresses?

Make the value a dictionary of the information you will later need. Do something like 

    lista['bob'] = {'phone':'555-555-5555'}

because then you can later do something like

    lista['bob']['address'] = '1600 Pennsylvania Ave NW'
nice and very helpful blog
Since both of the examples are straight from textbooks, I cannot help but notice that the principle point of generators is missing from the article.

So how about this:

    from itertools import takewhile
    def fibonacci():
        """ Infinite stream of Fibonacci numbers. """
        a, b = 0, 1
        while True:
            yield a
            a, b = b, a + b

    def primes():
        """ Infinite stream of prime numbers. """
        primes = []
        a = 2
        while True:
            if all([a % p != 0 for p in primes]):
                yield a
                primes += [a]
            a += 1

    # Fibonacci numbers less than 100
    print(list(takewhile(lambda x: x < 100, fibonacci())))

    # prime numbers less than 100
    print(list(takewhile(lambda x: x < 100, primes())))

    
> We have taken a look at generators in Python 3 through two examples which have shown how we can use them and utilize the lazyness of them to delay CPU-bound calculations to the time when they are demanded.

Although the article is informative, I don't feel this was shown. What I think was shown, is how generators can be used to do dynamic programming with great readability.
Very interesting and helpful. Thanks for sharing 
If you're going to write a package manager and you haven't read [this](https://medium.com/@sdboyer/so-you-want-to-write-a-package-manager-4ae9c17d9527) then... please do.
why is .json good for this over .py

pip is easy to install, its a single line of bash

packages can be scoped, it is unfortunate its global by default (but you know, config files exist)

> flat

doesn't matter since shit isn't versioned in the site packages, which is good, it makes people be considerate as far as depreciation timelines n' shit, which I would not want to give up to just get versioned packages

> lockfile

fully specified requirements.txt?

> local cache

p sure pip has that

> pull from git

can already do that

> with hashes

yep

> define extra stuff for setup.py

pretty sure that can be done too

> support something that will only last 4 more years for brand new software

no.

> speed

99% of it is network IO, pls

> don't overcomplicate it

you want versioned packages, auto-commiting requirements.txt, new backwards incompatible config file, instead of the current executable config file which means you can chose to use pip or not depending on how your deployment system works, etc

but you don't want to over-complicate it.

- - -

Are you sure you meant to submit this to r/python, because it honestly doesn't seem like a great improvement, other than adding versioning to an import system which doesn't support versioning, which sounds more like a pain in the ass than anything (and it would also cause it to be strictly locked to pipyarn, instead of being independent from the package manager, yay)
We need something much closer to cargo than to yarn because we want to package also extensions, and provide .exe|.dmg|deb, handle libs like PyQT, numpy, matplotlib, scikitlearn, etc.


[deleted]
let me know when you find one
I will write one for you for $4,258.73.

The code will be free. The charge is just for the shitpost.
What's wrong with using goGgle?

https://github.com/Worm4047/MovSort
We have lots of resources over at r/learnpython - make sure to check the wiki.
I suggest automate the boring stuff with python. Great book, will keep you interested too. Free online. Al has some other books available too, but imo this was the best one. 
http://tutorialspoint.com/ is my goto website for any language and I've just started out in python myself (coming from Java, Swift, and some C), and I've already created a web crawler from scratch.

They really show you the basics and everything and even some advanced topics are also listed.

Hope it helps!

Here is the direct link to the python page: https://www.tutorialspoint.com//python/index.htm
Try Coursera. Lots of begginer courses
https://www.codecademy.com/learn/python
I've written a [Scrapy tutorial](https://hexfox.com/web-scraping/scrape-your-cinemas-listings-to-get-a-daily-email-of-films-with-a-high-imdb-rating/) here if you'd like to get a start into it. It's a Python framework for web scraping and is the go-to solution when you're not just building one off throw away scraping tasks with requests & beautifulsoup (e.g at a professional job!)

Scrapy handles a lot of the following topics for you, so it's worth reading up on what they and why they are a good idea in the world of web scraping.

* Selector engines (css or xpath) for extraction
* Concurrent HTTP requests
* Throttling HTTP requests
* Respecting robots.txt
* Data exports (saving to database, xml, JSON, etc)
* The list goes on, check the docs!

If you need any extra help or you're stuck understanding something, ping me an email at darian@hexfox.com and I'll sort you out. This goes for anyone reading too :)

Good luck with the job!

1. Make sure you're honest. I got a job where they asked about my weaknesses and I mentioned I had half the required experience but went on to say that my love of code and hobbies outside of work would allow me to be a productive, energetic member of the team. I never regretted taking that job. I learned a ton and it helped me go from being a reporting analyst to a developer, which was really my dream.
2. Pick some scraping tool like PyQuery (easy if you already know JQuery selectors) or Beautiful Soup 4 (more mainstream), and try scraping something simple like a quotes website into a json file of just quotes and then make a simple static html site with Bootstrap with a few nav bar links that are for quotes from different people. The site won't be useful enough to buy a host to put it up somewhere, but it'll give you an idea of how to talk about some basic concepts.
3. Don't worry. If you get the job and you were honest, it's because the boss wanted you on the team. My boss right now sometimes asks for someone with 10 year experience, interviews some kids just out of school, and decides to hire them too while continuing a search for a senior dev. If you waste a little of their time but are polite and friendly, you won't burn any bridges, and an interview without an offer is just free training for a future interview.
[deleted]
Pro-con list of this vs something established like supervisord?
This is an unfortunate time to be named Donald. You have my support until it's all over.
Not sure if this is 100% appropriate for this sub, but I figure people would be interested in this post given Donald's role in Python's packaging ecosystem.
Any guesses as to what kind of salary would he go for? 
It doesn't really seem appropriate; this sub should be all about python development.
Seriously, at that level if you have to ask for someone to contact you and you are not already being recruited... dude, it's over.  Just start sending out resumes on craiglist and mentioning that you are proficient in python or something.

Sad.
You might get more help at /r/learnpython. 
> This online web app is for the modelling of the portion of the electron output factor that is dependent on the shape of the shielding insert mounted within the applicator. This allows modelling insert factors using only the measured factors already available at a centre. Should all outliers be removed from the data set the user might expect as low as 0.5% standard uncertainty for factor prediction with as little as 8 data points.

Ok, anyone care to translate? I got a feeling that this is gibberish.
I will put a shout out for [Click](http://click.pocoo.org/5/why/). If you don't know, Click allows you to define your command line options by using decorators. You write an 'entry' function, and then use decorators to define what options, and arguments are allowed. You have lots of options (including validation hooks and many others) to customize how your command line options work.  Each of your command options and arguments are simply passed to your main function as arguments - meaning that you can get on with just writing functionality rather than writing code to handle the command line.

It also has support for sub commands.
In your `setup.py` file for installation, you can specify `entry_points`, which allow you to run a command. [More info](https://chriswarrick.com/blog/2014/09/15/python-apps-the-right-way-entry_points-and-scripts/).

[DocOpt](https://github.com/docopt/docopt) is also a useful tool for creating command line interfaces.

I gave a talk on this at PyGotham, but it seems the video hasn't been uploaded yet. [Slides are here](http://slides.skien.cc/BuildingCommandLineToolswithPython-pygotham2016.pdf), but the video has a lot more context.
You want `struct.pack`, not just `struct`. `struct` is the module, and `struct.pack` is the function in it.

P.S. Please post questions in /r/learnpython next time.
Not to my knowledge, I believe Windows passes it as a regular mouse event. I think all events are regular (meaning there are no special "this is scripted or automated").
sqlite?

Other than fix your code, I'm not sure what else we could offer.
What are you doing with them? I wouldn't expect json files to get corrupted 'often' if you write them correctly. Do you have multiple processes or threads that could be changing them simultaneously?
You have two options

Implement your own database, which is what you started and found out how easy it is to do wrong

Or use someone else's database.

Id suggest #2. Specifically sqlite since it likely fits what you're doing. If you really want to stick with json data stores you could also use postgres which let's you store json directly in a db 
If only Python needs to read it, why not just pickle the data? https://docs.python.org/3/library/pickle.html
If you need a database use a real database. If it has to exist locally why not use sqlite?
If total size is limited and writes are not too frequent there is nothing wrong with using a file.

To avoid corruption make sure you successfully write the entire file and the replace it atomically. Here is a context manager to do this for you. 

http://code.activestate.com/recipes/578166-context-manager-to-atomically-replace-a-file


Maybe [Tinydb](http://tinydb.readthedocs.io/en/latest/)?

I've heard good things in the past.
Sounds like operator error to me honestly.  Want to post some of the code?
If you are dealing with a monolithic json object stored in a single file, you could consider using Pandas and its json i/o. The json io are single functions that take the filename and read or write to it. I expect it will be better tested and more resilient to errors. Pandas also offers a way forward towards other database backends as it is able to interface with many databases. 

Personally, I just use MongoDB for stashing scraped data. There are some downsides if you need to reprocess all the documents in python but it is good if you need random access to subsets and fast document creation. 
The Scrapy package can handle authentication. 
The best way to go about this is to look at the HTTP traffic that occurs when you log in.  If the login page rendering requires Javascript, I believe you will need to use selenium, which allows you to automate the browser activity needed to make it work.  If not, I would suggest using the Python Requests module using sessions and it's authentication features to handle it.  Do you have a link to the login page?  That would be helpful.
Try using the Requests module as others have mentioned. The following code example should get you on the right track. This method worked for me at work when I needed to access some data behind a login. You need to view the source code of the page containing the login form and check what the field names are called, and if there are any hidden fields as well, such as 'op' in this case. You also need to grab the form action's url to use in the session.post call.

    #!/usr/bin/env python

    import requests

    def main():
        payload = {
            'op': 'login-main',
            'user': 'YOUR-USERNAME-HERE',
            'passwd': 'YOUR-PASSWORD-HERE'
        }
        session = requests.session()
        session.post('https://www.reddit.com/post/login', data=payload)
        request = session.get('https://www.reddit.com/r/Python')
        print(request.headers)
        print(request.text)


    if __name__ == '__main__':
        main()

Personally I would use Grab, it's pretty nice for this sort of thing usually:

    from grab import Grab

    g = Grab()
    g.go(your_url)
    g.doc.set_input('user', username)
    g.doc.set_input('pass', password)
    g.submit()
    # you can g.go() to a different url here if needed.
    data_usage = g.doc.select(xpath).text()

You just need to work out the names for the user / pass inputs and the xpaths for the elements you want to extract the data from.

I like xpaths and I find this API style to be pretty congruent with the mental model of how I think about extracting data from a webpage.
Normally this will all happen in just 1 script.py.
Cleanest way would be to use selenium.
Kinda a loaded question. What are you trying to install it on? What are your system specs. What exactly are you looking for? :P 
You'll get a lot more help at /r/learnpython, especially if you say what OS you're on. 
None. Install homebrew and have that install Python for you. 
I'm not familiar with Pony. What's the advantage of using Pony over SQLAlchemy?
This is great but blaze is better IMO. http://blaze.readthedocs.io/en/latest/rosetta-sql.html
This is good news.  The previous license was little restrictive for me.
If you have to write unit tests for your spreadsheet, you probably shouldn't be using a spreadsheet to solve the problem in the first place. You should be using a database and Python or R.

https://web.archive.org/web/20160325131545/http://www.michaelmilton.net/2010/01/26/when-to-use-excel-when-to-use-r

http://fantasyfootballanalytics.net/2014/01/why-r-is-better-than-excel.html

I understand the article used the example of inheriting legacy code, but I just want people to be clear that Excel is not an ideal tool for this kind of situation if one does have a choice. If it's important enough to be unit-tested, it's important enough to be version controlled.
Haha. I think this is great.
I'd prefer rewriting stuff using xlwings, but hey, why not write the tests to work with excel first, and migrate afterwards..?! Cool!
You could do the same thing with VBA.  It is all about having good programming standards.
Neat.

I've done something similar with Python and dSpace.
Use a metasearch engine like searx, that provides a way to get json results ? https://github.com/asciimoo/searx
You might get more help at /r/learnpython.

You're question is a little confusing...it's both too vague and too specific at the same time.

You want to scrape the first page of google results and you know that you don't want a headless browser, API, or third-party service, but you don't know if it's possible and you need someone to tell you how?

    # using curl
    `curl https://www.google.com/#q=INSERT_SEARCH_TERMS_HERE`

    # using python and requests
    import requests
    response = requests.get('https://www.google.com/#q=SEARCH_TERM')

Now if your'e planning on doing some parsing and manipulation with the results I'd look into one of the numerous scraping libraries (`scrapy`, `beautifulsoup`, etc) available. They've been created for this exact use case.
Does this module work on Windows 10 or solely linux/OSX?
I've never used Funcy, but I've used Toolz quite a bit. I like it because it's all iterable, it's fast (cToolz drops in), and each piece is atomic. It also *feels* like native Python. It doesn't feel like I'm borrowing Haskell syntax, which I appreciate.
You might get more help at /r/learnpython. 
What is remi? it's really stupid when people post news about projects and expect people to know what the project is about.
Yes!

I could definitely use some help over at [p2p.today](https://github.com/gappleto97/p2p-project).

It's a peer-to-peer networking library designed to work with multiple languages. A lot of what I need help with is improving efficiency and readability in existing code. I'd be able to help walk you through anything you needed help with.

It would also be a good opportunity to come up with some better developer documentation.
Yes !

- https://github.com/asciimoo/searx/issues/363 searx is a meta search engine, with many features and sources. There are issues, enhancements and feature requests. The code is rather easy to get with. 
- MySearch is a proxy for google searches. https://framagit.org/tuxicoman/mysearch/ Large room for new features.
- Abelujo is a free software for bookshops, the first of the kind. Many stuff still to do, involving backend, frontend and a library with webscraping: https://gitlab.com/vindarel/abelujo and https://gitlab.com/vindarel/bookshops (that's my baby)
- gather multiple free social networks federation api in one package: https://github.com/jaywink/federation
- Mediaglobin, distributed youtube https://issues.mediagoblin.org/
- building end-user tools for zeronet (an easy installer, a desktop icon, the like)
I'm definitely up for some help with BitMon at https://github.com/DonaldKBrown/BitMon. It's a dialog based MMO game. I've gotten a few core components down, but I need a way of keeping track of battles, handling random encounters, etc. I'd gladly reciprocate any help by helping with any projects you might have.
Wait, so the goal was to demonstrate that docker is NOT "just cgroups and chroot", but this script does *only* that?

As far as I can tell, the rest of it is just for pulling prebuilt images and basic setup.
Change shirt slogan to "accept NotImplementedError" and you got yourself a stew goin'
I was at the meetup tonight - great project!
Thank you!
Thanks. The topics covered in the book are really a good selection of advanced topics. As a backer, I'm also looking forward to reading your new "latest" book. https://www.kickstarter.com/projects/34257246/wxpython-cookbook/description)
Thank you! Really! So many books about basic stuff and so few just the next level. 
Thank you thank you! :)
Bought this along with 101 about a month ago on Amazon and have really enjoyed both. Thanks for offering this to others who may not have known about or may not have been able to afford it in the past.
~~Thank you. Can I have your email? So I can send a small paypal donation~~

Edit: Got you a coffee via Leanpub :)
I appreciate your kindness, just got it. 
I get an error with Gumroad when I try to use the offer code **201free**: *âSorry, the offer code you wish to use is invalid.â*
Thanks man!
Thanks!
This should be fun. Thank you sir.
Thank you! And I absolutely love the cover art.
Just downloaded the book, thanks a lot!
Thank you for this! I've been looking into getting back into learning programming after a long hiatus. This will definitely help.
Thanks a lot for this! Contains quite a few topics I've been meaning to familiarize myself with.

Will certainly be on the lookout for upcoming material.
Thank you for this!

To anyone who doesn't know which provider to choose, using LeanPub meant I just had to put in an email address and it didn't even ask for payment information. I couldn't get Gumroad not to ask for payment info.
[deleted]
This looks like a great combination of stuff I already know or partly know and new things. And I love the cover. Thank you for the free book!
Thanks so much! This book looks great. I know Python pretty well, but I never used any kind of tutorial (horrible idea FYI), so there are a few odd gaps in my knowledge. I especially love the fact that you put a section on the `typing` module, since that'll probably be pretty important in the next years of Python.

Also, you had 101 upvotes before I hit it. :D
In "Reentrant Context Managers" section:

>  Letâs use the `redirect_stdout` context manager that we used before!

...the code sample here looks like it is not formatted correctly (PDF, from leanpub).

EDIT: [here's how it looked for me](http://imgur.com/yNil78S).
Thanks! I am not new to programming but I just started Dive into Python this week. Would you recommend I start with 101, or do you think after Dive that 201 would be fine? 
Woow, thanks a lot! I've been looking for a book like this for quite a while! I will definitely read it. Best of lucks!
Top stuff, thanks for this.
Thank you! I will definitely take a look at your book! I have been going through some of these subjects lately - just today I used the importlib module for the 1st time - as I try to do more sophisticated stuff.

Thank you again for the kindness of giving your work for free!
Thank you Driscollis

Very nice of you to offer your hard work up for free to the community

Kudos to you young jedi
Thank you! I was wondering how you decide what is intermediate level? I did about half of Automate the Boring Stuff with Python, currently on hold because I'm taking the edX MITx 6.00.1 course - actually I just saw the description of your 101 book. That's probably more on my level so I'll have to check that out too. 

I'm glad I chose to learn Python; so many great resources!
Very appreciative!
I will read it, need to refresh my Python knowledge anyway, but not with the basics so this comes in handy. Your other books seem very nice. After this one will probably look to buy the other ones. Cheers.
Cheers man. It's awesome that you would do something like this! 
Thank you! I am new to Python but this should be an interesting read!

Will check it out sometime this month. Thank you for your generosity.
There are so few books on Intermediate Programming, so thank you for this.  I'll give it a once over, and if I find it useful, pass the title and author off to the STEM team at my university, which is looking to start a few Python courses.  
Thanks a lot, man. I come from an Asp.net MVC background. Should I start with the 101 book or would I do OK diving directly to this 201 thingy.

Once again, thank you. 
I will pay for a new book after I studied it.
Great work, thank you !
Thanks for the book! So the cover art has a group of my coworkers wondering if there is more to this story? Are the rodents studying pythons, while one of them is being constricted at the front of the class?  :-)
Thanks and thank you for the epub format. Keep up the good work
@driscollis Thank you very much for offering this! I'm a student in computer vision and would expect your book to be useful :)
I don't want to repost this without your permission, but there are plenty of folks over at /r/learnpython that would probably benefit from this as well.
Awesome! Downloaded it now, thanks a million!
Thanks man, just started learning advanced python this semester :)

Also, that coverart is great!
Thank you ever so much for releasing this for free. While I love python, I have to use node.js and some ruby for work... came back to python recently as I missed it. I've been on a bit of a hunt for more advanced reading and your book looks perfect. There are sooooo many resources out there for basic/lower intermediate programmers, but the list of resources for advanced topics is considerably shorter.


That gumroad website is bizarre. Thereâs no desktop version, and itâs meant as a buy and sell hub, but absolutely all verbiage assumes youâre there to sell.
Congrats on finishing the book! Thank you for sharing; will point some other folks to it as well.
This is great, thanks for doing the world a good service!
Thank you also from me. Starting out here, but will soon come in handy. 

(love the mice)
[they made me say that]

Looks like a very comprehensive book, and seems to cover multithreading well. I'm always happy to improve, especially in my favourite language. Thanks for the book, and good luck with your next one! :D
University's been though with Python and encryption. This is absolutely perfect. Godspeed!
thank you sir!
Thank you for the book! 
Thanks for the book!
thanks
I am currently still reading through some beginners material to get a firm base since I am teaching myself, But I appreciate you doing this I now have this up next in the reading list.  Thank you so much!!!
Thank you! Consider posting to /r/FreeEbooks as well.
Thank you!
thanks a lot, friend :)
Thank you! 
Thanks, much appreciated!
Thank you very much!

Thanks!
Thanks!
Thank you!
Thanks! 
Thanks!

Awesome thanks!
Thanks!
Whoa this is a great book! Thanks for sharing it for free (:
Thanks a bunch!
Thank you OP, greatly appreciated.
Thank you kindly!

Thank you very mich. Will definetly read it instantly.
I'm at best a very novice python coder but had to learn a few things for work.

While I don't like the indentation style it does have a certain simplicity to it.

Im going to check this out. Thanks :)
Cheers OP, the topics look great :) 
Thank you!
Thank you!
Thank you!
I am a Python beginner but this might be interesting later on. :)
Thanks, awesome work.

Ever thought about adding it to the Google Play book section ?

Thanks!
Thank you.
Thanks a ton! I have been looking for a book (or tutorial) which could help me for the intermediate level. :)
Awesome, Thanks :)
Thank-you!
Thanks mate, I have a couple guys in my team who will appreciate this.   How come you do this, after the hard work you must have put in?
Thanks! I just bought a copy of Python 101 and I'm going to go through that first!
Thank you! Really appreciated.
Thanks!
Thank you
Thank you! 
Thank you!
Databases, asyncio, and threading? This books sounds like something I desperately needed, just as I'm finishing the MIT intro to CS with Python, and I had no idea. Thanks!
Thanks!
Thank you!
Thank you very much.   I took it for free this time because I am broke at the mo, but I'm going to support you once I'm back on my feet.   

The book looks to be awesome. 
Thank you so much!
Thanks. I took a look over it. Definitely something to recommend further along. 
Thank you from Tunisia!
Thanks many thanks. But i am interested also as to why you are giving it away for free?
Thank you so much! ð
Thank you. It covers a lot of topics which I am interested in.
As a student that has learned a little python on the side, I really appreciate this!
Thanks for this! Got my copy!
Thank you!! it is a great book!
Great job, /u/driscollis :D
Thanks !
I don't think I can never have enough resource to refer to for learning Python at the moment, a million thanks for doing this.

IMHO you're helping shape people's futures (certainly mine) by giving so much work out for free!
Thanks alot. 
Hey thank you so much! I looked through 201's topics, realized I wasn't there yet, and checked out 101 as well. 

There were a lot of things I wasn't familiar with still so I bought 101 to prepare myself first. :) 
Much appreciated
Which site is offering updates to the book?
Thank you! This will be a good avenue for me to start using Python again.
Would love to read this.

But it took 30+ minutes to get a token from leanpub, tried it 8 hours later and it didn't work.  Won't send me one now.   And gumroad just doesn't respond.

No idea what their issues are, but too annoying to keep bothering.
Would be great to get the 101  aswel ;)
thanks!
:)
Thanks!!
Thank you! I've been wondering about itertools for a while now :) !
Thank you sir!
THANK YOU KIND SIR!
Great! Beautiful cover.
Thank you so much sir.
So glad I stumbled across this when I did - thank you so much for giving this away!

(Shoutout to /u/ASIC_SP on /r/learnprogramming as well for linking everyone here)
You're the best. You and /u/AlSweigart both helped me when i started learning with you guys' books. Thank you.
So, I downloaded it because free and started to look. I decided I would see if I can figure out your `argparse` section and I am already seeing where I may become frustrated by this book. It isn't about content, it is presentation.

Two comments.

1\. It is very confusing that *all* code sections have numbers. For example, it makes sense in a **code** listing (e.g. page 5 and 6) but then you use the same thing for example interactions (middle page 7). Later on page 12 your good about using `>>>` which helps a little but for interacting in the shell, page 7 is unclear.

2\. Your coloring is messed up. Look at the colors in the bottom verbatim block of page 7.

    Namespace(x='something', y=False, z=10)

The coloring doesn't end at the end of `'something'` before `y=False`. Also, what is `Namespace`? I am guessing that is how `argparse` shows a `print`   call, but this is also unclear

**Addendum**: I just want to add that I do not mean to crap all over your book. Skimming through the rest of it, I think I may find some of it useful. I just started looking at the DB stuff and that looks good too (though, at the end it sounds like you suggest people use SQLAlchemy but don't teach it...). Anyway, thanks for the book. I will see if I find it useful
Thank you! 
Thank you!
Love you!
Thanks !
Thanks, man!
Thank you! This looks fantastic. :)
Will check it out.
Thanks!
Thank you!
Thank you!
Going to grab this later!
Thanks!
Thanks a lot, mate! Great work!
Thank you for this!
Thank you... I know this thread is full of these but 

This really means a lot to me  ð 
Thank you, this is super!
Thanks! 
Thank you, kindly!! 
Thanks!
Thx!!!
Thank you very much, I will happily check it out.
thank you!
Thank you!
Thanks!
Thanks!
Thank you!
Thanks, awesome!
Thank You!
Thank you!
Thank you so much 
Thank you!!!!! <3<3<3
Thank you!
Thank you
Thank you :)
Thanks mate...thats really cool
thank you! :)
Thank you! :)
Thank you :-)
Thank you, good sir. 
Thank you!
Thank you for your kindness, sir.
Just dropping a line to say thank you!
Thank you!
primo thanks!
Thank you! :)
Thank you!  I've been looking for something just like this!
Thanks!!
Thank you very much!  
Thank you so much!
Thanks so much!
Thanks! The topics look interesting.
wow thank you! 
Thanks!
Excellent, thanks for this! Also purchased your python 101 book, 
Thanks!
Thanks for this! Would definitely come in handy soon!
Awesome, thanks so much! Looks like great content!
Thanks a lot for this!! :) 
Thank you! Should I start with your 101 book if I'm just getting started? And/or use other resources along with the 101? Any recommendations? 
Thanks a lot!
This is fantastic, thank you! 
Can you recommend anywhere I can start for beginners? I'm very intrigued by this book and want a refresher. Thanks and great work! 
Thank you very much! Just downloaded it : )
I really  appreciate it, thank you bro.
Appreciated, as someone who's felt a little failed by Lua,  
I hope your book can put me on the straight and narrow of advancing my Python.
Thank you so much! I am learning python right now, having another resource will be great!
First of all, thanks for writing and sharing your book. I was glad to see the section on async/await so  I jumped straight to that, however there seem to be some mistakes in the examples. Using blocking I/O (eg request.read, time.sleep) in a coroutine defeats the purpose of having an event loop and prevents other asynchronous functions from running concurrently. Instead non-blocking versions of these functions should be used (eg aiohttp.ClientSession, asyncio.sleep), along with the await syntax, to allow control to pass back to the event loop while the I/O is pending.
Thanks! I found a typo... 

At the start of Chapter 22:

* urllib.rebotparser
Thanks!
thank you man
thank you 
thank you, thank you. I am buying you my first ever reddit gold.
Thank you so much. I know what I'm going to be doing this next few weeks
Thank You
Thank you, checking out your blog as well
Dude thank you so much from me and my friends (sorry for sale loss) this sure will come in handy!

Can we know what drove you to give it away for free for these days?
Oh, why do I always miss stuff like this (
How could I had missed this?  ð
Page 92 there is small mistake. You search regex in "text" variable instead of "silly_string".
Free - for $14.99 ?
And since some people like to represent null dates in databases as "0000-00-00 00:00:00", everything exploded !
The Gregorian calendar did not exist back then. Even extending it all the way back to year 1 is really stretching it (this is known as the proleptic Gregorian calendar).

Anyone who handles really ancient dates (astronomy, history) uses specialty libraries. 

I'm not a pro developer so pull requests improving the code/general feeback are welcome
Doesn't `num == 0 or 1` always evaluate to `True` or 1, and is therefore always true?
    from math import sqrt, floor
    
    num = int(input("Enter any number : "))
    
    if num > 1:
        if len([i for i in range(2, floor(sqrt(num))+1) if (num % i == 0)]):
            print('{0} is not a prime number'.format(num))
        else:
            print('{0} is a prime number'.format(num))
    else:
        print('{0} is neither composite nor prime'.format(num))
/r/learnpython
http://www.pythonforbeginners.com/basics/list-comprehensions-in-python <- this should explain comprehensions quite well.
Great case for django. Check the django extensions site for ecommerce.
I generally prefer flask but in that case, django may be a better fit. You choose flask for its flexibility and performance. These things are generally not an issue for an e-commerce website. I would pick flask for more complex/unique applications. 
I recently made a script that takes all my lecture notes and compiles them into a master file then uploads it to googledrive so i can study anytime on any of my devices. Had some fun compiling my notes from some older classes just to watch this baby in action.
Someone a while back did one of these threads, and unfortunately I can't find the link, but they said that they created a script to check their local cinema listings and then email themselves whenever their cinema was showing a film with a decent IMDb rating (that they set the bar for).

It garnerned a lot of interest and comments so I wrote a tutorial on how you would use [Python and Scrapy to automatically check your cinema listings and get notified about those with a high IMDb rating](https://hexfox.com/web-scraping/scrape-your-cinemas-listings-to-get-a-daily-email-of-films-with-a-high-imdb-rating/). Might help some!
I recently finished a total rewrite of a script that I run once a year to compile statistics on Wi-Fi usage at our local libraries. It reads dozens of .csv files as input (from an automated report that runs monthly and emails the report to me) and parses them using Pandas, crunches the data and then creates a pivot table with the results that I want and saves that as an Excel spreadsheet. This year it was 53 .csv files with close to 900,000 lines total parsed down to 13 rows  and 12 columns in the pivot table. Run time less than ten minutes. Good until next year.
Returning HTTP responses to people who make HTTP requests.

It TOTALLY beats running netcat on port 80 and manually typing out responses.
At home - I have a white noise generator for my son in his room (basically a speaker and a raspberry pi) which is controlled by a button on a webpage. It's extremely simple at the moment, but I plan to make it more feature-full (adding other types of white noise, lullabies, maybe control a night light?).

In work - well I use it for everything. I have build and test systems for our main code (in C) written in Python (we have no real need for a CI platform yet, so a simple system in Python is perfect. We also use it to automate all of our hardware testing - controlling instruments, generating reports, etc. Like, literally we use it for everything.
A script that watches a radio station I like and collects all the songs it plays, how many times and the new songs added so I can find new songs, next step is to add auto download with btsync to auto add to my phone and computer.

One that sends me a text when there is a Reddit post that reaches 4k upvotes in under 3 hours, working on migration from 2 to 3 and pep8ing (one of first scripts from 2 years ago).

One that logs into a micro investing site and checks the apy of offers and if ones good enough, right when it comes live it buys it.

One that goes through a huge list of stocks every hour and checks for undervalued high dividend stocks and puts it on my website. 

Future: making a script that logs into meh.com and buys it if it's the mystery box, but having trouble selecting the overlay to put in information.
I wrote myself a script that gets menu info from all pizzerias in selected area, puts them in the database and lets you search through them to get best deals, like least cost per cm^2 including delivery
Obviously... The Boring Stuff
I automate restarting my Flask server with Python. I don't like to run Flask in debug mode, but I also like being able to save a change and have it immediately restart the server to reflect the new changes. So, I whipped up a Python text editor using a tutorial I found a while back. I edit the file with it and save it. It runs it through some tests to make sure it won't get any traceback errors. If all looks good, it stops and restarts the Flask script using subprocess calls. If anything is wrong, it sends me back to the editor after displaying the Traceback and my still working previous version remains running.
The boring stuff.
A script that checks my local online marketplace for price drops every 15 min or so and sends me an email when the price is under the maximum amount I want to pay.


Basically a camelcamelcamel like alert for my local "eBay".
Automatically making invoices from the Purchase Orders my wife gets emailed to her. It scrapes her email and extracts the numbers, puts them in a formatted Excel sheet. She then copies that to Word just to make it pretty and attaches (I could go that step, too, possibly, but it wasn't worth it) . 

I assume most of the other employees have been putting this laborious crap in by hand for years. It takes like 25 min of eye-straining copy/pasting for every time you have to invoice even just $50 worth of invoiced work--every week! My way produces the Excel sheet with one click in 30 seconds.
downloading and resizing images for some of the blog work i do.  here are a couple of my scripts as gists: https://gist.github.com/tomcatfever
Web scraping. Although there are 3rd party APIs for this, sites normally change their code a lot to prevent anyone from pulling this directly. My workaround involved using Python's webbrowser module to fool them into thinking I'm doing this manually.
Hah, I actually *just* whipped up a quick command line tool to easily get SANs off SSL certs: http://btmiller.com/2016/10/17/sanpai-inspect-subject-alternative-names-on-ssl-certificates.html

or just cut to the chase and install it with `pip install sanpai` :)
At work I made a script to filter and trasform a datafile for bulk import into a database. It took 20 lines of Python to replace ~700 lines of C that didn't quite do what was needed.

At home I made a script to monitor my Documents folder for ClickerHeroes save files, and archive them, to take the manual tedium out of that.
Web scraping, bots, AWS scripts for work.
Migrating data from one dB to another. 
Network device configuration backups! I use it to connect to various APIs or CLIs to backup/archive the configurations in our environment. 

Additionally, I'm starting to use it to automate access later networking changes, that way any configurations come from a standardized/preconfigured and pre-approved list.

A really basic script that gets the embedded video from putlocker so I can YouTube-dl or mpv it. First python script and it gets used daily ð
Nothing much, just my job and my house.
Webscraping and notifying me by e-Mail under certain criteria for multiple websites.
Batch processing API calls, aggregating the resulting csv output files, writing additional calculated fields and cleaning up the structure into flat lists for Tableau visualisation.




My test team at work uses python in our system integration tests to control the launching of the multiple software components in our system, feeding test data into the system, and then observing and parsing the results.
I have jobs that use Windows Task Scheduler to run queries against a data warehouse. processes the results (mostly with Pandas), and writes the files to Excel or to CSV files.

I automate inventory entry for eCommerce with it...
My company's network.
We are upgrading to a new version of our business system and I have to make sure our data is copied exactly to the new version. I use Python to list the settings, compare the two systems for differences, and then automatically click through the menus to update the data.
About a year ago I was using AWS ec2 a lot for a project. Since I was on my uni's wifi and was reassigned a new ip every day or so, I needed a way to manage a white list of valid ip addresses. So I used the boto api with my Amazon credentials to check if my current ip was on the white list, and if not to add it. It would then wait a couple of seconds for this to register and then ssh me into my instance. 
Every morning I gather data, creates six graphs, embed them in an outlook email which is sent to the C-level executives...while I get a cup of coffee.  
.  
.  
It's really great to automate the coffee making.
People on here be doing stuff that actually matters...

Meanwhile, I made a script that reads from a csv file filled with show names and days they air and pulls up the correct streaming page for them based on the type of show they are. 

I did this because I'm on the other side of the world and keeping track of what's airing on what day in the US is a pain in the butt. Saves me a decent amount of time everyday because it opens the correct page in batches, rather than having to manually search each show across a couple different sites.

And I use python for automating my lesson plan sorting. I can just produce lessons and materials and it automatically sorts it into the right subdirectories so I can quickly find GAMES or WORKSHEETS or any tag quite simply based on class level.
Related to testing:

* Log backups.
* Log scraping for failure rollups.
* Performance measurement logging.
* CLI / menu testing.
* Web-based automation / regression testing
i have a cript that launches upon completion of a task that launches a 3rd party renaming app. from this it creates a folder structure based on the filename and copies to a NAS. 

at work i created a simple script that joined multiple csv files together. 
My morning web novel and manga scraping.
I was designing the ID cards for an event. There were 190 cards in total. Before printing we had to place 8 cards on an A4 sheet in Photoshop so that 8 cards can be printed at a time. I wrote a script which took individual card, scaled it and placed it on the A4 sheet in order. Needless to say I got a lot of applause from my mates who didn't know programming and were wondering what Voodoo I had just done. :D
I use it to cleanse production data after I've imported it into a dev DB (scrubbing people's names, blanking birthdates, etc.).
I augment our regression manual testing with automated scripts using Skiluli and Jython (I know its not python but its close!). anywhere in our program that does not have keystroke shortcuts or tab order and requires mouse clicks and user interaction, I  use sikuli to perform those tasks as well as assert results or perform negative testing in data fields.

Anywhere that does have keystrokes or keyboard shortcuts, i still use built in python commands which automates faster and more consistent than I can lol.
[Deploying Linux on bare metal hardware](http://www.stacki.com)

Of course, *I* didn't write it all myself, I just work for the company that does. 
[toggle](https://bitbucket.org/sietsebb/dotfiles/src/tip/bin/toggle?at=default&fileviewer=file-view-default): a script that will take a filename and append/remove an underscore. Very nice when you want to briefly disable a settings file, plugin, script, or somesuch. The script checks for both versions of the file, so you can use `toggle .hg/hgrc` to disable your repo's `hgrc`, and then reuse the same command to renable it.

Please disregard the presumably-imperfect use of Result objects, as well as the ToggleFile class which looks stateful but doesn't update itself. I thought I'd play with OO style in this script (functional is my usual thing), so there's a few design decisions that are more experiment than best practice.
Web scraping and autorun things ( with specific rules). But mostly im using it to automate stuff at my work (building reviews , etc)
Please check on r/learnprogramming or if you know python already check [here](http://rosalind.info/problems/locations/)
The sidebar here has a lot of good resources. Also might want to ask on /r/learnpython. 
If you are starting from zero (or don't have a solid base) I recommend Udacity's Intro to Computer Science. After that Udacity's course on Web programming with Steve Huffman (tbh I don't know of this specific one is still online)
Try /r/learnpython.
Write an app or a small command line tool using what your learning. When you do that, you're applying, which automatically helps with retention.  Not to mention it's fun!
What do you mean by "not working"? Also, post questions in /r/learnpython next time.
>The title pretty much explains my predicament 

The title explains your predicament about as well as birds and bees explain procreation.  We get the idea, but the details are a bit fuzzy.
The networked analysis of character relationships was fantastic!
Very good job :) 
Fantastic, thanks for sharing.
This is very interesting! :D
Did you consider the cases when an Aureliano/Jose Arcadio is referred just by the first name?

Also, https://en.wikipedia.org/wiki/Six_degrees_of_separation
Completely intentional. Python functions are just objects, so you doing that is basically equivalent to doing `x = 5` and then `x = 10`. Also, this is a question for /r/learnpython. Also, look into [this chapter](https://automatetheboringstuff.com/chapter18/) of Automate the Boring Stuff (and the entire book, really).
Low quality, spammy, hadn't noticed. We'd be better off without. Well done catching it, any way we can help?
just bunch of ads for their subscription service
Also, techcus.com is one of their domains.

The mods could also let /u/seo_nuke moderate the subreddit with post permissions, it's a manually updated blacklist that automatically detects more possible spam.
- grin and ffind ported to Python 3 with no unicode problems;
- a decent pure Python configuration manager (can save conf on disk, db, inmemory, webservice, etc, can be a microservice or not, live settings with PUB/SUB, hierarchic overriding for any values, namespacing, web conf editor, marshmallow model definition for values...)
- mypy working. Cause right now it sucks.
- a modern asyncio web framework. The current young projects and the old ones are not nearly a competitor for meteorjs.
- a packager for Python that deals with compiled dependancies, and spit out a stand alone msi/dmg/deb.
- crossbar.io sans compiled dependancies.
- a redis clone in pure Python for dev and small prods.
- celery based on WAMP.ws.
- an admin for your Python project including a UI for remote debugging, build tasks, installing packages, output of regular runs of py.test/flake8/mypy, logs, etc.
- a modern CMS in Python. Actually a good CMS in anything. Cause Ghots/WP/django-cms/mezzanine are all demonstrations of the low level of creativity we have in the field. Come on, it's 2017.
- a pure Python implementation of numpy so you can list it as a dependency anywhere even if it's slow.
- a pure Python image manipulator being a wrapper of the OS image manipulation capabilities. You should not have to depend on imagemagick or whatever to make rezise, shrink, convert formats or apply a filter. 
- a ticket manager that is emebded in project, saved in .git, and manage with a webinterface. So you don't need to host it, and  can share updates and comments with git push.
- decent tools for front-end developpers. Ruby dev have css preprocessor, JS minifiers and tasks builder at their fingertips. JS dev are not even in the same league. Designer people avoid Python because of this.
- an implementation of the browsersync server in asyncio, that is compatible with browsersync client.
A better UI framework. Kivy and Qt based are nice, but Kivy isn't native and is a pain to set up on Windows, and neither are native. 

Ideally, I would want 2 things. A binding like libui for mobile platforms, then a python library that allows one to leverage these two libraries along with a xaml like spec so that one can write guis with decent GUIs that are native, fast and still have the ease of writing Python and the conciseness that comes from languages like XAML.

I may be the only one who wants this, but I might try to make it if I find enough free time...
An asynchronous and pythonic sdl2 wrapper. Just for fun.
Facilities for building Python code with C/C++ dependencies with something other than distutils. Ideally, a general purpose build system like Cmake and Meson.
So now you got the list, what's your plan ?
WARNING:  Do not turn this into a drinking game by taking a shot every time they say visual studio. You will die. 
Affiliate spam
What was the problem with the generator? It's shorter and easier to read and no explanation for why it's inferior was given as far as I could see. 

Implementing a stack yourself is a bad idea in my experience. Recursion is fine and if your data structure is nested enough for it not to be you probably need to rethink something. 
This is a cool pattern that I haven't thought of or seen before. I don't know if you're the author of the article; if so, I'd suggest comparing this pattern with the familiar iterative DFS implementation:

    def dfs(root):
        stack = [root]
        while stack:
            node = stack.pop()
            stack.extend(node.children)

From what I can tell, your stack of iterators solution has the advantage of saving memory when the tree is wide, since it essentially stores one iterator per level of the current depth of the search, whereas the above will store many more nodes in the stack. If the tree is very narrow (a chain, for instance), then both approaches can store every node, so in the worst case both approaches take O(n) memory.

The loop-then-immediately-break seems really counter intuitive to me:

    for node in stack[-1]:
        stack.append(iter(children(node)))
        break
    else:
        stack.pop()

and could be replaced with a equivalent and more clear try-except if I'm not mistaken:


    try:
        node = next(stack[-1])
    except StopIteration:
        stack.pop()
    else:
        stack.append(iter(children(node)))
while: interesting, I do feel like I'm missing a conclusion at the return statement of the article.
For your search example you might want to return before you check if it's a dict just in case the first value you get is your match.
Needed that at the exact moment this popped up in my reddit. You are a king!
Do you know if there is a way to find the solutions to the problems posted?

I wanted a way to quickly spin up a custom GraphQL backend on AWS Lambda + DynamoDB. I liked PynamoDB for working with DynamoDB so I integrated it with the popular graphene library. 

With Zappa, loading a flask app to AWS Lambda is very straight forward as well.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:

- [/r/graphql] [X-Post: 10 minutes to a custom GraphQL backend](https://np.reddit.com/r/graphql/comments/582fc4/xpost_10_minutes_to_a_custom_graphql_backend/)

[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*

[](#bot)
IIRC there were some issues with how much bandwidth the RPi can handle either via ethernet or USB (or a combination of the two). At least I think this was the case for the first two versions - perhaps it was addressed in the most recent version of the RPi.

I might be that collecting 1080p video through the USB port is just too taxing on the RPi. This problem had something to do with how the USB/Ethernet chipset and its driver is implemented but I can't remember the specifics.
What did your profiler say?
You'll get a lot more help at /r/learnpython. Writing and reading to a serial port is a lot like a socket on a unix machine. Look at `pyserial`. 
Sounds like you need to install the python-devel package from your OS package manager.

I don't use Fedora but it should be:

`sudo yum install python-devel`
http://www.learncpp.com/

Was in exact situation, this helped immeasurably
Make sure the resources they learn from aren't dated. The language has changed a ton over the years. I first started programming with C++ when I was young, then maybe 15 years later started taking another stab at it (after working as a python dev) and it's way different than I remember. It's practically a managed memory language if you plan to use it that way.
Respect the semicolon.
Was in the same situation, I started reading c++ primer and then accelerated c++. Very well explained concepts in c++ primer ( its long tho, 1k+ pages but worth reading), accelerated c++ was also really good and concise without leaving aside important explanations. From what ive read, books are the best resources to learn c++ with the addition of the actual documentation of course. Hope that helps and good luck! Theres lot to learn and it will be weird at first.
Don't try to bite it all off at once.  Start small and spend the next 10 years figuring out the rest.
Don't learn "old" Cpp. Start at least with c++14 and look at c++17. You get a lot of features similar to python
My goto procedure when learning a new language is to read one well recommended book on the subject and then just to start on a project. From then on I will google my way through the language problems i get.

I used to read multiple books on new languages, but that didnt help much. When you read, every feature seem equally important, but in fact 20% of the language gives you 80% of the features you actually use. So too much theory is more noise than help.
Get a shrink.
Get a book, a good one has exercises, that's how I made the switch.
Other people have posted some good learning resources, so I'll just give a but of general advice. C++ has a couple of gotchas that you really need to look out for. Things like automatic type coercion (ints acting as bools for instance), undefined behavior (can be very difficult to detect), and default implementations for things like copy constructors can cause really insidious problems. Look up some articles on them so you know what you're facing, and make sure you set up your compiler to give you as many warnings as possible (usually this means using -Wall, - Wpedantic, and possibly - Werror). 
It's getting on a bit now (doesn't cover the latest fancy C++ additions), but I found the Wrox Press C++ Tutorial to be an excellent introduction to the fundamentals of C++.
Just google the books. They are online as pdf's. Reading them and practicing is enough
Have you evaluated other options? Why does he need C++ exactly? Performance? Has he looked at numpy?

I have tried a few different approaches to solve this problem.

SWIG sucks. Forget about SWIG. Weeks of wasted time fricking with macros.

Cython is great and has some C++ support https://github.com/cython/cython/wiki/WrappingCPlusPlus

it'll shit it's pants if C++ throws an uncaught exception though; you can get around this by writing a pure C wrapper that catches exceptions then wrapping that in cython. Extra work though.

Eventually I gave up, threw out my C++ code, and rewrote everything from scratch in C and wrapped it in Cython.

I have heard good things about

http://www.boost.org/doc/libs/develop/libs/python/doc/html/index.html

and

https://github.com/shedskin/shedskin

I would figure out what's the most bleeding edge version of the C++ standard you can support and target that for learning.

*I know OP's question was "How to I learn C++". The reason I responded with a bunch of tools is C++ is such a huge standard that, according Bjarne Stroustrup himself, it's too big for any one person to learn it all. So it makes sense to start with the subset required to use the tools you need, rather than learn a bunch of stuff that won't directly apply.
You can use cython to produce C/C++ extensions using very python-like syntax, though knowing some C (and maybe C++) is helpful.

Honestly, if it's an option, consider starting with C instead of C++. If you want to be any good at C++ you need to learn virtually all of C anyway, and C is a nice, compact language that's pretty easy to get your head around. C++ has lots of advanced features that can make your life easier once you have understood them, but it is not a well-designed language, to put it mildly. I used it for years, and I found myself having to google pretty basic stuff to remind myself how it worked all the time.
I'll reiterate what other commenters said: first and foremost make sure your references and learning materials are at least from 2014, and the more recent, the better. Idiomatic C++ from a decade ago is a completely different beast from C++ now.
Ah, you guys have knocked this out of the park.

Thanks for all the advice and recommendations.

I'm not the person who actually *needs* to learn C++, but now I think I might do it anyway!
Read some tutorials and write some code.  If you know one language, you can learn them all.  You'll be fine.
I come from the old school where you insist that every language other than the one you know is inferior so you refuse to learn anything else on principle, so I can't help.  :-(

I'd probably learn [Haxe](https://haxe.org/) though if there was no way out of the C++ requirement, which transpiles to C++ (and everything else), so the code could be in C++ but the language used could be comprehended my a mortal being. Come to think of it, if you learned Haxe you'd never need to learn another language. It's like the inverse of Python, which can import any language.
Wait, did you accidentally upload your Imgur API credentials to GitHub... If so change the secret key.
I really like your idea, but the article is a bit underwhelming. First you pointed out how you should approach tasks and think algorithmically then pasted a not-so-readable part of your code and finally stated that you used bs4 instead of the youtube API, however the latter is better. Writing articles is hard and takes practice and it will be better eventually :)  
As for your bot: I think you could implement a way to search for cuts in the video or loopable parts and make your gifs according to that.
what makes this a "bot" as compared to just a "script". it only does one thing, right? is there any interaction after the initial start?
Get that CamelCase nonsense out of here, this is Python my friend! âº
Fun times at g0Ggle headquarters I hear then.
https://gist.github.com/omz/9882a00abf59c6009fa4

This gist claims to work with Pythonista, a Python IDE for iOS with a bunch of custom classes for interacting with iOS devices.

Can't confirm it, but maybe it's worth a look.
You'll get a lot more help at /r/learnpython. 
Might also be helpful:
https://www.reddit.com/r/Atom/
Hello,

you are probably IN python , so thats what happens:

    Python 3.5.1 (v3.5.1:37a07cee5969, Dec  6 2015, 01:38:48)       [MSC v.1900 32 bit (Intel)] on win32
    Type "copyright", "credits" or "license()" for more   information.
    >>> pip install python-pptx
    SyntaxError: invalid syntax

but you need to do it from your command line.

    C:\Users\micha>pip install python-pptx
>>> 
I think python is trying to send the whole downloads folder to the trash. try using os.walk() to return the files and folders *inside* downloads and send those to the trash. I've only been using python for a little while now so this might not work but in my head it would be something like 
send2trash.send2trash(os.walk(C:\\Users\\MyUserName\\Downloads))
This might not solve it, but your escaping is wrong in the path you're passing to `send2trash`. You need to double the single backslashes.
From the docs, the usage should look like this:

    from send2trash import send2trash
    send2trash('some_file')

Here 'some_file' is a path to a file. As vctemc recommended, try using os.walk to get a list of files, and iterate through those like this:

    for item in list_of_files_to_delete:
        send2trash(item)

Take care with paths in Windows!
I'm with /u/rcklmbr on this one - for IO-bound tasks like web scraping, processes are the wrong approach.  I wouldn't bother with async in this case though, because `concurrent.futures` has a lovely interface for threads.

For an embarrassingly parallel problem, you should also avoid mucking around with futures directly - just use `executor.map`!  Full example:

    import concurrent.futures
    with concurrent.futures.ThreadPoolExecutor(max_workers=100) as pool:
        results = list(pool.map(parse, URLS))

This has exactly the same effect as the results-creating snippet in the first example, in as many lines of code (including the import statement), and runs almost two orders of magnitude faster.
Good article, but I want to point out that this is actually fairly inefficient for scraping.  You'd want to use ProcessPoolExecutor when you want to spread work to multiple processes, but generally when webscraping, you're not CPU bound.  Using asyncio and aiohttp, and probably a semaphore, would probably be better suited for this.
You can make an object that works a bit like it.

    class Ranger:
        def __getitem__(self, slices):
            first, second, ellip, last = slices
            if ellip is not Ellipsis:
                raise TypeError
            interval = second - first
            return range(first, last + 1, interval)

    r = Ranger()
    r[5, 7, ..., 10]
    # => range(5, 11, 2)

Could be expanded to produce ``itertools.count``, have default parameters and then you could put it on ~~npm~~ pypi. 
Just do range()
It's cool, but it's not super Pythonic, to my eyes.

However, if you turned this into a little library, I have a feeling you'd get quite a few downloads on pypi.
Why don't you like range()?
Meh. 
Perl6 called.  They want their garbage back.
You'll get a lot more help at /r/learnpython. 
You'll have the most flexibility if you consider Cordova instead of either. Kivy locks you into Python. Ionic locks you into Angular.

Cordova lets you choose to work with whatever frontend and backend tech you want and package it as a webview style app. JS->NativeAPI bridges come in the form of plugins.
Kivy is purely Python-based cross-platform app development from the glimpse of its website, while Ionic is more towards HTML5 frontend and Angular framework. 
Shamelessly plugging an alternative: now that there are (beta) wheels of pygame available, it's very easy to create an installer using Pynsist. You can even make a Windows installer from a Linux system.

https://github.com/takluyver/pynsist/tree/master/examples/pygame
beeware has a windows shipping thing too I think. 
That sounds like a homework problem

Check out /r/learnpython
This is REALLY interesting. Also YT has the video speed controls so I can speed up playback. Love this podcast
